<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
<meta name="keywords" content="Gridea静态个人博客">
<meta name="description" content="温故而知新">
<meta name="theme-color" content="#000">
<title>6、事务 | Gridea</title>
<link rel="shortcut icon" href="/favicon.ico?v=1605781569343">
<link rel="stylesheet" href="/media/css/pisces.css">
<link rel="stylesheet" href="/media/fonts/font-awesome.css">
<link
  href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Rosario:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext"
  rel="stylesheet" type="text/css">

<link href="/media/hljs/styles/default.css"
  rel="stylesheet">

<link rel="stylesheet" href="/styles/main.css">

<script src="/media/hljs/highlight.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.ui.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
  integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
  integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>





  <meta name="description" content="6、事务" />
  <meta name="keywords" content="Mysql" />
</head>

<body>
  <div class="head-top-line"></div>
  <div class="header-box">
    
<div class="pisces">
  <header class="header  ">
    <div class="blog-header box-shadow-wrapper bg-color " id="header">
      <div class="nav-toggle" id="nav_toggle">
        <div class="toggle-box">
          <div class="line line-top"></div>
          <div class="line line-center"></div>
          <div class="line line-bottom"></div>
        </div>
      </div>
      <div class="site-meta">       
        <div class="site-title">
          
            <a href="/" class="brand">
              <span>Gridea</span>
            </a>  
          
        </div>
        
          <p class="subtitle">精于心，简于形</p>
        
      </div>
      <nav class="site-nav" id="site_nav">
        <ul id="nav_ul">
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/" target="_self">
                  <i class="fa fa-home"></i> 首页
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/archives/" target="_self">
                  <i class="fa fa-archive"></i> 归档
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/tags/" target="_self">
                  <i class="fa fa-tags"></i> 标签
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/post/about/" target="_self">
                  <i class="fa fa-user"></i> 关于
                </a>
              
            </li>
          
          
            
              <li class="nav-item ">
                <a href="/friends/" target="_self">
                  
                    <i class="fa fa-address-book"></i> 友情链接
                  
                </a>
              </li>
            
          
          
            <li id="fa_search" class="nav-item">
              <a href="javascript:void(0);">
                <i class="fa fa-search"></i> <span class="language" data-lan="search">搜索</span>
              </a>
            </li>
          
        </ul>
      </nav>
    </div>
  </header>
</div>

<script type="text/javascript"> 
 
  let showNav = true;

  let navToggle = document.querySelector('#nav_toggle'),
  siteNav = document.querySelector('#site_nav');
  
  function navClick() {
    let sideBar = document.querySelector('.sidebar');
    let navUl = document.querySelector('#nav_ul');
    navToggle.classList.toggle('nav-toggle-active');
    siteNav.classList.toggle('nav-menu-active');
    if (siteNav.classList.contains('nav-menu-active')) {
      siteNav.style = "height: " + (navUl.children.length * 42) +"px !important";
    } else {
      siteNav.style = "";
    }
  }

  navToggle.addEventListener('click',navClick);  
</script>
  </div>
  <div class="main-continer">
    
    <div
      class="section-layout pisces ">
      <div class="section-layout-wrapper">
        

<div class="sidebar">
  
    <div class="sidebar-box box-shadow-wrapper bg-color right-motion" id="sidebar">
      
      <div class="sidebar-body pisces" id="sidebar_body">
        
          
            <div style="opacity: 1;">
              <div class="toc-box right-motion">
  <div class="toc-wrapper auto-number auto"
    id="toc_wrapper">
    <ul class="markdownIt-TOC">
<li><a href="#1-%E8%AE%A4%E8%AF%86%E4%BA%8B%E5%8A%A1"><strong>1、认识事务</strong></a>
<ul>
<li><a href="#%E5%8E%9F%E5%AD%90%E6%80%A7atomicity">原子性（atomicity)</a></li>
<li><a href="#%E4%B8%80%E8%87%B4%E6%80%A7consistency">一致性（consistency）</a></li>
<li><a href="#%E9%9A%94%E7%A6%BB%E6%80%A7isolation">隔离性（isolation）</a></li>
<li><a href="#%E6%8C%81%E4%B9%85%E6%80%A7durability">持久性（durability）</a></li>
</ul>
</li>
<li><a href="#2-%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%88%86%E7%B1%BB">2、事务的分类</a>
<ul>
<li><a href="#%E6%89%81%E5%B9%B3%E4%BA%8B%E5%8A%A1">扁平事务</a></li>
<li><a href="#%E5%B8%A6%E4%BF%9D%E5%AD%98%E7%82%B9%E7%9A%84%E6%89%81%E5%B9%B3%E4%BA%8B%E5%8A%A1">带保存点的扁平事务</a></li>
<li><a href="#%E9%93%BE%E4%BA%8B%E5%8A%A1">链事务</a></li>
<li><a href="#%E5%B5%8C%E5%A5%97%E4%BA%8B%E5%8A%A1">嵌套事务</a></li>
<li><a href="#%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1distributed-transaction">分布式事务（Distributed Transaction)</a></li>
</ul>
</li>
<li><a href="#3-%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB">3、事务的隔离级别</a>
<ul>
<li><a href="#%E8%AF%BB%E6%9C%AA%E6%8F%90%E4%BA%A4">读未提交</a></li>
<li><a href="#%E8%AF%BB%E5%B7%B2%E6%8F%90%E4%BA%A4"><strong>读已提交</strong></a></li>
<li><a href="#%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB"><strong>可重复读</strong></a>
<ul>
<li><a href="#%E5%A4%9A%E7%89%88%E6%9C%AC%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6">**多版本并发控制 **</a>
<ul>
<li><a href="#%E5%A6%82%E4%BD%95%E7%BB%84%E7%BB%87-undo-log-%E9%93%BE"><strong>如何组织 Undo Log 链</strong></a></li>
<li><a href="#readview">ReadView</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E4%B8%B2%E8%A1%8C%E5%8C%96">串行化</a></li>
</ul>
</li>
<li><a href="#4-%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%AE%9E%E7%8E%B0">4、事务的实现</a>
<ul>
<li><a href="#redo-log"><strong>redo log</strong></a>
<ul>
<li><a href="#%E4%B8%8E%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%97%A5%E5%BF%97%E7%9A%84%E5%8C%BA%E5%88%AB">与二进制日志的区别</a></li>
<li><a href="#log-block">log block</a></li>
<li><a href="#log-group">log group</a></li>
<li><a href="#%E9%87%8D%E5%81%9A%E6%97%A5%E5%BF%97%E6%A0%BC%E5%BC%8F">重做日志格式</a></li>
<li><a href="#lsn">LSN</a></li>
<li><a href="#%E6%81%A2%E5%A4%8D">恢复</a></li>
</ul>
</li>
<li><a href="#undo-log">undo log</a>
<ul>
<li><a href="#%E4%BA%8B%E5%8A%A1%E6%8F%90%E4%BA%A4">事务提交</a></li>
<li><a href="#%E6%B8%85%E7%90%86">清理</a></li>
<li><a href="#history-list">history list</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#5-%E4%BA%8B%E5%8A%A1%E4%BD%BF%E7%94%A8">5、事务使用</a></li>
<li><a href="#6-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1">6、分布式事务</a></li>
</ul>

  </div>
</div>

<script>

  let lastTop = 0, lList = [], hList = [], postBody, lastIndex = -1;
  let active = 'active-show', activeClass = 'active-current';
  let tocWrapper = document.querySelector('#toc_wrapper');
  let tocContent = tocWrapper.children[0];
  let autoNumber = tocWrapper && tocWrapper.classList.contains('auto-number');

  function addTocNumber(elem, deep) {
    if (!elem) {
      return;
    }
    let prop = elem.__proto__;

    if (prop === HTMLUListElement.prototype) {
      for (let i = 0; i < elem.children.length; i++) {
        addTocNumber(elem.children[i], deep + (i + 1) + '.');
      }
    } else if (prop === HTMLLIElement.prototype) {
      // 保存li元素
      if (elem.children[0] && elem.children[0].__proto__ === HTMLAnchorElement.prototype) {
        lList.push(elem);
      }
      for (let i = 0; i < elem.children.length; i++) {
        let cur = elem.children[i];
        if (cur.__proto__ === HTMLAnchorElement.prototype) {
          if (autoNumber) {
            cur.text = deep + ' ' + cur.text;
          }
        } else if (cur.__proto__ === HTMLUListElement.prototype) {
          addTocNumber(cur, deep);
        }
      }
    }
  }

  function removeParentActiveClass() {
    let parents = tocContent.querySelectorAll('.' + active)
    parents.forEach(function (elem) {
      elem.classList.remove(active);
    });
  }

  function addActiveClass(index) {
    if (index >= 0 && index < hList.length) {
      lList[index].classList.add(activeClass);
    }
  }

  function removeActiveClass(index) {
    if (index >= 0 && index < hList.length) {
      lList[index].classList.remove(activeClass);
    }
  }

  function addActiveLiElemment(elem, parent) {
    if (!elem || elem === parent) {
      return;
    } else {
      if (elem.__proto__ === HTMLLIElement.prototype) {
        elem.classList.add(active);
      }
      addActiveLiElemment(elem.parentElement, parent);
    }
  }

  function showToc() {
    if (tocWrapper) {
      postBody = document.querySelector('#post_body');
      for (let i = 0; i < postBody.children.length; i++) {
        if (postBody.children[i].__proto__ === HTMLHeadingElement.prototype) {
          hList.push(postBody.children[i]);
        }
      }
      if (tocWrapper.classList.contains('compress')) {
        tocContent.classList.add('closed');
      } else if (tocWrapper.classList.contains('no_compress')) {
        tocContent.classList.add('expanded');
      } else {
        if (hList.length > 10) {
          active = 'active-hidden'
          tocContent.classList.add('closed');
        } else {
          tocContent.classList.add('expanded');
        }
      }
    }
  }

  (function () {
    // 处理不是从#一级标题开始目录
    if (tocContent.children.length === 1 && tocContent.children[0].__proto__ === HTMLLIElement.prototype) {
      let con = tocContent.children[0].children[0];
      tocContent.innerHTML = con.innerHTML;
    }
    let markdownItTOC = document.querySelector('.markdownIt-TOC');
    let innerHeight = window.innerHeight;
    markdownItTOC.style = `max-height: ${innerHeight - 80 > 0 ? innerHeight - 80 : innerHeight}px`
    addTocNumber(tocContent, '');
  })();

  document.addEventListener('scroll', function (e) {
    if (lList.length <= 0) {
      return;
    }
    let scrollTop = document.scrollingElement.scrollTop + 10;
    let dir;

    if (lastTop - scrollTop > 0) {
      dir = 'up';
    } else {
      dir = 'down';
    }

    lastTop = scrollTop;
    if (scrollTop <= 0) {
      if (lastIndex >= 0 && lastIndex < hList.length) {
        lList[lastIndex].classList.remove(activeClass);
      }
      return;
    }

    let current = 0, hasFind = false;
    for (let i = 0; i < hList.length; i++) {
      if (hList[i].offsetTop > scrollTop) {
        current = i;
        hasFind = true;
        break;
      }
    }
    if (!hasFind && scrollTop > lList[lList.length - 1].offsetTop) {
      current = hList.length - 1;
    } else {
      current--;
    }
    if (dir === 'down') {
      if (current > lastIndex) {
        addActiveClass(current);
        removeActiveClass(lastIndex)
        lastIndex = current;
        removeParentActiveClass();
        lList[current] && addActiveLiElemment(lList[current].parentElement, tocContent);
      }
    } else {
      if (current < lastIndex) {
        addActiveClass(current);
        removeActiveClass(lastIndex);
        lastIndex = current;
        removeParentActiveClass();
        lList[current] && addActiveLiElemment(lList[current].parentElement, tocContent);
      }
    }
  });


  window.addEventListener('load', function () {
    showToc();
    document.querySelector('#sidebar').style = 'display: block;';
    tocWrapper.classList.add('toc-active');
    setTimeout(function () {
      if ("createEvent" in document) {
        let evt = document.createEvent("HTMLEvents");
        evt.initEvent("scroll", false, true);
        document.dispatchEvent(evt);
      }
      else {
        document.fireEvent("scroll");
      }
    }, 500)
  })

</script>
            </div>
          
        
      </div>
    </div>
  
</div>
<script>
  const SIDEBAR_TITLE_ACTIVE = 'sidebar-title-active';
  const SIDEBAR_BODY_ACTIVE = 'sidebar-body-active';
  const SLIDE_UP_IN = 'slide-up-in';

  let sidebar = document.querySelector('#sidebar'),
  tocSideBar = document.querySelector('#tocSideBar'),
  metaSideBar = document.querySelector('#metaSideBar'),
  postToc = document.querySelector('#post_toc'),
  postSiteMeta = document.querySelector('#post_side_meta'),
  sidebarTitle = document.querySelector('.sidebar-title'),
  sidebarBody = document.querySelector('#sidebar_body');

  tocSideBar && tocSideBar.addEventListener('click', (e) => {
    toggleSidebar(e);
  });

  metaSideBar && metaSideBar.addEventListener('click', (e) => {
    toggleSidebar(e);
  });

  function toggleSidebar(e) {
    let currentTitle = document.querySelector("."+SIDEBAR_TITLE_ACTIVE);
    if (currentTitle == e.srcElement) {
      return ;
    }
    let current, showElement, hideElement;
    if (e.srcElement == metaSideBar) {
      showElement = postSiteMeta;
      hideElement = postToc;
    } else if (e.srcElement == tocSideBar){
      showElement = postToc;
      hideElement = postSiteMeta;
    }
    currentTitle.classList.remove(SIDEBAR_TITLE_ACTIVE);
    e.srcElement.classList.add(SIDEBAR_TITLE_ACTIVE);

    window.Velocity(hideElement, 'stop');
    window.Velocity(hideElement, 'transition.slideUpOut', {
      display: 'none',
      duration: 200,
      complete: function () {
        window.Velocity(showElement, 'transition.slideDownIn', {
          duration: 200
        });
      }
    })
    hideElement.classList.remove(SIDEBAR_BODY_ACTIVE);
    showElement.classList.add(SIDEBAR_BODY_ACTIVE);
  }

  postToc && postToc.addEventListener('transitionend', function() {
    this.classList.remove(SLIDE_UP_IN);
  });

  if (sidebarBody) {
    if (sidebarBody.classList.contains('pisces') || sidebarBody.classList.contains('gemini')) {
      let hasFix = false;
      let scrollEl = document.querySelector('.main-continer');
      let limitTop = document.querySelector('#nav_ul').children.length * 42 + 162;
      window.addEventListener('scroll', function(e) {
        if (document.scrollingElement.scrollTop >= limitTop) {
          if (!hasFix) {
            sidebar.classList.add('sidebar-fixed');
            hasFix = true;
          }
        } else {
          if (hasFix) {
            sidebar.classList.remove('sidebar-fixed');
            hasFix = false;
          }
        }
      });
    }
  }
  
</script>
        <div class="section-box box-shadow-wrapper">
          <div class="section bg-color post post-page">
            <section class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://jboone1989.github.io/post/tanscation/">
      6、事务
    </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span class="language" data-lan="publish">发布于</span>
      <span class="publish-time" data-t="2020-11-19 18:06:16">2020-11-19</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-folder-o"></i>
      <span class="pc-show language" data-lan="category-in">分类于</span>
      
      
      <a href="https://jboone1989.github.io/tag/NP2MmsTrY/">
        <span>Mysql</span>
      </a>
      
      
    </span>
    <span class="post-meta-divider">|</span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span>26<span class="language" data-lan="minute">分钟</span></span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span>7179<span class="pc-show language" data-lan="words">字数</span></span>
    </span>
    
  </div>
</section>
            <div class="post-body next-md-body" id="post_body">
              <h1 id="1-认识事务"><strong>1、认识事务</strong></h1>
<p>事务其实就是并发控制的基本单位;</p>
<p>事务可由一条非常简单的SQL语句组成，也可以由一组复杂得SQL组成。事务是访问并更新数据库中各种数据项的一个程序执行单元。在事务中的 操作，要么都做修改，要么都不做，这就是事务的目的。</p>
<h2 id="原子性atomicity">原子性（atomicity)</h2>
<p>指整个数据库事务是不可分割的工作单位。只有使事务中所有的数据库操作都执行成功才算整个事务成功。任何一个SQL 执行失败，已经执行成功的SQL也必须撤销，数据库状态应该退回到执行事务前的状态。</p>
<h2 id="一致性consistency">一致性（consistency）</h2>
<p>数据库总是从一个一致性状态转换到另一个一致状态。就是一组SQL执行之前，数据必须是准确的，执行之后，数据也必须是准确的。</p>
<h2 id="隔离性isolation">隔离性（isolation）</h2>
<p>这个就是说多个事务在跑的时候不能互相干扰，别事务A操作个数据，弄到一半儿还没弄好呢，结果事务B来改了这个数据，导致事务A的操作出错了，那不就搞笑了。</p>
<h2 id="持久性durability">持久性（durability）</h2>
<p>事务一旦提交，其结果就是永久的，无法再回滚。</p>
<h1 id="2-事务的分类">2、事务的分类</h1>
<h2 id="扁平事务">扁平事务</h2>
<figure data-type="image" tabindex="1"><img src="https://upload-images.jianshu.io/upload_images/1293895-622edf781c29f57f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1104/format/webp" alt="img" loading="lazy"></figure>
<p>所有操作都处于同一层次，其由BEGIN WORK开始，由COMMIT WORK或ROLLBACK WORK结束，期间的操作都是原子的。扁平事务是应用程序成为原子操作的基本组成模块。 扁平事务的主要限制是不能提交或回滚事务的某一部分，或者分几个步骤提交。</p>
<h2 id="带保存点的扁平事务">带保存点的扁平事务</h2>
<figure data-type="image" tabindex="2"><img src="https://upload-images.jianshu.io/upload_images/1293895-5028ad0258fa5359.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1018/format/webp" alt="img" loading="lazy"></figure>
<p>某些事务可能在执行过程中出现的错误并<strong>不会导致所有的操作都无效，放弃整个事务不合乎要求</strong>，开销也太大。保存点（<code>savepoint</code>）用来通知 系统记录当前的处理状态。当出现问题时，保存点能用作内部的重启动点，根据应用逻辑，决定是回到最近一个保存点还是其他更早的保存点。</p>
<p>对扁平事务来说，其隐式地设置了一个保存点。然而在整个事务中，只有这一个保存点，回滚只能回滚到事务开始时的状态。保存点用 SAVE WORK函数来建立，通知系统记录当前的处理状态。</p>
<p>保存点在事务内部是递增的，ROLLBACK不影响保存点的计数。</p>
<h2 id="链事务">链事务</h2>
<figure data-type="image" tabindex="3"><img src="https://upload-images.jianshu.io/upload_images/1293895-17257fc0fc5dd905.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1174/format/webp" alt="img" loading="lazy"></figure>
<p>保存点模式的一种变种。带保存点的扁平事务在系统发生崩溃时，所有的保存点都将消失，因为其保存点是易失的（volatile），而非持久的 （persistent)。这就意味着当进行恢复时，事务需要从开始处重新执行，而不能从最近的一个保存点继续执行。</p>
<p>链事务的思想是：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。提交事务操作和开始下 一个事务操作将合并为一个原子操作。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中进行的一样。</p>
<p>与带保存点的扁平事务不同的是，带保存点的事务能回滚到任意正确的保存点。而链事务的回滚<strong>仅限于当前事务</strong>，即只能恢复到最近的一个保存 点。对于锁的处理也不相同，链事务在执行COMMIT后释放了当前事务所持有的锁，而带保存点的扁平事务不影响持有的锁。</p>
<h2 id="嵌套事务">嵌套事务</h2>
<p>由一个顶层事务控制着各个层次的事务。顶层事务之下嵌套的事务被称为子事务（<code>subtransaction</code>）,其控制着每一个局部的变换。</p>
<figure data-type="image" tabindex="4"><img src="https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipbomosdmard.png" alt="img" loading="lazy"></figure>
<p>实际的工作是交由叶子节点来完成的，只有叶子节点的事务才能访问数据。而高层的事务仅负责逻辑控制，决定何时调用相关的子事务。即使一个 系统不支持嵌套事务，用户也可以通过保存点技术来模拟嵌套事务。</p>
<h2 id="分布式事务distributed-transaction">分布式事务（Distributed Transaction)</h2>
<p>是一个在分布式环境下运行的扁平事务，因此需要根据数据所在的位置访问网络中的不同节点。</p>
<h1 id="3-事务的隔离级别">3、事务的隔离级别</h1>
<figure data-type="image" tabindex="5"><img src="https://pic4.zhimg.com/v2-17425f8aaf39eb83a451f9c8a8133427_r.jpg" alt="preview" loading="lazy"></figure>
<h2 id="读未提交">读未提交</h2>
<p>该级别引发的问题是——脏读(Dirty Read)：读取到了未提交的数据</p>
<p>脏页指的是在<strong>缓冲池</strong>中已被修改的页，但是还没有刷新到磁盘，即数据库实例内存中的页和磁盘中的页的数据不一致，当然在刷新到磁盘之前，日志都已被写入到了重做日志文件中。</p>
<p><strong>脏页</strong>并不影响数据的一致性，并且脏页刷新都是异步的，不影响数据库的可用性，因此可以带来性能的提高；</p>
<p><strong>脏数据</strong>是指事务对缓冲池中的<strong>记录的修改，并且还没有被提交</strong>，也就是当前事务可以读到另外事务未提交的数据。</p>
<h2 id="读已提交"><strong>读已提交</strong></h2>
<p>这种隔离级别出现的问题是——不可重复读(<code>Nonrepeatable Read</code>)：不可重复读意味着我们在<strong>同一个事务中</strong>执行完全相同的select语句时可能看到不一样的结果。</p>
<p>就是说事务A在跑的时候， 先查询了一个数据是值1，然后过了段时间，事务B把那个数据给修改了一下还提交了，此时事务A再次查询这个数据就成了值2了，这是读了人家事务提交的数据啊，所以是读已提交。就是所谓的<strong>一个事务内对一个数据两次读</strong>，可能会读到不一样的值。如图：<img src="https://mmbiz.qpic.cn/mmbiz_png/1J6IbIcPCLbraGeVNtE1GticOiaJia71SicHHVrXQKSDaibdc7cR89IxYQEUPBWzPRiatNB2Ry9Pos1ouhPervMzDVoA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img" loading="lazy"></p>
<h2 id="可重复读"><strong>可重复读</strong></h2>
<p>它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。就是说事务A在执行过程中，对某个数据的值，无论读多少次都是值1；哪怕这个过程中事务B修改了数据的值还提交了，但是事务A读到的还是自己事务开始时这个数据的值。如图：</p>
<figure data-type="image" tabindex="6"><img src="https://mmbiz.qpic.cn/mmbiz_png/1J6IbIcPCLbraGeVNtE1GticOiaJia71SicHXIULuYfxYLaulKtU5YK1GCvBD7aSibnqPibYz1ggVYQ2qTtNWPfYmSibA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" alt="img" loading="lazy"></figure>
<p>此级别可能出现的问题——幻读(Phantom Read)：当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行</p>
<p><strong>幻读</strong>：不可重复读和可重复读都是针对两个事务<strong>同时对某条数据在修改</strong>，但是<strong>幻读针对的是插入</strong></p>
<p><code>InnoDB</code>存储引擎通过多版本并发控制(MVCC，<code>Multiversion</code>Concurrency Control)机制解决幻读问题；<code>InnoDB</code>还通过<strong>间隙锁</strong>解决幻读问题。</p>
<h3 id="多版本并发控制">**多版本并发控制 **</h3>
<p>MVCC的实现是通过<strong>保存数据在某一个时间点快照来实现的</strong>。也就是说不管实现时间多长，每个事物看到的数据都是一致的。</p>
<ol>
<li><code>MySQL</code> 中 <code>InnoDB</code> 引擎支持 <code>MVCC</code></li>
<li>应对高并发事务, <code>MVCC</code> 比单纯的加行锁更有效, 开销更小</li>
<li><code>MVCC</code> 在读已提交<code>（Read Committed）</code>和可重复读<code>（Repeatable Read）</code>隔离级别下起作用
<ol>
<li><code>RC</code>、<code>RR</code> 两种隔离级别的事务在执行普通的读操作时，通过访问版本链的方法，使得事务间的读写操作得以并发执行，从而提升系统性能。</li>
<li><code>RC</code>、<code>RR</code> 这两个隔离级别的一个很大不同就是生成 <code>ReadView</code> 的时间点不同，
<ol>
<li><code>RC</code> 在<strong>每一次</strong> <code>SELECT</code> 语句前都会生成一个 <code>ReadView</code>，事务期间会更新，因此在其他事务提交前后所得到的 <code>m_ids</code> 列表<strong>可能发生变化</strong>，使得先前不可见的版本后续又突然可见了。</li>
<li>而 <code>RR</code> 只在事务的<strong>第一个</strong> <code>SELECT</code> 语句时生成一个 <code>ReadView</code>，事务操作期间<strong>不更新</strong>。</li>
</ol>
</li>
</ol>
</li>
<li><code>MVCC</code> 既可以基于<strong>乐观锁</strong>又可以基于<strong>悲观锁</strong>来实现</li>
</ol>
<figure data-type="image" tabindex="7"><img src="https://pic3.zhimg.com/80/v2-e1844f5816a332018183559d1573d80e_hd.jpg" alt="img" loading="lazy"></figure>
<p>在InnoDB中，每一行都有2个隐藏列DATA_TRX_ID和DATA_ROLL_PTR(如果没有定义主键，则还有个隐藏主键列)：</p>
<ol>
<li><code>DATA_TRX_ID</code>：记录最近更新这条行记录的<code>事务 ID</code>，大小为 <code>6</code> 个字节</li>
<li><code>DATA_ROLL_PTR</code>：表示指向该行回滚段<code>（rollback segment）</code>的指针，大小为 <code>7</code> 个字节，<code>InnoDB</code> 便是通过这个指针找到之前版本的数据。该行记录上所有旧版本，在 <code>undo</code> 中都通过链表的形式组织。</li>
</ol>
<h4 id="如何组织-undo-log-链"><strong>如何组织 Undo Log 链</strong></h4>
<p>在多个事务并行操作某行数据的情况下，不同事务对该行数据的 UPDATE 会产生<strong>多个版本</strong>，然后通过回滚指针组织成一条 <code>Undo Log</code> 链。</p>
<p>事务 <code>A</code> 对值 <code>x</code> 进行更新之后，该行即产生一个新版本和旧版本。假设之前插入该行的事务 <code>ID</code> 为 <code>100</code>，事务 <code>A</code> 的 <code>ID</code> 为 <code>200</code>，该行的隐藏主键为 <code>1</code>。</p>
<figure data-type="image" tabindex="8"><img src="https://pic4.zhimg.com/80/v2-759e2202ee64b45fb4bc8cdea640c813_hd.jpg" alt="img" loading="lazy"></figure>
<p>事务 <code>A</code> 的操作过程为：</p>
<ol>
<li>对 <code>DB_ROW_ID = 1</code> 的这行记录加排他锁</li>
<li>把该行原本的值拷贝到 <code>undo log</code> 中，<code>DB_TRX_ID</code> 和 <code>DB_ROLL_PTR</code> 都不动</li>
<li>修改该行的值这时产生一个新版本，更新 <code>DATA_TRX_ID</code> 为修改记录的事务 <code>ID</code>，将 <code>DATA_ROLL_PTR</code> 指向刚刚拷贝到 <code>undo log</code> 链中的旧版本记录，这样就能通过 <code>DB_ROLL_PTR</code> 找到这条记录的历史版本。如果对同一行记录执行连续的 <code>UPDATE</code>，<code>Undo Log</code> 会组成一个链表，遍历这个链表可以看到这条记录的变迁</li>
<li>记录 <code>redo log</code>，包括 <code>undo log</code> 中的修改</li>
</ol>
<p>那么 <code>INSERT</code> 和 <code>DELETE</code> 会怎么做呢？其实相比 <code>UPDATE</code> 这二者很简单，<code>INSERT</code> 会产生一条新纪录，它的 <code>DATA_TRX_ID</code> 为当前插入记录的事务 <code>ID</code>；<code>DELETE</code> 某条记录时可看成是一种特殊的 <code>UPDATE</code>，其实是软删，真正执行删除操作会在 <code>commit</code> 时，<code>DATA_TRX_ID</code> 则记录下删除该记录的事务 <code>ID</code>。</p>
<h4 id="readview">ReadView</h4>
<p><code>ReadView</code> 中是<strong>当前活跃的事务</strong> <code>ID</code> 列表，称之为 <code>m_ids</code>，其中最小值为 <code>up_limit_id</code>，最大值为 <code>low_limit_id</code>，事务 <code>ID</code> 是事务开启时 <code>InnoDB</code> 分配的，其大小决定了事务开启的先后顺序，因此我们可以通过 <code>ID</code> 的大小关系来决定版本记录的可见性。</p>
<ol>
<li>如果被访问版本的 <code>trx_id</code> 小于 <code>m_ids</code> 中的最小值 <code>up_limit_id</code>，说明生成该版本的事务在 <code>ReadView</code> 生成前就已经提交了，所以该版本可以被当前事务访问。</li>
<li>如果被访问版本的 <code>trx_id</code> 大于 <code>m_ids</code> 列表中的最大值 <code>low_limit_id</code>，说明生成该版本的事务在生成 <code>ReadView</code> 后才生成，所以该版本不可以被当前事务访问。需要根据 <code>Undo Log</code> 链找到前一个版本，然后根据该版本的 DB_TRX_ID 重新判断可见性。</li>
<li>如果被访问版本的 <code>trx_id</code> 属性值在 <code>m_ids</code> 列表中最大值和最小值之间（包含），那就需要判断一下 <code>trx_id</code> 的值是不是在 <code>m_ids</code> 列表中。如果在，说明创建 <code>ReadView</code> 时生成该版本所属事务还是活跃的，因此该版本不可以被访问，需要查找 Undo Log 链得到上一个版本，然后根据该版本的 <code>DB_TRX_ID</code> 再从头计算一次可见性；如果不在，说明创建 <code>ReadView</code> 时生成该版本的事务已经被提交，该版本可以被访问。</li>
<li>此时经过一系列判断我们已经得到了这条记录相对 <code>ReadView</code> 来说的可见结果。此时，如果这条记录的 <code>delete_flag</code> 为 <code>true</code>，说明这条记录已被删除，不返回。否则说明此记录可以安全返回给客户端。</li>
</ol>
<blockquote>
<p>​	https://zhuanlan.zhihu.com/p/64576887</p>
</blockquote>
<h2 id="串行化">串行化</h2>
<p>它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之,它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争</p>
<h1 id="4-事务的实现">4、事务的实现</h1>
<p><strong>redo_log 实现持久化和原子性，而undo_log实现一致性</strong>，二种日志均可以视为一种恢复操作，redo_log是恢复<strong>提交事务修改的页操作</strong>，而undo_log是<strong>回滚行记录到特定版本</strong>。二者记录的内容也不同，redo_log是物理日志，记录页的<strong>物理修改操作</strong>，而undo_log是逻辑日志，根据每行记录进行记录。</p>
<h2 id="redo-log"><strong>redo log</strong></h2>
<figure data-type="image" tabindex="9"><img src="https://user-gold-cdn.xitu.io/2019/4/21/16a3e7576b55c19f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1" alt="img" loading="lazy"></figure>
<p>redo日志用来实现事务的持久性，在事务提交后数据没来得及写会磁盘就宕机时，在下次重新启动后能够成功恢复数据（持久性）， 由两部分组成：</p>
<p>一是内存中的重做日志缓冲（redo <code>logbuffer</code>）；</p>
<p>二是重做日志文件（redo log file).</p>
<p>当我们在一个事务中尝试对数据进行修改时，它会先将数据从磁盘读入内存，并更新内存中缓存的数据，然后生成一条重做日志并写入重做日志缓存，当事务真正提交时，MySQL 会将重做日志缓存中的内容刷新到重做日志文件，再将内存中的数据更新到磁盘上，图中的第 4、5 步就是在 事务提交时执行的。</p>
<p>为了确保每次日志都写入重做日志文件，在每次将重做日志缓冲写入重做日志文件后，<code>InnoDB</code>都需要调用一次<code>fsync</code>操作。<code>fsync</code>的效率取决于 磁盘的性能，因此磁盘的性能决定了事务提交的性能，也就是数据的性能。</p>
<p><code>InnoDb</code>允许用户手工设置非持久性的情况发生，以此提高数据的性能。即当事务提交时，日志不写入重做日志文件，而是等一个时间周期后再执行<code>fsync</code>，但是发生宕机时会丢失最后一段时间的事务。</p>
<h3 id="与二进制日志的区别">与二进制日志的区别</h3>
<ul>
<li>
<p>重做日志是<code>InnoDB</code>存储引擎层产生，而二进制日志是在MySQL数据库的上层产生，并且二进制日志不仅仅针对<code>InnoDB</code>存储引擎，MySQL数据库中任何存储引擎对于数据库的编个都会产生二进制日志</p>
</li>
<li>
<p>两种日志记录的内容形式不一样，MySQL数据库上层的二进制日志是一种<strong>逻辑日志</strong>，其记录的是对应的<strong>SQL语句</strong>，而<code>InnoDB</code>存储引擎层面的重做日志是<strong>物理格式日志</strong>，其记录的是<strong>每个页的修改</strong></p>
</li>
<li>
<p>两种日志记录写入磁盘的时间点不同，如图，二进制日志只在<strong>事务提交完成后</strong>进行一次写入，而<code>InnoDB</code>存储引擎的<strong>重做日志在事务进行中不断地被写入</strong>，这表现为日志并不是随事务提交的顺序进行写入的</p>
</li>
</ul>
<figure data-type="image" tabindex="10"><img src="https://images2015.cnblogs.com/blog/754297/201602/754297-20160205112427569-810454883.jpg" alt="img" loading="lazy"></figure>
<ul>
<li>二进制日志近在事务提交时记录，并且对每一个事务，仅包含<strong>对应事务的一个日志</strong>，而对于<code>InnoDB</code>存储引擎的重做日志，由于其记录的是<strong>物理操作日志</strong>，因此每个<strong>事务对应多个日志条目</strong>，并且事务的重做日志是并发的，并非在事务提交时写入，故其在文件中的记录顺序并非是事务的开始顺序。*T1 * T2 *T3表示事务提交时的日志</li>
</ul>
<h3 id="log-block">log block</h3>
<p>在 <code>InnoDB</code>中，重做日志都是以 512 字节的块的形式进行存储的，同时因为块的大小与磁盘扇区大小相同，所以重做日志的写入可以保证原子性，不会由于机器断电导致重做日志仅写入一半并留下脏数据。</p>
<figure data-type="image" tabindex="11"><img src="https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboardfsfacd.png" alt="img" loading="lazy"></figure>
<p>日志块由三部分组成：日志块头（log <code>block</code>header),日志内容（log body),日志块尾（log block <code>tailer</code>)。</p>
<figure data-type="image" tabindex="12"><img src="https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipfsmfskboard.png" alt="img" loading="lazy"></figure>
<p>log buffer是由log block组成，在内部log buffer好似一个数据。</p>
<pre><code>log header:
LOG_BLOCK_HDR_NO用来标记这个数组中的位置，其是递增并循环使用的，占用4个字节，但是由于第一给我用来判断是否是flush bit，所以最大值是2G
LOG_BLOCK_HDR_DATA_LEN表示log block所占用的大小。
LOG_BLOCK_FIRST_REC_GROUP表示log block中第一个日志所在的偏移量。
LOG_BLOCK_CHECKPOINT_NO表示该log  block最后被写入时的检查点第4字节的值。

log tailer:
LOG_BLOCK_TRL_NO:与LOG_BLOCK_HDR_NO的值相同。
</code></pre>
<h3 id="log-group">log group</h3>
<p>log group是一个<strong>逻辑上的概念</strong>，并没有一个实际存储的物理文件来表示log group信息。</p>
<p>InnoDB存储引擎的数据目录下有两个名为ib_logfile0和ib_logfile1的文件，即是重做日志文件（redo log file)，记录了对于InnoDB 存储引擎的事物日志。在日志组中每个重做日志文件的大小一致，并以循环写入的方式运行。先写日志1，再写日志2，然后再写日志1.</p>
<pre><code>innoDB_log_file_size//每个重做日志的大小 
innoDB_log_file_in_group//每个组中重做日志的数量 
innoDB_mirrored_log_groups//日志镜像文件组的数量，默认为1，表示没有镜像 innodb_log_group_home_dir//日志文件组的路径 
</code></pre>
<p>一方面重做日志不能设置得太大，否则恢复时需要很长的时间；</p>
<p>另一方面也不能太小，否则会导致一个事物的日志需要多次切换重做日志文件。 也会频繁地发生async checkpoint，导致性能抖动。</p>
<p>重做日志文件中存储的就是之前在log buffer中保存的log block，也是根据块的方式进行物理存储的管理。，每个块的大小与log block一样，同样为512字节，在<code>InnoDB</code>存储引擎运行过程中，<code>logbuffer</code>根据一定的规则将内存 中的log block 刷新到磁盘：</p>
<ul>
<li>
<p>事务提交时；</p>
</li>
<li>
<p>log buffer中有一半的内存被使用时</p>
</li>
<li>
<p>log checkpoint时</p>
</li>
</ul>
<p>对log block的写入追加在redo log file的最后部分，当一个redo log file被写满时，会写入下一个redo log file，是使用方式是 round-robin.</p>
<p>对redo log file的写入并不是顺序的，因为redo log file除了保存log buffer刷新到磁盘的log block，还保存了一些其他的信息，这些信息一共占用2KB大小，即每个redo log file的前2KB的部分不保存log block信息，对于log group中的<strong>第一个redo log file</strong>,其前2KB的部分保存4个512字节大小的块</p>
<figure data-type="image" tabindex="13"><img src="https://images2015.cnblogs.com/blog/754297/201602/754297-20160205174138835-1834182063.jpg" alt="img" loading="lazy"></figure>
<p>其余的redo log file <strong>仅保留这些空间，不保存上述信息</strong>。后续的写入还要<strong>更新这2k的信息</strong>，这些信息对于<code>InnoDB</code>的恢复操作非常关键，所以对redo log file的写入 并不是完全顺序。</p>
<figure data-type="image" tabindex="14"><img src="https://images2015.cnblogs.com/blog/754297/201602/754297-20160205175120913-1624661049.jpg" alt="img" loading="lazy"></figure>
<p>log filer header后面的部分为<code>InnoDB</code>保存的checkpoint值，其设计是交替写入，这样是为了避免因介质失败而导致无法找到可用的 checkpoint的情况。</p>
<h3 id="重做日志格式">重做日志格式</h3>
<p><code>InnoDB</code>的存储管理是基于页的，故其重做日志格式也是基于页的。</p>
<figure data-type="image" tabindex="15"><img src="https://images2015.cnblogs.com/blog/754297/201602/754297-20160205175450335-1884721475.jpg" alt="img" loading="lazy"></figure>
<p>redo_log_type:重做日志的类型；</p>
<p>space:表空间的ID</p>
<p>page_no:页的偏移量</p>
<p>之后就是redo log body的部分，根据重做日志类型的不对，会有不同的存储内容，例如，对于页上记录的插入和删除操作，分别对应的如图的格式</p>
<figure data-type="image" tabindex="16"><img src="https://images2015.cnblogs.com/blog/754297/201602/754297-20160205175732710-743525968.jpg" alt="img" loading="lazy"></figure>
<h3 id="lsn">LSN</h3>
<p>LSN是Log Sequence Number的缩写，代表的是日志序列号,表示事务写入重做日志字节的总量。占用8字节，单调递增。例如当前重做日志的LSN为1000，有一个事务T1写入了100字节的重做日志，那么LSN久变成1100，若又有事务T2写入200字节的重做日志，那么LSN久变为1300</p>
<p>表示的含义有：</p>
<ul>
<li>
<p>重做日志写入的总量</p>
</li>
<li>
<p>checkpoint的位置</p>
</li>
<li>
<p>页的版本</p>
</li>
</ul>
<p>**LSN不仅记录在重做日志中，还存在每个页中，在每个页的头部，**有一个值FIL_PAGE_LSN，记录了该页的LSN，在页中，LSN表示该页最后刷新时LSN的大小。因为重做日志记录的是每个页的日志，因此页中的LSN可以判断页是否需要进行恢复操作。例如，页P1的LSN诶10000，而数据库启动时，<code>InnoDB</code>检测到写入重做日志中的LSN为13000，并且事务已经提交，那么数据库需要进行恢复操作。将重做日志应用到P1页中，同样的，对于重做日志中LSN小于P1页的LSN，不需要进行重做，因为P1页中的LSN标示已经被刷新到该位置</p>
<h3 id="恢复">恢复</h3>
<p><code>InnoDB</code>存储引擎在启动时<strong>不管上次数据运行是否正常关闭，都会尝试进行恢复操作</strong>，因为重做日志记录的是<strong>物理日志</strong>，因此恢复的速度比逻辑日志，如二进制日志要快的多，于此同时，<code>InnoDB</code>存储引擎自身也对恢复进行了一定程度的优化，如顺序读取及并行应用重做日志，这样可以进一步提高数据库恢复的速度</p>
<p>由于checkpoint表示已经刷新到磁盘页上的LSN，因此在恢复过程中仅需恢复checkpoint开始的日志部分。对于图中的例子，当数据库在checkpoint的LSN为10 000时发生宕机，恢复操作仅恢复LSN 10000~13000范围内的日志</p>
<figure data-type="image" tabindex="17"><img src="https://images2015.cnblogs.com/blog/754297/201602/754297-20160206111237913-1571379281.jpg" alt="img" loading="lazy"></figure>
<p>再来想想，redo log为什么可以实现事务的原子性和持久性。</p>
<ul>
<li><strong>原子性，是redo log记录了事务期间操作的物理日志，事务提交之前，并没有写入磁盘，保存在内存里，如果事务失败，数据库磁盘不会有影响，回滚掉事务内存部分即可</strong>。</li>
<li><strong>持久性，redo log 会在事务提交时将日志存储到磁盘redo log file，保证日志的持久性</strong>。</li>
</ul>
<h2 id="undo-log">undo log</h2>
<p>undo log有两个作用：<strong>提供回滚和多个行版本控制(MVCC)</strong>。</p>
<p>1、想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行回滚，而在 MySQL 中，恢复机制是通过回滚日志（undo log）实现的 ，所有事务进行的修改都会先记录到这个回滚日志中，然后在对数据库中的对应行进行写入。</p>
<p>2、undo log 存在于 undo log segments 中，undo log segments 位在于 rollback segments 中，rollback segment默认值为128个。每个回滚段中有1024个undo log segment。而 rollback segments 则可能存在于系统系统表空间(system tablespace)、临时表空间( temporary tablespace)、撤销表空间(undo tablespaces)中。 具体的分配策略如下：</p>
<p>undo log默认存放在共享表空间中，如果开启了<code>innodb_file_per_table</code>，将放在每个表的.<code>ibd</code>文件中。</p>
<p>3、回滚日志并不能将数据库物理地恢复到执行语句或者事务之前的样子；它是逻辑日志，当回滚日志被使用时，它只会按照日志逻辑地将数据库中的修改撤销掉，可以理解为，我们在事务中使用的每一条 INSERT 都对应了一条 DELETE，每一条 UPDATE 也都对应一条相反的 UPDATE  语句。</p>
<p>4、undo的另一个作用是<code>mvcc</code>。当用户读取一段记录时，若该行记录被其他事务所占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读取。</p>
<p>5、<strong>undo也会产生redo log</strong>，因为undo log也需要持久性的保护。</p>
<hr>
<h3 id="事务提交">事务提交</h3>
<p>当事务提交的时候，<code>innodb</code>不会立即删除undo log，因为后续还可能会用到undo log，如隔离级别为repeatable read时，事务读取的都是开启事务时的最新提交行版本，只要该事务不结束，该行版本就不能删除，即undo log不能删除。</p>
<p>但是在事务提交的时候，会将该事务对应的undo log放入到删除列表中，未来通过purge来删除。并且提交事务时，还会判断undo log分配的页是否可以重用，如果可以重用，则会分配给后面来的事务，避免为每个独立的事务分配独立的undo log页而浪费存储空间和性能。</p>
<p>通过undo log记录delete和update操作的结果发现：(insert操作无需分析，就是插入行而已)</p>
<ul>
<li>delete操作实际上不会直接删除，而是将delete对象打上delete flag，标记为删除，最终的删除操作是purge线程完成的。</li>
<li>update分为两种情况：update的列是否是主键列。
<ul>
<li>如果不是主键列，在undo log中直接反向记录是如何update的。即update是直接进行的。</li>
<li>如果是主键列，update分两部执行：先删除该行，再插入一行目标行。</li>
</ul>
</li>
</ul>
<h3 id="清理">清理</h3>
<p>delete和update 操作可能并不会直接删除原有数据，delete 操作只是将聚集索引列的 delete flag 置为 1 ，记录仍然存在于 B+ 树中， 最终的删除在 purge 线程中完成（这样的设计是因为其它事务可能引用这行，所以不能立刻删除）。</p>
<h3 id="history-list">history list</h3>
<p>history list 根据事务提交的顺序将 undo log 进行链接，先提交的事务总是在 history list 的尾部，同一 undo page 中的 undo log  也总是按照顺序排列的。</p>
<figure data-type="image" tabindex="18"><img src="https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipbomslfdslard.png" alt="img" loading="lazy"></figure>
<p>具体清理过程为 <code>innoDB</code> 会默认从 history list 中找到第一个需要被清理的数据tx1，清理成功之后清理线程会继续在 tx1 所在页中继续查找需要被清理的 __undo log (即 tx3，注意这里并不会从 history list 继续查找tx2)，之后继续向后查找，找到 tx5，此时发现  tx5 被其它事务引用不能清理(<code>trx</code>no 比当前 purge 到的位置更大)，所以再次去 history list 中查找尾部记录，此时为tx2 重复以上步骤</p>
<h1 id="5-事务使用">5、事务使用</h1>
<pre><code>START TRANSACTION | BEGIN [WORK] 
COMMIT [WORK] [AND [NO] CHAIN] [[NO] RELEASE] 
ROLLBACK [WORK] [AND [NO] CHAIN] [[NO] RELEASE] 
SET AUTOCOMMIT = {0 | 1}
</code></pre>
<ul>
<li>START TRANSACTION 或 BEGIN 语句：开始一项新的事务。</li>
<li>COMMIT 和 ROLLBACK：用来提交或者回滚事务。</li>
<li>CHAIN 和 RELEASE 子句：分别用来定义在事务提交或者回滚之后的操作，CHAIN 会立即启动一个新事物，并且和刚才的事务具有相同的隔离级别，RELEASE 则会断开和客户端的连接。</li>
<li>SET AUTOCOMMIT 可以修改当前连接的提交方式， 如果设置了 SET AUTOCOMMIT=0，则设置之后的所有事务都需要通过明确的命令进行提交或者回滚</li>
</ul>
<p><strong>自动提交（<code>autocommit</code>）：</strong><br>
<code>Mysql</code>默认采用自动提交模式，可以通过设置<code>autocommit</code>变量来启用或禁用自动提交模式</p>
<ul>
<li><strong>隐式锁定</strong></li>
</ul>
<p><code>InnoDB</code>在事务执行过程中，使用两阶段锁协议：</p>
<p>随时都可以执行锁定，<code>InnoDB</code>会根据隔离级别在需要的时候自动加锁；</p>
<p>锁只有在执行commit或者rollback的时候才会释放，并且所有的锁都是在<strong>同一时刻</strong>被释放。</p>
<ul>
<li><strong>显式锁定</strong></li>
</ul>
<p><code>InnoDB</code>也支持通过特定的语句进行显示锁定（存储引擎层）：</p>
<pre><code class="language-text">select ... lock in share mode //共享锁 
select ... for update //排他锁 
</code></pre>
<p>MySQL Server层的显示锁定：</p>
<pre><code class="language-text">lock table和unlock table
</code></pre>
<h1 id="6-分布式事务">6、分布式事务</h1>
<p><code>InnoDB</code>提供了对XA事务的支持，并通过XA事务来支持分布式事务的实现。分布式事务是允许多个独立的事务资源（transaction resources） 参与到一个全局的事务中。在使用分布式事务时，<code>InnoDb</code>的事务隔离季节必须设置为SERIALIZABLE。</p>
<p>XA事务允许不同数据库之间的分布式事务。XA事务有一个或多个资源管理、一个事务管理器以及一个应用程序组成。</p>
<p>资源管理器：提供范围事务资源的方法。通常一个数据库就是一个资源管理器；</p>
<p>事务管理器：协调参与全局事务中的各个事务。需要和参与全局事务的所有资源管理器通信。</p>
<p>应用程序：定义事务的边界，指定全局事务中的操作。</p>
<figure data-type="image" tabindex="19"><img src="https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipb223oard.png" alt="img" loading="lazy"></figure>
<p>分布式事务使用两段式提交（two-phase commit)。在第一阶段，所有参与全局事务的节点开始准备（prepare),告诉事务管理器他们准备好 提交了。在第二阶段，事务管理器告诉资源管理器执行ROLLBACK或COMMIT。如果任何一个节点显示不能提交，则所有节点都回滚。</p>

            </div>
            
              <div class="reward-btn">
                <div class="reward-btn-text">赞赏</div>
              </div>
            
            
              <div class="post-footer">
  <ul class="post-copyright">
    <li class="post-copyright-author">
      <strong class="language" data-lan="author">本文作者：</strong>
      Clover-Niu
    </li>
    <li class="post-copyright-link">
      <strong class="language" data-lan="link">本文链接：</strong>
      <a href="https://jboone1989.github.io/post/tanscation/" title="6、事务">https://jboone1989.github.io/post/tanscation/</a>
    </li>
    <li class="post-copyright-license">
      <strong class="language" data-lan="copyright">版权声明： </strong>
      本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！
    </li>
  </ul>
  <div class="tags">
    
      <a href="https://jboone1989.github.io/tag/NP2MmsTrY/"># Mysql</a>
    
  </div>
  <div class="nav">
    <div class="nav-prev">
      
        <i class="fa fa-chevron-left"></i>
        <a class="nav-pc-next" title="2、表" href="https://jboone1989.github.io/post/table/">2、表</a class="nav-pc-next">
        <a class="nav-mobile-prev" title="2、表" href="https://jboone1989.github.io/post/table/">上一篇</a>
      
    </div>
    <div class="nav-next">
      
        <a class="nav-pc-next" title="9、Mysql调优" href="https://jboone1989.github.io/post/tiaoyou/">9、Mysql调优</a>
        <a class="nav-mobile-next" title="9、Mysql调优" href="https://jboone1989.github.io/post/tiaoyou/">下一篇</a>
        <i class="fa fa-chevron-right"></i>
      
    </div>
  </div>
</div>
            
            
  

          </div>
        </div>
      </div>
    </div>
    <div class="footer-box">
  <footer class="footer">
    <div class="copyright">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | © 2019-2020 Theme By <a
        href="https://github.com/hsxyhao/gridea-theme-next" target="_blank">HsxyHao</a>
    </div>
    <div class="poweredby">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a>
    </div>
  </footer>
  
  
  <div class="pisces back-to-top" id="back_to_top">
    <i class="fa fa-arrow-up"></i>
    
    <span class="scrollpercent">
      <span id="back_to_top_text">0</span>%
    </span>
    
  </div>
  
  
  
</div>
<script>

  let sideBarOpen = 'sidebar-open';
  let body = document.body;
  let back2Top = document.querySelector('#back_to_top'),
    back2TopText = document.querySelector('#back_to_top_text'),
    drawerBox = document.querySelector('#drawer_box'),
    rightSideBar = document.querySelector('.sidebar'),
    viewport = document.querySelector('body');

  function scrollAnimation(currentY, targetY) {

    let needScrollTop = targetY - currentY
    let _currentY = currentY
    setTimeout(() => {
      const dist = Math.ceil(needScrollTop / 10)
      _currentY += dist
      window.scrollTo(_currentY, currentY)
      if (needScrollTop > 10 || needScrollTop < -10) {
        scrollAnimation(_currentY, targetY)
      } else {
        window.scrollTo(_currentY, targetY)
      }
    }, 1)
  }

  back2Top.addEventListener("click", function (e) {
    scrollAnimation(document.scrollingElement.scrollTop, 0);
    e.stopPropagation();
    return false;
  });

  window.addEventListener('scroll', function (e) {
    let percent = document.scrollingElement.scrollTop / (document.scrollingElement.scrollHeight - document.scrollingElement.clientHeight) * 100;
    if (percent > 1 && !back2Top.classList.contains('back-top-active')) {
      back2Top.classList.add('back-top-active');
    }
    if (percent == 0) {
      back2Top.classList.remove('back-top-active');
    }
    if (back2TopText) {
      back2TopText.textContent = Math.floor(percent);
    }
  });


  let hasCacu = false;
  window.onresize = function () {
    calcuHeight();
  }

  function calcuHeight() {
    // 动态调整站点概览高度
    if (!hasCacu && back2Top.classList.contains('pisces') || back2Top.classList.contains('gemini')) {
      let sideBar = document.querySelector('.sidebar');
      let navUl = document.querySelector('#site_nav');
      sideBar.style = 'margin-top:' + (navUl.offsetHeight + navUl.offsetTop + 15) + 'px;';
      hasCacu = true;
    }
  }
  calcuHeight();

  let open = false, MOTION_TIME = 300, RIGHT_MOVE_DIS = '320px';

  if (drawerBox) {
    let rightMotions = document.querySelectorAll('.right-motion');
    let right = drawerBox.classList.contains('right');

    let transitionDir = right ? "transition.slideRightIn" : "transition.slideLeftIn";

    let openProp, closeProp;
    if (right) {
      openProp = {
        paddingRight: RIGHT_MOVE_DIS
      };
      closeProp = {
        paddingRight: '0px'
      };
    } else {
      openProp = {
        paddingLeft: RIGHT_MOVE_DIS
      };
      closeProp = {
        paddingLeft: '0px'
      };
    }

    drawerBox.onclick = function () {
      open = !open;
      window.Velocity(rightSideBar, 'stop');
      window.Velocity(viewport, 'stop');
      window.Velocity(rightMotions, 'stop');
      if (open) {
        window.Velocity(rightSideBar, {
          width: RIGHT_MOVE_DIS
        }, {
          duration: MOTION_TIME,
          begin: function () {
            window.Velocity(rightMotions, transitionDir, {});
          }
        })
        window.Velocity(viewport, openProp, {
          duration: MOTION_TIME
        });
      } else {
        window.Velocity(rightSideBar, {
          width: '0px'
        }, {
          duration: MOTION_TIME,
          begin: function () {
            window.Velocity(rightMotions, {
              opacity: 0
            });
          }
        })
        window.Velocity(viewport, closeProp, {
          duration: MOTION_TIME
        });
      }
      for (let i = 0; i < drawerBox.children.length; i++) {
        drawerBox.children[i].classList.toggle('muse-line');
      }
      drawerBox.classList.toggle(sideBarOpen);
    }
  }

  // 链接跳转
  let newWindow = 'false'
  if (newWindow === 'true') {
    let links = document.querySelectorAll('.post-body a')
    links.forEach(item => {
      if (!item.classList.contains('btn')) {
        item.setAttribute("target", "_blank");
      }
    })
  }

  let faSearch = document.querySelector('#fa_search');
  faSearch.addEventListener('click', function () {
    document.querySelector('#search_mask').style = ''
  })

  // 代码高亮
  hljs.initHighlightingOnLoad();
  
  // 离开当前页title变化
  var leaveTitle = "";
  if (leaveTitle) {
    document.addEventListener('visibilitychange', function () {
      if (document.visibilityState == 'hidden') {
        normal_title = document.title;
        document.title = leaveTitle;
      } else {
        document.title = normal_title;
      }
    });
  }

</script>
    <div class="light-box" id="light_box"></div>
<script>
  let imgs = document.querySelectorAll('.post-body img');
  let lightBox = document.querySelector('#light_box');
  lightBox.addEventListener('mousedown', (e) => {
    e.preventDefault()
  })
  lightBox.addEventListener('mousewheel', (e) => {
    e.preventDefault()
  })
  let width = window.innerWidth * 0.8;
  lightBox.onclick = () => {
    let img = lightBox.querySelector('img');
    lightBox.style = '';
    img && img.remove();
  }
  imgs.forEach(item => {
    item.onclick = function (e) {
      let lightImg = document.createElement('img');
      lightImg.src = this.src;
      lightBox.style = `height: 100%; opacity: 1; background-color: rgba(0, 0, 0, 0.5);cursor: zoom-out;`;
      lightImg.style = `width: ${width}px;border-radius: 2px;`;
      lightImg.onclick = function () {
        lightBox.style = '';
        this.remove();
      }
      lightBox.append(lightImg);
    }
  })
</script>
    <div class="reward-mask" style="display: none;">
  <div class="reward-relative">
    <span class="close" aria-hidden="true">x</span>
    <div class="reward-body">
      <h2>感谢您的支持，我会继续努力的!</h2>
      <div class="reward-img-box">
        <div style="position: relative; width: 140px; height: 140px;">
          
          
          
        </div>
      </div>
      <p class="reward-word">扫码打赏，你说多少就多少</p>
      <p class="reward-tip">打开微信扫一扫，即可进行扫码打赏哦</p>
    </div>
    <div class="bottom">
      
      
    </div>
  </div>
</div>
<style>
  .reward-mask {
    position: fixed;
    z-index: 99999;
    top: 0;
    bottom: 0;
    left: 0;
    right: 0;
    background-color: #00000054;
  }

  .reward-relative {
    position: relative;
    width: 480px;
    text-align: center;
    margin: 0 auto;
    border-radius: 5px;
    background-color: #fff;
    top: 50%;
    margin-top: -205px;
  }

  .reward-relative .close {
    position: absolute;
    right: 10px;
    font-weight: normal;
    font-size: 16px;
    color: #929292;
  }

  .reward-body {
    padding: 40px 20px 20px;
  }

  .bottom {
    display: flex;
  }

  .reward-btn {
    text-align: center;
  }

  .reward-btn-text {
    display: inline-block;
    cursor: pointer;
    width: 60px;
    height: 60px;
    line-height: 60px;
    border-radius: 50%;
    background-color: #ff9734;
    color: #FFF;
    margin-top: 20px;
  }

  .pay-text {
    margin-top: 10px;
    padding: 10px;
    flex: 1;
    transition: all .2s linear;
  }

  .pay-text:hover {
    background-color: #a5a5a536;
  }

  .reward-body h2 {
    padding-top: 10px;
    text-align: center;
    color: #a3a3a3;
    font-size: 16px;
    font-weight: normal;
    margin: 0 0 20px;
  }

  .reward-body h2:after,
  .reward-body h2:before {
    font-family: Arial, Helvetica, sans-serif;
    background: 0 0;
    width: 0;
    height: 0;
    font-style: normal;
    color: #eee;
    font-size: 80px;
    position: absolute;
    top: 20px;
  }

  .reward-body h2:before {
    content: '\201c';
    left: 50px;
  }

  .reward-body h2:after {
    content: '\201d';
    right: 80px;
  }

  .reward-img-box {
    display: inline-block;
    padding: 10px;
    border: 6px solid #ea5f00;
    margin: 0 auto;
    border-radius: 3px;
    position: relative;
  }

  .reward-img {
    position: absolute;
    left: 0px;
    top: 0px;
    width: 100%;
    height: 100%;
  }

  @media (max-width: 767px) {
    .reward-relative {
      height: 100%;
      top: 0px;
      margin-top: 0;
      width: auto;
    }

    .reward-relative .bottom {
      flex-direction: column;
    }

    .reward-relative .pay-text {
      width: 80%;
      margin: 5px auto;
      border: 1px solid silver;
      padding: 6px;
      border-radius: 4px;
    }

    .reward-body h2:after {
      right: 40px;
    }

    .reward-body h2:after,
    .reward-body h2:before {
      font-size: 60px;
    }

    .reward-body h2:before {
      left: 20px;
    }
  }
</style>
<script>
  !function () {
    var mask = document.querySelector('.reward-mask');
    let close = document.querySelector('.reward-relative .close');
    let rewardBtn = document.querySelector('.reward-btn');

    let zfb = document.querySelector('#zfb'),
      wx = document.querySelector('#wx'),
      zfbBtn = document.querySelector('#zfbBtn'),
      wxBtn = document.querySelector('#wxBtn');

    if (zfbBtn && wxBtn) {
      zfbBtn.addEventListener('click', () => {
        window.Velocity(zfb, 'transition.slideLeftIn', {
          duration: 400
        });
        window.Velocity(wx, 'transition.slideRightOut', {
          display: 'none',
          duration: 400
        });
      });

      wxBtn.addEventListener('click', () => {
        window.Velocity(wx, 'transition.slideRightIn', {
          duration: 400
        });
        window.Velocity(zfb, 'transition.slideLeftOut', {
          display: 'none',
          duration: 400
        });
      });
    }

    rewardBtn.addEventListener('click', (e) => {
      window.Velocity(mask, 'transition.slideDownIn', {
        duration: 400
      })
    });

    close.addEventListener('click', (e) => {
      e.preventDefault();
      window.Velocity(mask, 'transition.slideUpOut', {
        duration: 400
      })
    })
  }()
</script>

  </div>
</body>

<div class="search-mask" id="search_mask" style="display: none;">
  <div class="search-box">
    <div class="search-title">
      <i class="fa fa-search"></i>
      <div class="input-box">
        <input id="search" type="text" class="language" data-lan="search" placeholder="搜索">
      </div>
      <i id="close" class="fa fa-times-circle"></i>
    </div>
    <div class="stat-box">
      <span id="stat_count">0</span><span class="language" data-lan="stat">条相关条目，使用了</span><span id="stat_times">0</span><span class="language" data-lan="stat-time">毫秒</span>
      <hr>
    </div>
    <div class="result" id="result">
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/fenkufenbiao/"" data-c="
          &lt;p&gt;&lt;strong&gt;（1）为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;分库分表一定是为了支撑高并发、数据量大两个问题的。&lt;/p&gt;
&lt;p&gt;单表数据量太大，会极大影响你的sql执行的性能，到了后面你的sql可能就跑的很慢了。一般来说，单表到几百万的时候，性能就会相对差一些了。&lt;/p&gt;
&lt;p&gt;一个库一般我们经验而言，最多支撑到并发2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒1000左右，不要太大。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（2）用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;比较常见的包括：&lt;code&gt;cobar、TDDL、atlas、sharding-jdbc、mycat&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;cobar&lt;/code&gt;：阿里b2b团队开发和开源的，属于proxy层方案。早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库join和分页等操作。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TDDL：淘宝团队开发的，属于client层方案。不支持join、多表查询等语法，就是基本的crud语法是ok，但是支持读写分离。目前使用的也不多，因为还依赖淘宝的diamond配置管理系统。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;atlas：360开源的，属于proxy层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在5年前了。所以，现在用的公司基本也很少了。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;sharding-jdbc&lt;/code&gt;：当当开源的，属于client层方案。确实之前用的还比较多一些，因为SQL语法支持也比较多，没有太多限制，而且目前推出到了2.0版本，支持分库分表、读写分离、分布式id生成、柔性事务（最大努力送达型事务、TCC事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从2017年一直到现在，是不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也可以选择的方案。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;myca&lt;/code&gt;t：基于&lt;code&gt;cobar&lt;/code&gt;改造的，属于proxy层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;（3）你们具体是如何对数据库如何进行垂直拆分或水平拆分的？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据库分布式核心内容无非就是数据切分（&lt;code&gt;Sharding&lt;/code&gt;），以及切分后对数据的定位、整合。&lt;/p&gt;
&lt;p&gt;数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库操作性能的目的。&lt;/p&gt;
&lt;p&gt;数据切分根据其切分类型，可以分为两种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;垂直（纵向）切分&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;水平（横向）切分&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;垂直纵向切分&#34;&gt;&lt;strong&gt;垂直（纵向）切分&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;垂直分库&#34;&gt;垂直分库&lt;/h3&gt;
&lt;p&gt;垂直分库就是根据业务耦合性，将&lt;strong&gt;关联度低&lt;/strong&gt;的不同表存储在不同的数据库。做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。&lt;/p&gt;
&lt;p&gt;与&amp;quot;微服务治理&amp;quot;的做法相似，每个微服务使用单独的一个数据库，如下图：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218111935341.png&#34; alt=&#34;image-20191218111935341&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;垂直分表&#34;&gt;垂直分表&lt;/h3&gt;
&lt;p&gt;垂直分表是基于数据库中的&amp;quot;列&amp;quot;进行，某个表字段较多，可以新建一张扩展表，将不经常用或字段长度较大的字段拆分出去到扩展表中。&lt;/p&gt;
&lt;p&gt;在字段很多的情况下（例如一个大表有 100 多个字段），通过&amp;quot;大表拆小表&amp;quot;，更便于开发与维护，也能避免跨页问题，&lt;strong&gt;MySQL 底层是通过数据页存储的，一条记录占用空间过大会导致跨页&lt;/strong&gt;，造成额外的性能开销。&lt;/p&gt;
&lt;p&gt;另外数据库以&lt;strong&gt;行为单位将数据加载到内存&lt;/strong&gt;中，这样&lt;strong&gt;表中字段长度较短且访问频率较高&lt;/strong&gt;，内存能加载更多的数据，命中率更高，减少了磁盘 IO，从而提升了数据库性能。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218112044893.png&#34; alt=&#34;image-20191218112044893&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;垂直切分的优点如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;解决业务系统层面的耦合，业务清晰&lt;/li&gt;
&lt;li&gt;与微服务的治理类似，也能对不同业务的数据进行分级管理、维护、监控、扩展等&lt;/li&gt;
&lt;li&gt;高并发场景下，垂直切分一定程度的提升 IO、数据库连接数、单机硬件资源的瓶颈&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;垂直切分的缺点如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;部分表无法 join，只能通过接口聚合方式解决，提升了开发的复杂度&lt;/li&gt;
&lt;li&gt;分布式事务处理复杂&lt;/li&gt;
&lt;li&gt;依然存在单表数据量过大的问题（需要水平切分）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;水平横向切分&#34;&gt;&lt;strong&gt;水平（横向）切分&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;当一个应用难以再细粒度的垂直切分，或切分后数据量行数巨大，存在单库读写、存储性能瓶颈，这时候就需要进行水平切分了。&lt;/p&gt;
&lt;p&gt;水平切分分为库内分表和分库分表，是根据表内数据内在的逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218112329261.png&#34; alt=&#34;image-20191218112329261&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;库内分表只解决了单一表数据量过大的问题，但没有将表分布到不同机器的库上。&lt;/p&gt;
&lt;p&gt;因此对于减轻 MySQL 数据库的压力来说，帮助不是很大，大家还是竞争同一个物理机的 CPU、内存、网络 IO，最好通过&lt;strong&gt;分库分表&lt;/strong&gt;来解决。&lt;/p&gt;
&lt;p&gt;水平切分的优点如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不存在单库数据量过大、高并发的性能瓶颈，提升系统稳定性和负载能力&lt;/li&gt;
&lt;li&gt;应用端改造较小，不需要拆分业务模块&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;水平切分的缺点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;跨分片的事务一致性难以保证&lt;/li&gt;
&lt;li&gt;跨库的 join 关联查询性能较差&lt;/li&gt;
&lt;li&gt;数据多次扩展难度和维护量极大&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;水平切分后同一张表会出现在多个数据库/表中，每个库/表的内容不同。&lt;/p&gt;
&lt;h2 id=&#34;几种典型的数据分片规则&#34;&gt;几种典型的数据分片规则：&lt;/h2&gt;
&lt;h3 id=&#34;1-根据数值范围按照时间区间或-id-区间来切分&#34;&gt;**1、根据数值范围：**按照时间区间或 ID 区间来切分。&lt;/h3&gt;
&lt;p&gt;例如：按日期将不同月甚至是日的数据分散到不同的库中；将 &lt;code&gt;userId&lt;/code&gt;为 1~9999 的记录分到第一个库，10000~20000 的分到第二个库，以此类推。&lt;/p&gt;
&lt;p&gt;某种意义上，某些系统中使用的&amp;quot;冷热数据分离&amp;quot;，将一些使用较少的历史数据迁移到其他库中，业务功能上只提供热点数据的查询，也是类似的实践。&lt;/p&gt;
&lt;p&gt;这样的优点在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单表大小可控&lt;/li&gt;
&lt;li&gt;天然便于水平扩展，后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移&lt;/li&gt;
&lt;li&gt;使用分片字段进行范围查找时，连续分片可快速定位分片进行快速查询，有效避免跨分片查询的问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;缺点在于：&lt;strong&gt;热点数据&lt;/strong&gt;成为性能瓶颈。连续分片可能存在数据热点，例如按时间字段分片，有些分片存储最近时间段内的数据，可能会被频繁的读写，而有些分片存储的历史数据，则很少被查询。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218112728686.png&#34; alt=&#34;image-20191218112728686&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;2-根据数值取模一般采用-hash-取模-mod-的切分方式&#34;&gt;**2、根据数值取模：**一般采用 hash 取模 mod 的切分方式。&lt;/h3&gt;
&lt;p&gt;例如：将 Customer 表根据 &lt;code&gt;cusno&lt;/code&gt;字段切分到 4 个库中，余数为 0 的放到第一个库，余数为 1 的放到第二个库，以此类推。&lt;/p&gt;
&lt;p&gt;这样同一个用户的数据会分散到同一个库中，如果查询条件带有 &lt;code&gt;cusno&lt;/code&gt;字段，则可明确定位到相应库去查询。&lt;/p&gt;
&lt;p&gt;优点：数据分片相对比较均匀，不容易出现热点和并发访问的瓶颈&lt;/p&gt;
&lt;p&gt;缺点如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;后期分片集群扩容时，需要迁移旧的数据（使用一致性 hash 算法能较好的避免这个问题）&lt;/li&gt;
&lt;li&gt;使用分片字段进行&lt;strong&gt;范围查找&lt;/strong&gt;时，需要同时向 4 个库发起查询，再在内存中合并数据，取最小集返回给应用，分库反而成为拖累。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218112906208.png&#34; alt=&#34;image-20191218112906208&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;非-uid的查询方法&#34;&gt;&lt;strong&gt;非 &lt;code&gt;uid&lt;/code&gt;的查询方法&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;水平切分后，对于按 &lt;code&gt;uid&lt;/code&gt;查询的需求能很好的满足，可以直接路由到具体数据库。&lt;/p&gt;
&lt;p&gt;而按非 &lt;code&gt;uid&lt;/code&gt;的查询，例如 login_name，就不知道具体该访问哪个库了，此时需要遍历所有库，性能会降低很多。&lt;/p&gt;
&lt;p&gt;对于用户侧，可以采用&amp;quot;建立非 &lt;code&gt;uid&lt;/code&gt;属性到 &lt;code&gt;uid&lt;/code&gt;的映射关系&amp;quot;的方案；对于运营侧，可以采用&amp;quot;前台与后台分离&amp;quot;的方案。&lt;/p&gt;
&lt;h3 id=&#34;建立非-uid属性到-uid的映射关系&#34;&gt;&lt;strong&gt;建立非 &lt;code&gt;uid&lt;/code&gt;属性到 &lt;code&gt;uid&lt;/code&gt;的映射关系&lt;/strong&gt;&lt;/h3&gt;
&lt;h4 id=&#34;映射关系&#34;&gt;&lt;strong&gt;映射关系&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;例如：login_name 不能直接定位到数据库，可以建立 login_name→&lt;code&gt;uid&lt;/code&gt;的映射关系，用索引表或缓存来存储。&lt;/p&gt;
&lt;p&gt;当访问 login_name 时，先通过映射表查询出 login_name 对应的 &lt;code&gt;uid&lt;/code&gt;，再通过 &lt;code&gt;uid&lt;/code&gt;定位到具体的库。&lt;/p&gt;
&lt;p&gt;映射表只有两列，可以承载很多数据，当数据量过大时，也可以对映射表再做水平切分。&lt;/p&gt;
&lt;p&gt;这类 &lt;code&gt;kv&lt;/code&gt;格式的索引结构，可以很好的使用 cache 来优化查询性能，而且映射关系不会频繁变更，缓存命中率会很高。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/955136-20180807105926589-1001810279.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;基因法&#34;&gt;&lt;strong&gt;基因法&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;分库基因，假如通过 &lt;code&gt;uid&lt;/code&gt;分库，分为 8 个库，采用 &lt;code&gt;uid&lt;/code&gt;%8 的方式进行路由，此时是由 &lt;code&gt;uid&lt;/code&gt;的最后 (2^3=8)3bit 来决定这行 User 数据具体落到哪个库上，那么这 3bit 可以看为分库基因。&lt;/p&gt;
&lt;p&gt;上面的映射关系的方法需要额外存储映射表，按非 &lt;code&gt;uid&lt;/code&gt;字段查询时，还需要多一次数据库或 cache 的访问。&lt;/p&gt;
&lt;p&gt;如果想要消除多余的存储和查询，可以通过 f 函数取 login_name 的基因作为 &lt;code&gt;uid&lt;/code&gt;的分库基因。&lt;/p&gt;
&lt;p&gt;生成 &lt;code&gt;uid&lt;/code&gt;时，参考分布式唯一 ID 生成方案，再加上最后 3 位 bit 值=f(login_name)。&lt;/p&gt;
&lt;p&gt;当查询 login_name 时，只需计算 f(login_name)%8 的值，就可以定位到具体的库。&lt;/p&gt;
&lt;p&gt;不过这样需要提前做好容量规划，预估未来几年的数据量需要分多少库，要预留一定 bit 的分库基因。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/955136-20180807131414339-111952151.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640-1582817190077.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;前台与后台分离&#34;&gt;&lt;strong&gt;前台与后台分离&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;对于用户侧，主要需求是以单行查询为主，需要建立 login_name/phone/email 到 &lt;code&gt;uid&lt;/code&gt;的映射关系，可以解决这些字段的查询问题。&lt;/p&gt;
&lt;p&gt;而对于运营侧，很多批量分页且条件多样的查询，这类查询计算量大，返回数据量大，对数据库的性能消耗较高。&lt;/p&gt;
&lt;p&gt;此时，如果和用户侧共用同一批服务或数据库，可能因为后台的少量请求，占用大量数据库资源，而导致用户侧访问性能降低或超时。&lt;/p&gt;
&lt;p&gt;这类业务最好采用&amp;quot;前台与后台分离&amp;quot;的方案，运营侧后台业务抽取独立的 service 和 DB，解决和前台业务系统的耦合。&lt;/p&gt;
&lt;p&gt;由于运营侧对可用性、一致性的要求不高，可以不访问实时库，而是通过 &lt;code&gt;binlog&lt;/code&gt;异步同步数据到运营库进行访问。&lt;/p&gt;
&lt;p&gt;在数据量很大的情况下，还可以使用 ES 搜索引擎或 Hive 来满足后台复杂的查询方式。&lt;/p&gt;
&lt;h2 id=&#34;分库分表带来的问题&#34;&gt;分库分表带来的问题&lt;/h2&gt;
&lt;p&gt;分库分表能有效的缓解单机和单库带来的性能瓶颈和压力，突破网络 IO、硬件资源、连接数的瓶颈，同时也带来了一些问题。下面将描述这些技术挑战以及对应的解决思路。&lt;/p&gt;
&lt;h3 id=&#34;事务一致性问题&#34;&gt;&lt;strong&gt;事务一致性问题&lt;/strong&gt;&lt;/h3&gt;
&lt;h4 id=&#34;1分布式事务&#34;&gt;&lt;strong&gt;①分布式事务&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;当更新内容同时分布在不同库中，不可避免会带来跨库事务问题。跨分片事务也是分布式事务，没有简单的方案，一般可使用&amp;quot;XA 协议&amp;quot;和&amp;quot;两阶段提交&amp;quot;处理。&lt;/p&gt;
&lt;p&gt;分布式事务能最大限度保证了数据库操作的原子性。但在提交事务时需要&lt;strong&gt;协调多个节点&lt;/strong&gt;，推后了提交事务的时间点，&lt;strong&gt;延长了事务的执行时间&lt;/strong&gt;。导致事务在访问共享资源时发生冲突或死锁的概率增高。&lt;/p&gt;
&lt;p&gt;随着数据库节点的增多，这种趋势会越来越严重，从而成为系统在数据库层面上水平扩展的枷 锁。&lt;/p&gt;
&lt;h4 id=&#34;2最终一致性&#34;&gt;&lt;strong&gt;②最终一致性&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;对于那些性能要求很高，但对一致性要求不高的系统，往往不苛求系统的实时一致性，只要在允许的时间段内达到最终一致性即可，可采用&lt;strong&gt;事务补偿&lt;/strong&gt;的方式。&lt;/p&gt;
&lt;p&gt;与事务在执行中发生错误后立即回滚的方式不同，事务补偿是一种事后检查补救的措施。&lt;/p&gt;
&lt;p&gt;一些常见的实现方法有：对数据进行对账检查，基于日志进行对比，定期同标准数据来源进行同步等等。事务补偿还要结合业务系统来考虑。&lt;/p&gt;
&lt;h3 id=&#34;跨节点关联查询-join-问题&#34;&gt;&lt;strong&gt;跨节点关联查询 join 问题&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;切分之前，系统中很多列表和详情页所需的数据可以通过 &lt;code&gt;sql&lt;/code&gt;join 来完成。&lt;/p&gt;
&lt;p&gt;而切分之后，数据可能分布在不同的节点上，此时 join 带来的问题就比较麻烦了，考虑到性能，尽量避免使用 join 查询。&lt;/p&gt;
&lt;p&gt;解决这个问题的一些方法：&lt;/p&gt;
&lt;h4 id=&#34;1全局表&#34;&gt;&lt;strong&gt;①全局表：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;全局表，也可看做是&amp;quot;数据字典表&amp;quot;，就是系统中所有模块都可能依赖的一些表，为了避免跨库 join 查询，可以将这类表在每个数据库中都保存一份。这些数据通常很少会进行修改，所以也不担心一致性的问题。&lt;/p&gt;
&lt;h4 id=&#34;2字段冗余&#34;&gt;&lt;strong&gt;②字段冗余：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;一种典型的反范式设计，利用空间换时间，为了性能而避免 join 查询。&lt;/p&gt;
&lt;p&gt;例如：订单表保存 &lt;code&gt;userId&lt;/code&gt;时候，也将 &lt;code&gt;userName&lt;/code&gt;冗余保存一份，这样查询订单详情时就不需要再去查询&amp;quot;买家 user 表&amp;quot;了。&lt;/p&gt;
&lt;p&gt;但这种方法适用场景也有限，比较适用于依赖字段比较少的情况。而冗余字段的数据一致性也较难保证，就像上面订单表的例子，买家修改了 &lt;code&gt;userName&lt;/code&gt;后，是否需要在历史订单中同步更新呢？这也要结合实际业务场景进行考虑。&lt;/p&gt;
&lt;h4 id=&#34;3数据组装&#34;&gt;&lt;strong&gt;③数据组装：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;在系统层面，分两次查询，第一次查询的结果集中找出关联数据  id，然后根据 id 发起第二次请求得到关联数据。最后将获得到的数据进行字段拼装。&lt;/p&gt;
&lt;h4 id=&#34;4er-分片&#34;&gt;&lt;strong&gt;④ER 分片：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;关系型数据库中，如果可以先确定表之间的关联关系，并将那些存在关联关系的表记录存放在同一个分片上，那么就能较好的避免跨分片 join 问题。在 1:1 或 1:n 的情况下，通常按照主表的 ID 主键切分。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218113202557.png&#34; alt=&#34;image-20191218113202557&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;这样一来，Data Node1 上面的 order 订单表与 &lt;code&gt;orderdetail&lt;/code&gt;订单详情表就可以通过 &lt;code&gt;orderId&lt;/code&gt;进行局部的关联查询了，Data Node2 上也一样。&lt;/p&gt;
&lt;h3 id=&#34;跨节点分页-排序-函数问题&#34;&gt;&lt;strong&gt;跨节点分页、排序、函数问题&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;跨节点多库进行查询时，会出现 limit 分页、order by 排序等问题。分页需要按照指定字段进行排序，当排序字段就是分片字段时，通过分片规则就比较容易定位到指定的分片；当排序字段非分片字段时，就变得比较复杂了。&lt;/p&gt;
&lt;p&gt;需要先在不同的分片节点中将数据进行排序并返回，然后将不同分片返回的结果集进行汇总和再次排序，最终返回给用户。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218113237804.png&#34; alt=&#34;image-20191218113237804&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;上图中只是取第一页的数据，对性能影响还不是很大。但是如果取得页数很大，情况则变得复杂很多。&lt;/p&gt;
&lt;p&gt;因为各分片节点中的数据可能是随机的，为了排序的准确性，需要将所有节点的前 N 页数据都排序好做合并，最后再进行整体的排序，这样的操作是很耗费 CPU 和内存资源的，所以页数越大，系统的性能也会越差。&lt;/p&gt;
&lt;p&gt;在使用 Max、Min、Sum、Count 之类的函数进行计算的时候，也需要先在每个分片上执行相应的函数，然后将各个分片的结果集进行汇总和再次计算，最终将结果返回。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218113256568.png&#34; alt=&#34;image-20191218113256568&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;全局主键避重问题&#34;&gt;&lt;strong&gt;全局主键避重问题&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;在分库分表环境中，由于表中数据同时存在不同数据库中，主键值平时使用的自增长将无用武之地，某个分区数据库自生成的 ID 无法保证全局唯一。&lt;/p&gt;
&lt;p&gt;因此需要单独设计全局主键，以避免跨库主键重复问题。有一些常见的主键生成策略：&lt;/p&gt;
&lt;h4 id=&#34;1uuid&#34;&gt;&lt;strong&gt;①UUID&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;UUID 标准形式包含 32 个 16 进制数字，分为 5 段，形式为 8-4-4-4-12 的 36 个字符，例如：550e8400-e29b-41d4-a716-446655440000。&lt;/p&gt;
&lt;p&gt;UUID 是主键是最简单的方案，本地生成，性能高，没有网络耗时。但缺点也很明显，由于 UUID 非常长，会占用大量的存储空间。&lt;/p&gt;
&lt;p&gt;另外，作为主键建立索引和基于索引进行查询时都会存在性能问题，在 &lt;code&gt;InnoDB&lt;/code&gt;下，UUID 的无序性会引&lt;strong&gt;起数据位置频繁变动，导致分页&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;2结合数据库维护主键-id-表&#34;&gt;&lt;strong&gt;②结合数据库维护主键 ID 表&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;在数据库中建立 sequence 表：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE TABLE `sequence` (  
  `id` bigint(20) unsigned NOT NULL auto_increment,  
  `stub` char(1) NOT NULL default &#39;&#39;,  
  PRIMARY KEY  (`id`),  
  UNIQUE KEY `stub` (`stub`)  
) ENGINE=MyISAM;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;stub 字段设置为唯一索引，同一 stub 值在 sequence 表中只有一条记录，可以同时为多张表生成全局 ID。&lt;/p&gt;
&lt;p&gt;sequence 表的内容，如下所示：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;+-------------------+------+  
| id                | stub |  
+-------------------+------+  
| 72157623227190423 |    a |  
+-------------------+------+  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用 &lt;code&gt;MyISAM&lt;/code&gt;存储引擎而不是 &lt;code&gt;InnoDB&lt;/code&gt;，以获取更高的性能。&lt;code&gt;MyISAM&lt;/code&gt;使用的是表级别的锁，对表的读写是串行的，所以不用担心在并发时两次读取同一个 ID 值。&lt;/p&gt;
&lt;p&gt;当需要全局唯一的 64 位 ID 时，执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;REPLACE INTO sequence (stub) VALUES (&#39;a&#39;);  
SELECT LAST_INSERT_ID();  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这两条语句是 Connection 级别的，select last_insert_id() 必须与 replace into 在同一数据库连接下才能得到刚刚插入的新 ID。&lt;/p&gt;
&lt;p&gt;使用 replace into 代替 insert into 好处是避免了表行数过大，不需要另外定期清理。&lt;/p&gt;
&lt;p&gt;此方案较为简单，但缺点也明显：存在单点问题，强依赖 DB，当 DB 异常时，整个系统都不可用。&lt;/p&gt;
&lt;p&gt;配置主从可以增加可用性，但当主库挂了，主从切换时，数据一致性在特殊情况下难以保证。另外性能瓶颈限制在单台 MySQL 的读写性能。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;flickr&lt;/code&gt; 团队使用的一种主键生成策略，与上面的 sequence 表方案类似，但更好的解决了单点和性能瓶颈的问题。&lt;/p&gt;
&lt;p&gt;这一方案的整体思想是：建立 2 个以上的全局 ID 生成的服务器，每个服务器上只部署一个数据库，每个库有一张 sequence 表用于记录当前全局 ID。&lt;/p&gt;
&lt;p&gt;表中 ID 增长的步长是库的数量，起始值依次错开，这样能将 ID 的生成散列到各个数据库上。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218113519582.png&#34; alt=&#34;image-20191218113519582&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;由两个数据库服务器生成 ID，设置不同的 auto_increment 值。第一台 sequence 的起始值为 1，每次步长增长 2，另一台的 sequence 起始值为 2，每次步长增长也是 2。&lt;/p&gt;
&lt;p&gt;结果第一台生成的 ID 都是奇数（1, 3, 5, 7 ...），第二台生成的 ID 都是偶数（2, 4, 6, 8 ...）。&lt;/p&gt;
&lt;p&gt;这种方案将生成 ID 的压力均匀分布在两台机器上。同时提供了系统容错，第一台出现了错误，可以自动切换到第二台机器上获取 ID。&lt;/p&gt;
&lt;p&gt;但有以下几个缺点：系统添加机器，水平扩展时较复杂；每次获取 ID 都要读写一次 DB，DB 的压力还是很大，只能靠堆机器来提升性能。&lt;/p&gt;
&lt;p&gt;可以基于 &lt;code&gt;flickr&lt;/code&gt;的方案继续优化，使用批量的方式降低数据库的写压力，每次获取一段区间的 ID 号段，用完之后再去数据库获取，可以大大减轻数据库的压力。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218113540801.png&#34; alt=&#34;image-20191218113540801&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;还是使用两台 DB 保证可用性，数据库中只存储当前的最大 ID。ID 生成服务每次批量拉取 6 个 ID，先将 max_id 修改为 5，当应用访问 ID 生成服务时，就不需要访问数据库，从号段缓存中依次派发 0~5 的 ID。&lt;/p&gt;
&lt;p&gt;当这些 ID 发完后，再将 max_id 修改为 11，下次就能派发 6~11 的 ID。于是，数据库的压力降低为原来的 1/6。&lt;/p&gt;
&lt;h4 id=&#34;3snowflake-分布式自增-id-算法&#34;&gt;&lt;strong&gt;③Snowflake 分布式自增 ID 算法&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Twitter 的 Snowflake 算法解决了分布式系统生成全局 ID 的需求，生成 64 位的 Long 型数字。&lt;/p&gt;
&lt;p&gt;组成部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一位未使用，因为二进制里第一个bit如果是1，那么都是负数，但是我们生成的id都是正数。&lt;/li&gt;
&lt;li&gt;接下来 41 位是毫秒级时间，41 位的长度可以表示 69 年的时间。&lt;/li&gt;
&lt;li&gt;5 位 &lt;code&gt;datacenterId&lt;/code&gt;，5 位 &lt;code&gt;workerId&lt;/code&gt;。10 位的长度最多支持部署 1024 个节点。&lt;/li&gt;
&lt;li&gt;最后 12 位是毫秒内的计数，12 位的计数顺序号支持每个节点每毫秒产生 4096 个 ID 序列。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218113620635.png&#34; alt=&#34;image-20191218113620635&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;**这样的好处是：**毫秒数在高位，生成的 ID 整体上按时间趋势递增；不依赖第三方系统，稳定性和效率较高。&lt;/p&gt;
&lt;p&gt;理论上 QPS 约为 409.6w/s（1000*2^12），并且整个分布式系统内不会产生 ID 碰撞；可根据自身业务灵活分配 bit 位。&lt;/p&gt;
&lt;p&gt;**不足就在于：**强依赖机器时钟，如果时钟回拨，则可能导致生成 ID 重复。&lt;/p&gt;
&lt;p&gt;综上结合数据库和 Snowflake 的唯一 ID 方案，可以参考业界较为成熟的解法：Leaf——美团点评分布式 ID 生成系统，并考虑到了高可用、容灾、分布式下时钟等问题：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://tech.meituan.com/2017/04/21/mt-leaf.html
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;数据迁移-扩容问题&#34;&gt;&lt;strong&gt;数据迁移、扩容问题&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;当业务高速发展，面临性能和存储的瓶颈时，才会考虑分片设计，此时就不可避免的需要考虑历史数据迁移的问题。&lt;/p&gt;
&lt;p&gt;一般做法是先读出历史数据，然后按指定的分片规则再将数据写入到各个分片节点中。&lt;/p&gt;
&lt;p&gt;此外还需要根据当前的数据量和 QPS，以及业务发展的速度，进行容量规划，推算出大概需要多少分片（一般建议单个分片上的单表数据量不超过 1000W）。&lt;/p&gt;
&lt;p&gt;如果采用数值范围分片，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。如果采用的是数值取模分片，则考虑后期的扩容问题就相对比较麻烦。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;水平扩容库（升级从库法）&lt;br&gt;
&lt;img src=&#34;https://images2018.cnblogs.com/blog/955136/201808/955136-20180807222601104-674464032.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;注：扩容是成倍的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;水平扩容表（双写迁移法）&lt;br&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/955136-20180807230203075-707265239.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
第一步：（同步双写）应用配置双写，部署；&lt;br&gt;
第二步：（同步双写）将老库中的老数据复制到新库中；&lt;br&gt;
第三步：（同步双写）以老库为准校对新库中的老数据；&lt;br&gt;
第四步：（同步双写）应用去掉双写，部署；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注：&lt;strong&gt;双写&lt;/strong&gt;是通用方案。&lt;/p&gt;
&lt;h2 id=&#34;什么时候考虑切分&#34;&gt;什么时候考虑切分&lt;/h2&gt;
&lt;p&gt;下面讲述一下什么时候需要考虑做数据切分。&lt;/p&gt;
&lt;h3 id=&#34;1能不切分尽量不要切分&#34;&gt;&lt;strong&gt;①能不切分尽量不要切分&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;并不是所有表都需要进行切分，主要还是看数据的增长速度。切分后会在某种程度上提升业务的复杂度，数据库除了承载数据的存储和查询外，协助业务更好的实现需求也是其重要工作之一。&lt;/p&gt;
&lt;p&gt;不到万不得已不用轻易使用分库分表这个大招，避免&amp;quot;过度设计&amp;quot;和&amp;quot;过早优化&amp;quot;。&lt;/p&gt;
&lt;p&gt;分库分表之前，不要为分而分，先尽力去做力所能及的事情，例如：升级硬件、升级网络、读写分离、索引优化等等。当数据量达到单表的瓶颈时候，再考虑分库分表。&lt;/p&gt;
&lt;h3 id=&#34;2数据量过大正常运维影响业务访问&#34;&gt;&lt;strong&gt;②数据量过大，正常运维影响业务访问&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;这里说的运维指：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对数据库备份，如果单表太大，备份时需要大量的磁盘 IO 和网络 IO。例如 1T 的数据，网络传输占 50MB 时候，需要 20000 秒才能传输完毕，整个过程的风险都是比较高的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对一个很大的表进行 DDL 修改时，MySQL 会锁住全表，这个时间会很长，这段时间业务不能访问此表，影响很大。&lt;/p&gt;
&lt;p&gt;如果使用 pt-online-schema-change，使用过程中会创建触发器和影子表，也需要很长的时间。在此操作过程中，都算为风险时间。将数据表拆分，总量减少，有助于降低这个风险。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;大表会经常访问与更新，就更有可能出现锁等待。将数据切分，用空间换时间，变相降低访问压力。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3随着业务发展需要对某些字段垂直拆分&#34;&gt;&lt;strong&gt;③随着业务发展，需要对某些字段垂直拆分&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;举个例子，假如项目一开始设计的用户表如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;id                   bigint             #用户的ID
name                 varchar            #用户的名字
last_login_time      datetime           #最近登录时间
personal_info        text               #私人信息
.....                                   #其他信息字段
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在项目初始阶段，这种设计是满足简单的业务需求的，也方便快速迭代开发。&lt;/p&gt;
&lt;p&gt;而当业务快速发展时，用户量从 10w 激增到 10 亿，用户非常的活跃，每次登录会更新 last_login_name 字段，使得 user 表被不断 update，压力很大。&lt;/p&gt;
&lt;p&gt;而其他字段：id，name，personal_info 是不变的或很少更新的，此时在业务角度，就要将 last_login_time 拆分出去，新建一个 user_time 表。&lt;/p&gt;
&lt;p&gt;personal_info 属性是更新和查询频率较低的，并且 text 字段占据了太多的空间。这时候，就要对此垂直拆分出 user_&lt;code&gt;ext&lt;/code&gt; 表了。&lt;/p&gt;
&lt;h3 id=&#34;4数据量快速增长&#34;&gt;&lt;strong&gt;④数据量快速增长&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;随着业务的快速发展，单表中的数据量会持续增长，当性能接近瓶颈时，就需要考虑水平切分，做分库分表了。此时一定要选择合适的切分规则，提前预估好数据容量。&lt;/p&gt;
&lt;h3 id=&#34;5安全性和可用性&#34;&gt;&lt;strong&gt;⑤安全性和可用性&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;鸡蛋不要放在一个篮子里。在业务层面上垂直切分，将不相关的业务的数据库分隔，因为每个业务的数据量、访问量都不同，不能因为一个业务把数据库搞挂而牵连到其他业务。&lt;/p&gt;
&lt;p&gt;利用水平切分，当一个数据库出现问题时，不会影响到 100% 的用户，每个库只承担业务的一部分数据，这样整体的可用性就能提高。&lt;/p&gt;
">8、分库分表</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/file/"" data-c="
          &lt;h2 id=&#34;1-参数文件&#34;&gt;&lt;strong&gt;1、参数文件&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Mysql实例启动时，数据库会先去读一个配置参数文件，若无法找到，则使用编译MySQL时指定的默认值。&lt;/p&gt;
&lt;p&gt;show variables like .....//查看参数 MySQL数据库中的参数可以分为动态参数和静态参数，静态参数是只读的。 set [global|session] system_var_name=expr;&lt;/p&gt;
&lt;p&gt;set [@@global.|@@session.]system_var_name=expr;&lt;/p&gt;
&lt;p&gt;SELECT [@@global.|@@session.]system_var_name;&lt;/p&gt;
&lt;p&gt;global和session表明该参数是基于当前会话还是整个实例的生命周期,对变量的全局值进行修改是在这次的实例生命周期中有效，但MySQL 实例本身并不会对参数文件中的该值进行修改，下次启动还是会读取参数文件的值&lt;/p&gt;
&lt;h2 id=&#34;2-日志文件&#34;&gt;&lt;strong&gt;2、日志文件&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;日志文件包括：错误日志，二进制日志，慢查询日志，查询日志&lt;/p&gt;
&lt;h3 id=&#34;1-错误日志&#34;&gt;1、错误日志&lt;/h3&gt;
&lt;p&gt;对MySQL的启动、运行、关闭过程进行了记录； SHOW variables like &#39;log_error&#39;\G;//定位错误日志文件&lt;/p&gt;
&lt;h3 id=&#34;2-慢查询日志&#34;&gt;2、慢查询日志&lt;/h3&gt;
&lt;p&gt;超过long_query_time设置阈值的sql语句会被记录到慢查询日志文件中,正好等于这个时间的sql不会被记录。 MySQL数据库默认不启动慢查询日志，需要手工将这个参数设为On&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;show variables like &#39;long_query_time&#39;;
show variables like &#39;log_slow_queries&#39;;
如果运行的SQL语句没有使用索引，则也会记录该语句到慢查询日志文件，首先要确认打开：
show variables like &#39;log_queries_not_using_indexes&#39;;
所有的慢查询日志从MySQL5.1开始放入了一张表中，在mysql架构下，名为slow_log.
参数log_output指定了慢查询数据的格式，默认为file，可以将它设为table
show variables like &#39;log_output&#39;;
set global log_output=&#39;table&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;3-查询日志&#34;&gt;3、查询日志&lt;/h3&gt;
&lt;p&gt;查询日志记录了所有对MySQL数据库的请求的信息，无论这些请求是否得到了正确的执行，默认文件名为主机名.log&lt;/p&gt;
&lt;h3 id=&#34;4-二进制日志&#34;&gt;4、二进制日志&lt;/h3&gt;
&lt;p&gt;二进制日志（binary log)记录了对MySQL数据库执行更改的所有操作，但是不包括select和show这类操作。&lt;/p&gt;
&lt;p&gt;binlog 的三种格式对比：&lt;br&gt;
&lt;strong&gt;statement&lt;/strong&gt;：&lt;strong&gt;记录到 binlog 里的是语句原文&lt;/strong&gt;，最后会有 COMMIT；可能会导致主备不一致，因为limit 、等sql 执行时可能主备优化器选择的索引不一样，排序也不一样。now()执行的结果也不一样。&lt;br&gt;
&lt;strong&gt;row&lt;/strong&gt; ：&lt;strong&gt;记录了操作的事件每一条数据的变化情况&lt;/strong&gt;，最后会有一个 XID event。缺点是太占空间。&lt;br&gt;
&lt;strong&gt;mixed&lt;/strong&gt;：同时使用两种格式，由数据库判断具体某条sql使用哪种格式。但是有选择错误的情况。&lt;/p&gt;
&lt;p&gt;redo log 和 binlog 是怎么关联起来的? 它们有一个共同的数据字段，&lt;strong&gt;叫 XID&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;崩溃恢复的时候，会按顺序扫描 redo log：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；&lt;/li&gt;
&lt;li&gt;如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 &lt;strong&gt;XID 去 binlog 找对应的事务&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;处于 prepare 阶段的 redo log 加上完整 binlog，重启也能恢复，因为 binlog 完整了，那么从库就同步过去了，为了保证主从一致，有完整的 binlog 就算成功。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;write 和 fsync 的时机，是由参数 sync_binlog 控制的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；&lt;/li&gt;
&lt;li&gt;sync_binlog=1 的时候，表示每次提交务都会执行 fsync；&lt;/li&gt;
&lt;li&gt;sync_binlog=N(N&amp;gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;比较常见的是将其设置为 100~1000 中的某个数值。对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;3-套接字文件&#34;&gt;&lt;strong&gt;3、套接字文件&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;show variables like &#39;socket&#39;;&lt;/p&gt;
&lt;h2 id=&#34;4-pid文件&#34;&gt;&lt;strong&gt;4、pid文件&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;当MySQL实例启动时，会将自己的进程ID写入一个文件中：主机名.pid show variables like &#39;pid_file&#39;;&lt;/p&gt;
&lt;h2 id=&#34;5-表结构定义文件&#34;&gt;&lt;strong&gt;5、表结构定义文件&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;因为MySQL插件式存储引擎的体系结构关系，数据的存储是跟进表进行的，每个表都有与之对应的文件，但不论表采用任何存储引擎， MySQL都有一个以frm为后缀名的文件，这个文件记录了该表的表结构定义。 frm还用来存放视图的定义。&lt;/p&gt;
&lt;h2 id=&#34;6-innodb存储引擎文件&#34;&gt;&lt;strong&gt;6、InnoDB存储引擎文件&lt;/strong&gt;&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/1571641455(1).png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;表空间文件&#34;&gt;表空间文件&lt;/h3&gt;
&lt;p&gt;InnoDB采用将存储的数据按表空间（tablespace)进行存放的设计。默认的表空间文件是一个初始为10MB的名为ibdata1的文件。 innodb_data_file_path可以设置其路径；&lt;/p&gt;
&lt;p&gt;可以将多个文件组成一个表空间，同时制定文件的属性；&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;innodb_data_file_path=/db/ibdata1:2000M;/dr2/db/ibdata2:2000M:autoextend; 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;若两个文件在不同的磁盘上，磁盘的负载可能被平均，从而提高性能&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;同时两个文件的文件名之后都跟了属性，表示ibdata1的大小为2000MB, ibdata2的大小为2000MB,并且可以自动增长（autoextend);&lt;/p&gt;
&lt;p&gt;表空间默认是共享表空间，如设置了参数innodb_file_per_table,则使用独立表空间，名字为tableName.ibd。单独的表空间仅存储该表的数据、 索引和插入缓冲BITMAP等信息，其余信息还是存放在默认的表空间中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表空间理解&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;表空间是数据库的逻辑划分，一个表空间只能属于一个数据库。&lt;/p&gt;
&lt;p&gt;所有的数据库对象都存放在指定的表空间中。但主要存放的是表， 所以称作表空间 例如：便于理解，把oracle数据库看作一个实在房间，表空间可以看作这个房间的空间，是可以自由分配，在这空间里面可以堆放多个箱子 （箱子可以看作数据库文件），箱子里面再装物件（物件看作表）。用户指定表空间也就是你希望把属于这个用户的表放在那个房间（表空间） 里面。 表空间是一个虚拟的概念可以无限大，但是需要由数据文件作为载体。&lt;/p&gt;
&lt;p&gt;一个数据库可以包含多个表空间，一个表空间只能属于一个数据库&lt;/p&gt;
&lt;p&gt;一个表空间包含多个数据文件，一个数据文件只能属于一个表空间&lt;/p&gt;
&lt;p&gt;一个数据库就是Linux下的一个文件夹，表空间文件就是和数据库同名的的一个文件。&lt;/p&gt;
">3、文件</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/index/"" data-c="
          &lt;p&gt;索引是数据库中非常非常重要的概念，它是存储引擎能够快速定位记录的秘密武器，对于提升数据库的性能、减轻数据库服务器的负担有着非常重要的作用；&lt;strong&gt;索引优化是对查询性能优化的最有效手段&lt;/strong&gt;，它能够轻松地将查询的性能提高几个数量级。&lt;/p&gt;
&lt;h3 id=&#34;一-索引的结构&#34;&gt;一、索引的结构&lt;/h3&gt;
&lt;h4 id=&#34;btree索引&#34;&gt;BTREE索引&lt;/h4&gt;
&lt;p&gt;虽说叫 &lt;code&gt;B-Tree&lt;/code&gt; 索引，甚至显示时也是显示成 &lt;code&gt;BTREE&lt;/code&gt;，但其实内部实现多使用的是其变种 &lt;code&gt;B+ 树&lt;/code&gt;索引，大多数 &lt;code&gt;MySQL&lt;/code&gt; 存储引擎都支持这种索引，包括 &lt;code&gt;InnoDB&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;因此，&lt;code&gt;B+ 树&lt;/code&gt;索引实际上就是我们所说的传统意义上的索引，也是目前关系型数据库中最为常用的、最有效的索引类型。&lt;code&gt;B+ 树&lt;/code&gt;在关系型数据库的索引设计中如此流行主要得益于它的&lt;strong&gt;高扇出性&lt;/strong&gt;，&lt;code&gt;B+ 树&lt;/code&gt;索引的高度一般维持在 &lt;code&gt;2 ~ 4&lt;/code&gt; 层，也就是说查询某一键值的行记录最多只需要 &lt;code&gt;2 ~ 4&lt;/code&gt; 次 &lt;code&gt;IO&lt;/code&gt;，极大减少了磁盘操作的次数。&lt;/p&gt;
&lt;h4 id=&#34;hash索引&#34;&gt;Hash索引&lt;/h4&gt;
&lt;p&gt;基于哈希表实现，只有精确&lt;strong&gt;匹配所有列的查询&lt;/strong&gt;才有效。实现方法为，对于每一行数据，存储引擎都会对&lt;strong&gt;所有的索引列&lt;/strong&gt;计算出一个哈希码，哈希码是一个较小的值，哈希索引将所有行算出的哈希码存储在索引中，并为每一个哈希码维护指向具体某一行的指针。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/c3beb895gy1g1cspwzvu4j20rj0almyd.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;MySQL&lt;/code&gt; 中只有 &lt;code&gt;Memory&lt;/code&gt; 引擎显式支持哈希索引。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt; 支持的哈希索引是自适应的，用户无法进行配置，&lt;code&gt;InnoDB&lt;/code&gt; 引擎会根据表的使用情况自动为表生成哈希索引。使用哈希索引的好处在于时间复杂度为 &lt;code&gt;O(1)&lt;/code&gt;，因此哈希索引的查询效率要远高于 &lt;code&gt;BTree&lt;/code&gt; 索引。但是其限制在于：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;只有精确匹配索引所有列的查询才有效,因为哈希索引是利用索引的所有列的字段值来计算哈希值的。&lt;/li&gt;
&lt;li&gt;只支持等值比较查询，不能用于&lt;strong&gt;范围查询&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;哈希索引的数据并不是顺序存储的，&lt;strong&gt;无法用于排序&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;full-text索引&#34;&gt;Full-Text索引&lt;/h4&gt;
&lt;p&gt;全文索引是一种特殊的索引类型，它查找的是文本中的关键词，而不是直接比较索引中的值。它更类似于搜索引擎做的事情，而不是简单的 &lt;code&gt;WHERE&lt;/code&gt; 条件匹配。实现方法是通过建立倒排索引，快速匹配文档，这种实现方式也在 &lt;code&gt;Apache Lucene&lt;/code&gt; 这种全文检索库中出现。&lt;/p&gt;
&lt;h4 id=&#34;空间数据索引&#34;&gt;空间数据索引&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;MyISAM&lt;/code&gt; 存储引擎支持空间索引，可以用作地理数据存储。&lt;/p&gt;
&lt;h3 id=&#34;二-索引的数据结构&#34;&gt;二、索引的数据结构&lt;/h3&gt;
&lt;p&gt;InnoDB 存储引擎在绝大多数情况下使用 B+ 树建立索引，这是关系型数据库中查找最为常用和有效的索引，但是 B+ 树索引并不能找到一个给定键对应的具体值，&lt;strong&gt;它只能找到数据行对应的页&lt;/strong&gt;，然后正如上一节所提到的，数据库把整个页读入到内存中，并在内存中查找具体的数据行。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/B+Tree.jpg&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/B+Tree.jpg&#34; alt=&#34;B+Tree&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;B+ 树是平衡树，它查找任意节点所耗费的时间都是完全相同的，比较的次数就是 B+ 树的高度；&lt;/p&gt;
&lt;h4 id=&#34;缺点&#34;&gt;缺点&lt;/h4&gt;
&lt;p&gt;1.虽然索引大大提高了查询速度，同时却会&lt;strong&gt;降低更新表的速度&lt;/strong&gt;，如对表进行insert、update和delete。因为更新表时，不仅要保存数据，还要保存一下索引文件。&lt;/p&gt;
&lt;p&gt;2.建立索引会占用磁盘空间的索引文件。一般情况这个问题不太严重，但如果你在一个大表上创建了多种组合索引，索引文件的会增长很快。&lt;br&gt;
索引只是提高效率的一个因素，如果有大数据量的表，就需要花时间研究建立最优秀的索引，或优化查询语句。&lt;/p&gt;
&lt;h3 id=&#34;三-聚集索引和辅助索引&#34;&gt;三、聚集索引和辅助索引&lt;/h3&gt;
&lt;p&gt;数据库中的 B+ 树索引可以分为聚集索引（clustered index）和辅助索引（secondary index），它们之间的最大区别就是，&lt;strong&gt;聚集索引中存放着一条行记录的全部信息&lt;/strong&gt;，&lt;strong&gt;而辅助索引中只包含索引列和一个用于查找对应行记录的『书签』&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;聚集索引&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;InnoDB 存储引擎中的表都是使用索引组织的，也就是按照键的顺序存放；&lt;strong&gt;聚集索引就是按照表中主键的顺序构建一颗 B+ 树，并在叶节点中存放表中的行记录数据&lt;/strong&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE TABLE users(    
    id INT NOT NULL,    
    first_name VARCHAR(20) NOT NULL,    
    last_name VARCHAR(20) NOT NULL,    
    age INT NOT NULL,    
    PRIMARY KEY(id),    
    KEY(last_name, first_name, age)    
    KEY(first_name));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果使用上面的 SQL 在数据库中创建一张表，B+ 树就会使用 &lt;code&gt;id&lt;/code&gt; 作为索引的键，并在叶子节点中存储一条记录中的&lt;strong&gt;所有&lt;/strong&gt;信息。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/Clustered-Index.jpg&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/Clustered-Index.jpg&#34; alt=&#34;Clustered-Index&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;图中对 B+ 树的描述与真实情况下 B+ 树中的数据结构有一些差别，不过这里想要表达的主要意思是：聚集索引叶节点中保存的是整条行记录，而不是其中的一部分。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;聚集索引与表的物理存储方式有着非常密切的关系，所有正常的表应该&lt;strong&gt;有且仅有一个&lt;/strong&gt;聚集索引（绝大多数情况下都是主键），表中的所有行记录数据都是按照&lt;strong&gt;聚集索引&lt;/strong&gt;的顺序存放的。&lt;/p&gt;
&lt;p&gt;当我们使用聚集索引对表中的数据进行检索时，可以直接获得聚集索引所对应的整条行记录数据所在的页，不需要进行第二次操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;辅助索引&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据库将所有的非聚集索引都划分为辅助索引，但是这个概念对我们理解辅助索引并没有什么帮助；辅助索引也是通过 B+ 树实现的，但是它的叶节点并不包含行记录的全部数据，仅包含索引中的所有键和一个用于查找对应行记录的『书签』，在 InnoDB 中这个&lt;strong&gt;书签就是当前记录的主键&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;辅助索引的存在并不会影响聚集索引，因为聚集索引构成的 B+ 树是&lt;strong&gt;数据实际存储&lt;/strong&gt;的形式，而辅助索引只用于加速数据的查找，所以一张表上往往有多个辅助索引以此来提升数据库的性能。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一张表一定包含一个聚集索引构成的 B+ 树以及若干辅助索引的构成的 B+ 树。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/Secondary-Index.jpg&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/Secondary-Index.jpg&#34; alt=&#34;Secondary-Index&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;如果在表 &lt;code&gt;users&lt;/code&gt; 中存在一个辅助索引 &lt;code&gt;(first_name, age)&lt;/code&gt;，那么它构成的 B+ 树大致就是上图这样，按照 &lt;code&gt;(first_name, age)&lt;/code&gt; 的字母顺序对表中的数据进行排序，当查找到主键时，再通过聚集索引获取到整条行记录。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/Clustered-Secondary-Index.jpg&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/Clustered-Secondary-Index.jpg&#34; alt=&#34;Clustered-Secondary-Index&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;上图展示了一个使用辅助索引查找一条表记录的过程：通过辅助索引查找到对应的主键，最后在聚集索引中使用主键获取对应的行记录，这也是通常情况下行记录的查找方式。&lt;/p&gt;
&lt;h3 id=&#34;四-索引类型&#34;&gt;四、索引类型&lt;/h3&gt;
&lt;h4 id=&#34;1普通索引&#34;&gt;1.普通索引&lt;/h4&gt;
&lt;p&gt;是最基本的索引，它没有任何限制。它有以下几种创建方式：&lt;br&gt;
（1）直接创建索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE INDEX index_name ON table(column(length))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（2）修改表结构的方式添加索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;ALTER TABLE table_name ADD INDEX index_name ON (column(length))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（3）创建表的时候同时创建索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE TABLE `table` (
    `id` int(11) NOT NULL AUTO_INCREMENT ,
    `title` char(255) CHARACTER NOT NULL ,
    `content` text CHARACTER NULL ,
    `time` int(10) NULL DEFAULT NULL , 
    PRIMARY KEY (`id`), 
    INDEX index_name (title(length))
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（4）删除索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;DROP INDEX index_name ON table
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2唯一索引&#34;&gt;2.唯一索引&lt;/h4&gt;
&lt;p&gt;与前面的普通索引类似，不同的就是：&lt;strong&gt;索引列的值必须唯一，但允许有空值&lt;/strong&gt;。如果是组合索引，则列值的组合必须唯一。它有以下几种创建方式：&lt;br&gt;
（1）创建唯一索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE UNIQUE INDEX indexName ON table(column(length))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（2）修改表结构&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;ALTER TABLE table_name ADD UNIQUE indexName ON (column(length))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（3）创建表的时候直接指定&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE TABLE `table` (
    `id` int(11) NOT NULL AUTO_INCREMENT ,
    `title` char(255) CHARACTER NOT NULL ,
    `content` text CHARACTER NULL ,
    `time` int(10) NULL DEFAULT NULL , 
    UNIQUE indexName (title(length))
);
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3主键索引&#34;&gt;3.主键索引&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;是一种特殊的唯一索引&lt;/strong&gt;，&lt;strong&gt;一个表只能有一个主键，不允许有空值&lt;/strong&gt;。一般是在建表的时候同时创建主键索引：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE TABLE `table` (
    `id` int(11) NOT NULL AUTO_INCREMENT ,
    `title` char(255) NOT NULL , PRIMARY KEY (`id`)
);
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;4组合索引&#34;&gt;4.组合索引&lt;/h4&gt;
&lt;p&gt;指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循&lt;strong&gt;最左前缀&lt;/strong&gt;集合&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;ALTER TABLE `table` ADD INDEX name_city_age (name,city,age); 
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;5全文索引&#34;&gt;5.全文索引&lt;/h4&gt;
&lt;p&gt;主要用来查找文本中的关键字，而不是直接与索引中的值相比较。fulltext索引跟其它索引大不相同，它更像是一个搜索引擎，而不是简单的where语句的参数匹配。fulltext索引配合match against操作使用，而不是一般的where语句加like。&lt;/p&gt;
&lt;p&gt;它可以在&lt;strong&gt;create table，alter table ，create index使用&lt;/strong&gt;，不过目前只有&lt;strong&gt;char、varchar，text&lt;/strong&gt; 列上可以创建全文索引。值得一提的是，在数据量较大时候，现将数据放入一个没有全局索引的表中，然后再用CREATE index创建fulltext索引，要比先为一张表建立fulltext然后再将数据写入的速度快很多。&lt;br&gt;
（1）创建表的适合添加全文索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE TABLE `table` (
    `id` int(11) NOT NULL AUTO_INCREMENT ,
    `title` char(255) CHARACTER NOT NULL ,
    `content` text CHARACTER NULL ,
    `time` int(10) NULL DEFAULT NULL , PRIMARY KEY (`id`),
    FULLTEXT (content)
);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（2）修改表结构添加全文索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;ALTER TABLE article ADD FULLTEXT index_content(content)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（3）直接创建索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE FULLTEXT INDEX index_content ON article(content)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;五-注意事项&#34;&gt;五、注意事项&lt;/h3&gt;
&lt;p&gt;使用索引时，有以下一些技巧和注意事项：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.索引不会包含有null值的列&lt;/strong&gt;&lt;br&gt;
只要列中包含有null值都将不会被包含在索引中，复合索引中只要有一列含有null值，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时不要让字段的默认值为null。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.使用短索引&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。&lt;/p&gt;
&lt;p&gt;对串列进行索引，如果可能应该指定一个前缀长度。例如，如果有一个char(255)的列，如果在前10个或20个字符内，多数值是惟一的，那么就&lt;strong&gt;不要对整个列进行索引&lt;/strong&gt;。&lt;strong&gt;短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作&lt;/strong&gt;，但是其&lt;strong&gt;缺点是不能用于ORDER BY和GROUP BY操作&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;3.&lt;strong&gt;索引列排序&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;查询只使用一个索引&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作；尽量不要包含多个列的排序，&lt;strong&gt;如果需要最好给这些列创建复合索引&lt;/strong&gt;。对于复合索引Mysql从左到右的使用索引中的字段，一个查询可以只使用索引中的一部份，但只能是最左侧部分。&lt;br&gt;
例如索引是key index (a,b,c). 相当于是创建了a|a,b| a,b,c 3种索引，但不支持 b,c进行查找。&lt;br&gt;
使用联合索引的好处是索引已经对&lt;strong&gt;第二个键值进行了排序，可以避免多一次的排序操作&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;4.&lt;strong&gt;like语句操作&lt;/strong&gt;&lt;br&gt;
一般情况下不推荐使用like操作，如果非使用不可，如何使用也是一个问题。like “%aaa%” 不会使用索引而like “aaa%”可以使用索引。&lt;/p&gt;
&lt;p&gt;5.&lt;strong&gt;不要在列上进行运算&lt;/strong&gt;&lt;br&gt;
这将导致索引失效而进行全表扫描，例如&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;SELECT * FROM table_name WHERE YEAR(column_name)&amp;lt;2017;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;6.&lt;strong&gt;不使用not in和&amp;lt;&amp;gt;操作&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;7、&lt;strong&gt;不同应用中使用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于OLTP应用中，查询操作一般只取一小部分数据，此时建立B+树索引才有意义；在OLAP中需要访问大量的数据，因此索引的列应当是宏观的信息而不是微观的信息。比起名字，日期更适合做索引。&lt;/p&gt;
&lt;p&gt;8、&lt;strong&gt;覆盖索引（covering index）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;覆盖索引（&lt;strong&gt;查询列和索引列尽量一致&lt;/strong&gt;，通俗说就是对A、B列创建了索引，然后查询中也使用A、B列），减少select *的使用。&lt;br&gt;
覆盖索引是select的&lt;strong&gt;数据列只用从辅助索引中就能够取得，不必读取数据行&lt;/strong&gt;，换句话说查询列要被所建的索引覆盖。即从辅助索引中就可以得到查询的记录，而不需要查询聚合索引中的记录。&lt;/p&gt;
&lt;p&gt;使用覆盖索引的一个好处是&lt;strong&gt;辅助索引不包含整行记录的所有信息，故其大小要远小于聚集索引，因此可以减少大量的IO操作。&lt;/strong&gt;&lt;br&gt;
另一个好处是对于某些统计问题而言，&lt;code&gt;SELECT count(*) from tbl_name;InnoDb&lt;/code&gt;并不会选择通过查询聚集索引来统计，而是通过选择辅助索引来减少IO操作。&lt;/p&gt;
&lt;p&gt;9、&lt;strong&gt;索引提示&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MySQL支持索引提示（Index hint),显示地告诉优化器使用哪个索引。&lt;br&gt;
一、当数据库的优化器错误地选择了某个索引，导致SQL语句很慢时（非常少见），可以使用索引提示&lt;br&gt;
二、SQL的索引非常多，优化器选择执行计划时间的开销超过了SQL本身时&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select * from tbl_name USE|FORCE INDEX(index_name ).......
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;10、尽量使用自增字段做主键&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录&lt;strong&gt;按主键顺序存放&lt;/strong&gt;，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。&lt;/p&gt;
&lt;p&gt;如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。如下图所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/13.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/13.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。&lt;/p&gt;
&lt;p&gt;如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/14.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/14.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。&lt;/p&gt;
&lt;p&gt;因此，只要可以，&lt;strong&gt;请尽量在InnoDB上采用自增字段做主键&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;11.尽量选择区分度高的列作为索引&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;区分度的公式是count(distinct col)/count(*)，&lt;strong&gt;表示字段不重复的比例，比例越大我们扫描的记录数越少&lt;/strong&gt;，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;12.尽量的扩展索引，不要新建索引，最佳左前缀法则。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可&lt;/p&gt;
&lt;h1 id=&#34;数据结构及算法基础&#34;&gt;数据结构及算法基础&lt;/h1&gt;
&lt;h2 id=&#34;索引的本质&#34;&gt;索引的本质&lt;/h2&gt;
&lt;p&gt;MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。&lt;/p&gt;
&lt;p&gt;我们知道，数据库查询是数据库的最主要功能之一。我们都希望查询数据的速度能尽可能的快，因此数据库系统的设计者会从查询算法的角度进行优化。最基本的查询算法当然是&lt;a href=&#34;http://en.wikipedia.org/wiki/Linear_search&#34;&gt;顺序查找&lt;/a&gt;（linear search），这种复杂度为O(n)的算法在数据量很大时显然是糟糕的，好在计算机科学的发展提供了很多更优秀的查找算法，例如&lt;a href=&#34;http://en.wikipedia.org/wiki/Binary_search_algorithm&#34;&gt;二分查找&lt;/a&gt;（binary search）、&lt;a href=&#34;http://en.wikipedia.org/wiki/Binary_search_tree&#34;&gt;二叉树查找&lt;/a&gt;（binary tree search）等。如果稍微分析一下会发现，每种查找算法都只能应用于特定的数据结构之上，例如二分查找要求被检索数据有序，而二叉树查找只能应用于&lt;a href=&#34;http://en.wikipedia.org/wiki/Binary_search_tree&#34;&gt;二叉查找树&lt;/a&gt;上，但是数据本身的组织结构不可能完全满足各种数据结构（例如，理论上不可能同时将两列都按顺序进行组织），所以，在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。&lt;/p&gt;
&lt;p&gt;看一个例子：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/1.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/1.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图1展示了一种可能的索引方式。左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。为了加快Col2的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针。&lt;/p&gt;
&lt;p&gt;虽然这是一个货真价实的索引，但是实际的数据库系统几乎没有使用二叉查找树或其进化品种&lt;a href=&#34;http://en.wikipedia.org/wiki/Red-black_tree&#34;&gt;红黑树&lt;/a&gt;（red-black tree）实现的，原因会在下文介绍。&lt;/p&gt;
&lt;h2 id=&#34;b-tree和btree&#34;&gt;B-Tree和B+Tree&lt;/h2&gt;
&lt;p&gt;目前大部分数据库系统及文件系统都采用B-Tree或其变种B+Tree作为索引结构，在本文的下一节会结合存储器原理及计算机存取原理讨论为什么B-Tree和B+Tree在被如此广泛用于索引，这一节先单纯从数据结构角度描述它们。&lt;/p&gt;
&lt;h3 id=&#34;b-tree&#34;&gt;B-Tree&lt;/h3&gt;
&lt;p&gt;为了描述B-Tree，首先定义一条数据记录为一个二元组[key, data]，key为记录的键值，对于不同数据记录，key是互不相同的；data为数据记录除key外的数据。那么B-Tree是满足下列条件的数据结构：&lt;/p&gt;
&lt;p&gt;d为大于1的一个正整数，称为B-Tree的度。&lt;/p&gt;
&lt;p&gt;h为一个正整数，称为B-Tree的高度。&lt;/p&gt;
&lt;p&gt;每个非叶子节点由n-1个key和n个指针组成，其中d&amp;lt;=n&amp;lt;=2d。&lt;/p&gt;
&lt;p&gt;每个叶子节点最少包含一个key和两个指针，最多包含2d-1个key和2d个指针，叶节点的指针均为null 。&lt;/p&gt;
&lt;p&gt;所有叶节点具有相同的深度，等于树高h。&lt;/p&gt;
&lt;p&gt;key和指针互相间隔，节点两端是指针。&lt;/p&gt;
&lt;p&gt;一个节点中的key从左到右非递减排列。&lt;/p&gt;
&lt;p&gt;所有节点组成树结构。&lt;/p&gt;
&lt;p&gt;每个指针要么为null，要么指向另外一个节点。&lt;/p&gt;
&lt;p&gt;如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于。&lt;/p&gt;
&lt;p&gt;图2是一个d=2的B-Tree示意图。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/2.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/2.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图2&lt;/p&gt;
&lt;p&gt;由于B-Tree的特性，在B-Tree中按key检索数据的算法非常直观：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到null指针，前者查找成功，后者查找失败。B-Tree上查找算法的伪代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1.  BTree_Search(node, key)  {
2.   if(node ==  null)  return  null;
3.   foreach(node.key)
4.   {
5.   if(node.key[i]  == key)  return node.data[i];
6.   if(node.key[i]  &amp;gt; key)  return  BTree_Search(point[i]-&amp;gt;node);
7.   }
8.   return  BTree_Search(point[i+1]-&amp;gt;node);
9.  }
10.  data =  BTree_Search(root, my_key);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;关于B-Tree有一系列有趣的性质，例如一个度为d的B-Tree，设其索引N个key，从这点可以看出，B-Tree是一个非常有效率的索引数据结构。&lt;/p&gt;
&lt;p&gt;另外，由于插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质，本文不打算完整讨论B-Tree这些内容，因为已经有许多资料详细说明了B-Tree的数学性质及插入删除算法，有兴趣的朋友可以在本文末的参考文献一栏找到相应的资料进行阅读。&lt;/p&gt;
&lt;h3 id=&#34;btree&#34;&gt;B+Tree&lt;/h3&gt;
&lt;p&gt;B-Tree有许多变种，其中最常见的是B+Tree，例如MySQL就普遍使用B+Tree实现其索引结构。&lt;/p&gt;
&lt;p&gt;与B-Tree相比，B+Tree有以下不同点：&lt;/p&gt;
&lt;p&gt;每个节点的指针上限为2d而不是2d+1。&lt;/p&gt;
&lt;p&gt;内节点不存储data，只存储key；叶子节点不存储指针。&lt;/p&gt;
&lt;p&gt;图3是一个简单的B+Tree示意。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/3.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/3.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图3&lt;/p&gt;
&lt;p&gt;由于并不是所有节点都具有相同的域，因此B+Tree中叶节点和内节点一般大小不同。这点与B-Tree不同，虽然B-Tree中不同节点存放的key和指针可能数量不一致，但是每个节点的域和上限是一致的，所以在实现中B-Tree往往对每个节点申请同等大小的空间。&lt;/p&gt;
&lt;p&gt;一般来说，B+Tree比B-Tree更适合实现外存储索引结构，具体原因与外存储器原理及计算机存取原理有关，将在下面讨论。&lt;/p&gt;
&lt;h3 id=&#34;带有顺序访问指针的btree&#34;&gt;带有顺序访问指针的B+Tree&lt;/h3&gt;
&lt;p&gt;一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/4.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/4.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图4&lt;/p&gt;
&lt;p&gt;如图4所示，在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。做这个优化的目的是为了提高区间访问的性能，例如图4中如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。&lt;/p&gt;
&lt;p&gt;这一节对B-Tree和B+Tree进行了一个简单的介绍，下一节结合存储器存取原理介绍为什么目前B+Tree是数据库系统实现索引的首选数据结构。&lt;/p&gt;
&lt;h2 id=&#34;为什么使用b-treebtree&#34;&gt;为什么使用B-Tree（B+Tree）&lt;/h2&gt;
&lt;p&gt;上文说过，红黑树等数据结构也可以用来实现索引，但是文件系统及数据库系统普遍采用B-/+Tree作为索引结构，这一节将结合计算机组成原理相关知识讨论B-/+Tree作为索引的理论基础。&lt;/p&gt;
&lt;p&gt;一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。下面先介绍内存和磁盘存取原理，然后再结合这些原理分析B-/+Tree作为索引的效率。&lt;/p&gt;
&lt;h3 id=&#34;主存存取原理&#34;&gt;主存存取原理&lt;/h3&gt;
&lt;p&gt;目前计算机使用的主存基本都是随机读写存储器（RAM），现代RAM的结构和存取原理比较复杂，这里本文抛却具体差别，抽象出一个十分简单的存取模型来说明RAM的工作原理。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/5.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/5.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图5&lt;/p&gt;
&lt;p&gt;从抽象角度看，主存是一系列的存储单元组成的矩阵，每个存储单元存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元。图5展示了一个4 x 4的主存模型。&lt;/p&gt;
&lt;p&gt;主存的存取过程如下：&lt;/p&gt;
&lt;p&gt;当系统需要读取主存时，则将地址信号放到地址总线上传给主存，主存读到地址信号后，解析信号并定位到指定存储单元，然后将此存储单元数据放到数据总线上，供其它部件读取。&lt;/p&gt;
&lt;p&gt;写主存的过程类似，系统将要写入单元地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，做相应的写操作。&lt;/p&gt;
&lt;p&gt;这里可以看出，主存存取的时间仅与存取次数呈线性关系，因为不存在机械操作，两次存取的数据的“距离”不会对时间有任何影响，例如，先取A0再取A1和先取A0再取D3的时间消耗是一样的。&lt;/p&gt;
&lt;h3 id=&#34;磁盘存取原理&#34;&gt;磁盘存取原理&lt;/h3&gt;
&lt;p&gt;上文说过，索引一般以文件形式存储在磁盘上，索引检索需要磁盘I/O操作。与主存不同，磁盘I/O存在机械运动耗费，因此磁盘I/O的时间消耗是巨大的。&lt;/p&gt;
&lt;p&gt;图6是磁盘的整体结构示意图。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/6.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/6.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图6&lt;/p&gt;
&lt;p&gt;一个磁盘由大小相同且同轴的圆形盘片组成，磁盘可以转动（各个磁盘必须同步转动）。在磁盘的一侧有磁头支架，磁头支架固定了一组磁头，每个磁头负责存取一个磁盘的内容。磁头不能转动，但是可以沿磁盘半径方向运动（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的（不过目前已经有多磁头独立技术，可不受此限制）。&lt;/p&gt;
&lt;p&gt;图7是磁盘结构的示意图。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/7.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/7.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图7&lt;/p&gt;
&lt;p&gt;盘片被划分成一系列同心环，圆心是盘片中心，每个同心环叫做一个磁道，所有半径相同的磁道组成一个柱面。磁道被沿半径线划分成一个个小的段，每个段叫做一个扇区，每个扇区是磁盘的最小存储单元。为了简单起见，我们下面假设磁盘只有一个盘片和一个磁头。&lt;/p&gt;
&lt;p&gt;当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。&lt;/p&gt;
&lt;h3 id=&#34;局部性原理与磁盘预读&#34;&gt;局部性原理与磁盘预读&lt;/h3&gt;
&lt;p&gt;由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：&lt;/p&gt;
&lt;p&gt;当一个数据被用到时，其附近的数据也通常会马上被使用。&lt;/p&gt;
&lt;p&gt;程序运行期间所需要的数据通常比较集中。&lt;/p&gt;
&lt;p&gt;由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;预读的长度一般为页（page）的整倍数&lt;/strong&gt;。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。&lt;/p&gt;
&lt;h3 id=&#34;b-tree索引的性能分析&#34;&gt;B-/+Tree索引的性能分析&lt;/h3&gt;
&lt;p&gt;到这里终于可以分析B-/+Tree索引的性能了。&lt;/p&gt;
&lt;p&gt;上文说过一般使用磁盘I/O次数评价索引结构的优劣。先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：&lt;/p&gt;
&lt;p&gt;每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。&lt;/p&gt;
&lt;p&gt;综上所述，用B-Tree作为索引结构效率是非常高的。&lt;/p&gt;
&lt;p&gt;而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。&lt;/p&gt;
&lt;p&gt;floor表示向下取整。由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。&lt;/p&gt;
&lt;p&gt;这一章从理论角度讨论了与索引相关的数据结构与算法问题，下一章将讨论B+Tree是如何具体实现为MySQL中索引，同时将结合MyISAM和InnDB存储引擎介绍非聚集索引和聚集索引两种不同的索引实现形式。&lt;/p&gt;
&lt;h2 id=&#34;mysql索引实现&#34;&gt;MySQL索引实现&lt;/h2&gt;
&lt;p&gt;在MySQL中，索引属于存储引擎级别的概念，不同存储引擎对索引的实现方式是不同的，本文主要讨论MyISAM和InnoDB两个存储引擎的索引实现方式。&lt;/p&gt;
&lt;h3 id=&#34;myisam索引实现&#34;&gt;MyISAM索引实现&lt;/h3&gt;
&lt;p&gt;MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的原理图：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;15&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/8.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/8.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图8&lt;/p&gt;
&lt;p&gt;这里设表一共有三列，假设我们以Col1为主键，则图8是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，&lt;strong&gt;只是主索引要求key是唯一的，而辅助索引的key可以重复&lt;/strong&gt;。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;16&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/9.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/9.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图9&lt;/p&gt;
&lt;p&gt;同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。&lt;/p&gt;
&lt;p&gt;MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。&lt;/p&gt;
&lt;h3 id=&#34;innodb索引实现&#34;&gt;InnoDB索引实现&lt;/h3&gt;
&lt;p&gt;虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。&lt;/p&gt;
&lt;p&gt;第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;17&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/10.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/10.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图10&lt;/p&gt;
&lt;p&gt;图10是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则&lt;strong&gt;MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键&lt;/strong&gt;，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，&lt;strong&gt;这个字段长度为6个字节&lt;/strong&gt;，类型为长整形。&lt;/p&gt;
&lt;p&gt;第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录&lt;strong&gt;主键的值而不是地址&lt;/strong&gt;。换句话说，InnoDB的所有&lt;strong&gt;辅助索引都引用主键作为data域&lt;/strong&gt;。例如，图11为定义在Col3上的一个辅助索引：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;18&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/11.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/11.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图11&lt;/p&gt;
&lt;p&gt;这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。&lt;/p&gt;
">4、索引</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/lock/"" data-c="
          &lt;h2 id=&#34;innodb中的事务隔离级别和锁的关系&#34;&gt;Innodb中的事务隔离级别和锁的关系&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;前言:&lt;/p&gt;
&lt;p&gt;我们都知道事务的几种性质，数据库为了维护这些性质，尤其是一致性和隔离性，一般使用加锁这种方式。同时数据库又是个高并发的应用，同一时间会有大量的并发访问，如果加锁过度，会极大的降低并发处理能力。所以对于加锁的处理，可以说就是数据库对于事务处理的精髓所在。这里通过分析MySQL中InnoDB引擎的加锁机制，来抛砖引玉，让读者更好的理解，在事务处理中数据库到底做了什么。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一次封锁or两段锁？ 因为有大量的并发访问，为了预防死锁，一般应用中推荐使用&lt;strong&gt;一次封锁法&lt;/strong&gt;，就是&lt;strong&gt;在方法的开始阶段，已经预先知道会用到哪些数据，然后全部锁住，在方法运行之后，再全部解锁&lt;/strong&gt;。这种方式可以有效的避免循环死锁，但在数据库中却不适用，因为在事务开始阶段，&lt;strong&gt;数据库并不知道会用到哪些数据&lt;/strong&gt;。 数据库遵循的是两段锁协议，将事务分成两个阶段，加锁阶段和解锁阶段（所以叫两段锁）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;加锁阶段：在该阶段可以进行加锁操作。在对任何数据进行读操作之前要申请并获得S锁（共享锁，其它事务可以继续加共享锁，但不能加排它锁），在进行写操作之前要申请并获得X锁（排它锁，其它事务不能再获得任何锁）。&lt;strong&gt;加锁不成功，则事务进入等待状态，直到加锁成功才继续执行。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;解锁阶段：当事务释放了一个封锁以后，事务进入解锁阶段，在该阶段只能进行解锁操作不能再进行加锁操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;事务&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;加锁/解锁处理&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;begin；&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;insert into test …..&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;加insert对应的锁&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;update test set…&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;加update对应的锁&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;delete from test ….&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;加delete对应的锁&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;commit;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;事务提交时，同时释放insert、update、delete对应的锁&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这种方式虽然&lt;strong&gt;无法避免死锁&lt;/strong&gt;，但是两段锁协议&lt;strong&gt;可以保证事务的并发调度是串行化&lt;/strong&gt;（串行化很重要，尤其是在数据恢复和备份的时候）的。&lt;/p&gt;
&lt;p&gt;我们都知道锁的种类一般分为乐观锁和悲观锁两种，InnoDB 存储引擎中使用的就是悲观锁，而按照锁的粒度划分，也可以分成行锁和表锁。&lt;/p&gt;
&lt;h3 id=&#34;并发控制机制&#34;&gt;并发控制机制&lt;/h3&gt;
&lt;p&gt;乐观锁和悲观锁其实都是并发控制的机制，同时它们在原理上就有着本质的差别；&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;乐观锁是一种思想，它其实并不是一种真正的『锁』，&lt;strong&gt;它会先尝试对资源进行修改，在写回时判断资源是否进行了改变&lt;/strong&gt;，&lt;strong&gt;如果没有发生改变就会写回，否则就会进行重试&lt;/strong&gt;，在整个的执行过程中其实都&lt;strong&gt;没有对数据库进行加锁&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;悲观锁就是一种真正的锁了，它会在获取资源前对资源进行加锁，确保同一时刻只有有限的线程能够访问该资源，其他想要尝试获取资源的操作都会进入等待状态，直到该线程完成了对资源的操作并且释放了锁后，其他线程才能重新操作资源；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虽然乐观锁和悲观锁在本质上并不是同一种东西，一个是一种思想，另一个是一种真正的锁，但是它们都是一种并发控制机制。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/Optimistic-Pessimistic-Locks.jpg&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/Optimistic-Pessimistic-Locks.jpg&#34; alt=&#34;Optimistic-Pessimistic-Locks&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;乐观锁不会存在死锁的问题，但是由于更新后验证，所以当&lt;strong&gt;冲突频率&lt;/strong&gt;和&lt;strong&gt;重试成本&lt;/strong&gt;较高时更推荐使用悲观锁，而需要非常高的&lt;strong&gt;响应速度&lt;/strong&gt;并且&lt;strong&gt;并发量&lt;/strong&gt;非常大的时候使用乐观锁就能较好的解决问题，在这时使用悲观锁就可能出现严重的性能问题；在选择并发控制机制时，需要综合考虑上面的四个方面（冲突频率、重试成本、响应速度和并发量）进行选择。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;锁的类型&#34;&gt;锁的类型&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;MyISAM&lt;/code&gt;采用表级锁(table-level locking)。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;支持行级锁(row-level locking)和表级锁,默认为行级锁&lt;/p&gt;
&lt;h4 id=&#34;表级锁&#34;&gt;表级锁&lt;/h4&gt;
&lt;p&gt;表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为共享锁和排他锁.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;用法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;共享锁(s 锁 读锁)&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640-1583145998710.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;排他锁(x 锁 写锁 )&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640-1583145998738.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;行级锁&#34;&gt;行级锁&lt;/h4&gt;
&lt;p&gt;行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。&lt;/p&gt;
&lt;p&gt;行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。&lt;/p&gt;
&lt;p&gt;行级锁分为共享锁和排他锁.&lt;/p&gt;
&lt;p&gt;MySQL的行锁是针对&lt;strong&gt;索引&lt;/strong&gt;加的锁，不是针对记录加的锁。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;用法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;共享锁(s 锁 读锁)&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640-1583145917027.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;排他锁(x 锁 写锁 )&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640-1583145917032.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;虽然使用行级索具有粒度小、并发度高等特点，但是表级锁有时候也是非常必要的：&lt;/p&gt;
&lt;p&gt;1）事务更新大表中的大部分数据直接使用表级锁效率更高；&lt;/p&gt;
&lt;p&gt;2）事务比较复杂，使用行级索很可能引起死锁导致回滚。&lt;/p&gt;
&lt;h4 id=&#34;意向锁&#34;&gt;意向锁&lt;/h4&gt;
&lt;p&gt;无论是共享锁还是互斥锁其实都只是对某一个数据行进行加锁，InnoDB 支持多种粒度的锁，也就是&lt;strong&gt;行锁和表锁&lt;/strong&gt;；为了支持多粒度锁定，InnoDB 存储引擎引入了&lt;strong&gt;意向锁（Intention Lock），意向锁就是一种表级锁&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;与上一节中提到的两种锁的种类相似的是，意向锁也分为两种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;意向共享锁&lt;/strong&gt;：事务想要在获得表中某些记录的共享锁，需要在表上先加意向共享锁；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;意向互斥锁&lt;/strong&gt;：事务想要在获得表中某些记录的互斥锁，需要在表上先加意向互斥锁；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;随着意向锁的加入，锁类型之间的兼容矩阵也变得愈加复杂：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/Lock-Type-Compatibility-Matrix.jpg&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/Lock-Type-Compatibility-Matrix.jpg&#34; alt=&#34;Lock-Type-Compatibility-Matrix&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;意向锁其实不会&lt;strong&gt;阻塞全表扫描之外的任何请求&lt;/strong&gt;，它们的主要目的是为了表示&lt;strong&gt;是否有人请求锁定表中的某一行数据&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;有的人可能会对意向锁的目的并不是完全的理解，我们在这里可以举一个例子：如果没有意向锁，当已经有人使用行锁对表中的某一行进行修改时，如果另外一个请求要对全表进行修改，那么就需要对所有的行是否被锁定进行扫描，在这种情况下，效率是非常低的；不过，在引入意向锁之后，当有人使用行锁对表中的某一行进行修改之前，会先为表添加意向互斥锁（IX），再为行记录添加互斥锁（X），在这时如果有人尝试对全表进行修改就不需要判断表中的每一行数据是否被加锁了，只需要通过等待意向互斥锁被释放就可以了。意向锁是&lt;code&gt;InnoDB&lt;/code&gt;自动 加的，不需要用户干预。IX，IS是表级锁，不会和行级的X，S锁发生冲突，只会和表级的X，S发生冲突。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id=&#34;innodb行锁实现方式&#34;&gt;&lt;code&gt;InnoDB&lt;/code&gt;行锁实现方式&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。 &lt;code&gt;InnoDB&lt;/code&gt;这种行锁实现特点意味着：&lt;strong&gt;只有通过索引条件检索数据&lt;/strong&gt;，&lt;code&gt;InnoDB&lt;/code&gt;才使用行级锁，否则，&lt;code&gt;InnoDB&lt;/code&gt;将使用表锁！&lt;/p&gt;
&lt;p&gt;不同隔离级别下，行锁有不同实现算法：&lt;code&gt;InnoDB&lt;/code&gt;默认的事物隔离级别是REPEATABLE READ，使用Next-key Locking；READ COMMITTED 仅采用Record Lock。&lt;/p&gt;
&lt;h4 id=&#34;1record-lock&#34;&gt;1）&lt;strong&gt;Record Lock&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;对索引项&lt;/strong&gt;加锁，锁定符合条件的行。其他事务不能修改和删除加锁项，如果表在建立的时候没有设置任何一个索引，那么这是&lt;code&gt;InnoDB&lt;/code&gt;会使用&lt;strong&gt;隐式的主键&lt;/strong&gt;来锁定；&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE TABLE users(    
    id INT NOT NULL AUTO_INCREMENT,    
    last_name VARCHAR(255) NOT NULL,    
    first_name VARCHAR(255),    
    age INT,    
    PRIMARY KEY(id),    
    KEY(last_name),    
    KEY(age));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果我们使用 &lt;code&gt;id&lt;/code&gt; 或者 &lt;code&gt;last_name&lt;/code&gt; 作为 SQL 中 &lt;code&gt;WHERE&lt;/code&gt; 语句的过滤条件，那么 InnoDB 就可以通过索引建立的 B+ 树找到行记录并添加索引，但是如果使用 &lt;code&gt;first_name&lt;/code&gt; 作为过滤条件时，由于 InnoDB 不知道待修改的记录具体存放的位置，也无法对将要修改哪条记录提前做出判断就会&lt;strong&gt;锁定整个表&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;2gap-lock&#34;&gt;2）&lt;strong&gt;Gap Lock&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;当我们用&lt;strong&gt;范围条件&lt;/strong&gt;而不是相等条件检索数据，并请求共享或排他锁时，&lt;code&gt;InnoDB&lt;/code&gt;会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”；对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁），不包含索引项本身。&lt;/p&gt;
&lt;h4 id=&#34;3next-key-lock&#34;&gt;3）&lt;strong&gt;Next-key Lock&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;锁定索引项本身和索引范围。即Record Lock和Gap Lock的结合锁定一个SQL申明的范围（eg. id&amp;gt;1），并且锁定记录本身。&lt;code&gt;InnoDB&lt;/code&gt;采用Next-Key Locking来避免幻读。通过对范围加X锁，那么这个范围的插入都是不允许的。&lt;code&gt;InnoDB&lt;/code&gt;使用Next-key Lock的目的，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;一）为了防止幻读，以满足相关隔离级别的要求，对于上面的例子，要是不使用间隙锁，如果其它事务插入了范围内的任何记录，那么本事务如果再次执行上述语句，就会发生幻读；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;二）为了满足其恢复和复制的需要。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MySQL 通过 &lt;code&gt;binlog&lt;/code&gt;记录执行成功的 insert、update 、delete 等更新数据的 &lt;code&gt;sql&lt;/code&gt;语句，并由此实现 MySQL数据库的恢复和主从复制。&lt;/p&gt;
&lt;p&gt;MySQL 5.6 支持 3 种 日志格式，即基于语句的日志格式 &lt;code&gt;sbl&lt;/code&gt;，基于行的日志格式 &lt;code&gt;rbl&lt;/code&gt;和混合格式，对基于语句日志格式（&lt;code&gt;sbl&lt;/code&gt;）的恢复和复制而言，由于 MySQL 的 &lt;code&gt;binlog&lt;/code&gt;是按照事务提交的先后顺序记录的，因此要正确恢复或复制数据，就必须满足：**在一个事务未提交前，其他并发事务不能插入满足其锁定条件的任何记录，也就是不允许出现幻读。**这已经超过了“可重复读”隔离级别的要求，实际上是要求事务要串行化。这也是许多情况下， &lt;code&gt;innodb&lt;/code&gt;要用 next-key 锁的原因。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SELECT * FROM tbl_name where col=xxx LOCK IN SHARE MODE; 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果通过索引查询一个值，并对该行加上一个&lt;code&gt;SLock&lt;/code&gt;，那么即使查询的值不在，其锁定的也是一个范围，因此若没有任何行返回，那么新插入的值一定是唯一的，如果有多个事物并发操作这种唯一性检查机制也不会有问题，因为此时会导致死锁，只有一个事务的插入操作会成功，其余的事物会抛出死锁的错误。&lt;/p&gt;
&lt;p&gt;在实际应用中，要特别注意 &lt;code&gt;innodb&lt;/code&gt; 行锁的这一特性，否则可能导致大量的锁冲突，从而影响并发性能。&lt;/p&gt;
&lt;p&gt;1）在不通过索引条件查询的时候，&lt;code&gt;InnoDB&lt;/code&gt;确实使用的是表锁，而不是行锁。&lt;/p&gt;
&lt;p&gt;2）由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的&lt;/p&gt;
&lt;p&gt;3）当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，&lt;code&gt;InnoDB&lt;/code&gt;都会使用行锁来对数据加锁。&lt;/p&gt;
&lt;p&gt;4）即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下&lt;code&gt;InnoDB&lt;/code&gt;将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;死锁&#34;&gt;死锁&lt;/h3&gt;
&lt;p&gt;MyISAM中是不会产生死锁的，因为MyISAM总是一次性获得所需的全部锁，要么全部满足，要么全部等待。&lt;/p&gt;
&lt;p&gt;而在InnoDB中，锁是逐步获得的，就造成了死锁的可能。在MySQL中，行级锁并不是直接锁记录，而是锁索引。&lt;/p&gt;
&lt;p&gt;索引分为主键索引和非主键索引两种，如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。&lt;/p&gt;
&lt;p&gt;在UPDATE、DELETE操作时，MySQL不仅锁定WHERE条件扫描过的所有索引记录，而且会锁定相邻的键值，即所谓的next-key locking。&lt;/p&gt;
&lt;p&gt;当两个事务同时执行，一个锁住了主键索引，在等待其他相关索引。另一个锁定了非主键索引，在等待主键索引。这样就会发生死锁。&lt;/p&gt;
&lt;p&gt;发生死锁后，InnoDB一般都可以检测到，并使一个事务释放锁回退，另一个获取锁完成事务。&lt;/p&gt;
&lt;h4 id=&#34;1-避免死锁&#34;&gt;1、避免死锁&lt;/h4&gt;
&lt;h5 id=&#34;1通过表级锁来减少死锁产生的概率&#34;&gt;1）通过表级锁来减少死锁产生的概率；&lt;/h5&gt;
&lt;h5 id=&#34;2使用抢占加事务回滚的方式预防死锁&#34;&gt;2）使用抢占加事务回滚的方式预防死锁&lt;/h5&gt;
&lt;p&gt;当事务开始执行时会&lt;strong&gt;先获得一个时间戳&lt;/strong&gt;，数据库程序会根据事务的时间戳决定事务应该等待还是回滚，在这时也有两种机制供我们选择，&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;wait-die 机制&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当执行事务的时间戳小于另一事务时，即事务 A 先于 B 开始，那么它就会等待另一个事务释放对应资源的锁， 否则就会保持当前的时间戳并回滚。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;wound-wait&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当前事务如果先于另一事务执行并请求了另一事务的资源，那么另一事务会立刻回滚，将资源让给先执行的事务，否则就会等待其他事务释放资源：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/climlmlmkpboard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;2-死锁的诊断与解除&#34;&gt;2、死锁的诊断与解除&lt;/h4&gt;
&lt;p&gt;数据库系统中诊断死锁的方法与操作系统类似，一般是用超时法或事务等待图法。&lt;/p&gt;
&lt;h5 id=&#34;1-超时法&#34;&gt;&lt;strong&gt;1、超时法&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;指的是如果一个事务的等待时间超过了规定的时限，就认为发生死锁。&lt;/p&gt;
&lt;p&gt;（一）有可能误判死锁，事务因为其他原因使等待时机超过时限。&lt;/p&gt;
&lt;p&gt;（二）时限若设置得太长，死锁发生后不能及时发现。&lt;/p&gt;
&lt;h5 id=&#34;2-等待图法&#34;&gt;&lt;strong&gt;2、等待图法&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;死锁的检测可以通过一个&lt;strong&gt;有向的等待图&lt;/strong&gt;来进行判断，wait-for graph要求数据库&lt;strong&gt;保存锁的信息链表和事务等待链表&lt;/strong&gt;可以构造出一张图，如果一个事务依赖于另一个事务正在处理的数据，那么当前事务就会等待另一个事务结束，这也就是整个等待图中的一条边：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipbmkdsloard2.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;如上图所示，如果在这个有向图中出现了环，就说明当前数据库进入了死锁的状态&lt;code&gt;TransB -&amp;gt; TransE -&amp;gt; TransF -&amp;gt; TransD -&amp;gt; TransB&lt;/code&gt;，在这时就需要死锁恢复机制接入了。&lt;/p&gt;
&lt;p&gt;解决办法就是选择整个环中一个事务进行回滚，以打破整个等待图中的环，在整个恢复的过程中有三个事情需要考虑：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboamomrd2.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;每次出现死锁时其实都会有多个事务被波及，而选择其中哪一个任务进行回滚是必须要做的事情，在选择牺牲品（Victim）时的黄金原则就是&lt;strong&gt;最小化代价&lt;/strong&gt;，所以我们需要综合考虑事务已经计算的时间、使用的数据行以及涉及的事务等因素；&lt;/p&gt;
&lt;p&gt;死锁恢复的过程中，其实还可能出现某些任务在多次死锁时都被选择成为牺牲品，一直都不会成功执行，造成饥饿（Starvation），我们需要保证事务会在有穷的时间内执行，所以要在选择牺牲品时将时间戳加入考虑的范围。&lt;/p&gt;
">5、锁</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/mybatis/"" data-c="
          &lt;p&gt;&lt;strong&gt;1、#{}和${}的区别是什么？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;是&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;文&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;件&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;中&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;的&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;变&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;量&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;占&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;位&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;符&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;，&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;它&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;可&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;以&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;用&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;于&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;标&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;签&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;属&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;性&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;值&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;和&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;内&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;部&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;，&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;属&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;于&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;静&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;态&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;文&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;本&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;替&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;换&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;，&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;比&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;如&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;{}是Properties文件中的变量占位符，它可以用于标签属性值和sql内部，属于静态文本替换，比如&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;是&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;文&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;件&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;中&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;的&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;变&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;量&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;占&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;位&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;符&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;它&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;可&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;以&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;用&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;于&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;标&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;签&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;属&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;性&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;值&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;和&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03588em;&#34;&gt;q&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.01968em;&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;内&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;部&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;属&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;于&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;静&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;态&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;文&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;本&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;替&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;换&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;比&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;如&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;{driver}会被静态替换为com.mysql.jdbc.Driver。#{}是sql的参数占位符，Mybatis会将sql中的#{}替换为?号，在sql执行前会使用PreparedStatement的参数设置方法，按序给sql的?号占位符设置参数值，比如ps.setInt(0, parameterValue)，#{item.name}的取值方式为使用反射从参数对象中获取item对象的name属性值，相当于param.getItem().getName()。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、Xml映射文件中，除了常见的select|insert|updae|delete标签之外，还有哪些标签？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：还有很多其他的标签，&lt;resultMap&gt;、&lt;parameterMap&gt;、&lt;sql&gt;、&lt;include&gt;、&lt;selectKey&gt;，加上动态sql的9个标签，trim|where|set|foreach|if|choose|when|otherwise|bind等，其中&lt;strong&gt;为sql片段标签，通过标签引入sql片段&lt;/strong&gt;，&lt;selectKey&gt;为不支持自增的主键生成策略标签。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、最佳实践中，通常一个Xml映射文件，都会写一个Dao接口与之对应，请问，这个Dao接口的工作原理是什么？Dao接口里的方法，参数不同时，方法能重载吗？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Dao接口，就是人们常说的Mapper接口，接口的全限名，就是映射文件中的namespace的值，接口的方法名，就是映射文件中&lt;strong&gt;MappedStatement&lt;/strong&gt;的id值，接口方法内的参数，就是传递给sql的参数。Mapper接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为key值，可唯一定位一个MappedStatement，举例：com.mybatis3.mappers.StudentDao.findStudentById，可以唯一找到namespace为com.mybatis3.mappers.StudentDao下面id = findStudentById的MappedStatement。在Mybatis中，每一个&lt;select&gt;、&lt;insert&gt;、&lt;update&gt;、&lt;delete&gt;标签，都会被解析为一个MappedStatement对象。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dao接口里的方法，是不能重载的，因为是全限名+方法名的保存和寻找策略。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Dao接口的工作原理是&lt;strong&gt;JDK动态代理&lt;/strong&gt;，Mybatis运行时会使用JDK动态代理为Dao接口生成代理proxy对象，代理对象proxy会拦截接口方法，转而执行MappedStatement所代表的sql，然后将sql执行结果返回。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4、Mybatis是如何进行分页的？分页插件的原理是什么？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Mybatis使用RowBounds对象进行分页，它是针对ResultSet结果集执行的&lt;strong&gt;内存分页&lt;/strong&gt;，而非物理分页，可以在sql内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。&lt;/p&gt;
&lt;p&gt;分页插件的基本原理是使用Mybatis提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的sql，然后重写sql，根据dialect方言，添加对应的物理分页语句和物理分页参数。&lt;/p&gt;
&lt;p&gt;举例：select * from student，拦截sql后重写为：select t.* from （select * from student）t limit 0，10&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5、简述Mybatis的插件运行原理，以及如何编写一个插件。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Mybatis仅可以编写针对&lt;strong&gt;ParameterHandler、ResultSetHandler、StatementHandler、Executor&lt;/strong&gt;这4种接口的插件，Mybatis使用JDK的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这4种接口对象的方法时，就会进入拦截方法，具体就是InvocationHandler的invoke()方法，当然，只会拦截那些你指定需要拦截的方法。&lt;/p&gt;
&lt;p&gt;实现Mybatis的Interceptor接口并复写intercept()方法，然后在给插件编写注解，指定要拦截哪一个接口的哪些方法即可，记住，别忘了在配置文件中配置你编写的插件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6、Mybatis执行批量插入，能返回数据库主键列表吗？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：能，JDBC都能，Mybatis当然也能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7、Mybatis动态sql是做什么的？都有哪些动态sql？能简述一下动态sql的执行原理不？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Mybatis动态sql可以让我们在Xml映射文件内，以标签的形式编写动态sql，完成逻辑判断和动态拼接sql的功能，Mybatis提供了9种动态sql标签trim|where|set|foreach|if|choose|when|otherwise|bind。&lt;/p&gt;
&lt;p&gt;其执行原理为，使&lt;strong&gt;用OGNL从sql参数对象中计算表达式的值，根据表达式的值动态拼接sql&lt;/strong&gt;，以此来完成动态sql的功能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8、Mybatis是如何将sql执行结果封装为目标对象并返回的？都有哪些映射形式？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：第一种是使用****标签，逐一定义列名和对象属性名之间的映射关系。第二种是使用sql列的别名功能，将列别名书写为对象属性名，比如T_NAME AS NAME，对象属性名一般是name，小写，但是列名不区分大小写，Mybatis会忽略列名大小写，智能找到与之对应对象属性名，你甚至可以写成T_NAME AS NaMe，Mybatis一样可以正常工作。&lt;/p&gt;
&lt;p&gt;有了列名与属性名的映射关系后，Mybatis通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9、Mybatis能执行一对一、一对多的关联查询吗？都有哪些实现方式，以及它们之间的区别。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：能，Mybatis不仅可以执行一对一、一对多的关联查询，还可以执行多对一，多对多的关联查询，多对一查询，其实就是一对一查询，只需要把selectOne()修改为selectList()即可；多对多查询，其实就是一对多查询，只需要把selectOne()修改为selectList()即可。&lt;/p&gt;
&lt;p&gt;关联对象查询，有两种实现方式，一种是单独发送一个sql去查询关联对象，赋给主对象，然后返回主对象。另一种是使用嵌套查询，嵌套查询的含义为使用join查询，一部分列是A对象的属性值，另外一部分列是关联对象B的属性值，好处是只发一个sql查询，就可以把主对象和其关联对象查出来。&lt;/p&gt;
&lt;p&gt;那么问题来了，join查询出来100条记录，如何确定主对象是5个，而不是100个？其去重复的原理是&lt;resultMap&gt;标签内的&lt;id&gt;子标签，指定了唯一确定一条记录的id列，Mybatis根据&lt;id&gt;列值来完成100条记录的去重复功能，&lt;id&gt;可以有多个，代表了联合主键的语意。&lt;/p&gt;
&lt;p&gt;同样主对象的关联对象，也是根据这个原理去重复的，尽管一般情况下，只有主对象会有重复记录，关联对象一般不会重复。&lt;/p&gt;
&lt;p&gt;举例：下面join查询出来6条记录，一、二列是Teacher对象列，第三列为Student对象列，Mybatis去重复处理后，结果为1个老师6个学生，而不是6个老师6个学生。&lt;/p&gt;
&lt;p&gt;​    t_id   t_name      s_id&lt;/p&gt;
&lt;p&gt;|      1 | teacher    |    38 |&lt;/p&gt;
&lt;p&gt;|      1 | teacher    |    39 |&lt;/p&gt;
&lt;p&gt;|      1 | teacher    |    40 |&lt;/p&gt;
&lt;p&gt;|      1 | teacher    |    41 |&lt;/p&gt;
&lt;p&gt;|      1 | teacher    |    42 |&lt;/p&gt;
&lt;p&gt;|      1 | teacher    |    43 |&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10、Mybatis是否支持延迟加载？如果支持，它的实现原理是什么？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Mybatis仅支持association关联对象和collection关联集合对象的延迟加载，association指的就是一对一，collection指的就是一对多查询。在Mybatis配置文件中，可以配置是否启用延迟加载lazyLoadingEnabled=true|false。&lt;/p&gt;
&lt;p&gt;它的原理是，使用CGLIB创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用a.getB().getName()，拦截器invoke()方法发现a.getB()是null值，那么就会单独发送事先保存好的查询关联B对象的sql，把B查询上来，然后调用a.setB(b)，于是a的对象b属性就有值了，接着完成a.getB().getName()方法的调用。这就是延迟加载的基本原理。&lt;/p&gt;
&lt;p&gt;当然了，不光是Mybatis，几乎所有的包括Hibernate，支持延迟加载的原理都是一样的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;11、Mybatis的Xml映射文件中，不同的Xml映射文件，id是否可以重复？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：不同的Xml映射文件，如果配置了namespace，那么id可以重复；如果没有配置namespace，那么id不能重复；毕竟namespace不是必须的，只是最佳实践而已。&lt;/p&gt;
&lt;p&gt;原因就是namespace+id是作为Map&amp;lt;String, MappedStatement&amp;gt;的key使用的，如果没有namespace，就剩下id，那么，id重复会导致数据互相覆盖。有了namespace，自然id就可以重复，namespace不同，namespace+id自然也就不同。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;12、Mybatis中如何执行批处理？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：使用BatchExecutor完成批处理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;13、Mybatis都有哪些Executor执行器？它们之间的区别是什么？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Mybatis有三种基本的Executor执行器，&lt;strong&gt;SimpleExecutor、ReuseExecutor、BatchExecutor。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;**SimpleExecutor：**每执行一次update或select，就开启一个Statement对象，用完立刻关闭Statement对象。&lt;/p&gt;
&lt;p&gt;**ReuseExecutor：**执行update或select，以sql作为key查找Statement对象，存在就使用，不存在就创建，用完后，不关闭Statement对象，而是放置于Map&amp;lt;String, Statement&amp;gt;内，供下一次使用。简言之，就是重复使用Statement对象。&lt;/p&gt;
&lt;p&gt;**BatchExecutor：**执行update（没有select，JDBC批处理不支持select），将所有sql都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个Statement对象，每个Statement对象都是addBatch()完毕后，等待逐一执行executeBatch()批处理。与JDBC批处理相同。&lt;/p&gt;
&lt;p&gt;作用范围：Executor的这些特点，都严格限制在SqlSession生命周期范围内。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;14、Mybatis中如何指定使用哪一种Executor执行器？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：在Mybatis配置文件中，可以指定默认的ExecutorType执行器类型，也可以手动给DefaultSqlSessionFactory的创建SqlSession的方法传递ExecutorType类型参数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;15、Mybatis是否可以映射Enum枚举类？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Mybatis可以映射枚举类，不单可以映射枚举类，Mybatis可以映射任何对象到表的一列上。映射方式为自定义一个TypeHandler，实现TypeHandler的setParameter()和getResult()接口方法。TypeHandler有两个作用，一是完成从javaType至jdbcType的转换，二是完成jdbcType至javaType的转换，体现为setParameter()和getResult()两个方法，分别代表设置sql问号占位符参数和获取列查询结果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;16、Mybatis映射文件中，如果A标签通过include引用了B标签的内容，请问，B标签能否定义在A标签的后面，还是说必须定义在A标签的前面？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：虽然Mybatis解析Xml映射文件是按照顺序解析的，但是，被引用的B标签依然可以定义在任何地方，Mybatis都可以正确识别。&lt;/p&gt;
&lt;p&gt;原理是，Mybatis解析A标签，发现A标签引用了B标签，但是B标签尚未解析到，尚不存在，此时，Mybatis会将A标签标记为&lt;strong&gt;未解析状态&lt;/strong&gt;，然后继续解析余下的标签，包含B标签，待所有标签解析完毕，Mybatis会重新解析那些被标记为未解析的标签，此时再解析A标签时，B标签已经存在，A标签也就可以正常解析完成了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;17、简述Mybatis的Xml映射文件和Mybatis内部数据结构之间的映射关系？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Mybatis将所有Xml配置信息都封装到All-In-One重量级对象Configuration内部。在Xml映射文件中，&lt;parameterMap&gt;标签会被解析为ParameterMap对象，其每个子元素会被解析为ParameterMapping对象。&lt;strong&gt;标签会被解析为ResultMap对象&lt;/strong&gt;，其每个子元素会被解析为&lt;strong&gt;ResultMapping对象&lt;/strong&gt;。每一个&lt;select&gt;、&lt;insert&gt;、&lt;update&gt;、&lt;delete&gt;标签均会被解析为&lt;strong&gt;MappedStatement&lt;/strong&gt;对象，标签内的sql会被解析为BoundSql对象。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;18、为什么说Mybatis是半自动ORM映射工具？它与全自动的区别在哪里？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Hibernate属于全自动ORM映射工具，使用Hibernate查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。而Mybatis在查询关联对象或关联集合对象时，需要手动编写sql来完成，所以，称之为半自动ORM映射工具。&lt;/p&gt;
&lt;p&gt;19、Mapper原理&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;../$%7Bimages%7D/cl11%E6%97%A5ipboard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;../$%7Bimages%7D/clipboa131231rd.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
">7、mybatis</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/resume/"" data-c="
          &lt;p&gt;&lt;strong&gt;1、MySQL的复制原理以及流程&lt;/strong&gt;&lt;br&gt;
MySQL 主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。&lt;br&gt;
MySQL 默认采用异步复制方式，这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。&lt;/p&gt;
&lt;p&gt;MySQL主从复制主要用途&lt;br&gt;
a、读写分离&lt;br&gt;
在开发工作中，有时候会遇见某个sql语句需要锁表，导致暂时不能使用读的服务，这样就会影响现有业务，使用主从复制，让主库负责写，从库负责读，这样即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作；&lt;br&gt;
b、数据实时备份，当系统中某个节点发生故障时，可以方便的故障切换；&lt;br&gt;
c、架构扩展&lt;br&gt;
随着系统中业务访问量的增大，如果是单机部署数据库，就会导致I/O访问频率过高。有了主从复制，增加多个数据存储节点，将负载分布在多个从节点上，降低单机磁盘I/O访问的频率，提高单个机器的I/O性能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MySQL 主从形式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;a、一主一从&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/26a37e68_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;b、一主多从，提高系统的读性能&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/a6a5b2ba_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;一主一从和一主多从是最常见的主从架构，实施起来简单并且有效，不仅可以实现HA，而且还能读写分离，进而提升集群的并发能力。&lt;/p&gt;
&lt;p&gt;c、多主一从&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/343b9114_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;多主一从可以将多个mysql数据库备份到一台存储性能比较好的服务器上。&lt;/p&gt;
&lt;p&gt;d、双主复制&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/486367e1_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;双主复制，也就是互做主从复制，每个master既是master，又是另外一台服务器的slave。这样任何一方所做的变更，都会通过复制应用到另外 一方的数据库中。&lt;/p&gt;
&lt;p&gt;e、级联复制&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/b4c48ad7_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;级联复制模式下，部分slave的数据同步不连接主节点，而是连接从节点。因为如果主节点有太多的从节点，就会损耗一部分性能用于 replication，那么我们可以让3~5个从节点连接主节点，其它从节点作为二级或者三级与从节点连接，这样不仅可以缓解主节点的压力，并且对 数据一致性没有负面影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MySQL 主从复制原理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MySQL主从复制涉及到三个线程，一个运行在主节点（log dump thread），其余两个(I/O thread, SQL thread)运行在从节点，如下图所示:&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/59b0ca24_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;1、主节点 binary log dump 线程 当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容。在读取bin-log中的操作时，此线程会对主节点上的 bin-log加锁，当读取完成，甚至在发送给从节点之前，锁会被释放。&lt;/p&gt;
&lt;p&gt;2、从节点I/O线程 当从节点上执行&lt;code&gt;start slave&lt;/code&gt;命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点 binlog dump 进程发来的更新之后，保存在本地relay-log中。&lt;/p&gt;
&lt;p&gt;3、从节点SQL线程 SQL线程负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。&lt;/p&gt;
&lt;p&gt;对于每一个主从连接，都需要三个线程来完成。当主节点有多个从节点时，主节点会为每一个当前连接的从节点建一个binary log dump 进程， 而每个从节点都有自己的I/O线程，SQL线程。从节点用两个线程将从主库拉取更新和执行分成独立的任务，这样在执行同步数据任务的时候， 不会降低读操作的性能。比如，如果从节点没有运行，此时I/O进程可以很快从主节点获取更新，尽管SQL线程还没有执行。如果在SQL进程执行 之前从节点服务停止，至少I/O进程已经从主节点拉取到了最新的变更并且保存在本地relay日志中，当服务再次起来之后，就可以完成数据的同 步。&lt;/p&gt;
&lt;p&gt;要实施复制，首先必须打开Master 端的binary log（bin-log）功能，否则无法实现。 因为整个复制过程实际上就是Slave 从Master 端获取该日志然后再在自己身上完全顺序的执行日志中所记录的各种操作。如下图所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/d055bed7_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;复制的基本过程如下：&lt;/p&gt;
&lt;p&gt;1、从节点上的I/O 进程连接主节点，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容；&lt;/p&gt;
&lt;p&gt;2、主节点接收到来自从节点的I/O请求后，通过负责复制的I/O进程根据请求信息读取指定日志指定位置之后的日志信息，返回给从节点。 返回信息中除了日志所包含的信息之外，还包括本次返回的信息的bin-log file 的以及bin-log position；从节点的I/O进程接收到内容后， 将接收到的日志内容更新到本机的relay log中，并将读取到的binary log文件名和位置保存到master-info 文件中，以便在下一次读取的 时候能够清楚的告诉Master“我需要从某个bin-log 的哪个位置开始往后的日志内容，请发给我”；&lt;/p&gt;
&lt;p&gt;3、Slave 的 SQL线程检测到relay-log 中新增加了内容后，会将relay-log的内容解析成在主节点上实际执行过的操作，并在本数据库中执行&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MySQL 主从复制模式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MySQL 主从复制默认是异步的模式。MySQL增删改操作会全部记录在binary log中，当slave节点连接master时，会主动从master处获取最新的 bin log文件。并把bin log中的sql relay。&lt;/p&gt;
&lt;p&gt;1、 异步模式（mysql async-mode）&lt;/p&gt;
&lt;p&gt;主库将事务 Binlog 事件写入到 Binlog 文件中，此时主库只会通知一下 Dump 线程发送这些新的 Binlog，然后主库就会继续处理提交操作， 而此时不会保证这些 Binlog 传到任何一个从库节点上。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/eebfcaac_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;2、半同步模式(mysql semi-sync)&lt;/p&gt;
&lt;p&gt;这种模式下主节点只需要接收到其中一台从节点的返回信息，就会commit；否则需要等待直到超时时间然后切换成异步模式再提交；这样做 的目的可以使主从数据库的数据延迟缩小，可以提高数据安全性，确保了事务提交后，binlog至少传输到了一个从节点上，不能保证从节点将 此事务更新到db中。性能上会有一定的降低，响应时间会变长。如下图所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/e089f0d5_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;半同步模式不是mysql内置的，从mysql 5.5开始集成，需要master 和slave 安装插件开启半同步模式。&lt;/p&gt;
&lt;p&gt;3、 全同步模式&lt;/p&gt;
&lt;p&gt;全同步模式是指主节点和从节点全部执行了commit并确认才会向客户端返回成功。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、MySQL中myisam与innodb的区别，至少5点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(1)、问5点不同；&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1&amp;gt;.InnoDB支持事务，而MyISAM不支持事&lt;/p&gt;
&lt;p&gt;2&amp;gt;.InnoDB支持行级锁，而MyISAM支持表级锁&lt;/p&gt;
&lt;p&gt;3&amp;gt;.InnoDB支持MVCC, 而MyISAM不支持&lt;/p&gt;
&lt;p&gt;4&amp;gt;.InnoDB支持外键，而MyISAM不支持&lt;/p&gt;
&lt;p&gt;5&amp;gt;.InnoDB关注事务，而MyISAM关注性能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(3)、2者selectcount(*)哪个更快，为什么&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;myisam更快，因为myisam内部维护了一个计数器，可以直接调取。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、MySQL中varchar与char的区别以及varchar(50)中的50代表的涵义&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;(1)、varchar与char的区别 char是一种固定长度的类型，varchar则是一种可变长度的类型&lt;/p&gt;
&lt;p&gt;(2)、varchar(50)中50的涵义 最多存放50个字符，varchar(50)和(200)存储hello所占空间一样，但后者在排序时会消耗更多内存，因为order by col采用fixed_length计 算col长度(memory引擎也一样)&lt;/p&gt;
&lt;p&gt;(3)、int（20）中20的涵义 是指显示字符的长度 但要加参数的，最大为255，比如它是记录行数的id,插入10笔资料，它就显示00000000001 ~~~00000000010，当字符的位数超过11,它也只 显示11位，如果你没有加那个让它未满11位就前面加0的参数，它不会在前面加020表示最大显示宽度为20，但仍占4字节存储，存储范围不变；&lt;/p&gt;
&lt;p&gt;(4)、mysql为什么这么设计 对大多数应用没有意义，只是规定一些工具用来显示字符的个数；int(1)和int(20)存储和计算均一样；&lt;/p&gt;
&lt;h3 id=&#34;怎么复制一张表&#34;&gt;&lt;strong&gt;怎么复制一张表&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1、mysqldump 方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用 mysqldump 命令将数据导出成一组 INSERT 语句。你可以使用下面的命令：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;mysqldump -hport -u$user --add-locks=0 --no-create-info --single-transaction --set-gtid-purged=OFF db1 t --where=&amp;quot;a&amp;gt;900&amp;quot; --result-file=/client_tmp/t.sql&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;然后可以通过下面这条命令，将这些 INSERT 语句放到 db2 库里去执行。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;mysql -h127.0.0.1 -P13000 -uroot db2 -e &amp;quot;source /client_tmp/t.sql&amp;quot;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;2、导出 CSV 文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;直接将结果导出成.csv 文件。MySQL 提供了下面的语法，用来将查询结果导出到服务端本地目录：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;select * from db1.t where a&amp;gt;900 into outfile &#39;/server_tmp/t.csv&#39;;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;然后用下面的 load data 命令将数据导入到目标表 db2.t 中。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;load data infile &#39;/server_tmp/t.csv&#39; into table db2.t;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;3、物理拷贝方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;直接拷贝文件是不行的，需要在数据字典中注册。&lt;/p&gt;
&lt;p&gt;MySQL 5.6 版本引入了可传输表空间(transportable tablespace) 的方法，，可以通过导出 + 导入表空间的方式，实现物理拷贝表的功能。&lt;/p&gt;
&lt;p&gt;mysqldump中备份出来的sql，如果我想sql文件中，一行只有一个insert….value()的话，怎么办？如果备份需要带上master的复制点信息怎么办？&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysqldump 是用于转存储 mysql 数据库的实用程序。主要产生一个 SQL 脚本，其中包含从头重新创建数据库的所有命令。
导出脚本过程大概如下：创建数据库判断语句、删除表、创建表、锁表、禁用索引、插入数据、启用索引、解锁表。

# game 是库名
# 完整导出一个库
# 包括建库语句、表结构、数据
mysqldump -uroot -proot --host=127.0.0.1 --port=3306 --databases game &amp;gt; test.sql

# 只导出表结构
mysqldump -uroot -proot --host=127.0.0.1 --port=3306 -d game &amp;gt; test.sql

# 只导出数据
mysqldump -uroot -proot --host=127.0.0.1 --port=3306 -t game &amp;gt; test.sql

# 导出一个数据库中多个表的数据和结构
mysqldump -uroot -proot --host=127.0.0.1 game --tables articles users &amp;gt; test.sql
mysqldump -uroot -proot --host=127.0.0.1 game articles users &amp;gt; test.sql

# 恢复导出数据
mysql -u username -proot databse &amp;lt; backup.sql

--extended-insert,  -e
使用具有多个VALUES列的INSERT语法。这样使导出文件更小，并加速导入时的速度。默认为打开状态，使用--skip-extended-insert取消选项
将当前服务器的binlog的位置和文件名追加到输出文件，--master-data
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;删除数据为何表文件大小不变&#34;&gt;&lt;strong&gt;删除数据，为何表文件大小不变&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;​    **delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。**也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。&lt;/p&gt;
&lt;p&gt;​    实际上，不止是删除数据会造成空洞，插入数据也会。如果数据是随机插入的，就可能造成索引的数据页分裂。更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。&lt;/p&gt;
&lt;p&gt;​    也就是说，&lt;strong&gt;经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。而重建表，就可以达到这样的目的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;使用 alter table A engine=InnoDB 命令来重建表。MySQL 会自动完成转存数据、交换表名、删除旧表的操作。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    重建表的时候，InnoDB 不会把整张表占满，每个页留了 1/16 给后续的更新用。也就是说，其实重建表之后不是“最”紧凑的。&lt;/p&gt;
&lt;h3 id=&#34;误删数据怎么办&#34;&gt;&lt;strong&gt;误删数据怎么办&lt;/strong&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;delete 语句误删数据行：Flashback工具过闪回把数据恢复回来。 原理是修改 binlog 的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保 binlog_format=row 和 binlog_row_image=FULL。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如何预防：把 sql_safe_updates 参数设置为 on。，delete 或者 update 语句必须有where条件，否则执行会报错。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;误删库 / 表：全量备份，加增量日志，在应用日志的时候，需要跳过 12 点误操作的那个语句的 binlog：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;如果原实例没有使用 GTID 模式，只能在应用到包含 12 点的 binlog 文件的时候，先用–stop-position 参数执行到误操作之前的日志，然后再用–start-position 从误操作之后的日志继续执行；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果实例使用了 GTID 模式，就方便多了。假设误操作命令的 GTID 是 gtid1，那么只需要执行 set gtid_next=gtid1;begin;commit; 先把这个 GTID 加到临时实例的 GTID 集合，之后按顺序执行 binlog 的时候，就会自动跳过误操作的语句。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如何加速恢复：使用 mysqlbinlog 命令时，加上一个–database 参数，用来指定误删表所在的库。&lt;br&gt;
在 start slave 之前，先通过执行﻿ ﻿change replication filter replicate_do_table = (tbl_name) 命令，就可以让临时库只同步误操作的表；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​    &lt;strong&gt;延迟复制备库&lt;/strong&gt;，一般的主备复制结构存在的问题是，如果主库上有个表被误删了，这个命令很快也会被发给所有从库，进而导致所有从库的数据表也都一起被误删了。延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N 命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。&lt;/p&gt;
&lt;p&gt;​    比如把 N 设置为 3600，这就代表了如果主库上有数据被误删了，并且在 1 小时内发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行 stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;预防误删库 / 表的方法，制定操作规范。这样做的目的，是避免写错要删除的表名。&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。&lt;/li&gt;
&lt;li&gt;改表名的时候，要求给表名加固定的后缀（比如加_to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;自增id用完怎么办&#34;&gt;&lt;strong&gt;自增id用完怎么办&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1、主键id&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    **再申请下一个 id 时，得到的值保持不变。**所以到最大值之后，再申请id，由于id不变，所以插入会报主键冲突，如果数据量比较大，主键id应该用 bigint unsigned。默认是无符号整型 (unsigned int) ，4 个字节232-1（4294967295）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、系统row_id&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    **如果创建的 InnoDB 表没有指定主键，那么 InnoDB 会创建一个不可见的，长度为 6 个字节的 row_id。**InnoDB 维护了一个全局的 dict_sys.row_id 值，所有无主键的 InnoDB 表，每插入一行数据，都把当前的 dict_sys.row_id 值作为要插入数据的 row_id，然后把 dict_sys.row_id 的值加 1。&lt;/p&gt;
&lt;p&gt;​    实际上，在代码实现时 row_id 是一个长度为 8 字节的无符号长整型 (bigint unsigned)。但是，InnoDB 在设计时，给 row_id 留的只是 6 个节的长度，这样写到数据表中时只放了最后 6 个字节，所以 row_id 能写到数据表中的值，就有两个特征：&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;248-1到 264 之间，row_id 会是0，264 之后会从0开始。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;在 InnoDB 逻辑里，申请到 row_id=N 后，就将这行数据写入表中；如果表中已经存在 row_id=N 的行，新写入的行就会覆盖原有的行。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;覆盖数据，就意味着数据丢失，影响的是数据可靠性；报主键冲突，是插入失败，影响的是可用性。而一般情况下，可靠性优先于可用性。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、Xid&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    redo log 和 binlog 相配合的时候，提到了有一个共同的字段叫作 Xid。它在 MySQL 中是用来对应事务的。&lt;/p&gt;
&lt;p&gt;​    MySQL 内部维护了一个全局变量 global_query_id，每次执行语句的时候将它赋值给 Query_id，然后给这个变量加 1。如果当前语句是这个事务执行的第一条语句，那么 MySQL 还会同时把 Query_id 赋值给这个事务的 Xid。&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;而 global_query_id 是一个纯内存变量，重启之后就清零了。所以就知道了，在同一个数据库实例中，不同事务的 Xid 也是有可能相同的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;但是 MySQL 重启之后会重新生成新的 binlog 文件，这就保证了，同一个 binlog 文件里，Xid 一定是惟一的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;但是 global_query_id 定义的长度是 8 个字节，这个自增值的上限是 264-1。理论上也是可能重复的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4、trx_id&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;Xid 是由 server 层维护的。InnoDB 内部使用 Xid，就是为了能够在 InnoDB 事务和 server 之间做关联。但是，InnoDB 自己的 trx_id，是另外维护的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    InnoDB 内部维护了一个 max_trx_id 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，然后并将 max_trx_id 加 1。&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;InnoDB 数据可见性的核心思想是：每一行数据都记录了更新它的 trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的 trx_id 做对比。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;对于正在执行的事务，可以从 information_schema.innodb_trx 表中看到事务的 trx_id。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;update 和 delete 语句除了事务本身，还涉及到标记删除旧数据，也就是要把数据放到 purge 队列里等待后续物理删除，这个操作也会把 max_trx_id+1， 因此在一个事务中至少加 2；&lt;/p&gt;
&lt;p&gt;InnoDB 的后台操作，比如表的索引信息统计这类操作，也是会启动内部事务的，因此你可能看到，trx_id 值并不是按照加 1 递增的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;​    **只读事务会分配一个特殊的，比较大的id，**把当前事务的 trx 变量的指针地址转成整数，再加上 248，使用这个算法，就可以保证以下两点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;因为同一个只读事务在执行期间，它的指针地址是不会变的，所以不论是在 innodb_trx 还是在 innodb_locks 表里，同一个只读事务查出来的 trx_id 就会是一样的。&lt;/li&gt;
&lt;li&gt;如果有并行的多个只读事务，每个事务的 trx 变量的指针地址肯定不同。这样，不同的并发只读事务，查出来的 trx_id 就是不同的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​    加上248是为了保证只读事务显示的 trx_id 值比较大，正常情况下就会区别于读写事务的 id。理论情况下也可能只读事务与读写事务相等，但是没有影响。&lt;/p&gt;
&lt;p&gt;​    max_trx_id 会持久化存储，重启也不会重置为 0，那么从理论上讲，只要一个 MySQL 服务跑得足够久，就&lt;strong&gt;可能出现 max_trx_id 达到 248-1 的上限，然后从 0 开始的情况。当达到这个状态后，MySQL 就会持续出现一个脏读的 bug。因为后续的trx_id肯定比末尾那些trx_id大，能看到这些数据。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5、thread_id&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    系统保存了一个全局变量 thread_id_counter，每新建一个连接，就将 thread_id_counter 赋值给这个新连接的线程变量。定义的大小是 4 个字节，因此达到 232-1 后，它就会重置为 0，然后继续增加。但是，在 show processlist 里不会看到两个相同的 thread_id。因为 MySQL 设计了一个唯一数组的逻辑，给新线程分配 thread_id 的时候，逻辑代码是这样的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;do {&lt;br&gt;
new_id= thread_id_counter++;&lt;br&gt;
} while (!thread_ids.insert_unique(new_id).second);&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;count-语句分析&#34;&gt;&lt;strong&gt;count(*) 语句分析&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;​    MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；&lt;/p&gt;
&lt;p&gt;​    InnoDB 引擎就麻烦了，执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。因为多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。&lt;/p&gt;
&lt;p&gt;​    count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。&lt;br&gt;
​    所以，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;按照效率排序的话，count(字段) &amp;lt; count(主键id) &amp;lt; count(1) &amp;lt; count(*)，所以建议，尽量使用count(*)。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;order-by-语句分析&#34;&gt;&lt;strong&gt;order by 语句分析&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;​    MySQL 会给每个线程分配一块内存用于&lt;strong&gt;快速排序&lt;/strong&gt;，称为 &lt;strong&gt;sort_buffer&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;​    explain 结果里的 Extra 这个字段中的“Using filesort”表示的就是需要排序。&lt;/p&gt;
&lt;p&gt;​    sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;建立联合索引，甚至覆盖索引，可以避免排序过程。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;join-语句分析&#34;&gt;&lt;strong&gt;join 语句分析&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;​    直接使用 join 语句，MySQL 优化器可能会选择表 t1 或 t2 作为驱动表，改用 straight_join 让 MySQL 使用固定的连接方式执行查询，这样优化器只会按照指定的方式去 join。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;select * from t1 straight_join t2 on (t1.a=t2.a);&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://segmentfault.com/img/bVbxvfJ?w=1394&amp;amp;h=163&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
在这条语句里，&lt;strong&gt;被驱动表 t2 的字段 a 上有索引，join 过程用上了这个索引，因此效率是很高的。称之为“Index Nested-Loop Join”，简称 NLJ。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;如果被驱动表 t2 的字段 a 上没有索引，那每次到 t2 去匹配的时候，就要做一次全表扫描。这个效率很低。这个算法叫做“Simple Nested-Loop Join”的算法，简称 BNL。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    所以在判断要不要使用 join 语句时，就是看 explain 结果里面，Extra 字段里面有没有出现“Block Nested Loop”字样。&lt;/p&gt;
&lt;p&gt;​    在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;Multi-Range Read 优化，这个优化的主要目的是尽量使用顺序读盘。因为大多数的数据都是按照主键递增顺序插入得到的，所以可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;select * from t1 where a&amp;gt;=1 and a&amp;lt;=100;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://segmentfault.com/img/bVbxvfN?w=1583&amp;amp;h=149&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;strong&gt;Batched Key Access(BKA) 算法。这个 BKA 算法，其实就是对 NLJ 算法的优化。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    NLJ 算法执行的逻辑是：从驱动表 t1，一行行地取出 a 的值，再到被驱动表 t2 去做 join。也就是说，对于表 t2 来说，每次都是匹配一个值。这时，MRR 的优势就用不上了。&lt;/p&gt;
&lt;p&gt;​    既然如此，就把表 t1 的数据取出来一部分，先放到一个临时内存。这个临时内存就是 join_buffer。&lt;/p&gt;
&lt;h3 id=&#34;自增主键&#34;&gt;&lt;strong&gt;自增主键&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://segmentfault.com/img/bVbxvfO?w=1430&amp;amp;h=542&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
表定义里面出现了一个 AUTO_INCREMENT=2，表示下一次插入数据时，如果需要自动生成自增值，会生成 id=2。&lt;/p&gt;
&lt;p&gt;实际上，表的结构定义存放在后缀名为.frm 的文件中，但是并不会保存自增值。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MyISAM 引擎的自增值保存在数据文件中。&lt;/li&gt;
&lt;li&gt;InnoDB 引擎的自增值，其实是保存在了内存里，MySQL 8.0 版本后，才有了“自增值持久化”的能力。
&lt;ul&gt;
&lt;li&gt;MySQL 5.7 及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值 max(id)，然后将 max(id)+1 作为这个表当前的自增值。&lt;/li&gt;
&lt;li&gt;MySQL 8.0 版本，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;自增值修改机制&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果插入数据时 id 字段指定为 0、null 或未指定值，那么就把这个表当前的 AUTO_INCREMENT 值填到自增字段；&lt;/li&gt;
&lt;li&gt;如果插入数据时 id 字段指定了具体的值 X ，就直接使用语句里指定的值 Y。
&lt;ul&gt;
&lt;li&gt;如果 X &amp;lt; Y，那么这个表的自增值不变；&lt;/li&gt;
&lt;li&gt;如果 X≥Y，就需要把当前自增值修改为新的自增值。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​    &lt;strong&gt;新的自增值生成算法是：从 auto_increment_offset 开始，以 auto_increment_increment 为步长，持续叠加，直到找到第一个大于 X 的值，作为新的自增值。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;自增值的修改时机&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;执行器调用 InnoDB 引擎接口写入一行，传入的这一行的值(0,1,1);&lt;/li&gt;
&lt;li&gt;InnoDB 发现用户没有指定自增 id 的值，获取表 t 当前的自增值 2；&lt;/li&gt;
&lt;li&gt;将传入的行的值改成 (2,1,1);&lt;/li&gt;
&lt;li&gt;将表的自增值改成 3；&lt;/li&gt;
&lt;li&gt;继续执行插入数据操作，由于已经存在 c=1 的记录，所以报 Duplicate key error，语句返回。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​    所以，sql执行报错了，自增值已经改变了，&lt;strong&gt;唯一键冲突是导致自增主键 id 不连续的第一种原因。同样地，事务回滚也会产生类似的现象，这就是第二种原因。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;批量插入的时候，由于系统预先不知道要申请多少个自增 id，所以就先申请一个，然后两个，然后四个，直到够用。这是主键 id 出现自增 id 不连续的第三种原因。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;备份恢复&#34;&gt;备份恢复&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;保存一定时间的binlog，同时系统会定期做整库备份。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当需要恢复到指定的某一秒时，&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先，找到最近的一次全量备份，如果运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库&lt;/li&gt;
&lt;li&gt;然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到指定的那个时刻。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​    **redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。**这个参数建议设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。&lt;/p&gt;
&lt;p&gt;​    **binlog用于备份恢复和从库同步。sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。**这个参数也建议设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。&lt;/p&gt;
&lt;h3 id=&#34;主备同步&#34;&gt;&lt;strong&gt;主备同步&lt;/strong&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。&lt;/li&gt;
&lt;li&gt;在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。&lt;/li&gt;
&lt;li&gt;主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。&lt;/li&gt;
&lt;li&gt;备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。&lt;/li&gt;
&lt;li&gt;sql_thread 读取中转日志，解析出日志里的命令，并执行。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://segmentfault.com/img/bVbxvfj?w=1142&amp;amp;h=856&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
一主一备结构，需要注意主备切换，备库设置只读，避免切换bug造成双写不一致问题（设置 readonly 对超级用户是无效的，同步更新的线程有超级权限，所以还能写入同步数据）。&lt;/p&gt;
&lt;p&gt;​    双主结构，要避免循环更新问题，因为MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的 server id。所以可以规定两个库的 server id 必须不同，每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。&lt;/p&gt;
&lt;h3 id=&#34;主备延迟&#34;&gt;&lt;strong&gt;主备延迟&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;​    **可以在备库上执行 show slave status 命令，它的返回结果里面会显示 seconds_behind_master，用于表示当前备库延迟了多少秒。**每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间； 备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 seconds_behind_master。&lt;/p&gt;
&lt;p&gt;主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢。&lt;/p&gt;
&lt;p&gt;主备延迟的来源&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;考虑到主备切换，主备机器一般都一样了，但是还可能备库读的压力太大，&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一主多从，或者通过binlog输出到外部系统(比如Hadoop)，让外部系统提供部分统计查询能力。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;大事务，如果事务执行十分钟，那就会导致主从延迟十分钟。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;主备复制策略&#34;&gt;&lt;strong&gt;主备复制策略&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;​    &lt;strong&gt;在官方的 5.6 版本之前，MySQL 只支持单线程复制&lt;/strong&gt;，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。&lt;/p&gt;
&lt;p&gt;​    并行复制策略有按表并行分发策略，按行并行分发策略，但是按行分发在决定线程分发的时候，需要消耗更多的计算资源。这两个方案其实都有一些约束条件：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；&lt;/li&gt;
&lt;li&gt;表必须有主键；&lt;/li&gt;
&lt;li&gt;不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​    **官方 MySQL5.6 版本，支持了并行复制，只是支持的粒度是按库并行。**相比于按表和按行分发，这个策略有两个优势：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;构造 hash 值的时候很快，只需要库名；而且一个实例上 DB 数也不会很多，不会出现需要构造 100 万个项这种情况。&lt;/li&gt;
&lt;li&gt;不要求 binlog 的格式。因为 statement 格式的 binlog 也可以很容易拿到库名。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​    &lt;strong&gt;MariaDB 的并行复制策略，伪模拟主库并发度&lt;/strong&gt;，主库 redo log 组提交 (group commit) 优化，同一组提交会记录commit_id，备库把同一个commit_id分发到多个worker执行。&lt;/p&gt;
&lt;p&gt;官方的 MySQL5.7 版本，由参数 slave-parallel-type 来控制并行复制策略：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；&lt;/li&gt;
&lt;li&gt;配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​    **MySQL 5.7.22 版本里，MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。**对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。&lt;/p&gt;
&lt;h3 id=&#34;union和union-all&#34;&gt;&lt;strong&gt;Union和Union All&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Union：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序；&lt;/p&gt;
&lt;p&gt;Union All：对两个结果集进行并集操作，包括重复行，不进行排序；&lt;/p&gt;
&lt;h3 id=&#34;join&#34;&gt;Join&lt;/h3&gt;
&lt;p&gt;1.inner join（内连接），在两张表进行连接查询时，只保留两张表中完全匹配的结果集。&lt;/p&gt;
&lt;p&gt;2.left join,在两张表进行连接查询时，会返回左表所有的行，即使在右表中没有匹配的记录。&lt;/p&gt;
&lt;p&gt;3.right join,在两张表进行连接查询时，会返回右表所有的行，即使在左表中没有匹配的记录。&lt;/p&gt;
&lt;p&gt;4.full join,在两张表进行连接查询时，返回左表和右表中所有没有匹配的行。&lt;/p&gt;
">mysql面试</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/sql-yuanli/"" data-c="
          &lt;h3 id=&#34;第一步连接器连接到数据库&#34;&gt;第一步，连接器连接到数据库&lt;/h3&gt;
&lt;p&gt;连接器负责跟客户端建立连接、获取权限、维持和管理连接。&lt;/p&gt;
&lt;p&gt;连接完成后，如果没有后续的动作，这个连接就处于空闲状态，可以在&lt;strong&gt;show processlist&lt;/strong&gt;命令中看到它。文本中这个图是show processlist的结果，其中的Command列显示为&amp;quot;Sleep&amp;quot;的这一行，就表示现在系统里面有一个空闲连接。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/3164013193-5d765911bd997_articlex.png&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;​    客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数&lt;strong&gt;wait timeout&lt;/strong&gt;控制的，默认值是8小时。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;断开后再执行sql会报错：Lost connection to MySQL server during query&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;​    建立连接的过程通常是比较复杂的，所以建议在使用中要尽量减少建立连接的动作，也就是&lt;strong&gt;尽量使用长连接。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    但是 MySQL 在执行过程中临时使用的&lt;strong&gt;内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放&lt;/strong&gt;。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启。&lt;/p&gt;
&lt;p&gt;怎么解决这个问题呢？可以考虑以下两种方案。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;如果用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql reset connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证但是会将连接恢复到刚刚创建完时的状态。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第二步查询语句会先查询缓存&#34;&gt;第二步，查询语句会先查询缓存&lt;/h3&gt;
&lt;p&gt;之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。&lt;/p&gt;
&lt;p&gt;​    但是&lt;strong&gt;查询缓存利大于弊&lt;/strong&gt;，因为&lt;strong&gt;查询缓存的失效非常频繁&lt;/strong&gt;，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。&lt;/p&gt;
&lt;p&gt;​    除非是静态配置表才适合用查询缓存。&lt;strong&gt;可以将参数 query_cache_type 设置成DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。SQL_CACHE 显式指定使用查询缓存。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;select SQL_CACHE * from T where ID=10；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;​    但是，&lt;strong&gt;MySQL 8.0版本彻底删除了查询缓存功能。&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第三步分析语句先是词法分析&#34;&gt;第三步，分析语句，先是词法分析&lt;/h3&gt;
&lt;p&gt;找出select，表名，列名等关键字；然后是语法分析，判断语法是否正确。&lt;strong&gt;表名列名不对的sql，会在语法分析时报错。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;语法错误：ERROR 1064 (42000): You have an error in your SQL syntax;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第四步优化器&#34;&gt;&lt;strong&gt;第四步&lt;/strong&gt;，优化器&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;决定使用哪个索引，join的时候决定各个表的连接顺序。&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第五步-执行器&#34;&gt;第五步、执行器&lt;/h3&gt;
&lt;p&gt;​    &lt;strong&gt;先判断对当前表是否有权限（如果命中查询缓存，会在返回结果时验证权限）。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ERROR 1142 (42000): SELECT command denied to user &#39;b&#39;@&#39;localhost&#39; for table &#39;T&#39;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;​    如：select * from T where ID=10; 执行过程&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；&lt;/li&gt;
&lt;li&gt;调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。&lt;/li&gt;
&lt;li&gt;执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;慢查询日志中有一行 rows_examined 字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。但是引擎扫描行数跟 rows_examined 并不是完全相同的。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;查询的数据如何返回&#34;&gt;&lt;strong&gt;查询的数据如何返回&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对一个200G的大表做全表扫描，而内存只有16G，会不会把数据库主机的内存用光了？&lt;/p&gt;
&lt;p&gt;实际上，MySQL不是取到全部数据再返回客户端。取数据和发数据的流程是这样的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。&lt;/li&gt;
&lt;li&gt;重复获取行，直到 net_buffer 写满，调用网络接口发出去。&lt;/li&gt;
&lt;li&gt;如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。&lt;/li&gt;
&lt;li&gt;如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MySQL 客户端发送请求后，接收服务端返回结果的方式有两种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;一种是本地缓存，也就是在本地开一片内存，先把结果存起来。如果用 API 开发，对应的就是 mysql_store_result 方法。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;另一种是不缓存，读一个处理一个。如果用 API 开发，对应的就是 mysql_use_result 方法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;MySQL 客户端默认采用第一种方式，而如果加上–quick 参数，就会使用第二种不缓存的方式。&lt;/p&gt;
&lt;p&gt;采用不缓存的方式时，如果本地处理得慢，就会导致服务端发送结果被阻塞，因此会让服务端变慢。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​    &lt;strong&gt;MySQL 是“边读边发的”。这就意味着，如果客户端接收得慢，会导致 MySQL 服务端由于结果发不出去，这个事务的执行时间变长。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;对于正常的线上业务来说，如果一个查询的返回结果不会很多的话，都建议使用 mysql_store_result 这个接口，直接把查询结果保存到本地内存。&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;sql语句的执行顺序&#34;&gt;SQL语句的执行顺序&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;sql&lt;/code&gt;语句的执行顺序可通过下图了解，注意&lt;code&gt;sql&lt;/code&gt;是从from开始执行的。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/51-966027615.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;FROM 
WHERE 
GROUP BY 
HAVING 
SELECT 
DISTINCT 
UNION 
ORDER BY 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;1、FROM 才是 SQL 语句执行的第一步，并非 SELECT 。数据库在执行 SQL 语句的第一步是将数据从硬盘加载到数据缓冲区中， 以便对这些数据进行操作。&lt;/p&gt;
&lt;p&gt;2、SELECT 是在大部分语句执行了之后才执行的，严格的说是在 FROM 和 GROUP BY 之后执行的。理解这一点是非常重要的，这就是你 不能在 WHERE 中使用在 SELECT 中设定别名的字段作为判断条件的原因。&lt;/p&gt;
&lt;p&gt;3、无论在语法上还是在执行顺序上， UNION 总是排在 ORDER BY 之前。很多人认为每个 UNION 段都能使用 ORDER BY 排序，但是根据  SQL 语言标准和各个数据库 SQL 的执行差异来看，这并不是真的。尽管某些数据库允许 SQL 语句对子查询（subqueries）或者派生表 （derived tables）进行排序，但是这并不说明这个排序在 UNION 操作过后仍保持排序后的顺序。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;更新语句执行过程&#34;&gt;更新语句执行过程&lt;/h2&gt;
&lt;p&gt;比如：update T set c=c+1 where ID=2;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;执行器先找引擎取 ID=2 这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。&lt;/li&gt;
&lt;li&gt;执行器拿到引擎给的行数据，把这个值加上 1，得到新的一行数据，再调用引擎接口写入这行新数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;执行器生成这个操作的 binlog，并把 binlog 写入磁盘。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里给出这个 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。&lt;strong&gt;其实就是把redo log 和binlog 做两阶段提交，为了让两份日志之间的逻辑一致。&lt;/strong&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/2966732684-5d76598f95aad_articlex.png&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
">1、sql原理</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/table/"" data-c="
          &lt;h2 id=&#34;数据库的定义&#34;&gt;数据库的定义&lt;/h2&gt;
&lt;p&gt;很多开发者在最开始时其实都对数据库有一个比较模糊的认识，觉得数据库就是一堆数据的集合，但是实际却比这复杂的多，数据库领域中有两个词非常容易混淆，也就是_数据库&lt;em&gt;和&lt;/em&gt;实例_：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据库：物理操作文件系统或其他形式文件类型的集合；&lt;/li&gt;
&lt;li&gt;实例：MySQL 数据库由后台线程以及一个共享内存区组成；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据库和实例&#34;&gt;数据库和实例&lt;/h3&gt;
&lt;p&gt;在 MySQL 中，实例和数据库往往都是一一对应的，而我们也无法直接操作数据库，而是要通过数据库实例来操作数据库文件，可以理解为数据库实例是数据库为上层提供的一个专门用于操作的接口。&lt;/p&gt;
&lt;p&gt;在 Unix 上，启动一个 MySQL 实例往往会产生两个进程，&lt;code&gt;mysqld&lt;/code&gt; 就是真正的数据库服务守护进程，而 &lt;code&gt;mysqld_safe&lt;/code&gt; 是一个用于检查和设置 &lt;code&gt;mysqld&lt;/code&gt; 启动的控制程序，它负责监控 MySQL 进程的执行，当 &lt;code&gt;mysqld&lt;/code&gt; 发生错误时，&lt;code&gt;mysqld_safe&lt;/code&gt; 会对其状态进行检查并在合适的条件下重启。&lt;/p&gt;
&lt;h3 id=&#34;mysql-的架构&#34;&gt;MySQL 的架构&lt;/h3&gt;
&lt;p&gt;MySQL 从第一个版本发布到现在已经有了 20 多年的历史，在这么多年的发展和演变中，整个应用的体系结构变得越来越复杂：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/Logical-View-of-MySQL-Architecture.jpg&#34; alt=&#34;Logical-View-of-MySQL-Architecture&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;最上层用于连接、线程处理的部分并不是 MySQL 『发明』的，很多服务都有类似的组成部分；第二层中包含了大多数 MySQL 的核心服务，包括了对 SQL 的解析、分析、优化和缓存等功能，存储过程、触发器和视图都是在这里实现的；而第三层就是 MySQL 中真正负责数据的存储和提取的存储引擎，例如：&lt;a href=&#34;https://en.wikipedia.org/wiki/InnoDB&#34;&gt;InnoDB&lt;/a&gt;、&lt;a href=&#34;https://en.wikipedia.org/wiki/MyISAM&#34;&gt;MyISAM&lt;/a&gt; 等，文中对存储引擎的介绍都是对 InnoDB 实现的分析。&lt;/p&gt;
&lt;h3 id=&#34;如何存储表&#34;&gt;如何存储表&lt;/h3&gt;
&lt;p&gt;MySQL 使用 InnoDB 存储表时，会将&lt;strong&gt;表的定义&lt;/strong&gt;和&lt;strong&gt;数据索引&lt;/strong&gt;等信息分开存储，其中前者存储在 &lt;code&gt;.frm&lt;/code&gt; 文件中，后者存储在 &lt;code&gt;.ibd&lt;/code&gt; 文件中，这一节就会对这两种不同的文件分别进行介绍。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;.frm 文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;无论在 MySQL 中选择了哪个存储引擎，所有的 MySQL 表都会在硬盘上创建一个 &lt;code&gt;.frm&lt;/code&gt; 文件用来描述表的格式或者说定义；&lt;code&gt;.frm&lt;/code&gt; 文件的格式在不同的平台上都是相同的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE TABLE test_frm(    column1 CHAR(5),    column2 INTEGER);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当我们使用上面的代码创建表时，会在磁盘上的 &lt;code&gt;datadir&lt;/code&gt; 文件夹中生成一个 &lt;code&gt;test_frm.frm&lt;/code&gt; 的文件，这个文件中就包含了表结构相关的信息：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/frm-file-hex.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/frm-file-hex.png&#34; alt=&#34;frm-file-hex&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;.ibd 文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;InnoDB 中用于存储数据的文件总共有两个部分，一是&lt;strong&gt;系统表空间文件&lt;/strong&gt;，包括 &lt;code&gt;ibdata1&lt;/code&gt;、&lt;code&gt;ibdata2&lt;/code&gt; 等文件，其中存储了 InnoDB 系统信息和用户数据库表数据和索引，是所有表公用的。&lt;/p&gt;
&lt;p&gt;当打开 &lt;code&gt;innodb_file_per_table&lt;/code&gt; 选项时，&lt;code&gt;.ibd&lt;/code&gt; 文件就是每一个表独有的表空间，文件存储了当前表的数据和相关的索引数据。&lt;/p&gt;
&lt;h3 id=&#34;索引组织表&#34;&gt;&lt;strong&gt;索引组织表&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;在InnoDb存储引擎中，表都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表（index organized table）。在InnoDB存储引擎表中，每张表都有个主键（primary key)，如果在创建表时没有显示地定义主键，则InnoDB存储引擎会按如下方式选择或创建主键：&lt;/p&gt;
&lt;p&gt;1、首先判断表中是否有非空的唯一索引（unique not null),以该列为主键&lt;/p&gt;
&lt;p&gt;2、否则自动创建一个6字节大小的指针&lt;/p&gt;
&lt;p&gt;当表中有多个非空唯一索引时，选择建表时&lt;strong&gt;第一个定义&lt;/strong&gt;的非空唯一索引为主键。&lt;strong&gt;主键的选择根据的是定义索引的顺序，而不是建表时列的顺序&lt;/strong&gt;。 _rowid可以显示表（单个列为主键时）的主键。&lt;/p&gt;
&lt;p&gt;MySQL查询过程&lt;/p&gt;
&lt;p&gt;1、InnoDb通过B+Tree聚集索引搜索时，只能找到该记录所在的索引页(index page)，而不能到具体的行记录。&lt;/p&gt;
&lt;p&gt;2、找到该索引页(index page)后将该页加载入内存。&lt;/p&gt;
&lt;p&gt;3、通过key在索引页(index page)的directory slots中进行二分查找（binary search），找到key对应的slot。&lt;/p&gt;
&lt;p&gt;4、因为slot是管理多条记录，普通的slot最少管辖4条,最多管辖8条,所以会再根据KEY在对应的slot管理的记录中顺序（linear search） 查找，找到最终结果。&lt;/p&gt;
&lt;h3 id=&#34;innodb逻辑存储结构&#34;&gt;&lt;strong&gt;InnoDB逻辑存储结构&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;从InnoDB存储引擎的逻辑存储结构看，所有数据都被逻辑的存放在一个空间中，称为表空间（tablespace）。表空间（tablespace）是存储引擎中最高的存储逻辑单位。表空间又由段（segment），区（extent),页（page)组成。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboar111d.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;表空间&#34;&gt;表空间&lt;/h4&gt;
&lt;p&gt;如果启动了innodb_file_per_table的参数，需要注意的是每张表的表空间内存放的只是数据、索引和插入缓冲Bitmap页，而其他数据如回滚（undo）信息，插入缓冲索引页，系统事务信息，二次写缓冲（double write buffer）还是放在共享表空间内，共享表空间还是会不断地增加大小。&lt;/p&gt;
&lt;p&gt;共享表空间和独立表空间的区别&lt;/p&gt;
&lt;h5 id=&#34;共享表空间&#34;&gt;共享表空间&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：可以将表空间分成多个文件存放到各个磁盘上（表空间文件大小不受表大小的限制，如一个表可以分布在不同的文件上）。&lt;/p&gt;
&lt;p&gt;缺点： 所有的数据和索引存放到一个文件中，虽然可以把一个大文件分成多个小文件，但是多个表及索引在表空间中混合存储，这样对于一个表做了大量删除操作后表空间中将会有大量的空隙；共享表空间分配后不能回缩，&lt;strong&gt;当出现临时建索引&lt;/strong&gt;或是&lt;strong&gt;创建一个临时表&lt;/strong&gt;的操作表空间扩大后，就是删除相关的表也没办法回缩那部分空间了（可以理解为oracle的表空间10G，但是才使用10M，但是操作系统显示mysql的表空间为10G），进行数据库的冷备很慢；&lt;/p&gt;
&lt;h5 id=&#34;独立表空间&#34;&gt;独立表空间&lt;/h5&gt;
&lt;p&gt;优点：&lt;/p&gt;
&lt;p&gt;1.每个表都有自已独立的表空间。&lt;/p&gt;
&lt;p&gt;2.每个表的数据和索引都会存在自已的表空间中。&lt;/p&gt;
&lt;p&gt;3.可以实现单表在不同的数据库中移动。&lt;/p&gt;
&lt;p&gt;4.空间可以回收（除drop table操作外，表空不能自已回收）&lt;/p&gt;
&lt;p&gt;缺点： 单表增加过大，当单表占用空间过大时，存储空间不足，只能从操作系统层面思考解决方法；&lt;/p&gt;
&lt;p&gt;推荐使用独立表空间的原因：共享表空间在Insert操作上少有优势。其它都没独立表空间表现好。&lt;/p&gt;
&lt;h4 id=&#34;段&#34;&gt;&lt;strong&gt;段&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;InnoDB存储引擎表是索引组织的（indexed organized），因此数据即索引，索引即数据。那么数据段即为B+树的叶子节点（leaf node  segment)，索引段即为B+树的非叶子节点（Non-leaf node segment)&lt;/p&gt;
&lt;h4 id=&#34;区&#34;&gt;&lt;strong&gt;区&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;区是由连续页组成的空间，在任何情况下每个区的大小都为1MB。为了保证区中页的连续性，InnoDB存储引擎一次从磁盘中申请4~5个区， 默认每个页的大小为16KB。这连续的数据页是在逻辑上是连续的，有可能在物理磁盘上是分散。一旦区间分配给某个对象（表、索引及簇）， 则该区间就不能再分配给其它的对象.&lt;/p&gt;
&lt;h4 id=&#34;页&#34;&gt;&lt;strong&gt;页&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;同一个数据库实例的所有表空间都有相同的页大小；默认情况下，表空间中的页大小都为 16KB，当然也可以通过改变 innodb_page_size  选项对默认大小进行修改，需要注意的是不同的页大小最终也会导致区大小的不同。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/cliphjhjhboard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;innodb数据页结构&#34;&gt;&lt;strong&gt;InnoDB数据页结构&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;页是 InnoDB 存储引擎管理数据的最小磁盘单位，而 B-Tree 节点就是实际存放表中数据的页面；fileheader、pageHeader、 fileTrailer的大小是固定的，分别是38,56,8字节。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboard123.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboard2413.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;内部的 &lt;strong&gt;Page Header/Page Directory 关心的是页的状态信息，而 Fil Header/Fil Trailer 关心的是记录页的头信息&lt;/strong&gt;。在File header中 ，FIL+PAGE_PREV,FIL_PAGE_NEXT两个表示当前页的上一页和下一页，由此可以看出&lt;strong&gt;叶子节点是双向链表串起来的&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;infimum-supremum&#34;&gt;Infimum + Supremum&lt;/h3&gt;
&lt;p&gt;在InnoDB中，每个数据页中有两个虚拟的行记录，&lt;strong&gt;用来限定记录的边界&lt;/strong&gt;。Infimum记录的是比该页数据中 任何主键值都小的值，Supremum指比任何可能大的值还要大的值。这两个值在页创建时被建立，并且在任何情 况下不会被删除。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipweweboard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;user-records-和-free-space-user-records&#34;&gt;User Records 和 Free Space User Records&lt;/h3&gt;
&lt;p&gt;整个页面中真正用于存放行记录的部分，而 Free Space 就是空余空间了，它是一个&lt;strong&gt;链表的数据结构&lt;/strong&gt;，为了保证插入和删除的效率，整个页面并&lt;strong&gt;不会按照主键顺序对所有记录进行排序&lt;/strong&gt;，它会自动&lt;strong&gt;从左侧向右寻找空白节点进行插入&lt;/strong&gt;，&lt;strong&gt;行记录在物理存储上并不是按照顺序的 ，它们之间的顺序是由 next_record 这一指针控制的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;B+ 树在查找对应的记录时，并不会直接从树中找出对应的行记录，&lt;strong&gt;它只能获取记录所在的页&lt;/strong&gt;，将整个页加载到内存中，再通过 Page Directory 中存储的稀疏索引和 n_owned、next_record 属性进行二叉查找取出对应的记录，不过因为这一操作是在内存中进行的，所以通常会忽略这部分查找的耗时。&lt;/p&gt;
&lt;p&gt;完全空闲的页是没有 User Records部分的； 插入数据时，从Free Space分配空间给User Records，直到Free Space没有空间或空间不够分配新的记录，这时需要申请新的页&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipbohhkshfard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;page-directory&#34;&gt;Page Directory&lt;/h3&gt;
&lt;p&gt;存放了&lt;strong&gt;记录的相对位置&lt;/strong&gt;（页相对位置，不是偏移量），这些记录指针称为（slots)或目录槽（Directory Slots) 。&lt;strong&gt;InnoDB并不是每个记录拥有一个槽，InnoDB的槽是一个稀疏目录&lt;/strong&gt;（sparse directory),即一个槽中可能包含多个记录。&lt;/p&gt;
&lt;p&gt;在Slots中&lt;strong&gt;记录按照索引键值从小到大顺序存放的一个数组&lt;/strong&gt;，这样可以利用二叉查找迅速找到记录的指针。然而二叉查找的结果只是一个粗略结果 ，因此InnoDB引擎必须通过recorderheader中的next_recored来继续查找相关记录。&lt;/p&gt;
&lt;p&gt;从上图可以看出Page Directory包含至少两个infimum slot,supermum slot，slot指向record(rec)指针(pointer to ‘A’), n_owned代表的是向前有多少个rec属于这个slot，中间被管辖的rec的n_owned = 0。 通过directory的二分查找只能查到对应记录所属的slot，还需要通过slot内部的二分查找才能精确定位到对应的记录。&lt;strong&gt;这种设计的做法可以减小directory对page空间的占用，又能有很好查找的效率。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;innodb行记录结构&#34;&gt;&lt;strong&gt;InnoDB行记录结构&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;与现有的大多数存储引擎一样，InnoDB 使用页作为磁盘管理的最小单位；数据在 InnoDB 存储引擎中都是按行存储的，每个 16KB 大小的页中可以存放 2-200 行的记录。&lt;/p&gt;
&lt;p&gt;当 InnoDB 存储数据时，它可以使用不同的行格式进行存储；MySQL 5.7 版本支持以下格式的行存储方式：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/Antelope-Barracuda-Row-Format.jpg&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/Antelope-Barracuda-Row-Format.jpg&#34; alt=&#34;Antelope-Barracuda-Row-Format&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;Antelope 是 InnoDB 最开始支持的文件格式，它包含两种行格式 Compact 和 Redundant，它最开始并没有名字；Antelope 的名字是在新的文件格式 Barracuda 出现后才起的，Barracuda 的出现引入了两种新的行格式 Compressed 和 Dynamic；InnoDB 对于文件格式都会向前兼容，而官方文档中也对之后会出现的新文件格式预先定义好了名字：Cheetah、Dragon、Elk 等等。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;两种行记录格式 Compact 和 Redundant 在磁盘上按照以下方式存储：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipbouduiodard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;Compact 和 Redundant 格式最大的不同就是记录格式的第一个部分；&lt;strong&gt;在 Compact 中，行记录的第一部分倒序存放了一行数据中列的长度 （Length），而 Redundant 中存的是每一列的偏移量（Offset）&lt;/strong&gt;，从总体上上看，Compact 行记录格式相比 Redundant 格式能够减少20% 的存储空间。&lt;/p&gt;
&lt;h4 id=&#34;1-变长字段长度列表&#34;&gt;1、变长字段长度列表&lt;/h4&gt;
&lt;p&gt;Compact行记录格式的首部是一个非NULL变长字段长度列表，并且是按照列的顺序的逆序放置的，其长度为： 若列的长度小于255字节，用1字节表示； 若列的长度大于255字节，用2字节表示。变长字段的长度最大不可以超过2字节，因为Varchar类型的最大长度限制为65535.&lt;/p&gt;
&lt;h4 id=&#34;2-null标志位&#34;&gt;2、NULL标志位&lt;/h4&gt;
&lt;p&gt;用一个字节来表示，指示了该行数据中是否有NULL值，有则用1表示，同样是逆序放置。&lt;/p&gt;
&lt;h4 id=&#34;3-记录头信息&#34;&gt;3、记录头信息&lt;/h4&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/cliphhjhboard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipbojhjhard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h5 id=&#34;delete_mask&#34;&gt;delete_mask&lt;/h5&gt;
&lt;p&gt;被删除的记录值为1, 正常记录为0。delete 语句后的记录不会被立刻删除,而是将这条记录的delete_mask置1, 称为delete mask操作，与真正的直接删除要区分开（update不更新主键且不能就地更新时直接删除，也就是改完delete_mask后直接加入到垃圾链表中）&lt;/p&gt;
&lt;h5 id=&#34;n_owned&#34;&gt;n_owned&lt;/h5&gt;
&lt;p&gt;在页面内为了快速搜索（二分查找）会分组，只有&lt;strong&gt;组内最大记录此字段有值&lt;/strong&gt;，记录组内记录数，除了最小记录,大小一般在4-8区间&lt;/p&gt;
&lt;h5 id=&#34;heap_no&#34;&gt;heap_no&lt;/h5&gt;
&lt;p&gt;记录在页面内其实会组成一个单链表，从头到尾，此属性依次增加. 最小记录为0，最大记录为1，真正记录的这个值从2开始&lt;/p&gt;
&lt;h5 id=&#34;record_type&#34;&gt;record_type&lt;/h5&gt;
&lt;p&gt;0就是我们的一般意义上的记录，1是索引用到的，2是最小记录、3 是最大记录&lt;/p&gt;
&lt;h5 id=&#34;next_record&#34;&gt;next_record&lt;/h5&gt;
&lt;p&gt;本记录的真正数据到下一条记录的真正数据的偏移量（可以当做存了个指针，向后是额外信息，向前是具体的列） 根据这个属性，页面内所有记录都串了一个单链表，&lt;strong&gt;单链表按主键排序&lt;/strong&gt;，从小到大，最小记录与最大记录分别为头结点和尾节点&lt;/p&gt;
&lt;h4 id=&#34;4-正式数据部分&#34;&gt;4、正式数据部分&lt;/h4&gt;
&lt;p&gt;a、表中没有指定主键且没有Unique列, MySQL会为我们添加一个row_id 作为主键,唯一标识一条记录&lt;/p&gt;
&lt;p&gt;b、trx_id 表示最近修改该行数据的事务ID&lt;/p&gt;
&lt;p&gt;c、roll_pointer 则表示指向该行回滚段的指针，该行上所有旧的版本，在undo中都通过链表的形式组织，而该值，正式指向undo中该行的历史记录链表&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;null不占该部分任何空间，即NULL除了占有NULL标志位，实际存储不占有任何空间。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;5-行溢出数据&#34;&gt;5、行溢出数据&lt;/h4&gt;
&lt;p&gt;当 InnoDB 使用 Compact 或者 Redundant 格式存储极长的 VARCHAR 或者 BLOB 这类大对象时，我们并不会直接将所有的内容都存放在数据 页节点中，而是将行数据中的前 768 个字节存储在数据页中，后面会通过偏移量指向溢出页。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboard-1582816818483.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;但是当我们使用新的行记录格式 Compressed 或者 Dynamic 时都只会在行记录中保存 20 个字节的指针，实际的数据都会存放在溢出页面中。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipdfdboard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h1 id=&#34;约束&#34;&gt;&lt;strong&gt;约束&lt;/strong&gt;&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;约束可以保证数据库中数据的完整性：
1、实体完整性保证表中有一个主键
2、域完整性保证每列的值满足特定的条件
3、参照完整性保证两张表之间的关系。

主键约束的默认名为PRIMARY，Unique Key默认约束名和列名一样，也可以人为指定名字。
select constraint_name,consraint_type from infomation_schema.table_constraints where table_schema=&#39;&#39; and table_name=&#39;&#39;;
alter table tbl_name add unique key keyname(col);

索引和约束的区别
约束是一个逻辑的概念，用来保证数据的完整性，而索引是一个数据结构，即有逻辑上的概念，在数据库中还代表着物理存储的方式。

某些情况下MySQL允许非法的或不正确的数据插入或更新，这就需要设置sql_mode来严格审核输入的参数
set sql_mode=&#39;STRICT_TRANS_TABLES&#39;;

ENUM约束
create table a(sex ENUM(&#39;male&#39;,&#39;female&#39;));ENUM约束只对离散值有效。

触发器的作用是在执行INSERT,DELETE,UPDATE命令之前或之后自动调用SQL命令或存储过程。通过触发器也是实现约束的一种手段和方法。
具备super权限的用户才能创建触发器
CREATE [difiner={user|CURRENT_USER}] TRIGGER trigger_name BEFORE|AFTER INSERT|UPDATE|DELERE ON tbl_name FOR 
EACH ROW trigger_stmt;
最多可以为一个表建立6个触发器，分别为INSERT,UPDATA和DELETE的BEFORE和AFTER各定义一个。Mysql只支持FOR EACH ROW.
mysql&amp;gt;DELIMITER $$
mysql&amp;gt;CREATE TRIGGER tgr_usercash_update BEFORE UPDATE ON usercash FOR EACH ROW 
-----&amp;gt;BEGIN
-----&amp;gt;IF new.cash - old.cash &amp;gt; 0 THEN
-----&amp;gt;INSERT INTO ........
-----&amp;gt;END IF
-----&amp;gt;END;
-----&amp;gt;$$
mysql&amp;gt;DELIMITER $$

外键约束

外键用来保证参照完整性，MySQL的MyISAM本身不支持外键，对于外键的定义只是起到一个注释的作用，而InnoDB则完整支持外键约束。
[CONSTRAINT [symbol]] FOREIGN KEY [index_name] (index_col_name,...) REFERENCES tbl_name （index_col_name,....)
[ON DELETE reference_option]
[ON UPDATE reference_option]
reference_option:
RESTRICT|//父表发生delete或update时,抛出错误，不允许此类操作发生。未设置时，此项为默认
CASCADE|//父表发生delete或update时，相应的字表中的数据页进行delete或update操作
SET NULL|//父表发生delete或update时,相应子表中的数据被更新为NULL值，但是子表中的相对应的列必须允许为NULL
NO ACTION//父表发生delete或update时,抛出错误，不允许此类操作发生。
一般来说被引用的表为父表，引用的表称为字表。ON DELETE和ON UPDATE 表示在对父表进行DELETE和UPDATE操作时，对子表做的操作。
create table child(id INT, parent_id INT,FOREGIN KEY(parent_id) REFERENCES parent(id))ENGINE=InnoDB;
InnoDB在建立外键时会自动对该列加一个索引，从而很好地避免外键列上无索引而导致的死锁问题。
对于参照完整性约束，外键能起到一个非常好的作用，但是对于数据的导入操作，外键往往导致在外键约束的检查上花费大量的时间，因为MySQL的外键时即时检查的，所以对导入的每一行都会进行外键检查。但是用户可以忽略外键的检查
set foreign_key_checks=0;
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;临时表&#34;&gt;临时表&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;临时表只在&lt;strong&gt;当前连接可见&lt;/strong&gt;，当关闭连接时，Mysql会自动删除表并释放所有空间,也可以在当前连接未关闭时，手动删除临时表。&lt;/li&gt;
&lt;li&gt;不同连接可以各自创建名字一样的临时表，不会相互冲突，这点不同于 Memory的引擎表&lt;/li&gt;
&lt;li&gt;你应该测试临时表看看它们是否真的比对大量数据库运行查询快。如果数据很好地索引,临时表可能一点不快。&lt;/li&gt;
&lt;li&gt;临时表默认的存储引擎是Innodb，数据存储在磁盘里面，且不会使用索引，即使该列在原表中有索引也不会使用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;使用场景：临时表主要用于对大数据量的表上作一个子集，提高查询效率。普通临时表，从大表中捞取部分的数据，可以在一个连接内重复使用，提速&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;CREATE TEMPORARY TABLE user_tem as select * from user where id&amp;lt;200;
DROP TEMPORARY TABLE IF EXISTS temp_tb;
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;视图&#34;&gt;&lt;strong&gt;视图&lt;/strong&gt;&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;视图是一个命名的虚表，他由一个SQL查询来定义，可以当做表使用，视图中的数据没有实际的物理存储。

视图主要被用作一个抽象装置，程序不关心表的结构，只需要按照视图定义来取数据或更新数据。
CREATE [OR REPALCE] [ALGORITHM={UNDEFINED|MERGE|TEMPTABLE}] [DEFINER={user|CURRENT_USER}] [SQL SECURITY {DEFINER |
INVOKER}]
VIEW view_name [(colum_list)]
AS select_statement
[with[CASCADED|LOCAL] CHECK OPTION]
用户可以对某些视图进行更新操作，其本质是通过视图的定义来更新基本表。一般称可以更新的视图为可更新视图（updatable view)。视图定义中的with check option就是针对可更新视图的，即更新的值是否需要检查。

物化视图
ORACLE物化视图不是基于表的虚表，而是根据基表实际存在的实表，即物化视图的数据存储在非易失的存储设备上。物化视图可以用于预先计算并保存多表的耗时较多的SQL操作结果，从而快速得到结果。
BUILD IMMEDIATE是默认的创建方式，在创建物化视图的时候就生成数据，而BUILD DEFERRED则在创建物化视图时不生成数据，以后根据需要再生成数据。
查询重写是指当对物化视图的基表进行查询时，数据库会自动判断能否通过查询物化视图来直接得到结果。
物化视图的刷新是指当基表发生了DML操作后，物化视图何时采用哪种方式进行同步：
ON DEMAND意味着在用户需要时进行，ON COMMITE 意味着对基表的DML操作提交的同时进行刷新。
刷新的办法：
FAST//采用增量刷新，值刷新上次刷新以后进行的修改
COMPLETE//对整个物化视图进行完全的刷新
FORCE//数据库在刷新时会去判断是否可以进行FAST刷新，如果可以就采用FAST,不行就采用COMPLETE
NEVER//不刷新

MySQL本身不支持物化视图，即MySQL中的视图总是虚拟的。但可以通过一定的方式来实现。
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;分区&#34;&gt;&lt;strong&gt;分区&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;不是所有引擎都支持分区。分区的过程是将一个表或索引分解为多个更小、更可管理的部分。&lt;/p&gt;
&lt;p&gt;就访问数据库而言，从逻辑上将，只有一个表或一个索引，但是在物理上这个表或索引可能由数十个物理分区组成，每个分区都是独立的对象，可以独自处理，也可以作为一个更大对象的一部分进行处理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MYSQL只支持水平分区（将同一个表中不同行的记录分配到不同的物理文件中），不支持垂直分区（将同一表中不同列的记录分配到不同的物理文件中）。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MySQL的分区是&lt;strong&gt;局部分区索引&lt;/strong&gt;，一个分区中既存放了&lt;strong&gt;数据又存放了索引&lt;/strong&gt;。而全分区是指，数据存放在各个分区中，但所有数据的索引放在一个对象中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;show variables like &#39;%partition%&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;分区可能会给某些SQL语句性能带来提高，但分区主要用于数据库高可用性的管理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;RANGE分区&lt;/strong&gt;：行数据基于属于一个给定连续区间的列值被放入分区,主要用于日期列的分区；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;LIST分区&lt;/strong&gt;：和RANGE分区类似，只是LIST分区面向的是离散的值；不同于RANGE用的是value less than ,list用的是 values in;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;HASH分区&lt;/strong&gt;：使用MySQL数据库提供的哈希函数来进行分区。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;KEY分区&lt;/strong&gt;：根据用户自定义的表达式的返回值来进行分区，返回值不能为负数；&lt;/p&gt;
&lt;p&gt;如果表中存在主键或唯一索引时，&lt;strong&gt;分区列表key是唯一索引的一个组成部分&lt;/strong&gt;。唯一索引可以是允许NULL值的，并且分区列只要是唯一索引的一个组成部分，不需要整个唯一索引列都是分区列。如果没有指定主键或唯一索引，则可以指定任何一个列为分区列。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;create table t(
    id INT
)ENGINE=INNODB
PARTITION BY RANGE(id){
    partition p0 values less than (10),
    partition p1 values less than(20);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;启用分区之后，表不再是由一个ibd文件组成了，而是由建立时的各个分区ibd文件组成。&lt;br&gt;
当插入一个不在分区中定义的值时，会抛出错误，所以可以定义一个MAXVALUE值的分区&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;partition p2 values less than maxvalue

mysql&amp;gt;EXPLAIN PARTITION select * from ....
通过EXPLAIN PARTITION，SQL优化器只需要搜索对应的分区，故查询速度得到了大幅度提升。优化器只能对YEAR(),TO_DAYS(),TO_SECONDS(),UNIX_TIMESTAMP()进行优化。

create table t_hash(
    a Int,
    b DATATIME
)ENGINE=INNODB
PARTITION BY HASH(YEAR(b))
PARTITONS 4;//表示分几个区，默认为1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;COLUMNS&lt;/strong&gt;分区&lt;br&gt;
RANGE\LIST\HASH\KEY分区的条件是数据必须是整型，否则需要转化。而columns分区可以直接使用非整型的数据进行分区。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;create table xx(
    b DATETIME
)ENGINE=INNODB
PARTITION BY RANG COLUMNS(b)(
    partition0 .....
)

alter table xx remove partition//删除分区
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;子分区&lt;/strong&gt;&lt;br&gt;
在分区的基础上再分区。MySQL允许在RANGE和LIST分区上再进行HASH或KEY的子分区。&lt;br&gt;
每个子分区的数量必须相同；要在一个分区表的任何分区上使用SUBPARTITION来明确定义任何子分区，就必须定义所有的子分区。每个SUBPARTITION子句必须包括子分区的一个名字。子分区的名字必须是唯一的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;create table xx(
    a INT,
    b DATE
)ENGINE=innodb
partition by RANGE(YEAR(b))
SUBPARTITION BY HASH(TO_DAYS(b)) PARTITIONS 2
(
    PARTITION p0 values less than (1990),
    PARTITION p1 values less than （2000），
    PARTITION p2 values less than maxvalue
);此时有3*2=6个分区
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;分区中的NULL值&lt;/strong&gt;&lt;br&gt;
MySQL允许对null分区，将其视为小于任何的一个非null值。如果是RANGE分区，则会将该值放在最左边的分区，也就是最小的分区。如果是LIST的分区，就必须显示的指定在哪个分区中放入NULL值，否则会报错。&lt;br&gt;
HASH和KEY分区则是将null值的记录返回为0.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分区和性能&lt;/strong&gt;&lt;br&gt;
数据库的应用分为OLTP(在线事物处理)和OLAP(在线分析处理)。&lt;br&gt;
对于OLAP,分区确实可以很好地提高查询的性能，因为OLAP应用大多需要频繁地扫描一张大表，因此只需要扫描对应的分区即可。&lt;br&gt;
而OLTP通常不会获取一张大表中10%的数据，大部分都是通过索引返回几条记录，而B+树索引对一张大表只需要2~3次的IO，因此可以很好的完成操作，不需要分区。但是如果查询条件中使用非索引的其他key，那么对于其他key来说则会进行所有分区的扫描，这时的IO次数就变成了了2*分区数，不仅不会更快，反而变慢了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在表和分区之间交换数据&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ALTER TABLE tbl_name EXCHANGE PARTITION px WITH TABLE tbl_name2.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该语句允许分区或子分区中的数据与另一个非分区的表中的数据进行交换。如果非分区表中的数据为空，那么相当于将分区中的数据移动到非分区表中，如果分区表中的数据为空，则相当于将外部表中的数据导入到分区中&lt;br&gt;
1、要交换的表需和分区表有着相同的表结构，但是表不能含有分区；&lt;br&gt;
2、在非分区表中的数据必须在交换的分区定义内&lt;br&gt;
3、被交换的表中不能含有外键，或者其他的表含有对该表的外键引用&lt;br&gt;
4、用户除了需要ALTER,INSERT和CREATE权限外，好需要DROP的权限，使用该语句时，不会触发交换表和被交换表上的触发器AUTO_INCREMENT列将被重置&lt;/p&gt;
&lt;p&gt;该语句允许分区或子分区中的数据与另一个非分区的表中的数据进行交换。如果非分区表中的数据为空，那么相当于将分区中的数据移动到非分区表中，如果分区表中的数据为空，则相当于将外部表中的数据导入到分区中&lt;br&gt;
1、要交换的表需和分区表有着相同的表结构，但是表不能含有分区；&lt;br&gt;
2、在非分区表中的数据必须在交换的分区定义内&lt;br&gt;
3、被交换的表中不能含有外键，或者其他的表含有对该表的外键引用&lt;br&gt;
4、用户除了需要ALTER,INSERT和CREATE权限外，好需要DROP的权限，使用该语句时，不会触发交换表和被交换表上的触发器&lt;/p&gt;
&lt;p&gt;AUTO_INCREMENT列将被重置&lt;/p&gt;
">2、表</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/tanscation/"" data-c="
          &lt;h1 id=&#34;1-认识事务&#34;&gt;&lt;strong&gt;1、认识事务&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;事务其实就是并发控制的基本单位;&lt;/p&gt;
&lt;p&gt;事务可由一条非常简单的SQL语句组成，也可以由一组复杂得SQL组成。事务是访问并更新数据库中各种数据项的一个程序执行单元。在事务中的 操作，要么都做修改，要么都不做，这就是事务的目的。&lt;/p&gt;
&lt;h2 id=&#34;原子性atomicity&#34;&gt;原子性（atomicity)&lt;/h2&gt;
&lt;p&gt;指整个数据库事务是不可分割的工作单位。只有使事务中所有的数据库操作都执行成功才算整个事务成功。任何一个SQL 执行失败，已经执行成功的SQL也必须撤销，数据库状态应该退回到执行事务前的状态。&lt;/p&gt;
&lt;h2 id=&#34;一致性consistency&#34;&gt;一致性（consistency）&lt;/h2&gt;
&lt;p&gt;数据库总是从一个一致性状态转换到另一个一致状态。就是一组SQL执行之前，数据必须是准确的，执行之后，数据也必须是准确的。&lt;/p&gt;
&lt;h2 id=&#34;隔离性isolation&#34;&gt;隔离性（isolation）&lt;/h2&gt;
&lt;p&gt;这个就是说多个事务在跑的时候不能互相干扰，别事务A操作个数据，弄到一半儿还没弄好呢，结果事务B来改了这个数据，导致事务A的操作出错了，那不就搞笑了。&lt;/p&gt;
&lt;h2 id=&#34;持久性durability&#34;&gt;持久性（durability）&lt;/h2&gt;
&lt;p&gt;事务一旦提交，其结果就是永久的，无法再回滚。&lt;/p&gt;
&lt;h1 id=&#34;2-事务的分类&#34;&gt;2、事务的分类&lt;/h1&gt;
&lt;h2 id=&#34;扁平事务&#34;&gt;扁平事务&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/1293895-622edf781c29f57f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1104/format/webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;所有操作都处于同一层次，其由BEGIN WORK开始，由COMMIT WORK或ROLLBACK WORK结束，期间的操作都是原子的。扁平事务是应用程序成为原子操作的基本组成模块。 扁平事务的主要限制是不能提交或回滚事务的某一部分，或者分几个步骤提交。&lt;/p&gt;
&lt;h2 id=&#34;带保存点的扁平事务&#34;&gt;带保存点的扁平事务&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/1293895-5028ad0258fa5359.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1018/format/webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;某些事务可能在执行过程中出现的错误并&lt;strong&gt;不会导致所有的操作都无效，放弃整个事务不合乎要求&lt;/strong&gt;，开销也太大。保存点（&lt;code&gt;savepoint&lt;/code&gt;）用来通知 系统记录当前的处理状态。当出现问题时，保存点能用作内部的重启动点，根据应用逻辑，决定是回到最近一个保存点还是其他更早的保存点。&lt;/p&gt;
&lt;p&gt;对扁平事务来说，其隐式地设置了一个保存点。然而在整个事务中，只有这一个保存点，回滚只能回滚到事务开始时的状态。保存点用 SAVE WORK函数来建立，通知系统记录当前的处理状态。&lt;/p&gt;
&lt;p&gt;保存点在事务内部是递增的，ROLLBACK不影响保存点的计数。&lt;/p&gt;
&lt;h2 id=&#34;链事务&#34;&gt;链事务&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/1293895-17257fc0fc5dd905.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1174/format/webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;保存点模式的一种变种。带保存点的扁平事务在系统发生崩溃时，所有的保存点都将消失，因为其保存点是易失的（volatile），而非持久的 （persistent)。这就意味着当进行恢复时，事务需要从开始处重新执行，而不能从最近的一个保存点继续执行。&lt;/p&gt;
&lt;p&gt;链事务的思想是：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。提交事务操作和开始下 一个事务操作将合并为一个原子操作。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中进行的一样。&lt;/p&gt;
&lt;p&gt;与带保存点的扁平事务不同的是，带保存点的事务能回滚到任意正确的保存点。而链事务的回滚&lt;strong&gt;仅限于当前事务&lt;/strong&gt;，即只能恢复到最近的一个保存 点。对于锁的处理也不相同，链事务在执行COMMIT后释放了当前事务所持有的锁，而带保存点的扁平事务不影响持有的锁。&lt;/p&gt;
&lt;h2 id=&#34;嵌套事务&#34;&gt;嵌套事务&lt;/h2&gt;
&lt;p&gt;由一个顶层事务控制着各个层次的事务。顶层事务之下嵌套的事务被称为子事务（&lt;code&gt;subtransaction&lt;/code&gt;）,其控制着每一个局部的变换。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipbomosdmard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;实际的工作是交由叶子节点来完成的，只有叶子节点的事务才能访问数据。而高层的事务仅负责逻辑控制，决定何时调用相关的子事务。即使一个 系统不支持嵌套事务，用户也可以通过保存点技术来模拟嵌套事务。&lt;/p&gt;
&lt;h2 id=&#34;分布式事务distributed-transaction&#34;&gt;分布式事务（Distributed Transaction)&lt;/h2&gt;
&lt;p&gt;是一个在分布式环境下运行的扁平事务，因此需要根据数据所在的位置访问网络中的不同节点。&lt;/p&gt;
&lt;h1 id=&#34;3-事务的隔离级别&#34;&gt;3、事务的隔离级别&lt;/h1&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://pic4.zhimg.com/v2-17425f8aaf39eb83a451f9c8a8133427_r.jpg&#34; alt=&#34;preview&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;读未提交&#34;&gt;读未提交&lt;/h2&gt;
&lt;p&gt;该级别引发的问题是——脏读(Dirty Read)：读取到了未提交的数据&lt;/p&gt;
&lt;p&gt;脏页指的是在&lt;strong&gt;缓冲池&lt;/strong&gt;中已被修改的页，但是还没有刷新到磁盘，即数据库实例内存中的页和磁盘中的页的数据不一致，当然在刷新到磁盘之前，日志都已被写入到了重做日志文件中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;脏页&lt;/strong&gt;并不影响数据的一致性，并且脏页刷新都是异步的，不影响数据库的可用性，因此可以带来性能的提高；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;脏数据&lt;/strong&gt;是指事务对缓冲池中的&lt;strong&gt;记录的修改，并且还没有被提交&lt;/strong&gt;，也就是当前事务可以读到另外事务未提交的数据。&lt;/p&gt;
&lt;h2 id=&#34;读已提交&#34;&gt;&lt;strong&gt;读已提交&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;这种隔离级别出现的问题是——不可重复读(&lt;code&gt;Nonrepeatable Read&lt;/code&gt;)：不可重复读意味着我们在&lt;strong&gt;同一个事务中&lt;/strong&gt;执行完全相同的select语句时可能看到不一样的结果。&lt;/p&gt;
&lt;p&gt;就是说事务A在跑的时候， 先查询了一个数据是值1，然后过了段时间，事务B把那个数据给修改了一下还提交了，此时事务A再次查询这个数据就成了值2了，这是读了人家事务提交的数据啊，所以是读已提交。就是所谓的&lt;strong&gt;一个事务内对一个数据两次读&lt;/strong&gt;，可能会读到不一样的值。如图：&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_png/1J6IbIcPCLbraGeVNtE1GticOiaJia71SicHHVrXQKSDaibdc7cR89IxYQEUPBWzPRiatNB2Ry9Pos1ouhPervMzDVoA/640?wx_fmt=png&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;可重复读&#34;&gt;&lt;strong&gt;可重复读&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。就是说事务A在执行过程中，对某个数据的值，无论读多少次都是值1；哪怕这个过程中事务B修改了数据的值还提交了，但是事务A读到的还是自己事务开始时这个数据的值。如图：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_png/1J6IbIcPCLbraGeVNtE1GticOiaJia71SicHXIULuYfxYLaulKtU5YK1GCvBD7aSibnqPibYz1ggVYQ2qTtNWPfYmSibA/640?wx_fmt=png&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;此级别可能出现的问题——幻读(Phantom Read)：当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;幻读&lt;/strong&gt;：不可重复读和可重复读都是针对两个事务&lt;strong&gt;同时对某条数据在修改&lt;/strong&gt;，但是&lt;strong&gt;幻读针对的是插入&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;存储引擎通过多版本并发控制(MVCC，&lt;code&gt;Multiversion&lt;/code&gt;Concurrency Control)机制解决幻读问题；&lt;code&gt;InnoDB&lt;/code&gt;还通过&lt;strong&gt;间隙锁&lt;/strong&gt;解决幻读问题。&lt;/p&gt;
&lt;h3 id=&#34;多版本并发控制&#34;&gt;**多版本并发控制 **&lt;/h3&gt;
&lt;p&gt;MVCC的实现是通过&lt;strong&gt;保存数据在某一个时间点快照来实现的&lt;/strong&gt;。也就是说不管实现时间多长，每个事物看到的数据都是一致的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;MySQL&lt;/code&gt; 中 &lt;code&gt;InnoDB&lt;/code&gt; 引擎支持 &lt;code&gt;MVCC&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;应对高并发事务, &lt;code&gt;MVCC&lt;/code&gt; 比单纯的加行锁更有效, 开销更小&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MVCC&lt;/code&gt; 在读已提交&lt;code&gt;（Read Committed）&lt;/code&gt;和可重复读&lt;code&gt;（Repeatable Read）&lt;/code&gt;隔离级别下起作用
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;RC&lt;/code&gt;、&lt;code&gt;RR&lt;/code&gt; 两种隔离级别的事务在执行普通的读操作时，通过访问版本链的方法，使得事务间的读写操作得以并发执行，从而提升系统性能。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RC&lt;/code&gt;、&lt;code&gt;RR&lt;/code&gt; 这两个隔离级别的一个很大不同就是生成 &lt;code&gt;ReadView&lt;/code&gt; 的时间点不同，
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;RC&lt;/code&gt; 在&lt;strong&gt;每一次&lt;/strong&gt; &lt;code&gt;SELECT&lt;/code&gt; 语句前都会生成一个 &lt;code&gt;ReadView&lt;/code&gt;，事务期间会更新，因此在其他事务提交前后所得到的 &lt;code&gt;m_ids&lt;/code&gt; 列表&lt;strong&gt;可能发生变化&lt;/strong&gt;，使得先前不可见的版本后续又突然可见了。&lt;/li&gt;
&lt;li&gt;而 &lt;code&gt;RR&lt;/code&gt; 只在事务的&lt;strong&gt;第一个&lt;/strong&gt; &lt;code&gt;SELECT&lt;/code&gt; 语句时生成一个 &lt;code&gt;ReadView&lt;/code&gt;，事务操作期间&lt;strong&gt;不更新&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MVCC&lt;/code&gt; 既可以基于&lt;strong&gt;乐观锁&lt;/strong&gt;又可以基于&lt;strong&gt;悲观锁&lt;/strong&gt;来实现&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://pic3.zhimg.com/80/v2-e1844f5816a332018183559d1573d80e_hd.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;在InnoDB中，每一行都有2个隐藏列DATA_TRX_ID和DATA_ROLL_PTR(如果没有定义主键，则还有个隐藏主键列)：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;DATA_TRX_ID&lt;/code&gt;：记录最近更新这条行记录的&lt;code&gt;事务 ID&lt;/code&gt;，大小为 &lt;code&gt;6&lt;/code&gt; 个字节&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DATA_ROLL_PTR&lt;/code&gt;：表示指向该行回滚段&lt;code&gt;（rollback segment）&lt;/code&gt;的指针，大小为 &lt;code&gt;7&lt;/code&gt; 个字节，&lt;code&gt;InnoDB&lt;/code&gt; 便是通过这个指针找到之前版本的数据。该行记录上所有旧版本，在 &lt;code&gt;undo&lt;/code&gt; 中都通过链表的形式组织。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;如何组织-undo-log-链&#34;&gt;&lt;strong&gt;如何组织 Undo Log 链&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;在多个事务并行操作某行数据的情况下，不同事务对该行数据的 UPDATE 会产生&lt;strong&gt;多个版本&lt;/strong&gt;，然后通过回滚指针组织成一条 &lt;code&gt;Undo Log&lt;/code&gt; 链。&lt;/p&gt;
&lt;p&gt;事务 &lt;code&gt;A&lt;/code&gt; 对值 &lt;code&gt;x&lt;/code&gt; 进行更新之后，该行即产生一个新版本和旧版本。假设之前插入该行的事务 &lt;code&gt;ID&lt;/code&gt; 为 &lt;code&gt;100&lt;/code&gt;，事务 &lt;code&gt;A&lt;/code&gt; 的 &lt;code&gt;ID&lt;/code&gt; 为 &lt;code&gt;200&lt;/code&gt;，该行的隐藏主键为 &lt;code&gt;1&lt;/code&gt;。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://pic4.zhimg.com/80/v2-759e2202ee64b45fb4bc8cdea640c813_hd.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;事务 &lt;code&gt;A&lt;/code&gt; 的操作过程为：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对 &lt;code&gt;DB_ROW_ID = 1&lt;/code&gt; 的这行记录加排他锁&lt;/li&gt;
&lt;li&gt;把该行原本的值拷贝到 &lt;code&gt;undo log&lt;/code&gt; 中，&lt;code&gt;DB_TRX_ID&lt;/code&gt; 和 &lt;code&gt;DB_ROLL_PTR&lt;/code&gt; 都不动&lt;/li&gt;
&lt;li&gt;修改该行的值这时产生一个新版本，更新 &lt;code&gt;DATA_TRX_ID&lt;/code&gt; 为修改记录的事务 &lt;code&gt;ID&lt;/code&gt;，将 &lt;code&gt;DATA_ROLL_PTR&lt;/code&gt; 指向刚刚拷贝到 &lt;code&gt;undo log&lt;/code&gt; 链中的旧版本记录，这样就能通过 &lt;code&gt;DB_ROLL_PTR&lt;/code&gt; 找到这条记录的历史版本。如果对同一行记录执行连续的 &lt;code&gt;UPDATE&lt;/code&gt;，&lt;code&gt;Undo Log&lt;/code&gt; 会组成一个链表，遍历这个链表可以看到这条记录的变迁&lt;/li&gt;
&lt;li&gt;记录 &lt;code&gt;redo log&lt;/code&gt;，包括 &lt;code&gt;undo log&lt;/code&gt; 中的修改&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;那么 &lt;code&gt;INSERT&lt;/code&gt; 和 &lt;code&gt;DELETE&lt;/code&gt; 会怎么做呢？其实相比 &lt;code&gt;UPDATE&lt;/code&gt; 这二者很简单，&lt;code&gt;INSERT&lt;/code&gt; 会产生一条新纪录，它的 &lt;code&gt;DATA_TRX_ID&lt;/code&gt; 为当前插入记录的事务 &lt;code&gt;ID&lt;/code&gt;；&lt;code&gt;DELETE&lt;/code&gt; 某条记录时可看成是一种特殊的 &lt;code&gt;UPDATE&lt;/code&gt;，其实是软删，真正执行删除操作会在 &lt;code&gt;commit&lt;/code&gt; 时，&lt;code&gt;DATA_TRX_ID&lt;/code&gt; 则记录下删除该记录的事务 &lt;code&gt;ID&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&#34;readview&#34;&gt;ReadView&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;ReadView&lt;/code&gt; 中是&lt;strong&gt;当前活跃的事务&lt;/strong&gt; &lt;code&gt;ID&lt;/code&gt; 列表，称之为 &lt;code&gt;m_ids&lt;/code&gt;，其中最小值为 &lt;code&gt;up_limit_id&lt;/code&gt;，最大值为 &lt;code&gt;low_limit_id&lt;/code&gt;，事务 &lt;code&gt;ID&lt;/code&gt; 是事务开启时 &lt;code&gt;InnoDB&lt;/code&gt; 分配的，其大小决定了事务开启的先后顺序，因此我们可以通过 &lt;code&gt;ID&lt;/code&gt; 的大小关系来决定版本记录的可见性。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如果被访问版本的 &lt;code&gt;trx_id&lt;/code&gt; 小于 &lt;code&gt;m_ids&lt;/code&gt; 中的最小值 &lt;code&gt;up_limit_id&lt;/code&gt;，说明生成该版本的事务在 &lt;code&gt;ReadView&lt;/code&gt; 生成前就已经提交了，所以该版本可以被当前事务访问。&lt;/li&gt;
&lt;li&gt;如果被访问版本的 &lt;code&gt;trx_id&lt;/code&gt; 大于 &lt;code&gt;m_ids&lt;/code&gt; 列表中的最大值 &lt;code&gt;low_limit_id&lt;/code&gt;，说明生成该版本的事务在生成 &lt;code&gt;ReadView&lt;/code&gt; 后才生成，所以该版本不可以被当前事务访问。需要根据 &lt;code&gt;Undo Log&lt;/code&gt; 链找到前一个版本，然后根据该版本的 DB_TRX_ID 重新判断可见性。&lt;/li&gt;
&lt;li&gt;如果被访问版本的 &lt;code&gt;trx_id&lt;/code&gt; 属性值在 &lt;code&gt;m_ids&lt;/code&gt; 列表中最大值和最小值之间（包含），那就需要判断一下 &lt;code&gt;trx_id&lt;/code&gt; 的值是不是在 &lt;code&gt;m_ids&lt;/code&gt; 列表中。如果在，说明创建 &lt;code&gt;ReadView&lt;/code&gt; 时生成该版本所属事务还是活跃的，因此该版本不可以被访问，需要查找 Undo Log 链得到上一个版本，然后根据该版本的 &lt;code&gt;DB_TRX_ID&lt;/code&gt; 再从头计算一次可见性；如果不在，说明创建 &lt;code&gt;ReadView&lt;/code&gt; 时生成该版本的事务已经被提交，该版本可以被访问。&lt;/li&gt;
&lt;li&gt;此时经过一系列判断我们已经得到了这条记录相对 &lt;code&gt;ReadView&lt;/code&gt; 来说的可见结果。此时，如果这条记录的 &lt;code&gt;delete_flag&lt;/code&gt; 为 &lt;code&gt;true&lt;/code&gt;，说明这条记录已被删除，不返回。否则说明此记录可以安全返回给客户端。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;​	https://zhuanlan.zhihu.com/p/64576887&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;串行化&#34;&gt;串行化&lt;/h2&gt;
&lt;p&gt;它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之,它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争&lt;/p&gt;
&lt;h1 id=&#34;4-事务的实现&#34;&gt;4、事务的实现&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;redo_log 实现持久化和原子性，而undo_log实现一致性&lt;/strong&gt;，二种日志均可以视为一种恢复操作，redo_log是恢复&lt;strong&gt;提交事务修改的页操作&lt;/strong&gt;，而undo_log是&lt;strong&gt;回滚行记录到特定版本&lt;/strong&gt;。二者记录的内容也不同，redo_log是物理日志，记录页的&lt;strong&gt;物理修改操作&lt;/strong&gt;，而undo_log是逻辑日志，根据每行记录进行记录。&lt;/p&gt;
&lt;h2 id=&#34;redo-log&#34;&gt;&lt;strong&gt;redo log&lt;/strong&gt;&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://user-gold-cdn.xitu.io/2019/4/21/16a3e7576b55c19f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;redo日志用来实现事务的持久性，在事务提交后数据没来得及写会磁盘就宕机时，在下次重新启动后能够成功恢复数据（持久性）， 由两部分组成：&lt;/p&gt;
&lt;p&gt;一是内存中的重做日志缓冲（redo &lt;code&gt;logbuffer&lt;/code&gt;）；&lt;/p&gt;
&lt;p&gt;二是重做日志文件（redo log file).&lt;/p&gt;
&lt;p&gt;当我们在一个事务中尝试对数据进行修改时，它会先将数据从磁盘读入内存，并更新内存中缓存的数据，然后生成一条重做日志并写入重做日志缓存，当事务真正提交时，MySQL 会将重做日志缓存中的内容刷新到重做日志文件，再将内存中的数据更新到磁盘上，图中的第 4、5 步就是在 事务提交时执行的。&lt;/p&gt;
&lt;p&gt;为了确保每次日志都写入重做日志文件，在每次将重做日志缓冲写入重做日志文件后，&lt;code&gt;InnoDB&lt;/code&gt;都需要调用一次&lt;code&gt;fsync&lt;/code&gt;操作。&lt;code&gt;fsync&lt;/code&gt;的效率取决于 磁盘的性能，因此磁盘的性能决定了事务提交的性能，也就是数据的性能。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;InnoDb&lt;/code&gt;允许用户手工设置非持久性的情况发生，以此提高数据的性能。即当事务提交时，日志不写入重做日志文件，而是等一个时间周期后再执行&lt;code&gt;fsync&lt;/code&gt;，但是发生宕机时会丢失最后一段时间的事务。&lt;/p&gt;
&lt;h3 id=&#34;与二进制日志的区别&#34;&gt;与二进制日志的区别&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;重做日志是&lt;code&gt;InnoDB&lt;/code&gt;存储引擎层产生，而二进制日志是在MySQL数据库的上层产生，并且二进制日志不仅仅针对&lt;code&gt;InnoDB&lt;/code&gt;存储引擎，MySQL数据库中任何存储引擎对于数据库的编个都会产生二进制日志&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;两种日志记录的内容形式不一样，MySQL数据库上层的二进制日志是一种&lt;strong&gt;逻辑日志&lt;/strong&gt;，其记录的是对应的&lt;strong&gt;SQL语句&lt;/strong&gt;，而&lt;code&gt;InnoDB&lt;/code&gt;存储引擎层面的重做日志是&lt;strong&gt;物理格式日志&lt;/strong&gt;，其记录的是&lt;strong&gt;每个页的修改&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;两种日志记录写入磁盘的时间点不同，如图，二进制日志只在&lt;strong&gt;事务提交完成后&lt;/strong&gt;进行一次写入，而&lt;code&gt;InnoDB&lt;/code&gt;存储引擎的&lt;strong&gt;重做日志在事务进行中不断地被写入&lt;/strong&gt;，这表现为日志并不是随事务提交的顺序进行写入的&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://images2015.cnblogs.com/blog/754297/201602/754297-20160205112427569-810454883.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;二进制日志近在事务提交时记录，并且对每一个事务，仅包含&lt;strong&gt;对应事务的一个日志&lt;/strong&gt;，而对于&lt;code&gt;InnoDB&lt;/code&gt;存储引擎的重做日志，由于其记录的是&lt;strong&gt;物理操作日志&lt;/strong&gt;，因此每个&lt;strong&gt;事务对应多个日志条目&lt;/strong&gt;，并且事务的重做日志是并发的，并非在事务提交时写入，故其在文件中的记录顺序并非是事务的开始顺序。*T1 * T2 *T3表示事务提交时的日志&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;log-block&#34;&gt;log block&lt;/h3&gt;
&lt;p&gt;在 &lt;code&gt;InnoDB&lt;/code&gt;中，重做日志都是以 512 字节的块的形式进行存储的，同时因为块的大小与磁盘扇区大小相同，所以重做日志的写入可以保证原子性，不会由于机器断电导致重做日志仅写入一半并留下脏数据。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboardfsfacd.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;日志块由三部分组成：日志块头（log &lt;code&gt;block&lt;/code&gt;header),日志内容（log body),日志块尾（log block &lt;code&gt;tailer&lt;/code&gt;)。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipfsmfskboard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;log buffer是由log block组成，在内部log buffer好似一个数据。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;log header:
LOG_BLOCK_HDR_NO用来标记这个数组中的位置，其是递增并循环使用的，占用4个字节，但是由于第一给我用来判断是否是flush bit，所以最大值是2G
LOG_BLOCK_HDR_DATA_LEN表示log block所占用的大小。
LOG_BLOCK_FIRST_REC_GROUP表示log block中第一个日志所在的偏移量。
LOG_BLOCK_CHECKPOINT_NO表示该log  block最后被写入时的检查点第4字节的值。

log tailer:
LOG_BLOCK_TRL_NO:与LOG_BLOCK_HDR_NO的值相同。
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;log-group&#34;&gt;log group&lt;/h3&gt;
&lt;p&gt;log group是一个&lt;strong&gt;逻辑上的概念&lt;/strong&gt;，并没有一个实际存储的物理文件来表示log group信息。&lt;/p&gt;
&lt;p&gt;InnoDB存储引擎的数据目录下有两个名为ib_logfile0和ib_logfile1的文件，即是重做日志文件（redo log file)，记录了对于InnoDB 存储引擎的事物日志。在日志组中每个重做日志文件的大小一致，并以循环写入的方式运行。先写日志1，再写日志2，然后再写日志1.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;innoDB_log_file_size//每个重做日志的大小 
innoDB_log_file_in_group//每个组中重做日志的数量 
innoDB_mirrored_log_groups//日志镜像文件组的数量，默认为1，表示没有镜像 innodb_log_group_home_dir//日志文件组的路径 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一方面重做日志不能设置得太大，否则恢复时需要很长的时间；&lt;/p&gt;
&lt;p&gt;另一方面也不能太小，否则会导致一个事物的日志需要多次切换重做日志文件。 也会频繁地发生async checkpoint，导致性能抖动。&lt;/p&gt;
&lt;p&gt;重做日志文件中存储的就是之前在log buffer中保存的log block，也是根据块的方式进行物理存储的管理。，每个块的大小与log block一样，同样为512字节，在&lt;code&gt;InnoDB&lt;/code&gt;存储引擎运行过程中，&lt;code&gt;logbuffer&lt;/code&gt;根据一定的规则将内存 中的log block 刷新到磁盘：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;事务提交时；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;log buffer中有一半的内存被使用时&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;log checkpoint时&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对log block的写入追加在redo log file的最后部分，当一个redo log file被写满时，会写入下一个redo log file，是使用方式是 round-robin.&lt;/p&gt;
&lt;p&gt;对redo log file的写入并不是顺序的，因为redo log file除了保存log buffer刷新到磁盘的log block，还保存了一些其他的信息，这些信息一共占用2KB大小，即每个redo log file的前2KB的部分不保存log block信息，对于log group中的&lt;strong&gt;第一个redo log file&lt;/strong&gt;,其前2KB的部分保存4个512字节大小的块&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://images2015.cnblogs.com/blog/754297/201602/754297-20160205174138835-1834182063.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;其余的redo log file &lt;strong&gt;仅保留这些空间，不保存上述信息&lt;/strong&gt;。后续的写入还要&lt;strong&gt;更新这2k的信息&lt;/strong&gt;，这些信息对于&lt;code&gt;InnoDB&lt;/code&gt;的恢复操作非常关键，所以对redo log file的写入 并不是完全顺序。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://images2015.cnblogs.com/blog/754297/201602/754297-20160205175120913-1624661049.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;log filer header后面的部分为&lt;code&gt;InnoDB&lt;/code&gt;保存的checkpoint值，其设计是交替写入，这样是为了避免因介质失败而导致无法找到可用的 checkpoint的情况。&lt;/p&gt;
&lt;h3 id=&#34;重做日志格式&#34;&gt;重做日志格式&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;的存储管理是基于页的，故其重做日志格式也是基于页的。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;15&#34;&gt;&lt;img src=&#34;https://images2015.cnblogs.com/blog/754297/201602/754297-20160205175450335-1884721475.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;redo_log_type:重做日志的类型；&lt;/p&gt;
&lt;p&gt;space:表空间的ID&lt;/p&gt;
&lt;p&gt;page_no:页的偏移量&lt;/p&gt;
&lt;p&gt;之后就是redo log body的部分，根据重做日志类型的不对，会有不同的存储内容，例如，对于页上记录的插入和删除操作，分别对应的如图的格式&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;16&#34;&gt;&lt;img src=&#34;https://images2015.cnblogs.com/blog/754297/201602/754297-20160205175732710-743525968.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;lsn&#34;&gt;LSN&lt;/h3&gt;
&lt;p&gt;LSN是Log Sequence Number的缩写，代表的是日志序列号,表示事务写入重做日志字节的总量。占用8字节，单调递增。例如当前重做日志的LSN为1000，有一个事务T1写入了100字节的重做日志，那么LSN久变成1100，若又有事务T2写入200字节的重做日志，那么LSN久变为1300&lt;/p&gt;
&lt;p&gt;表示的含义有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;重做日志写入的总量&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;checkpoint的位置&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;页的版本&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;**LSN不仅记录在重做日志中，还存在每个页中，在每个页的头部，**有一个值FIL_PAGE_LSN，记录了该页的LSN，在页中，LSN表示该页最后刷新时LSN的大小。因为重做日志记录的是每个页的日志，因此页中的LSN可以判断页是否需要进行恢复操作。例如，页P1的LSN诶10000，而数据库启动时，&lt;code&gt;InnoDB&lt;/code&gt;检测到写入重做日志中的LSN为13000，并且事务已经提交，那么数据库需要进行恢复操作。将重做日志应用到P1页中，同样的，对于重做日志中LSN小于P1页的LSN，不需要进行重做，因为P1页中的LSN标示已经被刷新到该位置&lt;/p&gt;
&lt;h3 id=&#34;恢复&#34;&gt;恢复&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;存储引擎在启动时&lt;strong&gt;不管上次数据运行是否正常关闭，都会尝试进行恢复操作&lt;/strong&gt;，因为重做日志记录的是&lt;strong&gt;物理日志&lt;/strong&gt;，因此恢复的速度比逻辑日志，如二进制日志要快的多，于此同时，&lt;code&gt;InnoDB&lt;/code&gt;存储引擎自身也对恢复进行了一定程度的优化，如顺序读取及并行应用重做日志，这样可以进一步提高数据库恢复的速度&lt;/p&gt;
&lt;p&gt;由于checkpoint表示已经刷新到磁盘页上的LSN，因此在恢复过程中仅需恢复checkpoint开始的日志部分。对于图中的例子，当数据库在checkpoint的LSN为10 000时发生宕机，恢复操作仅恢复LSN 10000~13000范围内的日志&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;17&#34;&gt;&lt;img src=&#34;https://images2015.cnblogs.com/blog/754297/201602/754297-20160206111237913-1571379281.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;再来想想，redo log为什么可以实现事务的原子性和持久性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;原子性，是redo log记录了事务期间操作的物理日志，事务提交之前，并没有写入磁盘，保存在内存里，如果事务失败，数据库磁盘不会有影响，回滚掉事务内存部分即可&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;持久性，redo log 会在事务提交时将日志存储到磁盘redo log file，保证日志的持久性&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;undo-log&#34;&gt;undo log&lt;/h2&gt;
&lt;p&gt;undo log有两个作用：&lt;strong&gt;提供回滚和多个行版本控制(MVCC)&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;1、想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行回滚，而在 MySQL 中，恢复机制是通过回滚日志（undo log）实现的 ，所有事务进行的修改都会先记录到这个回滚日志中，然后在对数据库中的对应行进行写入。&lt;/p&gt;
&lt;p&gt;2、undo log 存在于 undo log segments 中，undo log segments 位在于 rollback segments 中，rollback segment默认值为128个。每个回滚段中有1024个undo log segment。而 rollback segments 则可能存在于系统系统表空间(system tablespace)、临时表空间( temporary tablespace)、撤销表空间(undo tablespaces)中。 具体的分配策略如下：&lt;/p&gt;
&lt;p&gt;undo log默认存放在共享表空间中，如果开启了&lt;code&gt;innodb_file_per_table&lt;/code&gt;，将放在每个表的.&lt;code&gt;ibd&lt;/code&gt;文件中。&lt;/p&gt;
&lt;p&gt;3、回滚日志并不能将数据库物理地恢复到执行语句或者事务之前的样子；它是逻辑日志，当回滚日志被使用时，它只会按照日志逻辑地将数据库中的修改撤销掉，可以理解为，我们在事务中使用的每一条 INSERT 都对应了一条 DELETE，每一条 UPDATE 也都对应一条相反的 UPDATE  语句。&lt;/p&gt;
&lt;p&gt;4、undo的另一个作用是&lt;code&gt;mvcc&lt;/code&gt;。当用户读取一段记录时，若该行记录被其他事务所占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读取。&lt;/p&gt;
&lt;p&gt;5、&lt;strong&gt;undo也会产生redo log&lt;/strong&gt;，因为undo log也需要持久性的保护。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;事务提交&#34;&gt;事务提交&lt;/h3&gt;
&lt;p&gt;当事务提交的时候，&lt;code&gt;innodb&lt;/code&gt;不会立即删除undo log，因为后续还可能会用到undo log，如隔离级别为repeatable read时，事务读取的都是开启事务时的最新提交行版本，只要该事务不结束，该行版本就不能删除，即undo log不能删除。&lt;/p&gt;
&lt;p&gt;但是在事务提交的时候，会将该事务对应的undo log放入到删除列表中，未来通过purge来删除。并且提交事务时，还会判断undo log分配的页是否可以重用，如果可以重用，则会分配给后面来的事务，避免为每个独立的事务分配独立的undo log页而浪费存储空间和性能。&lt;/p&gt;
&lt;p&gt;通过undo log记录delete和update操作的结果发现：(insert操作无需分析，就是插入行而已)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;delete操作实际上不会直接删除，而是将delete对象打上delete flag，标记为删除，最终的删除操作是purge线程完成的。&lt;/li&gt;
&lt;li&gt;update分为两种情况：update的列是否是主键列。
&lt;ul&gt;
&lt;li&gt;如果不是主键列，在undo log中直接反向记录是如何update的。即update是直接进行的。&lt;/li&gt;
&lt;li&gt;如果是主键列，update分两部执行：先删除该行，再插入一行目标行。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;清理&#34;&gt;清理&lt;/h3&gt;
&lt;p&gt;delete和update 操作可能并不会直接删除原有数据，delete 操作只是将聚集索引列的 delete flag 置为 1 ，记录仍然存在于 B+ 树中， 最终的删除在 purge 线程中完成（这样的设计是因为其它事务可能引用这行，所以不能立刻删除）。&lt;/p&gt;
&lt;h3 id=&#34;history-list&#34;&gt;history list&lt;/h3&gt;
&lt;p&gt;history list 根据事务提交的顺序将 undo log 进行链接，先提交的事务总是在 history list 的尾部，同一 undo page 中的 undo log  也总是按照顺序排列的。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;18&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipbomslfdslard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;具体清理过程为 &lt;code&gt;innoDB&lt;/code&gt; 会默认从 history list 中找到第一个需要被清理的数据tx1，清理成功之后清理线程会继续在 tx1 所在页中继续查找需要被清理的 __undo log (即 tx3，注意这里并不会从 history list 继续查找tx2)，之后继续向后查找，找到 tx5，此时发现  tx5 被其它事务引用不能清理(&lt;code&gt;trx&lt;/code&gt;no 比当前 purge 到的位置更大)，所以再次去 history list 中查找尾部记录，此时为tx2 重复以上步骤&lt;/p&gt;
&lt;h1 id=&#34;5-事务使用&#34;&gt;5、事务使用&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;START TRANSACTION | BEGIN [WORK] 
COMMIT [WORK] [AND [NO] CHAIN] [[NO] RELEASE] 
ROLLBACK [WORK] [AND [NO] CHAIN] [[NO] RELEASE] 
SET AUTOCOMMIT = {0 | 1}
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;START TRANSACTION 或 BEGIN 语句：开始一项新的事务。&lt;/li&gt;
&lt;li&gt;COMMIT 和 ROLLBACK：用来提交或者回滚事务。&lt;/li&gt;
&lt;li&gt;CHAIN 和 RELEASE 子句：分别用来定义在事务提交或者回滚之后的操作，CHAIN 会立即启动一个新事物，并且和刚才的事务具有相同的隔离级别，RELEASE 则会断开和客户端的连接。&lt;/li&gt;
&lt;li&gt;SET AUTOCOMMIT 可以修改当前连接的提交方式， 如果设置了 SET AUTOCOMMIT=0，则设置之后的所有事务都需要通过明确的命令进行提交或者回滚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;自动提交（&lt;code&gt;autocommit&lt;/code&gt;）：&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;Mysql&lt;/code&gt;默认采用自动提交模式，可以通过设置&lt;code&gt;autocommit&lt;/code&gt;变量来启用或禁用自动提交模式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;隐式锁定&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;在事务执行过程中，使用两阶段锁协议：&lt;/p&gt;
&lt;p&gt;随时都可以执行锁定，&lt;code&gt;InnoDB&lt;/code&gt;会根据隔离级别在需要的时候自动加锁；&lt;/p&gt;
&lt;p&gt;锁只有在执行commit或者rollback的时候才会释放，并且所有的锁都是在&lt;strong&gt;同一时刻&lt;/strong&gt;被释放。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;显式锁定&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;也支持通过特定的语句进行显示锁定（存储引擎层）：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;select ... lock in share mode //共享锁 
select ... for update //排他锁 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;MySQL Server层的显示锁定：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;lock table和unlock table
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;6-分布式事务&#34;&gt;6、分布式事务&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;提供了对XA事务的支持，并通过XA事务来支持分布式事务的实现。分布式事务是允许多个独立的事务资源（transaction resources） 参与到一个全局的事务中。在使用分布式事务时，&lt;code&gt;InnoDb&lt;/code&gt;的事务隔离季节必须设置为SERIALIZABLE。&lt;/p&gt;
&lt;p&gt;XA事务允许不同数据库之间的分布式事务。XA事务有一个或多个资源管理、一个事务管理器以及一个应用程序组成。&lt;/p&gt;
&lt;p&gt;资源管理器：提供范围事务资源的方法。通常一个数据库就是一个资源管理器；&lt;/p&gt;
&lt;p&gt;事务管理器：协调参与全局事务中的各个事务。需要和参与全局事务的所有资源管理器通信。&lt;/p&gt;
&lt;p&gt;应用程序：定义事务的边界，指定全局事务中的操作。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;19&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipb223oard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;分布式事务使用两段式提交（two-phase commit)。在第一阶段，所有参与全局事务的节点开始准备（prepare),告诉事务管理器他们准备好 提交了。在第二阶段，事务管理器告诉资源管理器执行ROLLBACK或COMMIT。如果任何一个节点显示不能提交，则所有节点都回滚。&lt;/p&gt;
">6、事务</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/tiaoyou/"" data-c="
          &lt;p&gt;除非单表数据未来会一直不断上涨，否则不要一开始就考虑拆分，拆分会带来逻辑、部署、运维的各种复杂度，一般以整型值为主的表在&lt;code&gt;千万级&lt;/code&gt;以下，字符串为主的表在&lt;code&gt;五百万&lt;/code&gt;以下是没有太大问题的。而事实上很多时候MySQL单表的性能依然有不少优化空间，甚至能正常支撑千万级以上的数据量：&lt;/p&gt;
&lt;h2 id=&#34;字段&#34;&gt;字段&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;尽量使用&lt;code&gt;TINYINT&lt;/code&gt;、&lt;code&gt;SMALLINT&lt;/code&gt;、&lt;code&gt;MEDIUM_INT&lt;/code&gt;作为整数类型而非&lt;code&gt;INT&lt;/code&gt;，如果非负则加上&lt;code&gt;UNSIGNED&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;VARCHAR&lt;/code&gt;的长度只分配真正需要的空间&lt;/li&gt;
&lt;li&gt;使用枚举或整数代替字符串类型&lt;/li&gt;
&lt;li&gt;尽量使用&lt;code&gt;TIMESTAMP&lt;/code&gt;而非&lt;code&gt;DATETIME&lt;/code&gt;，&lt;/li&gt;
&lt;li&gt;单表不要有太多字段，建议在20以内&lt;/li&gt;
&lt;li&gt;避免使用NULL字段，很难查询优化且占用额外索引空间&lt;/li&gt;
&lt;li&gt;用整型来存IP&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;索引&#34;&gt;索引&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;索引并不是越多越好，要根据查询有针对性的创建，考虑在&lt;code&gt;WHERE&lt;/code&gt;和&lt;code&gt;ORDER BY&lt;/code&gt;命令上涉及的列建立索引，可根据&lt;code&gt;EXPLAIN&lt;/code&gt;来查看是否用了索引还是全表扫描&lt;/li&gt;
&lt;li&gt;应尽量避免在&lt;code&gt;WHERE&lt;/code&gt;子句中对字段进行&lt;code&gt;NULL&lt;/code&gt;值判断，否则将导致引擎放弃使用索引而进行全表扫描&lt;/li&gt;
&lt;li&gt;值分布很稀少的字段不适合建索引，例如”性别”这种只有两三个值的字段&lt;/li&gt;
&lt;li&gt;字符字段只建前缀索引&lt;/li&gt;
&lt;li&gt;字符字段最好不要做主键&lt;/li&gt;
&lt;li&gt;不用外键，由程序保证约束&lt;/li&gt;
&lt;li&gt;尽量不用&lt;code&gt;UNIQUE&lt;/code&gt;，由程序保证约束&lt;/li&gt;
&lt;li&gt;使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;查询sql&#34;&gt;查询SQL&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;可通过开启&lt;strong&gt;慢查询日志&lt;/strong&gt;来找出较慢的SQL&lt;/li&gt;
&lt;li&gt;不做列运算：&lt;code&gt;SELECT id WHERE age + 1 = 10&lt;/code&gt;，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边&lt;/li&gt;
&lt;li&gt;sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库&lt;/li&gt;
&lt;li&gt;不用&lt;code&gt;SELECT *&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;OR&lt;/code&gt;改写成&lt;code&gt;IN&lt;/code&gt;：&lt;code&gt;OR&lt;/code&gt;的效率是n级别，&lt;code&gt;IN&lt;/code&gt;的效率是log(n)级别，in的个数建议控制在200以内&lt;/li&gt;
&lt;li&gt;不用函数和触发器，在应用程序实现&lt;/li&gt;
&lt;li&gt;避免&lt;code&gt;%xxx&lt;/code&gt;式查询&lt;/li&gt;
&lt;li&gt;少用&lt;code&gt;JOIN&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;使用同类型进行比较，比如用&lt;code&gt;&#39;123&#39;&lt;/code&gt;和&lt;code&gt;&#39;123&#39;&lt;/code&gt;比，&lt;code&gt;123&lt;/code&gt;和&lt;code&gt;123&lt;/code&gt;比&lt;/li&gt;
&lt;li&gt;尽量避免在&lt;code&gt;WHERE&lt;/code&gt;子句中使用!=或&amp;lt;&amp;gt;操作符，否则将引擎放弃使用索引而进行全表扫描&lt;/li&gt;
&lt;li&gt;对于连续数值，使用&lt;code&gt;BETWEEN&lt;/code&gt;不用&lt;code&gt;IN&lt;/code&gt;：&lt;code&gt;SELECT id FROM t WHERE num BETWEEN 1 AND 5&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;列表数据不要拿全表，要使用&lt;code&gt;LIMIT&lt;/code&gt;来分页，每页数量也不要太大&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;引擎&#34;&gt;引擎&lt;/h2&gt;
&lt;p&gt;目前广泛使用的是MyISAM和InnoDB两种引擎：&lt;/p&gt;
&lt;h3 id=&#34;myisam&#34;&gt;MyISAM&lt;/h3&gt;
&lt;p&gt;MyISAM引擎是MySQL 5.1及之前版本的默认引擎，它的特点是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不支持行锁，读取时对需要读到的所有表加锁，写入时则对表加排它锁&lt;/li&gt;
&lt;li&gt;不支持事务&lt;/li&gt;
&lt;li&gt;不支持外键&lt;/li&gt;
&lt;li&gt;不支持崩溃后的安全恢复&lt;/li&gt;
&lt;li&gt;在表有读取查询的同时，支持往表中插入新纪录&lt;/li&gt;
&lt;li&gt;支持&lt;code&gt;BLOB&lt;/code&gt;和&lt;code&gt;TEXT&lt;/code&gt;的前500个字符索引，支持全文索引&lt;/li&gt;
&lt;li&gt;支持延迟更新索引，极大提升写入性能&lt;/li&gt;
&lt;li&gt;对于不会进行修改的表，支持压缩表，极大减少磁盘空间占用&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;innodb&#34;&gt;InnoDB&lt;/h3&gt;
&lt;p&gt;InnoDB在MySQL 5.5后成为默认索引，它的特点是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持行锁，采用MVCC来支持高并发&lt;/li&gt;
&lt;li&gt;支持事务&lt;/li&gt;
&lt;li&gt;支持外键&lt;/li&gt;
&lt;li&gt;支持崩溃后的安全恢复&lt;/li&gt;
&lt;li&gt;不支持全文索引&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总体来讲，MyISAM适合&lt;code&gt;SELECT&lt;/code&gt;密集型的表，而InnoDB适合&lt;code&gt;INSERT&lt;/code&gt;和&lt;code&gt;UPDATE&lt;/code&gt;密集型的表&lt;/p&gt;
&lt;h2 id=&#34;创建必要的索引&#34;&gt;创建必要的索引&lt;/h2&gt;
&lt;p&gt;在经常需要进行检索的字段上创建索引，比如要按照姓名进行检索，那么就应该在姓名字段上创建索引，如果经常要按照员工部门和员工岗位级别 进行检索，那么就应该在员工部门和员工岗位级别这两个字段上创建索引。创建索引给检索带来的性能提升往往是巨大的，因此在发现检索速度过 慢的时候应该首先想到的就是创建索引。&lt;/p&gt;
&lt;h2 id=&#34;使用预编译查询&#34;&gt;使用预编译查询&lt;/h2&gt;
&lt;p&gt;程序中通常是根据用户的输入来动态执行SQL，这时应该尽量使用参数化SQL,这样不仅可以避免SQL注入漏洞攻击，最重要数据库会对这些参数化 SQL进行预编译，这样第一次执行的时候DBMS会为这个SQL语句进行查询优化并且执行预编译，这样以后再执行这个SQL的时候就直接使用预编译的 结果，这样可以大大提高执行的速度。&lt;/p&gt;
&lt;h2 id=&#34;调整where字句中的连接顺序&#34;&gt;调整Where字句中的连接顺序&lt;/h2&gt;
&lt;p&gt;DBMS一般采用自下而上的顺序解析where字句，根据这个原理表连接最好写在其他where条件之前，那些可以过滤掉最大数量记录。&lt;/p&gt;
&lt;h2 id=&#34;index-condition-pushdownicp优化&#34;&gt;Index Condition Pushdown（ICP)优化&lt;/h2&gt;
&lt;p&gt;MySQL在取出&lt;strong&gt;索引的同时判断是否可以进行where条件的过滤&lt;/strong&gt;，也就是将where的部分过滤操作放在了存储引擎层，某些查询下可以减少上层SQL层对记录的索取，从而提高性能。当然where可以过滤的条件是要该索引可以覆盖到的范围。&lt;br&gt;
ICP支持range、ref、eq_ref、ref_or_null类型的查询，支持MyISAM和InnoDB，当优化器选择ICP时，可在执行计划的列Extra看到Using index condition提示。&lt;/p&gt;
&lt;h2 id=&#34;尽量将多条sql语句压缩到一句&#34;&gt;尽量将多条SQL语句压缩到一句&lt;/h2&gt;
&lt;p&gt;SQL中每次执行SQL的时候都要建立网络连接、进行权限校验、进行SQL语句的查询优化、发送执行结果，这个过程是非常耗时的，因此应该尽量 避免过多的执行SQL语句，能够压缩到一句SQL执行的语句就不要用多条来执行。&lt;/p&gt;
&lt;h2 id=&#34;用where字句替换having字句&#34;&gt;用where字句替换HAVING字句&lt;/h2&gt;
&lt;p&gt;避免使用HAVING字句，因为&lt;strong&gt;HAVING只会在检索出所有记录之后才对结果集进行过滤&lt;/strong&gt;，而&lt;strong&gt;where则是在聚合前刷选记录&lt;/strong&gt;，如果能通过where字句限制记录的数目，那就能减少这方面的开销。HAVING中的条件一般用于聚合函数的过滤，除此之外，应该将条件写在where字句中。&lt;/p&gt;
&lt;h2 id=&#34;使用表的别名&#34;&gt;使用表的别名&lt;/h2&gt;
&lt;p&gt;当在SQL语句中连接多个表时，请使用表的别名并把别名前缀于每个列名上。这样就可以减少解析的时间并减少哪些友列名歧义引起的语法错误。&lt;/p&gt;
&lt;h2 id=&#34;在in和exists中通常情况下使用exists因为in不走索引&#34;&gt;在in和exists中通常情况下使用EXISTS，因为in不走索引。&lt;/h2&gt;
&lt;h2 id=&#34;避免在索引上使用计算&#34;&gt;避免在索引上使用计算&lt;/h2&gt;
&lt;p&gt;在where字句中，如果索引列是计算或者函数的一部分，DBMS的优化器将不会使用索引而使用全表查询,函数属于计算的一种 效率低：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;select * from Employee where dsalary*12&amp;gt;2500.0(dsalary是索引列,索引不起作用) 效率高：

select * from Employee where dsalary&amp;gt;2500.0/12(dsalary是索引列) 
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;用union-all替换union&#34;&gt;用union all替换union&lt;/h2&gt;
&lt;p&gt;当SQL 语句需要UNION 两个查询结果集合时,这两个结果集合会以UNION-ALL 的方式被&lt;/p&gt;
&lt;p&gt;合并, 然后在输出最终结果前进行排序.&lt;strong&gt;如果用UNION ALL 替代UNION, 这样排序就不是必要了&lt;/strong&gt;. 效率就会因此得到提高.&lt;/p&gt;
&lt;h2 id=&#34;避免sql中出现隐式类型转换&#34;&gt;避免SQL中出现隐式类型转换&lt;/h2&gt;
&lt;p&gt;当某一张表中的索引字段在作为where条件的时候，如果&lt;strong&gt;进行了隐式类型转换，则此索引字段将会不被识别，因为隐式类型转换也属于计算&lt;/strong&gt;，所以 此时DBMS会使用全表扫面。&lt;/p&gt;
&lt;h2 id=&#34;防止检索范围过宽&#34;&gt;防止检索范围过宽&lt;/h2&gt;
&lt;p&gt;如果DBMS优化器认为检索范围过宽，那么将放弃索引查找而使用全表扫描。下面几种可能造成检索范围过宽的情况。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a、使用is not null或者不等于判断，可能造成优化器假设匹配的记录数太多。&lt;/li&gt;
&lt;li&gt;b、使用like运算符的时候，“a%”将会使用索引，而“a%c”和“%a”则会使用全表扫描，因此“a%c”和“%a”不能被有效的评估匹配的数量，&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;用小表驱动大表in和exist&#34;&gt;&lt;strong&gt;用小表驱动大表IN和EXIST&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;1、驱动表的定义&lt;/p&gt;
&lt;p&gt;当进行多表连接查询时， [驱动表] 的定义为：&lt;/p&gt;
&lt;p&gt;1）&lt;strong&gt;指定了联接条件时&lt;/strong&gt;，满足查询条件的记录行数少的表为[驱动表]&lt;/p&gt;
&lt;p&gt;2）未指定联接条件时，&lt;strong&gt;行数少的表为&lt;/strong&gt;[驱动表]（Important!）&lt;/p&gt;
&lt;p&gt;忠告：如果你搞不清楚该让谁做驱动表、谁 join 谁，请让 MySQL 运行时自行判断&lt;/p&gt;
&lt;p&gt;2、mysql关联查询的概念:&lt;/p&gt;
&lt;p&gt;MySQL 表关联的算法是 Nest Loop Join，&lt;strong&gt;是通过驱动表的结果集作为循环基础数据&lt;/strong&gt;，然后一条一条地通过该结果集中的数据作为过滤条件到 下一个表中查询数据，然后合并结果。&lt;/p&gt;
&lt;p&gt;优化的目标是尽可能减少JOIN中Nested Loop的循环次数。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboa1313rd.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;select * from tbl_name where EXIST (subquery);
可以理解为将主查询的数据，放到子查询中做条件验证，根据结果（TRUE或FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;orderby优化&#34;&gt;&lt;strong&gt;ORDERBY优化&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;在使用order by时，经常出现Using filesort，因此对于此类sql语句需尽力优化，使其尽量使用Using index。&lt;/p&gt;
&lt;p&gt;①MySQL支持两种方式的排序filesort和index，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低。&lt;/p&gt;
&lt;p&gt;②order by满足两种情况会使用Using index。&lt;/p&gt;
&lt;p&gt;1.&lt;strong&gt;order by语句使用索引最左前列&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;2.使用where子句与order by子句条件列组合满足索引最左前列。&lt;/p&gt;
&lt;p&gt;③尽量在索引列上完成排序，遵循索引建立（索引创建的顺序）时的最佳左前缀法则。&lt;/p&gt;
&lt;p&gt;④如果order by的条件不在索引列上，就会产生Using filesort。&lt;/p&gt;
&lt;p&gt;1.filesort有两种排序算法：双路排序和单路排序。&lt;/p&gt;
&lt;p&gt;​       双路排序：在MySQL4.1之前使用双路排序，就是两次磁盘扫描，得到最终数据。读取行指针和order by列，对他们进行排序，然后扫描已经排好序的列表，按照列表中的值重新从列表中读取对应的数据输出。即从磁盘读取排序字段，在buffer进行排序，再从磁盘取其他字段。&lt;br&gt;
​    如果使用双路排序，取一批数据要对磁盘进行两次扫描，众所周知，I/O操作是很耗时的，因此在MySQL4.1以后，出现了改进的算法：单路排序。&lt;br&gt;
​    单路排序：从磁盘中查询所需的列，按照order by列在buffer中对它们进行排序，然后扫描排序后的列表进行输出。它的效率更高一些，避免了第二次读取数据，并且把随机I/O变成了顺序I/O，但是会使用更多的空间，因为它把每一行都保存在内存中了。&lt;br&gt;
​&lt;/p&gt;
&lt;p&gt;2.单路排序出现的问题。&lt;/p&gt;
&lt;p&gt;​     当读取数据超过sort_buffer的容量时，就会导致多次读取数据，并创建临时表，最后多路合并，产生多次I/O，反而增加其I/O运算。&lt;br&gt;
​    解决方式：&lt;br&gt;
​    a.增加sort_buffer_size参数的设置。&lt;br&gt;
​    b.增大max_length_for_sort_data参数的设置。&lt;br&gt;
⑤提升order by速度的方式：&lt;/p&gt;
&lt;p&gt;1.在使用order by时，不要用select *，只查询所需的字段。&lt;/p&gt;
&lt;p&gt;​    因为当查询字段过多时，会导致sort_buffer不够，从而使用多路排序或进行多次I/O操作。&lt;/p&gt;
&lt;p&gt;2.尝试提高sort_buffer_size。&lt;/p&gt;
&lt;p&gt;3.尝试提高max_length_for_sort_data。&lt;/p&gt;
&lt;p&gt;⑦group by与order by很类似，其实质是先排序后分组，遵照索引创建顺序的最佳左前缀法则。当无法使用索引列的时候，也要对sort_buffer_size和max_length_for_sort_data参数进行调整。注意where高于having，能写在where中的限定条件就不要去having限定了。&lt;/p&gt;
&lt;h2 id=&#34;使用主键索引来优化数据分页&#34;&gt;使用主键索引来优化数据分页&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;select * from user where id&amp;gt;(select id from user where id&amp;gt;=**100000** limit **1**) limit **20**;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;##使用explain&lt;/p&gt;
&lt;h4 id=&#34;有什么用&#34;&gt;有什么用？&lt;/h4&gt;
&lt;p&gt;在MySQL中，当数据量增长的特别大的时候就需要用到索引来优化SQL语句，而如何才能判断我们辛辛苦苦写出的SQL语句是否优良？这时候&lt;strong&gt;explain&lt;/strong&gt;就派上了用场。&lt;/p&gt;
&lt;h4 id=&#34;怎么使用&#34;&gt;怎么使用？&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;explain + SQL语句即可 如：explain select * from table;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如下&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;相信第一次使用explain参数的朋友一定会疑惑这一大堆参数究竟有什么用呢？笔者搜集了一些资料，在这儿做一个总结希望能够帮助大家理解。&lt;/p&gt;
&lt;p&gt;explain（执行计划），使用explain关键字可以模拟优化器执行sql查询语句，从而知道MySQL是如何处理sql语句。 explain主要用于分析查询语句或表结构的性能瓶颈。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;id&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;id的值表示select子句或表的执行顺序，id相同，执行顺序从上到下，id不同，值越大的执行优先级越高。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;select_type&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;SIMPLE&lt;/p&gt;
&lt;p&gt;简单的select查询，查询中不包含子查询或union查询。&lt;/p&gt;
&lt;p&gt;PRIMARY&lt;/p&gt;
&lt;p&gt;查询中若包含任何复杂的子部分，最外层查询为PRIMARY，也就是最后加载的就是PRIMARY。&lt;/p&gt;
&lt;p&gt;SUBQUERY&lt;/p&gt;
&lt;p&gt;在select或where列表中包含了子查询，就为被标记为SUBQUERY。&lt;/p&gt;
&lt;p&gt;DERIVED&lt;/p&gt;
&lt;p&gt;在from列表中包含的子查询会被标记为DERIVED(衍生)，MySQL会递归执行这些子查询，将结果放在临时表中。    UNION&lt;/p&gt;
&lt;p&gt;若第二个select出现在union后，则被标记为UNION，若union包含在from子句的子查询中，外层select将被标记为DERIVED。&lt;/p&gt;
&lt;p&gt;UNION RESULT&lt;/p&gt;
&lt;p&gt;从union表获取结果的select。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;type&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;表示查询所使用的访问类型，该值表示查询的sql语句好坏，从最好到最差依次为：system&amp;gt;const&amp;gt;eq_ref&amp;gt;ref&amp;gt;range&amp;gt;index&amp;gt;ALL。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;1.system    表只有一行记录（等于系统表），是const的特例类型，平时不会出现，可以忽略不计。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2.const    表示通过一次索引就找到了结果，常出现于primary key或unique索引。因为只匹配一行数据，所以查询非常快。    如将主键置于where条件中，MySQL就能将查询转换为一个常量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;3.eq_ref：唯一索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见主键或唯一索引扫描。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;4.ref：非唯一性索引扫描，返回匹配某个单独值的所有行。本质上也是一种索引访问，返回匹配某值（某条件）的多行值，属于查找和扫描的    混合体。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;5.range：只检索给定范围的行，使用一个索引来检索行，可以在key列中查看使用的索引，一般出现在where语句的条件中，如使用between、&amp;gt;、&amp;lt;、    in等查询。    这种索引的范围扫描比全索引扫描要好，因为索引的开始点和结束点都固定，范围相对较小。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;6.index：全索引扫描，index和ALL的区别：index只遍历索引树，通常比ALL快，因为索引文件通常比数据文件小。虽说index和ALL都是全表扫描，    但是index是从索引中读取，ALL是从磁盘中读取。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;7.ALL：全表扫描。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;哪些索引可以使用。（对应possible_keys）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;哪些索引被实际使用。（对应key）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;表直接的引用。（对应ref）显示关联的字段。如果使用常数等值查询，则显示const，如果是连接查询，则会显示关联的字段。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;每张表有多少行被优化器查询。（对应rows）根据表统计信息及索引选用情况大致估算出找到所需记录所要读取的行数。当然该值越小越好。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Extra&lt;/strong&gt;&lt;br&gt;
1.Using filesort&lt;/p&gt;
&lt;p&gt;Using filesort表明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。    mysql中无法利用索引完成的排序操作称为“文件排序”。    出现Using filesort就非常危险了，在数据量非常大的时候几乎“九死一生”。出现Using filesort尽快优化sql语句。&lt;br&gt;
2.Using temporary&lt;/p&gt;
&lt;p&gt;使用了临时表保存中间结果，常见于排序order by和分组查询group by。非常危险，“十死无生”，急需优化。&lt;/p&gt;
&lt;p&gt;3.Using index&lt;/p&gt;
&lt;p&gt;表明相应的select操作中使用了覆盖索引，避免访问表的额外数据行，效率不错。&lt;/p&gt;
&lt;p&gt;如果同时出现了Using where，表明索引被用来执行索引键值的查找。（where deptid=1）    如果没有同时出现Using where，表明索引用来读取数据而非执行查找动作。&lt;/p&gt;
&lt;h2 id=&#34;change-buffer&#34;&gt;&lt;strong&gt;change buffer&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就&lt;strong&gt;不需要从磁盘中读入这个数据页了&lt;/strong&gt;。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。&lt;strong&gt;虽然是只更新内存，但是在事务提交的时候，把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，change buffer 也能找回来。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了**访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。**在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。&lt;/p&gt;
&lt;p&gt;​    显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式能够避免占用内存，提高内存利用率。&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。&lt;/p&gt;
&lt;p&gt;如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的。&lt;/p&gt;
&lt;p&gt;第一种情况是，这个记录要&lt;strong&gt;更新的目标页在内存中&lt;/strong&gt;。这时，InnoDB 的处理流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对于唯一索引来说，找到 3 和 5 之间的位置，&lt;strong&gt;判断到没有冲突&lt;/strong&gt;，插入这个值，语句执行结束；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;第二种情况是，这个记录要&lt;strong&gt;更新的目标页不在内存中&lt;/strong&gt;。这时，InnoDB 的处理流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​    将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;change buffer 适用于写多读少的业务，比如账单类、日志类的系统。因为会记录很多change buffer（写的时候） 才会merge（读的时候）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    反过来，读多写少的业务，几乎每次把更新记录在change buffer 后，就会&lt;strong&gt;立即出发merge&lt;/strong&gt;，这样随机访问 IO 的次数不会减少，反而增加了change buffer 的维护代价。&lt;/p&gt;
&lt;p&gt;所以，对于身份证号这类字段，如果业务已经保证不会写入重复数据，不需要数据库做约束，加普通索引比加主键索引要好，如果所有的更新后面，都马上伴随着对这个记录的查询，那么应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。&lt;/p&gt;
&lt;p&gt;在实际使用中，可以发现，&lt;strong&gt;普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的，特别是在使用机械硬盘时。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;change buffer 和 redo log 对比&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;insert into t(id,k) values(id1,k1),(id2,k2);&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这条更新语句做了如下操作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Page 在内存中，直接更新内存；&lt;/li&gt;
&lt;li&gt;Page 没有在内存中，就在内存的 change buffer 区域，记录下“要往 Page 插入一行”这个信。&lt;/li&gt;
&lt;li&gt;将上述两个动作记入 redo log 中。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;后续的更新操作&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Page 在内存中，会直接从内存返回。&lt;/li&gt;
&lt;li&gt;Page 不在内容中，需要把 Page 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，&lt;strong&gt;redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;优化器如何选择索引&#34;&gt;&lt;strong&gt;优化器如何选择索引&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;优化器结合&lt;strong&gt;是否扫描行数、是否使用临时表、是否排序&lt;/strong&gt;等因素进行综合判断。&lt;/p&gt;
&lt;p&gt;MySQL 在真正开始执行语句之前，并不能精确地知道满足条件的记录有多少条，而只能根据统计信息来估算记录数。&lt;/p&gt;
&lt;p&gt;这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可以使用 show index 方法，看到一个索引的基数。&lt;/strong&gt;&lt;br&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/bVbxvfx&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;MySQL 采样统计的方法获得基数，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。&lt;strong&gt;analyze table t 命令，可以用来重新统计索引信息。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。&lt;/li&gt;
&lt;li&gt;设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/bVbxvfy&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;rows 这个字段表示的是预计扫描行数。&lt;/p&gt;
&lt;h2 id=&#34;二次写double-write&#34;&gt;二次写(double write)&lt;/h2&gt;
&lt;p&gt;doublewrite组成： 内存中的doublewrite buffer,大小2M。 物理磁盘上&lt;strong&gt;共享表空间&lt;/strong&gt;中连续的128个页，即2个区（extend），大小同样为2M。&lt;/p&gt;
&lt;p&gt;Doublewrite缓存是位于&lt;strong&gt;系统表空间的存储区域&lt;/strong&gt;，对缓冲池的脏页进行刷新时，不是直接写磁盘，而是会通过memcpy()函数将脏页先&lt;strong&gt;复制到内存中的doublewrite buffer&lt;/strong&gt;，因为doublewrite页是连续的，因此这个过程是顺序写的，开销并不是很大。&lt;/p&gt;
&lt;p&gt;在完成doublewrite页的写入后，再将doublewrite buffer 中的页再分两次，每次1M顺序地写入各个表空间文件中，此时的写入则是离散的。&lt;/p&gt;
&lt;p&gt;如果操作系统在将页写入磁盘的过程中发生了崩溃，在恢复过程中，innodb可以 从系统表空间中的doublewrite中找到该页的一个副本，将其复制到表空间文件，再应用重做日志。&lt;/p&gt;
">9、Mysql调优</a>
      </div>
      
    </div>
    <div class="page">
      <div id="page_ul"></div>
    </div>
  </div>
</div>
<script>
  !function () {
    let searchMask = document.querySelector('#search_mask');
    let result = document.querySelector('#result');
    let items = document.querySelectorAll('.item');
    let searchBox = document.querySelector('#search');
    let statCount = document.querySelector('#stat_count');
    let statTimes = document.querySelector('#stat_times');
    let pageUl = document.querySelector('#page_ul');
    let close = document.querySelector('#close');
    
    close.addEventListener('click', function() {
      searchMask.style = 'display: none;'
    })

    let finds = [];
    let contents = [];
    let pageSize = 10;
    items.forEach(item => {
      let a = item.querySelector('a');
      contents.push({
        title: a.innerText,
        details: a.dataset.c,
        link: a.href
      })
      item.remove();
    })

    function insertStr(soure, start, count) {
      let newStr = soure.substr(start, count);
      return soure.slice(0, start) + '<em>' + newStr + '</em>' + soure.slice(start + count);
    }

    pageUl.addEventListener('click', function(event) {
      let target = event.target;
      if (target.__proto__ === HTMLSpanElement.prototype) {
        appendResults(parseInt(target.dataset.i));
      }
    })

    function appendResults(index) {
      let htmlResult = '';
      let start = index || 0;
      let end = Math.min(start + pageSize, finds.length);
      for (let i = start; i < end; i++) {
        const current = finds[i];
        let html = current.title;
        let sum = 0;
        let positions = current.positions;
        positions.forEach(position => {
          html = insertStr(html, position.start + sum, position.count);
          sum += 9;
        })
        htmlResult += `<div class="item"><a class="result-title" href="${current.link}">${html}</a></div>`;
      }
      result.innerHTML = htmlResult;
      pageUl.innerHTML = '';
      let count = finds.length / pageSize;
      let lis = '';
      if (start !== 0) {
        lis += `<span class="fa fa-angle-left" data-i='${start - 1}'></span>`;
      }
      for (let i = 0; i < count; i++) {
        lis += `<span class='${i === start?'current':''}' data-i='${i}'>${i+1}</span>`;     
      }
      if (start+1 < count) {
        lis += `<span class="fa fa-angle-right" data-i='${start+1}'></span>`;  
      }
      pageUl.innerHTML = lis;
    }

    function search(delay) {
      let timer = null
      return function () {
        clearTimeout(timer)
        timer = setTimeout(() => {
          let start = Date.now();
          let segments = searchBox.value.split(' ').filter(c => c != '');
          if (segments.length <= 0) {
            return;
          }
          finds = [];
          let htmlResult = '';
          contents.forEach(content => {
            let title = content.title;
            let positions = [];
            let find = false;
            segments.forEach((segment) => {
              if (content.title.includes(segment)) {
                find = true;
                positions.push({
                  start: content.title.indexOf(segment),
                  count: segment.length
                })
              } else if (content.details.includes(segment)) {
                find = true;
              }
            });
            if (find) {
              finds.push({
                title: content.title,
                link: content.link,
                positions
              });
            }
          })
          appendResults(0);
          statCount.textContent = finds.length;
          statTimes.textContent = Date.now() - start;
        }, delay)
      }
    }
    searchBox.addEventListener('input', search(200));
  }()
</script>

<input hidden id="copy" />
<script>
  !function () {
    let times = document.querySelectorAll('.publish-time');
    for (let i = 0; i < times.length; i++) {
      let date = times[i].dataset.t;
      let time = Math.floor((new Date().getTime() - new Date(date).getTime()) / 1000);
      if (time < 60) {
        str = time + '秒之前';
      } else if (time < 3600) {
        str = Math.floor(time / 60) + '分钟之前';
      } else if (time >= 3600 && time < 86400) {
        str = Math.floor(time / 3600) + '小时之前';
      } else if (time >= 86400 && time < 259200) {
        str = Math.floor(time / 86400) + '天之前';
      } else {
        str = times[i].textContent;
      }
      times[i].textContent = str;
    }
  }();
</script>

<script>
  let language = '';
  if (language !== '') {
    let map = new Map();
    if (language === 'en') {
      map.set('search', 'Search');
      map.set('category', 'Categories');
      map.set('article', 'Articles');
      map.set('tag', 'Tags');
      map.set('top', 'Top');
      map.set('publish', 'published');
      map.set('minute', ' minutes');
      map.set('read-more', 'Read More');
      map.set('view', 'View');
      map.set('words', ' words');
      map.set('category-in', 'category in');
      map.set('preview', 'Meta');
      map.set('index', 'Toc');
      map.set('no-archives', "You haven't created yet");
      map.set('archives', " articles in total");
      map.set('cloud-tags', " tags in total");
      map.set('copyright', "Copyright: ");
      map.set('author', "Author: ");
      map.set('link', "Link: ");
      map.set('leave-message', "Leave a message");
      map.set('format', "Links Format");
      map.set('site-name', "Name: ");
      map.set('site-link', "Link: ");
      map.set('site-desc', "Desc: ");
      map.set('stat', " related results, taking ");
      map.set('stat-time', " ms");
      map.set('site-img', "Image: ");
    }

    if (map.size > 0) {
      let lanElems = document.querySelectorAll('.language');
      lanElems.forEach(elem => {
        let lan = elem.dataset.lan, text = map.get(lan);
        if (elem.__proto__ === HTMLInputElement.prototype) {
          elem.placeholder = text
        } else {
          if (elem.dataset.count) {
            text = elem.dataset.count + text;
          }
          elem.textContent = text;
        }
      })
    }
  }
  //拿来主义(真香)^_^，Clipboard 实现摘自掘金 https://juejin.im/post/5aefeb6e6fb9a07aa43c20af
  window.Clipboard = (function (window, document, navigator) {
    var textArea,
      copy;

    // 判断是不是ios端
    function isOS() {
      return navigator.userAgent.match(/ipad|iphone/i);
    }
    //创建文本元素
    function createTextArea(text) {
      textArea = document.createElement('textArea');
      textArea.value = text;
      textArea.style.width = 0;
      textArea.style.height = 0;
      textArea.clientHeight = 0;
      textArea.clientWidth = 0;
      document.body.appendChild(textArea);
    }
    //选择内容
    function selectText() {
      var range,
        selection;

      if (isOS()) {
        range = document.createRange();
        range.selectNodeContents(textArea);
        selection = window.getSelection();
        selection.removeAllRanges();
        selection.addRange(range);
        textArea.setSelectionRange(0, 999999);
      } else {
        textArea.select();
      }
    }

    //复制到剪贴板
    function copyToClipboard() {
      try {
        document.execCommand("Copy")
      } catch (err) {
        alert("复制错误！请手动复制！")
      }
      document.body.removeChild(textArea);
    }

    copy = function (text) {
      createTextArea(text);
      selectText();
      copyToClipboard();
    };

    return {
      copy: copy
    };
  })(window, document, navigator);

  function copyCode(e) {
    if (e.srcElement.tagName === 'SPAN' && e.srcElement.classList.contains('copy-code')) {
      let code = e.currentTarget.querySelector('code');
      var text = code.innerText;
      if (e.srcElement.textContent === '复制成功') {
        return;
      }
      e.srcElement.textContent = '复制成功';
      (function (elem) {
        setTimeout(() => {
          if (elem.textContent === '复制成功') {
            elem.textContent = '复制代码'
          }
        }, 1000);
      })(e.srcElement)
      Clipboard.copy(text);
    }
  }

  let pres = document.querySelectorAll('pre');
  pres.forEach(pre => {
    let code = pre.querySelector('code');
    let copyElem = document.createElement('span');
    copyElem.classList.add('copy-code');
    copyElem.textContent = '复制代码';
    pre.appendChild(copyElem);
    pre.onclick = copyCode
  })

</script>
<script src="/media/js/motion.js"></script>

<script src="https://cdn.jsdelivr.net/gh/cferdinandi/smooth-scroll/dist/smooth-scroll.polyfills.min.js"></script>
<script>
  var scroll = new SmoothScroll('a[href*="#"]', {
    speed: 200
  });
</script>





</html>