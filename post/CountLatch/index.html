<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
<meta name="keywords" content="Gridea静态个人博客">
<meta name="description" content="君子终日乾乾，夕惕若，厉，无咎。">
<meta name="theme-color" content="#000">
<title>CountDownLatch | 异见</title>
<link rel="shortcut icon" href="/favicon.ico?v=1606471877586">
<link rel="stylesheet" href="/media/css/pisces.css">
<link rel="stylesheet" href="/media/fonts/font-awesome.css">
<link
  href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Rosario:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext"
  rel="stylesheet" type="text/css">

<link href="/media/hljs/styles/default.css"
  rel="stylesheet">

<link rel="stylesheet" href="/styles/main.css">

<script src="/media/hljs/highlight.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.0/velocity.ui.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"
  integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"
  integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"
  integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
  onload="renderMathInElement(document.body);"></script>





  <meta name="description" content="CountDownLatch" />
  <meta name="keywords" content="JAVA并发" />
</head>

<body>
  <div class="head-top-line"></div>
  <div class="header-box">
    
<div class="pisces">
  <header class="header  ">
    <div class="blog-header box-shadow-wrapper bg-color " id="header">
      <div class="nav-toggle" id="nav_toggle">
        <div class="toggle-box">
          <div class="line line-top"></div>
          <div class="line line-center"></div>
          <div class="line line-bottom"></div>
        </div>
      </div>
      <div class="site-meta">       
        <div class="site-title">
          
            <a href="/" class="brand">
              <span>异见</span>
            </a>  
          
        </div>
        
          <p class="subtitle">君子终日乾乾，夕惕若，厉，无咎。</p>
        
      </div>
      <nav class="site-nav" id="site_nav">
        <ul id="nav_ul">
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/" target="_self">
                  <i class="fa fa-home"></i> 首页
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/archives/" target="_self">
                  <i class="fa fa-archive"></i> 归档
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="/tags/" target="_self">
                  <i class="fa fa-tags"></i> 标签
                </a>
              
            </li>
          
            
            
              
            
            <li class="nav-item ">
              
              
                <a href="https://jboone1989.github.io/" target="_self">
                  <i class="fa fa-globe"></i> 关于
                </a>
              
            </li>
          
          
            
              <li class="nav-item ">
                <a href="/friends/" target="_self">
                  
                    <i class="fa fa-address-book"></i> 友情链接
                  
                </a>
              </li>
            
          
          
            <li id="fa_search" class="nav-item">
              <a href="javascript:void(0);">
                <i class="fa fa-search"></i> <span class="language" data-lan="search">搜索</span>
              </a>
            </li>
          
        </ul>
      </nav>
    </div>
  </header>
</div>

<script type="text/javascript"> 
 
  let showNav = true;

  let navToggle = document.querySelector('#nav_toggle'),
  siteNav = document.querySelector('#site_nav');
  
  function navClick() {
    let sideBar = document.querySelector('.sidebar');
    let navUl = document.querySelector('#nav_ul');
    navToggle.classList.toggle('nav-toggle-active');
    siteNav.classList.toggle('nav-menu-active');
    if (siteNav.classList.contains('nav-menu-active')) {
      siteNav.style = "height: " + (navUl.children.length * 42) +"px !important";
    } else {
      siteNav.style = "";
    }
  }

  navToggle.addEventListener('click',navClick);  
</script>
  </div>
  <div class="main-continer">
    
    <div
      class="section-layout pisces ">
      <div class="section-layout-wrapper">
        

<div class="sidebar">
  
    <div class="sidebar-box box-shadow-wrapper bg-color right-motion" id="sidebar">
      
      <div class="sidebar-body pisces" id="sidebar_body">
        
          
            <div style="opacity: 1;">
              <div class="toc-box right-motion">
  <div class="toc-wrapper auto-number auto"
    id="toc_wrapper">
    <ul class="markdownIt-TOC">
<li>
<ul>
<li>
<ul>
<li><a href="#countdownlatch">CountDownLatch</a></li>
<li><a href="#cyclicbarrier">CyclicBarrier</a></li>
<li><a href="#semaphore">Semaphore</a></li>
<li><a href="#%E6%80%BB%E7%BB%93">总结</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </div>
</div>

<script>

  let lastTop = 0, lList = [], hList = [], postBody, lastIndex = -1;
  let active = 'active-show', activeClass = 'active-current';
  let tocWrapper = document.querySelector('#toc_wrapper');
  let tocContent = tocWrapper.children[0];
  let autoNumber = tocWrapper && tocWrapper.classList.contains('auto-number');

  function addTocNumber(elem, deep) {
    if (!elem) {
      return;
    }
    let prop = elem.__proto__;

    if (prop === HTMLUListElement.prototype) {
      for (let i = 0; i < elem.children.length; i++) {
        addTocNumber(elem.children[i], deep + (i + 1) + '.');
      }
    } else if (prop === HTMLLIElement.prototype) {
      // 保存li元素
      if (elem.children[0] && elem.children[0].__proto__ === HTMLAnchorElement.prototype) {
        lList.push(elem);
      }
      for (let i = 0; i < elem.children.length; i++) {
        let cur = elem.children[i];
        if (cur.__proto__ === HTMLAnchorElement.prototype) {
          if (autoNumber) {
            cur.text = deep + ' ' + cur.text;
          }
        } else if (cur.__proto__ === HTMLUListElement.prototype) {
          addTocNumber(cur, deep);
        }
      }
    }
  }

  function removeParentActiveClass() {
    let parents = tocContent.querySelectorAll('.' + active)
    parents.forEach(function (elem) {
      elem.classList.remove(active);
    });
  }

  function addActiveClass(index) {
    if (index >= 0 && index < hList.length) {
      lList[index].classList.add(activeClass);
    }
  }

  function removeActiveClass(index) {
    if (index >= 0 && index < hList.length) {
      lList[index].classList.remove(activeClass);
    }
  }

  function addActiveLiElemment(elem, parent) {
    if (!elem || elem === parent) {
      return;
    } else {
      if (elem.__proto__ === HTMLLIElement.prototype) {
        elem.classList.add(active);
      }
      addActiveLiElemment(elem.parentElement, parent);
    }
  }

  function showToc() {
    if (tocWrapper) {
      postBody = document.querySelector('#post_body');
      for (let i = 0; i < postBody.children.length; i++) {
        if (postBody.children[i].__proto__ === HTMLHeadingElement.prototype) {
          hList.push(postBody.children[i]);
        }
      }
      if (tocWrapper.classList.contains('compress')) {
        tocContent.classList.add('closed');
      } else if (tocWrapper.classList.contains('no_compress')) {
        tocContent.classList.add('expanded');
      } else {
        if (hList.length > 10) {
          active = 'active-hidden'
          tocContent.classList.add('closed');
        } else {
          tocContent.classList.add('expanded');
        }
      }
    }
  }

  (function () {
    // 处理不是从#一级标题开始目录
    if (tocContent.children.length === 1 && tocContent.children[0].__proto__ === HTMLLIElement.prototype) {
      let con = tocContent.children[0].children[0];
      tocContent.innerHTML = con.innerHTML;
    }
    let markdownItTOC = document.querySelector('.markdownIt-TOC');
    let innerHeight = window.innerHeight;
    markdownItTOC.style = `max-height: ${innerHeight - 80 > 0 ? innerHeight - 80 : innerHeight}px`
    addTocNumber(tocContent, '');
  })();

  document.addEventListener('scroll', function (e) {
    if (lList.length <= 0) {
      return;
    }
    let scrollTop = document.scrollingElement.scrollTop + 10;
    let dir;

    if (lastTop - scrollTop > 0) {
      dir = 'up';
    } else {
      dir = 'down';
    }

    lastTop = scrollTop;
    if (scrollTop <= 0) {
      if (lastIndex >= 0 && lastIndex < hList.length) {
        lList[lastIndex].classList.remove(activeClass);
      }
      return;
    }

    let current = 0, hasFind = false;
    for (let i = 0; i < hList.length; i++) {
      if (hList[i].offsetTop > scrollTop) {
        current = i;
        hasFind = true;
        break;
      }
    }
    if (!hasFind && scrollTop > lList[lList.length - 1].offsetTop) {
      current = hList.length - 1;
    } else {
      current--;
    }
    if (dir === 'down') {
      if (current > lastIndex) {
        addActiveClass(current);
        removeActiveClass(lastIndex)
        lastIndex = current;
        removeParentActiveClass();
        lList[current] && addActiveLiElemment(lList[current].parentElement, tocContent);
      }
    } else {
      if (current < lastIndex) {
        addActiveClass(current);
        removeActiveClass(lastIndex);
        lastIndex = current;
        removeParentActiveClass();
        lList[current] && addActiveLiElemment(lList[current].parentElement, tocContent);
      }
    }
  });


  window.addEventListener('load', function () {
    showToc();
    document.querySelector('#sidebar').style = 'display: block;';
    tocWrapper.classList.add('toc-active');
    setTimeout(function () {
      if ("createEvent" in document) {
        let evt = document.createEvent("HTMLEvents");
        evt.initEvent("scroll", false, true);
        document.dispatchEvent(evt);
      }
      else {
        document.fireEvent("scroll");
      }
    }, 500)
  })

</script>
            </div>
          
        
      </div>
    </div>
  
</div>
<script>
  const SIDEBAR_TITLE_ACTIVE = 'sidebar-title-active';
  const SIDEBAR_BODY_ACTIVE = 'sidebar-body-active';
  const SLIDE_UP_IN = 'slide-up-in';

  let sidebar = document.querySelector('#sidebar'),
  tocSideBar = document.querySelector('#tocSideBar'),
  metaSideBar = document.querySelector('#metaSideBar'),
  postToc = document.querySelector('#post_toc'),
  postSiteMeta = document.querySelector('#post_side_meta'),
  sidebarTitle = document.querySelector('.sidebar-title'),
  sidebarBody = document.querySelector('#sidebar_body');

  tocSideBar && tocSideBar.addEventListener('click', (e) => {
    toggleSidebar(e);
  });

  metaSideBar && metaSideBar.addEventListener('click', (e) => {
    toggleSidebar(e);
  });

  function toggleSidebar(e) {
    let currentTitle = document.querySelector("."+SIDEBAR_TITLE_ACTIVE);
    if (currentTitle == e.srcElement) {
      return ;
    }
    let current, showElement, hideElement;
    if (e.srcElement == metaSideBar) {
      showElement = postSiteMeta;
      hideElement = postToc;
    } else if (e.srcElement == tocSideBar){
      showElement = postToc;
      hideElement = postSiteMeta;
    }
    currentTitle.classList.remove(SIDEBAR_TITLE_ACTIVE);
    e.srcElement.classList.add(SIDEBAR_TITLE_ACTIVE);

    window.Velocity(hideElement, 'stop');
    window.Velocity(hideElement, 'transition.slideUpOut', {
      display: 'none',
      duration: 200,
      complete: function () {
        window.Velocity(showElement, 'transition.slideDownIn', {
          duration: 200
        });
      }
    })
    hideElement.classList.remove(SIDEBAR_BODY_ACTIVE);
    showElement.classList.add(SIDEBAR_BODY_ACTIVE);
  }

  postToc && postToc.addEventListener('transitionend', function() {
    this.classList.remove(SLIDE_UP_IN);
  });

  if (sidebarBody) {
    if (sidebarBody.classList.contains('pisces') || sidebarBody.classList.contains('gemini')) {
      let hasFix = false;
      let scrollEl = document.querySelector('.main-continer');
      let limitTop = document.querySelector('#nav_ul').children.length * 42 + 162;
      window.addEventListener('scroll', function(e) {
        if (document.scrollingElement.scrollTop >= limitTop) {
          if (!hasFix) {
            sidebar.classList.add('sidebar-fixed');
            hasFix = true;
          }
        } else {
          if (hasFix) {
            sidebar.classList.remove('sidebar-fixed');
            hasFix = false;
          }
        }
      });
    }
  }
  
</script>
        <div class="section-box box-shadow-wrapper">
          <div class="section bg-color post post-page">
            <section class="post-header">
  <h1 class="post-title">
    <a class="post-title-link" href="https://jboone1989.github.io/post/CountLatch/">
      CountDownLatch
    </a>
  </h1>
  <div class="post-meta">
    
    <span class="meta-item pc-show">
      <i class="fa fa-calendar-o"></i>
      <span class="language" data-lan="publish">发布于</span>
      <span class="publish-time" data-t="2020-11-19 18:06:16">2020-11-19</span>
      <span class="post-meta-divider pc-show">|</span>
    </span>
    
    <span class="meta-item">
      <i class="fa fa-folder-o"></i>
      <span class="pc-show language" data-lan="category-in">分类于</span>
      
      
      <a href="https://jboone1989.github.io/tag/G52vlkmZR/">
        <span>JAVA并发</span>
      </a>
      
      
    </span>
    <span class="post-meta-divider">|</span>
    
    <span class="meta-item">
      <i class="fa fa-clock-o"></i>
      <span>9<span class="language" data-lan="minute">分钟</span></span>
    </span>
    <span class="meta-item">
      <span class="post-meta-divider">|</span>
      <i class="fa fa-file-word-o"></i>
      <span>2076<span class="pc-show language" data-lan="words">字数</span></span>
    </span>
    
  </div>
</section>
            <div class="post-body next-md-body" id="post_body">
              <h3 id="countdownlatch">CountDownLatch</h3>
<p>CountDownLatch适用于在多线程的场景需要等待所有子线程全部执行完毕之后再做操作的场景。</p>
<p>举个例子，早上部门开会，有人在上厕所，这时候需要等待所有人从厕所回来之后才能开始会议。</p>
<pre><code class="language-java">public class CountDownLatchTest {
    private static int num = 3;
    private static CountDownLatch countDownLatch = new CountDownLatch(num);
    private static ExecutorService executorService = Executors.newFixedThreadPool(num);
    public static void main(String[] args) throws Exception{
        executorService.submit(() -&gt; {
            System.out.println(&quot;A在上厕所&quot;);
            try {
                Thread.sleep(4000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }finally {
                countDownLatch.countDown();
                System.out.println(&quot;A上完了&quot;);
            }
        });
        executorService.submit(()-&gt;{
            System.out.println(&quot;B在上厕所&quot;);
            try {
                Thread.sleep(2000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }finally {
                countDownLatch.countDown();
                System.out.println(&quot;B上完了&quot;);
            }
        });
        executorService.submit(()-&gt;{
            System.out.println(&quot;C在上厕所&quot;);
            try {
                Thread.sleep(3000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }finally {
                countDownLatch.countDown();
                System.out.println(&quot;C上完了&quot;);
            }
        });

        System.out.println(&quot;等待所有人从厕所回来开会...&quot;);
        countDownLatch.await();
        System.out.println(&quot;所有人都好了，开始开会...&quot;);
        executorService.shutdown();

    }
}
</code></pre>
<p>代码执行结果：</p>
<pre><code>A在上厕所
B在上厕所
等待所有人从厕所回来开会...
C在上厕所
B上完了
C上完了
A上完了
所有人都好了，开始开会...
</code></pre>
<p>初始化一个CountDownLatch实例传参3，因为我们有3个子线程，每次子线程执行完毕之后调用countDown()方法给计数器-1，主线程调用await()方法后会被阻塞，直到最后计数器变为0，await()方法返回，执行完毕。他和join()方法的区别就是join会阻塞子线程直到运行结束，而CountDownLatch可以在任何时候让await()返回，而且用ExecutorService没法用join了，相比起来，CountDownLatch更灵活。</p>
<p>CountDownLatch基于AQS实现，volatile变量state维持倒数状态，多线程共享变量可见。</p>
<ol>
<li>CountDownLatch通过构造函数初始化传入参数实际为AQS的state变量赋值，维持计数器倒数状态</li>
<li>当主线程调用await()方法时，当前线程会被阻塞，当state不为0时进入AQS阻塞队列等待。</li>
<li>其他线程调用countDown()时，state值原子性递减，当state值为0的时候，唤醒所有调用await()方法阻塞的线程</li>
</ol>
<h3 id="cyclicbarrier">CyclicBarrier</h3>
<p>CyclicBarrier叫做回环屏障，它的作用是<strong>让一组线程全部达到一个状态之后再全部同时执行</strong>，而且他有一个特点就是所有线程执行完毕之后是可以重用的。</p>
<pre><code>public class CyclicBarrierTest {
    private static int num = 3;
    private static CyclicBarrier cyclicBarrier = new CyclicBarrier(num, () -&gt; {
        System.out.println(&quot;所有人都好了，开始开会...&quot;);
        System.out.println(&quot;-------------------&quot;);
    });
    private static ExecutorService executorService = Executors.newFixedThreadPool(num);
    public static void main(String[] args) throws Exception{
        executorService.submit(() -&gt; {
            System.out.println(&quot;A在上厕所&quot;);
            try {
                Thread.sleep(4000);
                System.out.println(&quot;A上完了&quot;);
                cyclicBarrier.await();
                System.out.println(&quot;会议结束，A退出&quot;);
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });
        executorService.submit(()-&gt;{
            System.out.println(&quot;B在上厕所&quot;);
            try {
                Thread.sleep(2000);
                System.out.println(&quot;B上完了&quot;);
                cyclicBarrier.await();
                System.out.println(&quot;会议结束，B退出&quot;);
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });
        executorService.submit(()-&gt;{
            System.out.println(&quot;C在上厕所&quot;);
            try {
                Thread.sleep(3000);
                System.out.println(&quot;C上完了&quot;);
                cyclicBarrier.await();
                System.out.println(&quot;会议结束，C退出&quot;);
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });

        executorService.shutdown();

    }
}
</code></pre>
<p>输出结果为：</p>
<pre><code>A在上厕所
B在上厕所
C在上厕所
B上完了
C上完了
A上完了
所有人都好了，开始开会...
-------------------
会议结束，A退出
会议结束，B退出
会议结束，C退出
</code></pre>
<p>从结果来看和CountDownLatch非常相似，初始化传入3个线程和一个任务，线程调用await()之后进入阻塞，计数器-1，当计数器为0时，就去执行CyclicBarrier中构造函数的任务，当任务执行完毕后，唤醒所有阻塞中的线程。这验证了CyclicBarrier<strong>让一组线程全部达到一个状态之后再全部同时执行</strong>的效果。</p>
<p>再举个例子来验证CyclicBarrier可重用的效果。</p>
<pre><code>public class CyclicBarrierTest2 {
    private static int num = 3;
    private static CyclicBarrier cyclicBarrier = new CyclicBarrier(num, () -&gt; {
        System.out.println(&quot;-------------------&quot;);
    });
    private static ExecutorService executorService = Executors.newFixedThreadPool(num);

    public static void main(String[] args) throws Exception {
        executorService.submit(() -&gt; {
            System.out.println(&quot;A在上厕所&quot;);
            try {
                Thread.sleep(4000);
                System.out.println(&quot;A上完了&quot;);
                cyclicBarrier.await();
                System.out.println(&quot;会议结束，A退出，开始撸代码&quot;);
                cyclicBarrier.await();
                System.out.println(&quot;C工作结束，下班回家&quot;);
                cyclicBarrier.await();
            } catch (Exception e) {
                e.printStackTrace();
            } finally {

            }
        });
        executorService.submit(() -&gt; {
            System.out.println(&quot;B在上厕所&quot;);
            try {
                Thread.sleep(2000);
                System.out.println(&quot;B上完了&quot;);
                cyclicBarrier.await();
                System.out.println(&quot;会议结束，B退出，开始摸鱼&quot;);
                cyclicBarrier.await();
                System.out.println(&quot;B摸鱼结束，下班回家&quot;);
                cyclicBarrier.await();
            } catch (Exception e) {
                e.printStackTrace();
            } finally {

            }
        });
        executorService.submit(() -&gt; {
            System.out.println(&quot;C在上厕所&quot;);
            try {
                Thread.sleep(3000);
                System.out.println(&quot;C上完了&quot;);
                cyclicBarrier.await();
                System.out.println(&quot;会议结束，C退出，开始摸鱼&quot;);
                cyclicBarrier.await();
                System.out.println(&quot;C摸鱼结束，下班回家&quot;);
                cyclicBarrier.await();
            } catch (Exception e) {
                e.printStackTrace();
            } finally {

            }
        });

        executorService.shutdown();

    }
}
</code></pre>
<p>输出结果：</p>
<pre><code>A在上厕所
B在上厕所
C在上厕所
B上完了
C上完了
A上完了
-------------------
会议结束，A退出，开始撸代码
会议结束，B退出，开始摸鱼
会议结束，C退出，开始摸鱼
-------------------
C摸鱼结束，下班回家
C工作结束，下班回家
B摸鱼结束，下班回家
-------------------
</code></pre>
<p>从结果来看，每个子线程调用await()计数器减为0之后才开始继续一起往下执行，会议结束之后一起进入摸鱼状态，最后一天结束一起下班，这就是<strong>可重用</strong>。</p>
<p>CyclicBarrier还是基于AQS实现的，内部维护parties记录总线程数，count用于计数，最开始count=parties，调用await()之后count原子递减，当count为0之后，再次将parties赋值给count，这就是复用的原理。</p>
<ol>
<li>当子线程调用await()方法时，获取独占锁，同时对count递减，进入阻塞队列，然后释放锁</li>
<li>当第一个线程被阻塞同时释放锁之后，其他子线程竞争获取锁，操作同1</li>
<li>直到最后count为0，执行CyclicBarrier构造函数中的任务，执行完毕之后子线程继续向下执行</li>
</ol>
<h3 id="semaphore">Semaphore</h3>
<p>Semaphore叫做信号量，和前面两个不同的是，他的计数器是递增的。</p>
<pre><code>public class SemaphoreTest {
    private static int num = 3;
    private static int initNum = 0;
    private static Semaphore semaphore = new Semaphore(initNum);
    private static ExecutorService executorService = Executors.newFixedThreadPool(num);
    public static void main(String[] args) throws Exception{
        executorService.submit(() -&gt; {
            System.out.println(&quot;A在上厕所&quot;);
            try {
                Thread.sleep(4000);
                semaphore.release();
                System.out.println(&quot;A上完了&quot;);
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });
        executorService.submit(()-&gt;{
            System.out.println(&quot;B在上厕所&quot;);
            try {
                Thread.sleep(2000);
                semaphore.release();
                System.out.println(&quot;B上完了&quot;);
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });
        executorService.submit(()-&gt;{
            System.out.println(&quot;C在上厕所&quot;);
            try {
                Thread.sleep(3000);
                semaphore.release();
                System.out.println(&quot;C上完了&quot;);
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });

        System.out.println(&quot;等待所有人从厕所回来开会...&quot;);
        semaphore.acquire(num);
        System.out.println(&quot;所有人都好了，开始开会...&quot;);

        executorService.shutdown();

    }
}
</code></pre>
<p>输出结果为：</p>
<pre><code>A在上厕所
B在上厕所
等待所有人从厕所回来开会...
C在上厕所
B上完了
C上完了
A上完了
所有人都好了，开始开会...
</code></pre>
<p>稍微和前两个有点区别，构造函数传入的初始值为0，当子线程调用release()方法时，计数器递增，主线程acquire()传参为3则说明主线程一直阻塞，直到计数器为3才会返回。</p>
<p>Semaphore还还还是基于AQS实现的，同时获取信号量有公平和非公平两种策略</p>
<ol>
<li>主线程调用acquire()方法时，用当前信号量值-需要获取的值，如果小于0，则进入同步阻塞队列，大于0则通过CAS设置当前信号量为剩余值，同时返回剩余值</li>
<li>子线程调用release()给当前信号量值计数器+1(增加的值数量由传参决定)，同时不停的尝试因为调用acquire()进入阻塞的线程</li>
</ol>
<h3 id="总结">总结</h3>
<p>CountDownLatch通过计数器提供了比join更灵活的多线程控制方式，CyclicBarrier也可以达到CountDownLatch的效果，而且有可复用的特点，Semaphore则是采用信号量递增的方式，开始的时候并不需要关注需要同步的线程个数，并且提供获取信号的公平和非公平策略。</p>

            </div>
            
              <div class="reward-btn">
                <div class="reward-btn-text">赞赏</div>
              </div>
            
            
              <div class="post-footer">
  <ul class="post-copyright">
    <li class="post-copyright-author">
      <strong class="language" data-lan="author">本文作者：</strong>
      异见
    </li>
    <li class="post-copyright-link">
      <strong class="language" data-lan="link">本文链接：</strong>
      <a href="https://jboone1989.github.io/post/CountLatch/" title="CountDownLatch">https://jboone1989.github.io/post/CountLatch/</a>
    </li>
    <li class="post-copyright-license">
      <strong class="language" data-lan="copyright">版权声明： </strong>
      本博客所有文章除特别声明外，均采用<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i> BY-NC-SA</a> 许可协议。转载请注明出处！
    </li>
  </ul>
  <div class="tags">
    
      <a href="https://jboone1989.github.io/tag/G52vlkmZR/"># JAVA并发</a>
    
  </div>
  <div class="nav">
    <div class="nav-prev">
      
        <i class="fa fa-chevron-left"></i>
        <a class="nav-pc-next" title="Iterator，fail-fast机制与比较器" href="https://jboone1989.github.io/post/iteratorfail-fast-ji-zhi-yu-bi-jiao-qi/">Iterator，fail-fast机制与比较器</a class="nav-pc-next">
        <a class="nav-mobile-prev" title="Iterator，fail-fast机制与比较器" href="https://jboone1989.github.io/post/iteratorfail-fast-ji-zhi-yu-bi-jiao-qi/">上一篇</a>
      
    </div>
    <div class="nav-next">
      
        <a class="nav-pc-next" title="JVM" href="https://jboone1989.github.io/post/Jvm/">JVM</a>
        <a class="nav-mobile-next" title="JVM" href="https://jboone1989.github.io/post/Jvm/">下一篇</a>
        <i class="fa fa-chevron-right"></i>
      
    </div>
  </div>
</div>
            
            
  

          </div>
        </div>
      </div>
    </div>
    <div class="footer-box">
  <footer class="footer">
    <div class="copyright">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | © 2019-2020 Theme By <a
        href="https://github.com/hsxyhao/gridea-theme-next" target="_blank">HsxyHao</a>
    </div>
    <div class="poweredby">
      
    </div>
  </footer>
  
  
  <div class="pisces back-to-top" id="back_to_top">
    <i class="fa fa-arrow-up"></i>
    
    <span class="scrollpercent">
      <span id="back_to_top_text">0</span>%
    </span>
    
  </div>
  
  
  
</div>
<script>

  let sideBarOpen = 'sidebar-open';
  let body = document.body;
  let back2Top = document.querySelector('#back_to_top'),
    back2TopText = document.querySelector('#back_to_top_text'),
    drawerBox = document.querySelector('#drawer_box'),
    rightSideBar = document.querySelector('.sidebar'),
    viewport = document.querySelector('body');

  function scrollAnimation(currentY, targetY) {

    let needScrollTop = targetY - currentY
    let _currentY = currentY
    setTimeout(() => {
      const dist = Math.ceil(needScrollTop / 10)
      _currentY += dist
      window.scrollTo(_currentY, currentY)
      if (needScrollTop > 10 || needScrollTop < -10) {
        scrollAnimation(_currentY, targetY)
      } else {
        window.scrollTo(_currentY, targetY)
      }
    }, 1)
  }

  back2Top.addEventListener("click", function (e) {
    scrollAnimation(document.scrollingElement.scrollTop, 0);
    e.stopPropagation();
    return false;
  });

  window.addEventListener('scroll', function (e) {
    let percent = document.scrollingElement.scrollTop / (document.scrollingElement.scrollHeight - document.scrollingElement.clientHeight) * 100;
    if (percent > 1 && !back2Top.classList.contains('back-top-active')) {
      back2Top.classList.add('back-top-active');
    }
    if (percent == 0) {
      back2Top.classList.remove('back-top-active');
    }
    if (back2TopText) {
      back2TopText.textContent = Math.floor(percent);
    }
  });


  let hasCacu = false;
  window.onresize = function () {
    calcuHeight();
  }

  function calcuHeight() {
    // 动态调整站点概览高度
    if (!hasCacu && back2Top.classList.contains('pisces') || back2Top.classList.contains('gemini')) {
      let sideBar = document.querySelector('.sidebar');
      let navUl = document.querySelector('#site_nav');
      sideBar.style = 'margin-top:' + (navUl.offsetHeight + navUl.offsetTop + 15) + 'px;';
      hasCacu = true;
    }
  }
  calcuHeight();

  let open = false, MOTION_TIME = 300, RIGHT_MOVE_DIS = '320px';

  if (drawerBox) {
    let rightMotions = document.querySelectorAll('.right-motion');
    let right = drawerBox.classList.contains('right');

    let transitionDir = right ? "transition.slideRightIn" : "transition.slideLeftIn";

    let openProp, closeProp;
    if (right) {
      openProp = {
        paddingRight: RIGHT_MOVE_DIS
      };
      closeProp = {
        paddingRight: '0px'
      };
    } else {
      openProp = {
        paddingLeft: RIGHT_MOVE_DIS
      };
      closeProp = {
        paddingLeft: '0px'
      };
    }

    drawerBox.onclick = function () {
      open = !open;
      window.Velocity(rightSideBar, 'stop');
      window.Velocity(viewport, 'stop');
      window.Velocity(rightMotions, 'stop');
      if (open) {
        window.Velocity(rightSideBar, {
          width: RIGHT_MOVE_DIS
        }, {
          duration: MOTION_TIME,
          begin: function () {
            window.Velocity(rightMotions, transitionDir, {});
          }
        })
        window.Velocity(viewport, openProp, {
          duration: MOTION_TIME
        });
      } else {
        window.Velocity(rightSideBar, {
          width: '0px'
        }, {
          duration: MOTION_TIME,
          begin: function () {
            window.Velocity(rightMotions, {
              opacity: 0
            });
          }
        })
        window.Velocity(viewport, closeProp, {
          duration: MOTION_TIME
        });
      }
      for (let i = 0; i < drawerBox.children.length; i++) {
        drawerBox.children[i].classList.toggle('muse-line');
      }
      drawerBox.classList.toggle(sideBarOpen);
    }
  }

  // 链接跳转
  let newWindow = 'false'
  if (newWindow === 'true') {
    let links = document.querySelectorAll('.post-body a')
    links.forEach(item => {
      if (!item.classList.contains('btn')) {
        item.setAttribute("target", "_blank");
      }
    })
  }

  let faSearch = document.querySelector('#fa_search');
  faSearch.addEventListener('click', function () {
    document.querySelector('#search_mask').style = ''
  })

  // 代码高亮
  hljs.initHighlightingOnLoad();
  
  // 离开当前页title变化
  var leaveTitle = "";
  if (leaveTitle) {
    document.addEventListener('visibilitychange', function () {
      if (document.visibilityState == 'hidden') {
        normal_title = document.title;
        document.title = leaveTitle;
      } else {
        document.title = normal_title;
      }
    });
  }

</script>
    <div class="light-box" id="light_box"></div>
<script>
  let imgs = document.querySelectorAll('.post-body img');
  let lightBox = document.querySelector('#light_box');
  lightBox.addEventListener('mousedown', (e) => {
    e.preventDefault()
  })
  lightBox.addEventListener('mousewheel', (e) => {
    e.preventDefault()
  })
  let width = window.innerWidth * 0.8;
  lightBox.onclick = () => {
    let img = lightBox.querySelector('img');
    lightBox.style = '';
    img && img.remove();
  }
  imgs.forEach(item => {
    item.onclick = function (e) {
      let lightImg = document.createElement('img');
      lightImg.src = this.src;
      lightBox.style = `height: 100%; opacity: 1; background-color: rgba(0, 0, 0, 0.5);cursor: zoom-out;`;
      lightImg.style = `width: ${width}px;border-radius: 2px;`;
      lightImg.onclick = function () {
        lightBox.style = '';
        this.remove();
      }
      lightBox.append(lightImg);
    }
  })
</script>
    <div class="reward-mask" style="display: none;">
  <div class="reward-relative">
    <span class="close" aria-hidden="true">x</span>
    <div class="reward-body">
      <h2>感谢您的支持，我会继续努力的!</h2>
      <div class="reward-img-box">
        <div style="position: relative; width: 140px; height: 140px;">
          
          
          
        </div>
      </div>
      <p class="reward-word">扫码打赏，你说多少就多少</p>
      <p class="reward-tip">打开微信扫一扫，即可进行扫码打赏哦</p>
    </div>
    <div class="bottom">
      
      
    </div>
  </div>
</div>
<style>
  .reward-mask {
    position: fixed;
    z-index: 99999;
    top: 0;
    bottom: 0;
    left: 0;
    right: 0;
    background-color: #00000054;
  }

  .reward-relative {
    position: relative;
    width: 480px;
    text-align: center;
    margin: 0 auto;
    border-radius: 5px;
    background-color: #fff;
    top: 50%;
    margin-top: -205px;
  }

  .reward-relative .close {
    position: absolute;
    right: 10px;
    font-weight: normal;
    font-size: 16px;
    color: #929292;
  }

  .reward-body {
    padding: 40px 20px 20px;
  }

  .bottom {
    display: flex;
  }

  .reward-btn {
    text-align: center;
  }

  .reward-btn-text {
    display: inline-block;
    cursor: pointer;
    width: 60px;
    height: 60px;
    line-height: 60px;
    border-radius: 50%;
    background-color: #ff9734;
    color: #FFF;
    margin-top: 20px;
  }

  .pay-text {
    margin-top: 10px;
    padding: 10px;
    flex: 1;
    transition: all .2s linear;
  }

  .pay-text:hover {
    background-color: #a5a5a536;
  }

  .reward-body h2 {
    padding-top: 10px;
    text-align: center;
    color: #a3a3a3;
    font-size: 16px;
    font-weight: normal;
    margin: 0 0 20px;
  }

  .reward-body h2:after,
  .reward-body h2:before {
    font-family: Arial, Helvetica, sans-serif;
    background: 0 0;
    width: 0;
    height: 0;
    font-style: normal;
    color: #eee;
    font-size: 80px;
    position: absolute;
    top: 20px;
  }

  .reward-body h2:before {
    content: '\201c';
    left: 50px;
  }

  .reward-body h2:after {
    content: '\201d';
    right: 80px;
  }

  .reward-img-box {
    display: inline-block;
    padding: 10px;
    border: 6px solid #ea5f00;
    margin: 0 auto;
    border-radius: 3px;
    position: relative;
  }

  .reward-img {
    position: absolute;
    left: 0px;
    top: 0px;
    width: 100%;
    height: 100%;
  }

  @media (max-width: 767px) {
    .reward-relative {
      height: 100%;
      top: 0px;
      margin-top: 0;
      width: auto;
    }

    .reward-relative .bottom {
      flex-direction: column;
    }

    .reward-relative .pay-text {
      width: 80%;
      margin: 5px auto;
      border: 1px solid silver;
      padding: 6px;
      border-radius: 4px;
    }

    .reward-body h2:after {
      right: 40px;
    }

    .reward-body h2:after,
    .reward-body h2:before {
      font-size: 60px;
    }

    .reward-body h2:before {
      left: 20px;
    }
  }
</style>
<script>
  !function () {
    var mask = document.querySelector('.reward-mask');
    let close = document.querySelector('.reward-relative .close');
    let rewardBtn = document.querySelector('.reward-btn');

    let zfb = document.querySelector('#zfb'),
      wx = document.querySelector('#wx'),
      zfbBtn = document.querySelector('#zfbBtn'),
      wxBtn = document.querySelector('#wxBtn');

    if (zfbBtn && wxBtn) {
      zfbBtn.addEventListener('click', () => {
        window.Velocity(zfb, 'transition.slideLeftIn', {
          duration: 400
        });
        window.Velocity(wx, 'transition.slideRightOut', {
          display: 'none',
          duration: 400
        });
      });

      wxBtn.addEventListener('click', () => {
        window.Velocity(wx, 'transition.slideRightIn', {
          duration: 400
        });
        window.Velocity(zfb, 'transition.slideLeftOut', {
          display: 'none',
          duration: 400
        });
      });
    }

    rewardBtn.addEventListener('click', (e) => {
      window.Velocity(mask, 'transition.slideDownIn', {
        duration: 400
      })
    });

    close.addEventListener('click', (e) => {
      e.preventDefault();
      window.Velocity(mask, 'transition.slideUpOut', {
        duration: 400
      })
    })
  }()
</script>

  </div>
</body>

<div class="search-mask" id="search_mask" style="display: none;">
  <div class="search-box">
    <div class="search-title">
      <i class="fa fa-search"></i>
      <div class="input-box">
        <input id="search" type="text" class="language" data-lan="search" placeholder="搜索">
      </div>
      <i id="close" class="fa fa-times-circle"></i>
    </div>
    <div class="stat-box">
      <span id="stat_count">0</span><span class="language" data-lan="stat">条相关条目，使用了</span><span id="stat_times">0</span><span class="language" data-lan="stat-time">毫秒</span>
      <hr>
    </div>
    <div class="result" id="result">
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/mian-shi/"" data-c="
          &lt;p&gt;&lt;strong&gt;说说进程和线程的区别？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;进程是程序的一次执行，是系统进行资源分配和调度的独立单位，他的作用是是程序能够并发执行提高资源利用率和吞吐率。&lt;/p&gt;
&lt;p&gt;由于进程是资源分配和调度的基本单位，因为进程的创建、销毁、切换产生大量的时间和空间的开销，进程的数量不能太多，而线程是比进程更小的能独立运行的基本单位，他是进程的一个实体，可以减少程序并发执行时的时间和空间开销，使得操作系统具有更好的并发性。&lt;/p&gt;
&lt;p&gt;线程基本不拥有系统资源，只有一些运行时必不可少的资源，比如程序计数器、寄存器和栈，进程则占有堆、栈。&lt;/p&gt;
&lt;h3 id=&#34;知道synchronized原理吗&#34;&gt;&lt;strong&gt;知道synchronized原理吗？&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;synchronized是java提供的原子性内置锁，这种内置的并且使用者看不到的锁也被称为&lt;strong&gt;监视器锁&lt;/strong&gt;，使用synchronized之后，会在编译之后在同步的代码块前后加上monitorenter和monitorexit字节码指令，他依赖操作系统底层互斥锁实现。他的作用主要就是实现原子性操作和解决共享变量的内存可见性问题。&lt;/p&gt;
&lt;p&gt;执行monitorenter指令时会尝试获取对象锁，如果对象没有被锁定或者已经获得了锁，锁的计数器+1。此时其他竞争锁的线程则会进入等待队列中。&lt;/p&gt;
&lt;p&gt;执行monitorexit指令时则会把计数器-1，当计数器值为0时，则锁释放，处于等待队列中的线程再继续竞争锁。&lt;/p&gt;
&lt;p&gt;synchronized是排它锁，当一个线程获得锁之后，其他线程必须等待该线程释放锁后才能获得锁，而且由于Java中的线程和操作系统原生线程是一一对应的，线程被阻塞或者唤醒时时会从用户态切换到内核态，这种转换非常消耗性能。&lt;/p&gt;
&lt;p&gt;从内存语义来说，加锁的过程会清除工作内存中的共享变量，再从主内存读取，而释放锁的过程则是将工作内存中的共享变量写回主内存。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;实际上大部分时候我认为说到monitorenter就行了，但是为了更清楚的描述，还是再具体一点&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;如果再深入到源码来说，synchronized实际上有两个队列waitSet和entryList。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;当多个线程进入同步代码块时，首先进入entryList&lt;/li&gt;
&lt;li&gt;有一个线程获取到monitor锁后，就赋值给当前线程，并且计数器+1&lt;/li&gt;
&lt;li&gt;如果线程调用wait方法，将释放锁，当前线程置为null，计数器-1，同时进入waitSet等待被唤醒，调用notify或者notifyAll之后又会进入entryList竞争锁&lt;/li&gt;
&lt;li&gt;如果线程执行完毕，同样释放锁，计数器-1，当前线程置为null&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehVayU2Ey8Fm3lFvDoaSjT2prBjWibRkk2tB1ric2LHVDCXYicyK2gb195Q/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;那锁的优化机制了解吗&#34;&gt;&lt;strong&gt;那锁的优化机制了解吗？&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;从JDK1.6版本之后，synchronized本身也在不断优化锁的机制，有些情况下他并不会是一个很重量级的锁了。优化机制包括自适应锁、自旋锁、锁消除、锁粗化、轻量级锁和偏向锁。&lt;/p&gt;
&lt;p&gt;锁的状态从低到高依次为&lt;strong&gt;无锁-&amp;gt;偏向锁-&amp;gt;轻量级锁-&amp;gt;重量级锁&lt;/strong&gt;，升级的过程就是从低到高，降级在一定条件也是有可能发生的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;自旋锁&lt;/strong&gt;：由于大部分时候，锁被占用的时间很短，共享变量的锁定时间也很短，所有没有必要挂起线程，用户态和内核态的来回上下文切换严重影响性能。自旋的概念就是让线程执行一个忙循环，可以理解为就是啥也不干，防止从用户态转入内核态，自旋锁可以通过设置-XX:+UseSpining来开启，自旋的默认次数是10次，可以使用-XX:PreBlockSpin设置。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;自适应锁&lt;/strong&gt;：自适应锁就是自适应的自旋锁，自旋的时间不是固定时间，而是由前一次在同一个锁上的自旋时间和锁的持有者状态来决定。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;锁消除&lt;/strong&gt;：锁消除指的是JVM检测到一些同步的代码块，完全不存在数据竞争的场景，也就是不需要加锁，就会进行锁消除。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;锁粗化&lt;/strong&gt;：锁粗化指的是有很多操作都是对同一个对象进行加锁，就会把锁的同步范围扩展到整个操作序列之外。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;偏向锁&lt;/strong&gt;：当线程访问同步块获取锁时，会在对象头和栈帧中的锁记录里存储偏向锁的线程ID，之后这个线程再次进入同步块时都不需要CAS来加锁和解锁了，偏向锁会永远偏向第一个获得锁的线程，如果后续没有其他线程获得过这个锁，持有锁的线程就永远不需要进行同步，反之，当有其他线程竞争偏向锁时，持有偏向锁的线程就会释放偏向锁。可以用过设置-XX:+UseBiasedLocking开启偏向锁。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;轻量级锁&lt;/strong&gt;：JVM的对象的对象头中包含有一些锁的标志位，代码进入同步块的时候，JVM将会使用CAS方式来尝试获取锁，如果更新成功则会把对象头中的状态位标记为轻量级锁，如果更新失败，当前线程就尝试自旋来获得锁。&lt;/p&gt;
&lt;p&gt;整个锁升级的过程非常复杂，我尽力去除一些无用的环节，简单来描述整个升级的机制。&lt;/p&gt;
&lt;p&gt;简单点说，偏向锁就是通过对象头的偏向线程ID来对比，甚至都不需要CAS了，而轻量级锁主要就是通过CAS修改对象头锁记录和自旋来实现，重量级锁则是除了拥有锁的线程其他全部阻塞。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehP1heYUUerKq0Xd3k7DGl9xqicy6NsgJow4xHIYSK0Oc90aN7TO2TsibA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;那对象头具体都包含哪些内容&#34;&gt;&lt;strong&gt;那对象头具体都包含哪些内容？&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;在我们常用的Hotspot虚拟机中，对象在内存中布局实际包含3个部分：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对象头&lt;/li&gt;
&lt;li&gt;实例数据&lt;/li&gt;
&lt;li&gt;对齐填充&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;而对象头包含两部分内容，Mark Word中的内容会随着锁标志位而发生变化，所以只说存储结构就好了。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对象自身运行时所需的数据，也被称为Mark Word，也就是用于轻量级锁和偏向锁的关键点。具体的内容包含对象的hashcode、分代年龄、轻量级锁指针、重量级锁指针、GC标记、偏向锁线程ID、偏向锁时间戳。&lt;/li&gt;
&lt;li&gt;存储类型指针，也就是指向类的元数据的指针，通过这个指针才能确定对象是属于哪个类的实例。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;如果是数组的话，则还包含了数组的长度&lt;/em&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehqwibXA66l7WiaIxZx91PaPNjz8NDfYYvlm2tmWUjOIknNdYweYEBINzw/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;对于加锁那再说下reentrantlock原理他和synchronized有什么区别&#34;&gt;&lt;strong&gt;对于加锁，那再说下ReentrantLock原理？他和synchronized有什么区别？&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;相比于synchronized，ReentrantLock需要显式的获取锁和释放锁，相对现在基本都是用JDK7和JDK8的版本，ReentrantLock的效率和synchronized区别基本可以持平了。他们的主要区别有以下几点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;等待可中断，当持有锁的线程长时间不释放锁的时候，等待中的线程可以选择放弃等待，转而处理其他的任务。&lt;/li&gt;
&lt;li&gt;公平锁：synchronized和ReentrantLock默认都是非公平锁，但是ReentrantLock可以通过构造函数传参改变。只不过使用公平锁的话会导致性能急剧下降。&lt;/li&gt;
&lt;li&gt;绑定多个条件：ReentrantLock可以同时绑定多个Condition条件对象。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ReentrantLock基于AQS(&lt;strong&gt;AbstractQueuedSynchronizer 抽象队列同步器&lt;/strong&gt;)实现。别说了，我知道问题了，AQS原理我来讲。&lt;/p&gt;
&lt;p&gt;AQS内部维护一个state状态位，尝试加锁的时候通过CAS(CompareAndSwap)修改值，如果成功设置为1，并且把当前线程ID赋值，则代表加锁成功，一旦获取到锁，其他的线程将会被阻塞进入阻塞队列自旋，获得锁的线程释放锁的时候将会唤醒阻塞队列中的线程，释放锁的时候则会把state重新置为0，同时当前线程ID置为空。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehjaoTsjWvmlr4VwFnX8ZHGh8xUPt87pI4iaYBOoltaT7zWibDqrO1HouA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;cas的原理呢&#34;&gt;&lt;strong&gt;CAS的原理呢？&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;CAS叫做CompareAndSwap，比较并交换，主要是通过处理器的指令来保证操作的原子性，它包含三个操作数：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;变量内存地址，V表示&lt;/li&gt;
&lt;li&gt;旧的预期值，A表示&lt;/li&gt;
&lt;li&gt;准备设置的新值，B表示&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当执行CAS指令时，只有当V等于A时，才会用B去更新V的值，否则就不会执行更新操作。&lt;/p&gt;
&lt;h3 id=&#34;那么cas有什么缺点吗&#34;&gt;&lt;strong&gt;那么CAS有什么缺点吗？&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;CAS的缺点主要有3点：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ABA问题&lt;/strong&gt;：ABA的问题指的是在CAS更新的过程中，当读取到的值是A，然后准备赋值的时候仍然是A，但是实际上有可能A的值被改成了B，然后又被改回了A，这个CAS更新的漏洞就叫做ABA。只是ABA的问题大部分场景下都不影响并发的最终效果。&lt;/p&gt;
&lt;p&gt;Java中有AtomicStampedReference来解决这个问题，他加入了预期标志和更新后标志两个字段，更新时不光检查值，还要检查当前的标志是否等于预期标志，全部相等的话才会更新。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;循环时间长开销大&lt;/strong&gt;：自旋CAS的方式如果长时间不成功，会给CPU带来很大的开销。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;只能保证一个共享变量的原子操作&lt;/strong&gt;：只对一个共享变量操作可以保证原子性，但是多个则不行，多个可以通过AtomicReference来处理或者使用锁synchronized实现。&lt;/p&gt;
&lt;h3 id=&#34;好说说hashmap原理吧&#34;&gt;&lt;strong&gt;好，说说HashMap原理吧？&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;HashMap主要由数组和链表组成，他不是线程安全的。核心的点就是put插入数据的过程，get查询数据以及扩容的方式。JDK1.7和1.8的主要区别在于头插和尾插方式的修改，头插容易导致HashMap链表死循环，并且1.8之后加入红黑树对性能有提升。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;put插入数据流程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;往map插入元素的时候首先通过对key hash然后与数组长度-1进行与运算((n-1)&amp;amp;hash)，都是2的次幂所以等同于取模，但是位运算的效率更高。找到数组中的位置之后，如果数组中没有元素直接存入，反之则判断key是否相同，key相同就覆盖，否则就会插入到链表的尾部，如果链表的长度超过8，则会转换成红黑树，最后判断数组长度是否超过默认的长度*负载因子也就是12，超过则进行扩容。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehhYJqIVUVqkQmiaXVoachgswvKcUfQ5AdgbJpYngXOvicVTDub1KxYMsw/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;get查询数据&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;查询数据相对来说就比较简单了，首先计算出hash值，然后去数组查询，是红黑树就去红黑树查，链表就遍历链表查询就可以了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;resize扩容过程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;扩容的过程就是对key重新计算hash，然后把数据拷贝到新的数组。&lt;/p&gt;
&lt;h3 id=&#34;那多线程环境怎么使用map呢concurrenthashmap了解过吗&#34;&gt;&lt;strong&gt;那多线程环境怎么使用Map呢？ConcurrentHashmap了解过吗？&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;多线程环境可以使用Collections.synchronizedMap同步加锁的方式，还可以使用HashTable，但是同步的方式显然性能不达标，而ConurrentHashMap更适合高并发场景使用。&lt;/p&gt;
&lt;p&gt;ConcurrentHashmap在JDK1.7和1.8的版本改动比较大，1.7使用Segment+HashEntry分段锁的方式实现，1.8则抛弃了Segment，改为使用CAS+synchronized+Node实现，同样也加入了红黑树，避免链表过长导致性能的问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.7分段锁&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;从结构上说，1.7版本的ConcurrentHashMap采用分段锁机制，里面包含一个Segment数组，Segment继承于ReentrantLock，Segment则包含HashEntry的数组，HashEntry本身就是一个链表的结构，具有保存key、value的能力能指向下一个节点的指针。&lt;/p&gt;
&lt;p&gt;实际上就是相当于每个Segment都是一个HashMap，默认的Segment长度是16，也就是支持16个线程的并发写，Segment之间相互不会受到影响。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehq0unBKlKXBhARwBmeYWZJFgiaXCX2zCTjMk0Xq3gduRqI6fsR2ao9Hw/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;put流程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;其实发现整个流程和HashMap非常类似，只不过是先定位到具体的Segment，然后通过ReentrantLock去操作而已，后面的流程我就简化了，因为和HashMap基本上是一样的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;计算hash，定位到segment，segment如果是空就先初始化&lt;/li&gt;
&lt;li&gt;使用ReentrantLock加锁，如果获取锁失败则尝试自旋，自旋超过次数就阻塞获取，保证一定获取锁成功&lt;/li&gt;
&lt;li&gt;遍历HashEntry，就是和HashMap一样，数组中key和hash一样就直接替换，不存在就再插入链表，链表同样&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPeh5Ua8JnShvjMmVbqbnG4SBeM0XbGC7XicL1tyic2ZsCLUM8doxianE5W9w/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;get流程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;get也很简单，key通过hash定位到segment，再遍历链表定位到具体的元素上，需要注意的是value是volatile的，所以get是不需要加锁的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.8、CAS+synchronized&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.8抛弃分段锁，转为用CAS+synchronized来实现，同样HashEntry改为Node，也加入了红黑树的实现。主要还是看put的流程。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehOaIZhNNGIw92iaLxnZW4PsxRN64LOy5vZCLrOcjf22f4umKTgtEU9TQ/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;put流程&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先计算hash，遍历node数组，如果node是空的话，就通过CAS+自旋的方式初始化&lt;/li&gt;
&lt;li&gt;如果当前数组位置是空则直接通过CAS自旋写入数据&lt;/li&gt;
&lt;li&gt;如果hash==MOVED，说明需要扩容，执行扩容&lt;/li&gt;
&lt;li&gt;如果都不满足，就使用synchronized写入数据，写入数据同样判断链表、红黑树，链表写入和HashMap的方式一样，key hash一样就覆盖，反之就尾插法，链表长度超过8就转换成红黑树&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehSWXgNAwd00W76yvhUsqNK8uztPmTQwzicee3zNic0po5hjZILceUTiaCg/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;get查询&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;get很简单，通过key计算hash，如果key hash相同就返回，如果是红黑树按照红黑树获取，都不是就遍历链表获取。&lt;/p&gt;
&lt;h3 id=&#34;volatile原理知道吗&#34;&gt;&lt;strong&gt;volatile原理知道吗？&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;相比synchronized的加锁方式来解决共享变量的内存可见性问题，volatile就是更轻量的选择，他没有上下文切换的额外开销成本。使用volatile声明的变量，可以确保值被更新的时候对其他线程立刻可见。volatile使用内存屏障来保证不会发生指令重排，解决了内存可见性的问题。&lt;/p&gt;
&lt;p&gt;我们知道，线程都是从主内存中读取共享变量到工作内存来操作，完成之后再把结果写会主内存，但是这样就会带来可见性问题。举个例子，假设现在我们是两级缓存的双核CPU架构，包含L1、L2两级缓存。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;线程A首先获取变量X的值，由于最初两级缓存都是空，所以直接从主内存中读取X，假设X初始值为0，线程A读取之后把X值都修改为1，同时写回主内存。这时候缓存和主内存的情况如下图。&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPeh2IXL5iaBEibeGqJKKHl3Gf731F1eqUlsWUUZKIgBuvZicV9Xb7WuSkGqQ/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;2.线程B也同样读取变量X的值，由于L2缓存已经有缓存X=1，所以直接从L2缓存读取，之后线程B把X修改为2，同时写回L2和主内存。这时候的X值入下图所示。&lt;/p&gt;
&lt;p&gt;那么线程A如果再想获取变量X的值，因为L1缓存已经有x=1了，所以这时候变量内存不可见问题就产生了，B修改为2的值对A来说没有感知。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehzJKtGbqLVwjSh0MvYUVQg9ygbGhIVKSD5bK5V1ibtcYgRlKLVnasuEw/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;那么，如果X变量用volatile修饰的话，当线程A再次读取变量X的话，CPU就会根据缓存一致性协议强制线程A重新从主内存加载最新的值到自己的工作内存，而不是直接用缓存中的值。&lt;/p&gt;
&lt;p&gt;再来说内存屏障的问题，volatile修饰之后会加入不同的内存屏障来保证可见性的问题能正确执行。这里写的屏障基于书中提供的内容，但是实际上由于CPU架构不同，重排序的策略不同，提供的内存屏障也不一样，比如x86平台上，只有StoreLoad一种内存屏障。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;StoreStore屏障，保证上面的普通写不和volatile写发生重排序&lt;/li&gt;
&lt;li&gt;StoreLoad屏障，保证volatile写与后面可能的volatile读写不发生重排序&lt;/li&gt;
&lt;li&gt;LoadLoad屏障，禁止volatile读与后面的普通读重排序&lt;/li&gt;
&lt;li&gt;LoadStore屏障，禁止volatile读和后面的普通写重排序&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehWmicawj6sLn1eYoBoPYlPUfFJHHV9jVaTtIy7al6m58Zp6MMtXsOl7g/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;那么说说你对jmm内存模型的理解为什么需要jmm&#34;&gt;&lt;strong&gt;那么说说你对JMM内存模型的理解？为什么需要JMM？&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;本身随着CPU和内存的发展速度差异的问题，导致CPU的速度远快于内存，所以现在的CPU加入了高速缓存，高速缓存一般可以分为L1、L2、L3三级缓存。基于上面的例子我们知道了这导致了缓存一致性的问题，所以加入了缓存一致性协议，同时导致了内存可见性的问题，而编译器和CPU的重排序导致了原子性和有序性的问题，JMM内存模型正是对多线程操作下的一系列规范约束，因为不可能让陈雇员的代码去兼容所有的CPU，通过JMM我们才屏蔽了不同硬件和操作系统内存的访问差异，这样保证了Java程序在不同的平台下达到一致的内存访问效果，同时也是保证在高效并发的时候程序能够正确执行。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehfsHXibmwFS8CsYP1MkEr6PEJMfic9qfA5fqq9ic3XWIic7sgTOkJVtkIMg/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;原子性&lt;/strong&gt;：Java内存模型通过read、load、assign、use、store、write来保证原子性操作，此外还有lock和unlock，直接对应着synchronized关键字的monitorenter和monitorexit字节码指令。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可见性&lt;/strong&gt;：可见性的问题在上面的回答已经说过，Java保证可见性可以认为通过volatile、synchronized、final来实现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;有序性&lt;/strong&gt;：由于处理器和编译器的重排序导致的有序性问题，Java通过volatile、synchronized来保证。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;happen-before规则&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;虽然指令重排提高了并发的性能，但是Java虚拟机会对指令重排做出一些规则限制，并不能让所有的指令都随意的改变执行位置，主要有以下几点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;单线程每个操作，happen-before于该线程中任意后续操作&lt;/li&gt;
&lt;li&gt;volatile写happen-before与后续对这个变量的读&lt;/li&gt;
&lt;li&gt;synchronized解锁happen-before后续对这个锁的加锁&lt;/li&gt;
&lt;li&gt;final变量的写happen-before于final域对象的读，happen-before后续对final变量的读&lt;/li&gt;
&lt;li&gt;传递性规则，A先于B，B先于C，那么A一定先于C发生&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;说了半天到底工作内存和主内存是什么&#34;&gt;&lt;strong&gt;说了半天，到底工作内存和主内存是什么？&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;主内存可以认为就是物理内存，Java内存模型中实际就是虚拟机内存的一部分。而工作内存就是CPU缓存，他有可能是寄存器也有可能是L1\L2\L3缓存，都是有可能的。&lt;/p&gt;
&lt;h3 id=&#34;说说threadlocal原理&#34;&gt;&lt;strong&gt;说说ThreadLocal原理？&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;ThreadLocal可以理解为线程本地变量，他会在每个线程都创建一个副本，那么在线程之间访问内部副本变量就行了，做到了线程之间互相隔离，相比于synchronized的做法是用空间来换时间。&lt;/p&gt;
&lt;p&gt;ThreadLocal有一个静态内部类ThreadLocalMap，ThreadLocalMap又包含了一个Entry数组，Entry本身是一个弱引用，他的key是指向ThreadLocal的弱引用，Entry具备了保存key value键值对的能力。&lt;/p&gt;
&lt;p&gt;弱引用的目的是为了防止内存泄露，如果是强引用那么ThreadLocal对象除非线程结束否则始终无法被回收，弱引用则会在下一次GC的时候被回收。&lt;/p&gt;
&lt;p&gt;但是这样还是会存在内存泄露的问题，假如key和ThreadLocal对象被回收之后，entry中就存在key为null，但是value有值的entry对象，但是永远没办法被访问到，同样除非线程结束运行。&lt;/p&gt;
&lt;p&gt;但是只要ThreadLocal使用恰当，在使用完之后调用remove方法删除Entry对象，实际上是不会出现这个问题的。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehlyogmxkbKb9Sibtp5k8lz73a2AlyVgerJAtfmibhIic38dJh38NF0QYZA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;那引用类型有哪些有什么区别&#34;&gt;&lt;strong&gt;那引用类型有哪些？有什么区别？&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;引用类型主要分为强软弱虚四种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;强引用指的就是代码中普遍存在的赋值方式，比如A a = new A()这种。强引用关联的对象，永远不会被GC回收。&lt;/li&gt;
&lt;li&gt;软引用可以用SoftReference来描述，指的是那些有用但是不是必须要的对象。系统在发生内存溢出前会对这类引用的对象进行回收。&lt;/li&gt;
&lt;li&gt;弱引用可以用WeakReference来描述，他的强度比软引用更低一点，弱引用的对象下一次GC的时候一定会被回收，而不管内存是否足够。&lt;/li&gt;
&lt;li&gt;虚引用也被称作幻影引用，是最弱的引用关系，可以用PhantomReference来描述，他必须和ReferenceQueue一起使用，同样的当发生GC的时候，虚引用也会被回收。可以用虚引用来管理堆外内存。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;线程池原理知道吗&#34;&gt;&lt;strong&gt;线程池原理知道吗？&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;首先线程池有几个核心的参数概念：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;最大线程数maximumPoolSize&lt;/li&gt;
&lt;li&gt;核心线程数corePoolSize&lt;/li&gt;
&lt;li&gt;活跃时间keepAliveTime&lt;/li&gt;
&lt;li&gt;阻塞队列workQueue&lt;/li&gt;
&lt;li&gt;拒绝策略RejectedExecutionHandler&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当提交一个新任务到线程池时，具体的执行流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;当我们提交任务，线程池会根据corePoolSize大小创建若干任务数量线程执行任务&lt;/li&gt;
&lt;li&gt;当任务的数量超过corePoolSize数量，后续的任务将会进入阻塞队列阻塞排队&lt;/li&gt;
&lt;li&gt;当阻塞队列也满了之后，那么将会继续创建(maximumPoolSize-corePoolSize)个数量的线程来执行任务，如果任务处理完成，maximumPoolSize-corePoolSize额外创建的线程等待keepAliveTime之后被自动销毁&lt;/li&gt;
&lt;li&gt;如果达到maximumPoolSize，阻塞队列还是满的状态，那么将根据不同的拒绝策略对应处理&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;15&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUljPgPC9h7FmEyOSbttvPehFlVhBew4SJXUzCicAjSkHdwXoLCaOMI7x2HhamkQqvHoBd1Zw9LS6OQ/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;拒绝策略有哪些&#34;&gt;&lt;strong&gt;拒绝策略有哪些？&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;主要有4种拒绝策略：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;AbortPolicy：直接丢弃任务，抛出异常，这是默认策略&lt;/li&gt;
&lt;li&gt;CallerRunsPolicy：只用调用者所在的线程来处理任务&lt;/li&gt;
&lt;li&gt;DiscardOldestPolicy：丢弃等待队列中最旧的任务，并执行当前任务&lt;/li&gt;
&lt;li&gt;DiscardPolicy：直接丢弃任务，也不抛出异常&lt;/li&gt;
&lt;/ol&gt;
">java面试1</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/ying-yu-jin-ju/"" data-c="
          &lt;p&gt;1、A true master/grandmaster is an eternal student;&lt;br&gt;
2、I long for a worthy opponent;  I&#39;ve been longing for girlfriend;&lt;br&gt;
3、It&#39;s not how much time you have;It&#39;s how you use it;&lt;br&gt;
4、I have been to the top of the mountain,and the bottom of the gutter.Thers&#39;s much to learn from both.&lt;br&gt;
5、It&#39;s all somke and mirrors;&lt;/p&gt;
&lt;h4 id=&#34;宾语从句&#34;&gt;宾语从句&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;I didn&#39;t say you could leave; He said he was coming;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;that 之后的内容做宾语修饰that之前的内容。&lt;/p&gt;
&lt;h5 id=&#34;主过从过宾语从句时态与主句一致&#34;&gt;&lt;mark&gt;主过从过：宾语从句时态与主句一致&lt;/mark&gt;&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Do:过去式（的否定式）didn’t  -&amp;gt; can:过去式 could&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;定语从句&#34;&gt;定语从句&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;I came back for others who could not;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;who定语从句：who后面内容修饰前面的人&lt;/p&gt;
&lt;p&gt;相对于宾语从句：&lt;mark&gt;定语从句时态不受主句影响&lt;/mark&gt;,只起修饰的作用&lt;/p&gt;
&lt;h4 id=&#34;what主语从句what引导一句话来从当主语&#34;&gt;What主语从句：what引导一句话来从当主语&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;what is broken can be reforged.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;主语句子是一个整体，谓语一般用单数&lt;/mark&gt;&lt;/p&gt;
&lt;h4 id=&#34;倒装句当主语是名词且&#34;&gt;倒装句：当主语是名词，且&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;mark&gt;句首&lt;/mark&gt;表示时间，或&lt;/li&gt;
&lt;li&gt;&lt;mark&gt;句首&lt;/mark&gt;表示运动方向，或&lt;/li&gt;
&lt;li&gt;&lt;mark&gt;句首&lt;/mark&gt;表示位置&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;把谓语在主语前。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;In Carnage I bloom, like a flower in the dawn.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;当主语是一个代词，eg. I 就不需要倒装&lt;/mark&gt;。&lt;/p&gt;
&lt;h4 id=&#34;what引导的感叹句what-被修饰的名词主语谓语&#34;&gt;What引导的感叹句：what +被修饰的名词+主语+谓语&lt;/h4&gt;
&lt;p&gt;如果名词是可数的，需要加a/an;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;what delightfull agony we shall inflict.
&lt;/code&gt;&lt;/pre&gt;
">英语金句</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/HashMap/"" data-c="
          &lt;h2 id=&#34;hashmap&#34;&gt;HashMap&lt;/h2&gt;
&lt;p&gt;HashMap也是我们使用非常多的Collection，它是基于哈希表的 Map 接口的实现，以key-value的形式存在。在HashMap中，key-value总是会当做一个整体来处理，系统会根据hash算法来来计算key-value的存储位置，我们总是可以通过key快速地存、取value。下面就来分析HashMap的存取。&lt;/p&gt;
&lt;h3 id=&#34;定义&#34;&gt;定义&lt;/h3&gt;
&lt;p&gt;HashMap实现了Map接口，继承AbstractMap。其中Map接口定义了键映射到值的规则，而AbstractMap类提供 Map 接口的骨干实现，以最大限度地减少实现此接口所需的工作，其实AbstractMap类已经实现了Map，这里标注Map LZ觉得应该是更加清晰吧！&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class HashMap&amp;lt;K,V&amp;gt;
    extends AbstractMap&amp;lt;K,V&amp;gt;
    implements Map&amp;lt;K,V&amp;gt;, Cloneable, Serializable
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;构造函数&#34;&gt;构造函数&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;  HashMap提供了三个构造函数：

  HashMap()：构造一个具有默认初始容量 (16) 和默认加载因子 (0.75) 的空 HashMap。

  HashMap(int initialCapacity)：构造一个带指定初始容量和默认加载因子 (0.75) 的空 HashMap。

  HashMap(int initialCapacity, float loadFactor)：构造一个带指定初始容量和加载因子的空 HashMap。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在这里提到了两个参数：初始容量，加载因子。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这两个参数是影响HashMap性能的重要参数，其中容量表示哈希表中桶的数量，初始容量是创建哈希表时的容量，加载因子是哈希表在其容量自动增加之前可以达到多满的一种尺度，它衡量的是一个散列表的空间的使用程度，负载因子越大表示散列表的装填程度越高，反之愈小。&lt;/p&gt;
&lt;p&gt;对于使用链表法的散列表来说，查找一个元素的平均时间是O(1+a)，因此如果负载因子越大，对空间的利用更充分，然而后果是查找效率的降低；如果负载因子太小，那么散列表的数据将过于稀疏，对空间造成严重浪费。系统默认负载因子为0.75，一般情况下我们是无需修改的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;HashMap是一种支持快速存取的数据结构，要了解它的性能必须要了解它的数据结构。&lt;/p&gt;
&lt;h3 id=&#34;数据结构&#34;&gt;数据结构&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;我们知道在Java中最常用的两种结构是数组和模拟指针(引用)，几乎所有的数据结构都可以利用这两种来组合实现，HashMap也是如此。实际上HashMap是一个“链表散列”，如下是它的数据结构：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;HashMap数据结构图&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://gitee.com/chenssy/blog-home/raw/master/image/sijava/152128351581.png&#34; alt=&#34;HashMap数据结构图_thumb[13]&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;下图的table数组的每个格子都是一个桶。负载因子就是map中的元素占用的容量百分比。比如负载因子是0.75，初始容量（桶数量）为16时，那么允许装填的元素最大个数就是16*0.75 = 12，这个最大个数也被成为阈值，就是map中定义的threshold。超过这个阈值时，map就会自动扩容。&lt;/p&gt;
&lt;h3 id=&#34;存储实现putkeyvlaue&#34;&gt;存储实现：put(key,vlaue)&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public V put(K key, V value) {
        //当key为null，调用putForNullKey方法，保存null在table第一个位置中，这是HashMap允许为null的原因
        if (key == null)
            return putForNullKey(value);
        //计算key的hash值，此处对原来元素的hashcode进行了再次hash
        int hash = hash(key.hashCode());                  ------(1)
        //计算key hash 值在 table 数组中的位置
        int i = indexFor(hash, table.length);             ------(2)
        //从i出开始迭代 e,找到 key 保存的位置
        for (Entry&amp;lt;K, V&amp;gt; e = table[i]; e != null; e = e.next) {
            Object k;
            //判断该条链上是否有hash值相同的(key相同)
            //若存在相同，则直接覆盖value，返回旧value
            if (e.hash == hash &amp;amp;&amp;amp; ((k = e.key) == key || key.equals(k))) {
                V oldValue = e.value;    //旧值 = 新值
                e.value = value;
                e.recordAccess(this);
                return oldValue;     //返回旧值
            }
        }
        //修改次数增加1
        modCount++;
        //将key、value添加至i位置处
        addEntry(hash, key, value, i);
        return null;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;通过源码我们可以清晰看到HashMap保存数据的过程为：首先判断key是否为null，若为null，则直接调用putForNullKey方法。&lt;/p&gt;
&lt;p&gt;若不为空则先计算key的hash值，然后根据hash值搜索在table数组中的索引位置，如果table数组在该位置处有元素，则通过比较是否存在相同的key，若存在则覆盖原来key的value，&lt;mark&gt;否则将该元素保存在链头（最先保存的元素放在链尾）&lt;/mark&gt;。&lt;/p&gt;
&lt;p&gt;若table在该处没有元素，则直接保存。这个过程看似比较简单，其实深有内幕。有如下几点：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1、 先看迭代处。此处迭代原因就是为了防止存在相同的key值，若发现两个hash值（key）相同时，HashMap的处理方式是用新value替换旧value，这里并没有处理key，这就解释了HashMap中没有两个相同的key。&lt;/p&gt;
&lt;p&gt;2、 在看（1）、（2）处。这里是HashMap的精华所在。首先是hash方法，该方法为一个纯粹的数学计算，就是计算h的hash值。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;static int hash(int h) {
        h ^= (h &amp;gt;&amp;gt;&amp;gt; 20) ^ (h &amp;gt;&amp;gt;&amp;gt; 12);
        return h ^ (h &amp;gt;&amp;gt;&amp;gt; 7) ^ (h &amp;gt;&amp;gt;&amp;gt; 4);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;我们知道对于HashMap的table而言，数据分布需要均匀（最好每项都只有一个元素，这样就可以直接找到），不能太紧也不能太松，太紧会导致查询速度慢，太松则浪费空间。计算hash值后，怎么才能保证table元素分布均衡呢？我们会想到取模，但是由于取模的消耗较大，HashMap是这样处理的：调用indexFor方法。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;static int indexFor(int h, int length) {
        return h &amp;amp; (length-1);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;HashMap的底层数组长度总是2的n次方，在构造函数中存在：capacity &amp;lt;&amp;lt;= 1;这样做总是能够保证HashMap的底层数组长度为2的n次方。当length为2的n次方时，h&amp;amp;(length - 1)就相当于对length取模，而且速度比直接取模快得多，这是HashMap在速度上的一个优化。至于为什么是2的n次方下面解释。&lt;/p&gt;
&lt;p&gt;&lt;mark&gt;对length取模来得到hash是常用的hash索引方法，这里采用位运算的话效率更高。&lt;/mark&gt;&lt;/p&gt;
&lt;p&gt;我们回到indexFor方法，该方法仅有一条语句：h&amp;amp;(length - 1)，这句话除了上面的取模运算外还有一个非常重要的责任：均匀分布table数据和充分利用空间。&lt;/p&gt;
&lt;p&gt;这里我们假设length为16(2^n)和15，h为5、6、7。&lt;/p&gt;
&lt;p&gt;当n=15时，6和7的结果一样，这样表示他们在table存储的位置是相同的，也就是产生了碰撞，6、7就会在一个位置形成链表，这样就会导致查询速度降低。诚然这里只分析三个数字不是很多，那么我们就看0-15。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;而当length = 16时，length – 1 = 15 即1111，那么进行低位&amp;amp;运算时，值总是与原来hash值相同，而进行高位运算时，其值等于其低位值。所以说当length = 2^n时，不同的hash值发生碰撞的概率比较小，这样就会使得数据在table数组中分布较均匀，查询速度也较快。&lt;/p&gt;
&lt;p&gt;这里我们再来复习put的流程：当我们想一个HashMap中添加一对key-value时，系统首先会计算key的hash值，然后根据hash值确认在table中存储的位置。若该位置没有元素，则直接插入。否则迭代该处元素链表并依此比较其key的hash值。&lt;/p&gt;
&lt;p&gt;如果两个hash值相等且key值相等(e.hash == hash &amp;amp;&amp;amp; ((k = e.key) == key || key.equals(k))),则用新的Entry的value覆盖原来节点的value。如果两个hash值相等但key值不等 ，则将该节点插入该链表的链头。具体的实现过程见addEntry方法，如下：&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;void addEntry(int hash, K key, V value, int bucketIndex) {
        //获取bucketIndex处的Entry
        Entry&amp;lt;K, V&amp;gt; e = table[bucketIndex];
        //将新创建的 Entry 放入 bucketIndex 索引处，并让新的 Entry 指向原来的 Entry 
        table[bucketIndex] = new Entry&amp;lt;K, V&amp;gt;(hash, key, value, e);
        //若HashMap中元素的个数超过极限了，则容量扩大两倍
        if (size++ &amp;gt;= threshold)
            resize(2 * table.length);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这个方法中有两点需要注意：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;后面添加的entry反而会接到前面。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一、是链的产生。&lt;/p&gt;
&lt;p&gt;这是一个非常优雅的设计。系统总是将新的Entry对象添加到bucketIndex处。如果bucketIndex处已经有了对象，那么新添加的Entry对象将指向原有的Entry对象，形成一条Entry链，但是若bucketIndex处没有Entry对象，也就是e==null,那么新添加的Entry对象指向null，也就不会产生Entry链了。&lt;/p&gt;
&lt;p&gt;二、扩容问题。&lt;/p&gt;
&lt;p&gt;随着HashMap中元素的数量越来越多，发生碰撞的概率就越来越大，所产生的链表长度就会越来越长，这样势必会影响HashMap的速度，为了保证HashMap的效率，系统必须要在某个临界点进行扩容处理。&lt;/p&gt;
&lt;p&gt;该临界点在当HashMap中元素的数量等于table数组长度*加载因子。但是扩容是一个非常耗时的过程，因为它需要重新计算这些数据在新table数组中的位置并进行复制处理。所以如果我们已经预知HashMap中元素的个数，那么预设元素的个数能够有效的提高HashMap的性能。&lt;/p&gt;
&lt;h3 id=&#34;jdk18的hashmapput方法&#34;&gt;JDK1.8的hashmap：put方法&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node&amp;lt;K,V&amp;gt;[] tab; Node&amp;lt;K,V&amp;gt; p; int n, i;
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
        if ((p = tab[i = (n - 1) &amp;amp; hash]) == null)
            tab[i] = newNode(hash, key, value, null);
        else {
            Node&amp;lt;K,V&amp;gt; e; K k;
            if (p.hash == hash &amp;amp;&amp;amp;
                ((k = p.key) == key || (key != null &amp;amp;&amp;amp; key.equals(k))))
                e = p;
                //如果p是红黑树节点，则用另外的处理方法
            else if (p instanceof TreeNode)
                e = ((TreeNode&amp;lt;K,V&amp;gt;)p).putTreeVal(this, tab, hash, key, value);
            else {
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        if (binCount &amp;gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        //当链表节点数超过8个，则直接进行红黑树化。
                            treeifyBin(tab, hash);
                        break;
                    }
                    if (e.hash == hash &amp;amp;&amp;amp;
                        ((k = e.key) == key || (key != null &amp;amp;&amp;amp; key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        if (++size &amp;gt; threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;JDK1.8在链表长度超过8时会转换为红黑树。 转换方法如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;final void treeifyBin(Node&amp;lt;K,V&amp;gt;[] tab, int hash) {
        int n, index; Node&amp;lt;K,V&amp;gt; e;
        if (tab == null || (n = tab.length) &amp;lt; MIN_TREEIFY_CAPACITY)
        //如果节点数变小小于红黑树的节点数阈值时，调整空间
            resize();
        else if ((e = tab[index = (n - 1) &amp;amp; hash]) != null) {
            TreeNode&amp;lt;K,V&amp;gt; hd = null, tl = null;
            do {
            //该方法直接返回一个红黑树结点。
                TreeNode&amp;lt;K,V&amp;gt; p = replacementTreeNode(e, null);
                if (tl == null)
                    hd = p;
                else {
                //从链表头开始依次插入红黑树
                    p.prev = tl;
                    tl.next = p;
                }
                tl = p;
            } while ((e = e.next) != null);
            if ((tab[index] = hd) != null)
                hd.treeify(tab);
        }
    }
    
        // For treeifyBin
TreeNode&amp;lt;K,V&amp;gt; replacementTreeNode(Node&amp;lt;K,V&amp;gt; p, Node&amp;lt;K,V&amp;gt; next) {
    return new TreeNode&amp;lt;&amp;gt;(p.hash, p.key, p.value, next);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;扩容&#34;&gt;扩容&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;final Node&amp;lt;K,V&amp;gt;[] resize() {
        Node&amp;lt;K,V&amp;gt;[] oldTab = table;
        int oldCap = (oldTab == null) ? 0 : oldTab.length;
        int oldThr = threshold;
        int newCap, newThr = 0;
        if (oldCap &amp;gt; 0) {
            //如果原容量大于最大空间，则让阈值为最大值。因为不能再扩容了，最大容量就是整数最大值。
            if (oldCap &amp;gt;= MAXIMUM_CAPACITY) {
                threshold = Integer.MAX_VALUE;
                return oldTab;
            }
            //两倍扩容，阈值也跟着变为两倍
            else if ((newCap = oldCap &amp;lt;&amp;lt; 1) &amp;lt; MAXIMUM_CAPACITY &amp;amp;&amp;amp;
                     oldCap &amp;gt;= DEFAULT_INITIAL_CAPACITY)
                newThr = oldThr &amp;lt;&amp;lt; 1; // double threshold
        }
        else if (oldThr &amp;gt; 0) // initial capacity was placed in threshold
            newCap = oldThr;
        else {               // zero initial threshold signifies using defaults
            newCap = DEFAULT_INITIAL_CAPACITY;
            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
        }
        if (newThr == 0) {
            float ft = (float)newCap * loadFactor;
            newThr = (newCap &amp;lt; MAXIMUM_CAPACITY &amp;amp;&amp;amp; ft &amp;lt; (float)MAXIMUM_CAPACITY ?
                      (int)ft : Integer.MAX_VALUE);
        }
        threshold = newThr;
        @SuppressWarnings({&amp;quot;rawtypes&amp;quot;,&amp;quot;unchecked&amp;quot;})
            Node&amp;lt;K,V&amp;gt;[] newTab = (Node&amp;lt;K,V&amp;gt;[])new Node[newCap];
        table = newTab;
        if (oldTab != null) {
            for (int j = 0; j &amp;lt; oldCap; ++j) {
                Node&amp;lt;K,V&amp;gt; e;
                if ((e = oldTab[j]) != null) {
                    oldTab[j] = null;
                    if (e.next == null)
                        //当后面没有节点时，直接插入即可 //每个元素重新计算索引位置，此处的hash值并没有变，只是改变索引值
                        newTab[e.hash &amp;amp; (newCap - 1)] = e;
                    else if (e instanceof TreeNode)
                        ((TreeNode&amp;lt;K,V&amp;gt;)e).split(this, newTab, j, oldCap);
                    else { // preserve order
                    //否则，就从头到尾依次将节点进行索引然后插入新数组，这样插入后的链表顺序会和原来的顺序相反。
                        Node&amp;lt;K,V&amp;gt; loHead = null, loTail = null;
                        Node&amp;lt;K,V&amp;gt; hiHead = null, hiTail = null;
                        Node&amp;lt;K,V&amp;gt; next;
                        do {
                            next = e.next;
                            if ((e.hash &amp;amp; oldCap) == 0) {
                                if (loTail == null)
                                    loHead = e;
                                else
                                    loTail.next = e;
                                loTail = e;
                            }
                            else {
                                if (hiTail == null)
                                    hiHead = e;
                                else
                                    hiTail.next = e;
                                hiTail = e;
                            }
                        } while ((e = next) != null);
                        if (loTail != null) {
                            loTail.next = null;
                            newTab[j] = loHead;
                        }
                        if (hiTail != null) {
                            hiTail.next = null;
                            newTab[j + oldCap] = hiHead;
                        }
                    }
                }
            }
        }
        return newTab;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;读取实现getkey&#34;&gt;读取实现：get(key)&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;        相对于HashMap的存而言，取就显得比较简单了。通过key的hash值找到在table数组中的索引处的Entry，然后返回该key对应的value即可。

public V get(Object key) {
        // 若为null，调用getForNullKey方法返回相对应的value
        if (key == null)
            return getForNullKey();
        // 根据该 key 的 hashCode 值计算它的 hash 码  
        int hash = hash(key.hashCode());
        // 取出 table 数组中指定索引处的值
        for (Entry&amp;lt;K, V&amp;gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) {
            Object k;
            //若搜索的key与查找的key相同，则返回相对应的value
            if (e.hash == hash &amp;amp;&amp;amp; ((k = e.key) == key || key.equals(k)))
                return e.value;
        }
        return null;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;在这里能够根据key快速的取到value除了和HashMap的数据结构密不可分外，还和Entry有莫大的关系，在前面就提到过，HashMap在存储过程中并没有将key，value分开来存储，而是当做一个整体key-value来处理的，这个整体就是Entry对象。&lt;/p&gt;
&lt;p&gt;同时value也只相当于key的附属而已。在存储的过程中，系统根据key的hashcode来决定Entry在table数组中的存储位置，在取的过程中同样根据key的hashcode取出相对应的Entry对象。&lt;/p&gt;
&lt;p&gt;在java中与有两个类都提供了一个多种用途的hashTable机制，他们都可以将可以key和value结合起来构成键值对通过put(key,value)方法保存起来，然后通过get(key)方法获取相对应的value值。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;hashtable&#34;&gt;HashTable&lt;/h2&gt;
&lt;p&gt;一个是前面提到的HashMap，还有一个就是马上要讲解的HashTable。对于HashTable而言，它在很大程度上和HashMap的实现差不多，如果我们对HashMap比较了解的话，对HashTable的认知会提高很大的帮助。他们两者之间只存在几点的不同，这个后面会阐述。&lt;/p&gt;
&lt;h3 id=&#34;定义-2&#34;&gt;定义&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  HashTable在Java中的定义如下：

public class Hashtable&amp;lt;K,V&amp;gt;
    extends Dictionary&amp;lt;K,V&amp;gt;
    implements Map&amp;lt;K,V&amp;gt;, Cloneable, java.io.Serializable
      从中可以看出HashTable继承Dictionary类，实现Map接口。其中Dictionary类是任何可将键映射到相应值的类（如 Hashtable）的抽象父类。每个键和每个值都是一个对象。在任何一个 Dictionary 对象中，每个键至多与一个值相关联。Map是&amp;quot;key-value键值对&amp;quot;接口。



  HashTable采用&amp;quot;拉链法&amp;quot;实现哈希表，它定义了几个重要的参数：table、count、threshold、loadFactor、modCount。



  table：为一个Entry[]数组类型，Entry代表了“拉链”的节点，每一个Entry代表了一个键值对，哈希表的&amp;quot;key-value键值对&amp;quot;都是存储在Entry数组中的。



  count：HashTable的大小，注意这个大小并不是HashTable的容器大小，而是他所包含Entry键值对的数量。



  threshold：Hashtable的阈值，用于判断是否需要调整Hashtable的容量。threshold的值=&amp;quot;容量*加载因子&amp;quot;。



  loadFactor：加载因子。



  modCount：用来实现“fail-fast”机制的（也就是快速失败）。所谓快速失败就是在并发集合中，其进行迭代操作时，若有其他线程对其进行结构性的修改，这时迭代器会立马感知到，并且立即抛出ConcurrentModificationException异常，而不是等到迭代完成之后才告诉你（你已经出错了）。
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;构造方法&#34;&gt;构造方法&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;  在HashTabel中存在5个构造函数。通过这5个构造函数我们构建出一个我想要的HashTable。

public Hashtable() {
        this(11, 0.75f);
    }
      默认构造函数，容量为11，加载因子为0.75。

public Hashtable(int initialCapacity) {
        this(initialCapacity, 0.75f);
    }
      用指定初始容量和默认的加载因子 (0.75) 构造一个新的空哈希表。

public Hashtable(int initialCapacity, float loadFactor) {
        //验证初始容量
        if (initialCapacity &amp;lt; 0)
            throw new IllegalArgumentException(&amp;quot;Illegal Capacity: &amp;quot;+
                                               initialCapacity);
        //验证加载因子
        if (loadFactor &amp;lt;= 0 || Float.isNaN(loadFactor))
            throw new IllegalArgumentException(&amp;quot;Illegal Load: &amp;quot;+loadFactor);

        if (initialCapacity==0)
            initialCapacity = 1;

        this.loadFactor = loadFactor;

        //初始化table，获得大小为initialCapacity的table数组
        table = new Entry[initialCapacity];
        //计算阀值
        threshold = (int)Math.min(initialCapacity * loadFactor, MAX_ARRAY_SIZE + 1);
        //初始化HashSeed值
        initHashSeedAsNeeded(initialCapacity);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;用指定初始容量和指定加载因子构造一个新的空哈希表。其中initHashSeedAsNeeded方法用于初始化hashSeed参数，其中hashSeed用于计算key的hash值，它与key的hashCode进行按位异或运算。这个hashSeed是一个与实例相关的随机值，主要用于解决hash冲突。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;private int hash(Object k) {
        return hashSeed ^ k.hashCode();
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;构造一个与给定的 Map 具有相同映射关系的新哈希表。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public Hashtable(Map&amp;lt;? extends K, ? extends V&amp;gt; t) {
        //设置table容器大小，其值==t.size * 2 + 1
        this(Math.max(2*t.size(), 11), 0.75f);
        putAll(t);
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;主要方法&#34;&gt;主要方法&lt;/h3&gt;
&lt;p&gt;HashTable的API对外提供了许多方法，这些方法能够很好帮助我们操作HashTable，但是这里我只介绍两个最根本的方法：put、get。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  首先我们先看put方法：将指定 key 映射到此哈希表中的指定 value。注意这里键key和值value都不可为空。

public synchronized V put(K key, V value) {
        // 确保value不为null
        if (value == null) {
            throw new NullPointerException();
        }

        /*
         * 确保key在table[]是不重复的
         * 处理过程：
         * 1、计算key的hash值，确认在table[]中的索引位置
         * 2、迭代index索引位置，如果该位置处的链表中存在一个一样的key，则替换其value，返回旧值
         */
        Entry tab[] = table;
        int hash = hash(key);    //计算key的hash值
        int index = (hash &amp;amp; 0x7FFFFFFF) % tab.length;     //确认该key的索引位置
        //迭代，寻找该key，替换
        for (Entry&amp;lt;K,V&amp;gt; e = tab[index] ; e != null ; e = e.next) {
            if ((e.hash == hash) &amp;amp;&amp;amp; e.key.equals(key)) {
                V old = e.value;
                e.value = value;
                return old;
            }
        }

        modCount++;
        if (count &amp;gt;= threshold) {  //如果容器中的元素数量已经达到阀值，则进行扩容操作
            rehash();
            tab = table;
            hash = hash(key);
            index = (hash &amp;amp; 0x7FFFFFFF) % tab.length;
        }

        // 在索引位置处插入一个新的节点
        Entry&amp;lt;K,V&amp;gt; e = tab[index];
        tab[index] = new Entry&amp;lt;&amp;gt;(hash, key, value, e);
        //容器中元素+1
        count++;
        return null;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;put方法的整个处理流程是：计算key的hash值，根据hash值获得key在table数组中的索引位置，然后迭代该key处的Entry链表（我们暂且理解为链表），若该链表中存在一个这个的key对象，那么就直接替换其value值即可，否则在将改key-value节点插入该index索引位置处&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在HashTabled的put方法中有两个地方需要注意：&lt;/p&gt;
&lt;p&gt;1、HashTable的扩容操作，在put方法中，如果需要向table[]中添加Entry元素，会首先进行容量校验，如果容量已经达到了阀值，HashTable就会进行扩容处理rehash()，如下:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;protected void rehash() {
        int oldCapacity = table.length;
        //元素
        Entry&amp;lt;K,V&amp;gt;[] oldMap = table;

        //新容量=旧容量 * 2 + 1
        int newCapacity = (oldCapacity &amp;lt;&amp;lt; 1) + 1;
        if (newCapacity - MAX_ARRAY_SIZE &amp;gt; 0) {
            if (oldCapacity == MAX_ARRAY_SIZE)
                return;
            newCapacity = MAX_ARRAY_SIZE;
        }

        //新建一个size = newCapacity 的HashTable
        Entry&amp;lt;K,V&amp;gt;[] newMap = new Entry[];

        modCount++;
        //重新计算阀值
        threshold = (int)Math.min(newCapacity * loadFactor, MAX_ARRAY_SIZE + 1);
        //重新计算hashSeed
        boolean rehash = initHashSeedAsNeeded(newCapacity);

        table = newMap;
        //将原来的元素拷贝到新的HashTable中
        for (int i = oldCapacity ; i-- &amp;gt; 0 ;) {
            for (Entry&amp;lt;K,V&amp;gt; old = oldMap[i] ; old != null ; ) {
                Entry&amp;lt;K,V&amp;gt; e = old;
                old = old.next;

                if (rehash) {
                    e.hash = hash(e.key);
                }
                int index = (e.hash &amp;amp; 0x7FFFFFFF) % newCapacity;
                e.next = newMap[index];
                newMap[index] = e;
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在这个rehash()方法中我们可以看到容量扩大两倍+1，同时需要将原来HashTable中的元素一一复制到新的HashTable中，这个过程是比较消耗时间的，同时还需要重新计算hashSeed的，毕竟容量已经变了。&lt;/p&gt;
&lt;p&gt;这里对阀值啰嗦一下：比如初始值11、加载因子默认0.75，那么这个时候阀值threshold=8，当容器中的元素达到8时，HashTable进行一次扩容操作，容量 = 8 * 2 + 1 =17，而阀值threshold=17*0.75 = 13，当容器元素再一次达到阀值时，HashTable还会进行扩容操作，依次类推。&lt;/p&gt;
&lt;p&gt;下面是计算key的hash值，这里hashSeed发挥了作用。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;private int hash(Object k) {
        return hashSeed ^ k.hashCode();
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;相对于put方法，get方法就会比较简单，处理过程就是计算key的hash值，判断在table数组中的索引位置，然后迭代链表，匹配直到找到相对应key的value,若没有找到返回null。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public synchronized V get(Object key) {
        Entry tab[] = table;
        int hash = hash(key);
        int index = (hash &amp;amp; 0x7FFFFFFF) % tab.length;
        for (Entry&amp;lt;K,V&amp;gt; e = tab[index] ; e != null ; e = e.next) {
            if ((e.hash == hash) &amp;amp;&amp;amp; e.key.equals(key)) {
                return e.value;
            }
        }
        return null;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;hashtable与hashmap的异同点&#34;&gt;HashTable与HashMap的异同点&lt;/h2&gt;
&lt;p&gt;HashTable和HashMap存在很多的相同点，但是他们还是有几个比较重要的不同点。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;第一：我们从他们的定义就可以看出他们的不同，HashTable基于Dictionary类，而HashMap是基于AbstractMap。Dictionary是什么？它是任何可将键映射到相应值的类的抽象父类，而AbstractMap是基于Map接口的骨干实现，它以最大限度地减少实现此接口所需的工作。&lt;/p&gt;
&lt;p&gt;第二：HashMap可以允许存在一个为null的key和任意个为null的value，但是HashTable中的key和value都不允许为null。如下：&lt;/p&gt;
&lt;p&gt;当HashMap遇到为null的key时，它会调用putForNullKey方法来进行处理。对于value没有进行任何处理，只要是对象都可以。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if (key == null)
            return putForNullKey(value);
      而当HashTable遇到null时，他会直接抛出NullPointerException异常信息。
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;pre&gt;&lt;code&gt;if (value == null) {
    throw new NullPointerException();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;第三：Hashtable的方法是同步的，而HashMap的方法不是。所以有人一般都建议如果是涉及到多线程同步时采用HashTable，没有涉及就采用HashMap，但是在Collections类中存在一个静态方法：synchronizedMap()，该方法创建了一个线程安全的Map对象，并把它作为一个封装的对象来返回，所以通过Collections类的synchronizedMap方法是可以我们你同步访问潜在的HashMap。这样君该如何选择呢？？？&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;面试题hashmap和hashtable的区别&#34;&gt;面试题：HashMap和HashTable的区别&lt;/h2&gt;
&lt;p&gt;HashMap线程不安全，HashTable是线程安全的。HashMap内部实现没有任何线程同步相关的代码，所以相对而言性能要好一点。如果在多线程中使用HashMap需要自己管理线程同步。HashTable大部分对外接口都使用synchronized包裹，所以是线程安全的，但是性能会相对差一些。&lt;/p&gt;
&lt;p&gt;二者的基类不一样。HashMap派生于AbstractMap，HashTable派生于Dictionary。它们都实现Map, Cloneable, Serializable这些接口。AbstractMap中提供的基础方法更多，并且实现了多个通用的方法，而在Dictionary中只有少量的接口，并且都是abstract类型。&lt;/p&gt;
&lt;p&gt;key和value的取值范围不同。HashMap的key和value都可以为null，但是HashTablekey和value都不能为null。对于HashMap如果get返回null，并不能表明HashMap不存在这个key，如果需要判断HashMap中是否包含某个key，就需要使用containsKey这个方法来判断。&lt;/p&gt;
&lt;p&gt;算法不一样。HashMap的initialCapacity为16，而HashTable的initialCapacity为11。HashMap中初始容量必须是2的幂,如果初始化传入的initialCapacity不是2的幂，将会自动调整为大于出入的initialCapacity最小的2的幂。HashMap使用自己的计算hash的方法(会依赖key的hashCode方法)，HashTable则使用key的hashCode方法得到。&lt;/p&gt;
">HashMap与HashTable</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/iteratorfail-fast-ji-zhi-yu-bi-jiao-qi/"" data-c="
          &lt;h2 id=&#34;iterator&#34;&gt;Iterator&lt;/h2&gt;
&lt;p&gt;迭代对于我们搞Java的来说绝对不陌生。我们常常使用JDK提供的迭代接口进行Java集合的迭代。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Iterator iterator = list.iterator();
        while(iterator.hasNext()){
            String string = iterator.next();
            do something
        }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;迭代其实我们可以简单地理解为遍历，是一个标准化遍历各类容器里面的所有对象的方法类，它是一个很典型的设计模式。Iterator模式是用于遍历集合类的标准访问方法。&lt;/p&gt;
&lt;p&gt;它可以把访问逻辑从不同类型的集合类中抽象出来，从而避免向客户端暴露集合的内部结构。 在没有迭代器时我们都是这么进行处理的。如下：&lt;/p&gt;
&lt;p&gt;对于数组我们是使用下标来进行处理的&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;int[] arrays = new int[10];
   for(int i = 0 ; i  arrays.length ; i++){
       int a = arrays[i];
       do something
   }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对于ArrayList是这么处理的&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ListString list = new ArrayListString();
   for(int i = 0 ; i  list.size() ;  i++){
      String string = list.get(i);
      do something
   }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对于这两种方式，我们总是都事先知道集合的内部结构，访问代码和集合本身是紧密耦合的，无法将访问逻辑从集合类和客户端代码中分离出来。同时每一种集合对应一种遍历方法，客户端代码无法复用。&lt;/p&gt;
&lt;p&gt;在实际应用中如何需要将上面将两个集合进行整合是相当麻烦的。所以为了解决以上问题，Iterator模式腾空出世，它总是用同一种逻辑来遍历集合。&lt;/p&gt;
&lt;p&gt;使得客户端自身不需要来维护集合的内部结构，所有的内部状态都由Iterator来维护。客户端从不直接和集合类打交道，它总是控制Iterator，向它发送向前，向后，取当前元素的命令，就可以间接遍历整个集合。&lt;/p&gt;
&lt;p&gt;上面只是对Iterator模式进行简单的说明，下面我们看看Java中Iterator接口，看他是如何来进行实现的。&lt;/p&gt;
&lt;h3 id=&#34;javautiliterator&#34;&gt;java.util.Iterator&lt;/h3&gt;
&lt;p&gt;在Java中Iterator为一个接口，它只提供了迭代了基本规则，在JDK中他是这样定义的：对 collection 进行迭代的迭代器。迭代器取代了 Java Collections Framework 中的 Enumeration。迭代器与枚举有两点不同：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;迭代器允许调用者利用定义良好的语义在迭代期间从迭代器所指向的 collection 移除元素。&lt;/li&gt;
&lt;li&gt;方法名称得到了改进。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其接口定义如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface Iterator {
　　boolean hasNext();
　　Object next();
　　void remove();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;其中：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Object next()：返回迭代器刚越过的元素的引用，返回值是Object，需要强制转换成自己需要的类型

boolean hasNext()：判断容器内是否还有可供访问的元素

void remove()：删除迭代器刚越过的元素
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对于我们而言，我们只一般只需使用next()、hasNext()两个方法即可完成迭代。如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;for(Iterator it = c.iterator(); it.hasNext(); ) {
　　Object o = it.next();
　　 do something
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;mark&gt;前面阐述了Iterator有一个很大的优点,就是我们不必知道集合的内部结果,集合的内部结构、状态由Iterator来维持，通过统一的方法hasNext()、next()来判断、获取下一个元素，至于具体的内部实现我们就不用关心了。&lt;/mark&gt;&lt;/p&gt;
&lt;p&gt;但是作为一个合格的程序员我们非常有必要来弄清楚Iterator的实现。下面就ArrayList的源码进行分析分析。&lt;/p&gt;
&lt;h3 id=&#34;各个集合的iterator的实现&#34;&gt;各个集合的Iterator的实现&lt;/h3&gt;
&lt;p&gt;下面就ArrayList的Iterator实现来分析，其实如果我们理解了ArrayList、Hashset、TreeSet的数据结构，内部实现，对于他们是如何实现Iterator也会胸有成竹的。因为ArrayList的内部实现采用数组，所以我们只需要记录相应位置的索引即可，其方法的实现比较简单。&lt;/p&gt;
&lt;h4 id=&#34;arraylist的iterator实现&#34;&gt;ArrayList的Iterator实现&lt;/h4&gt;
&lt;p&gt;在ArrayList内部首先是定义一个内部类Itr，该内部类实现Iterator接口，如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;private class Itr implements IteratorE {
    do something
}
而ArrayList的iterator()方法实现：

public IteratorE iterator() {
        return new Itr();
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;所以通过使用ArrayList.iterator()方法返回的是Itr()内部类，所以现在我们需要关心的就是Itr()内部类的实现：&lt;/p&gt;
&lt;p&gt;在Itr内部定义了三个int型的变量：cursor、lastRet、expectedModCount。其中cursor表示下一个元素的索引位置，lastRet表示上一个元素的索引位置&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;        int cursor;             
        int lastRet = -1;     
        int expectedModCount = modCount;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从cursor、lastRet定义可以看出，lastRet一直比cursor少一所以hasNext()实现方法异常简单，只需要判断cursor和lastRet是否相等即可。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public boolean hasNext() {
    return cursor != size;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对于next()实现其实也是比较简单的，只要返回cursor索引位置处的元素即可，然后修改cursor、lastRet即可。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public E next() {
    checkForComodification();
    int i = cursor;    //记录索引位置
    if (i = size)    //如果获取元素大于集合元素个数，则抛出异常
        throw new NoSuchElementException();
    Object[] elementData = ArrayList.this.elementData;
    if (i = elementData.length)
        throw new ConcurrentModificationException();
    cursor = i + 1;      //cursor + 1
    return (E) elementData[lastRet = i];  //lastRet + 1 且返回cursor处元素
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;checkForComodification()主要用来判断集合的修改次数是否合法，即用来判断遍历过程中集合是否被修改过。&lt;/p&gt;
&lt;p&gt;。modCount用于记录ArrayList集合的修改次数，初始化为0，，每当集合被修改一次（结构上面的修改，内部update不算），如add、remove等方法，modCount + 1，所以如果modCount不变，则表示集合内容没有被修改。&lt;/p&gt;
&lt;p&gt;该机制主要是用于实现ArrayList集合的快速失败机制，在Java的集合中，较大一部分集合是存在快速失败机制的，这里就不多说，后面会讲到。&lt;/p&gt;
&lt;p&gt;所以要保证在遍历过程中不出错误，我们就应该保证在遍历过程中不会对集合产生结构上的修改（当然remove方法除外），出现了异常错误，我们就应该认真检查程序是否出错而不是catch后不做处理。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;final void checkForComodification() {
            if (modCount != expectedModCount)
                throw new ConcurrentModificationException();
        }
//对于remove()方法的是实现，它是调用ArrayList本身的remove()方法删除lastRet位置元素，然后修改modCount即可。

public void remove() {
    if (lastRet  0)
        throw new IllegalStateException();
    checkForComodification();

    try {
        ArrayList.this.remove(lastRet);
        cursor = lastRet;
        lastRet = -1;
        expectedModCount = modCount;
    } catch (IndexOutOfBoundsException ex) {
        throw new ConcurrentModificationException();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这里就对ArrayList的Iterator实现讲解到这里，对于Hashset、TreeSet等集合的Iterator实现，各位如果感兴趣可以继续研究，个人认为在研究这些集合的源码之前，有必要对该集合的数据结构有清晰的认识，这样会达到事半功倍的效果！！！！&lt;/p&gt;
&lt;h3 id=&#34;fail-fast机制&#34;&gt;fail-fast机制&lt;/h3&gt;
&lt;p&gt;这部分参考http://cmsblogs.com/p=1220&lt;/p&gt;
&lt;p&gt;在JDK的Collection中我们时常会看到类似于这样的话：&lt;/p&gt;
&lt;p&gt;例如，ArrayList&lt;/p&gt;
&lt;p&gt;注意，迭代器的快速失败行为无法得到保证，因为一般来说，不可能对是否出现不同步并发修改做出任何硬性保证。快速失败迭代器会尽最大努力抛出ConcurrentModificationException。 因此，为提高这类迭代器的正确性而编写一个依赖于此异常的程序是错误的做法：迭代器的快速失败行为应该仅用于检测 bug。&lt;/p&gt;
&lt;p&gt;HashMap中：&lt;/p&gt;
&lt;p&gt;注意，迭代器的快速失败行为不能得到保证，一般来说，存在非同步的并发修改时，不可能作出任何坚决的保证。快速失败迭代器尽最大努力抛出 ConcurrentModificationException。因此，编写依赖于此异常的程序的做法是错误的，正确做法是：迭代器的快速失败行为应该仅用于检测程序错误。&lt;/p&gt;
&lt;p&gt;在这两段话中反复地提到”快速失败”。那么何为”快速失败”机制呢？&lt;/p&gt;
&lt;p&gt;“快速失败”也就是fail-fast，它是Java集合的一种错误检测机制。当多个线程对集合进行结构上的改变的操作时，有可能会产生fail-fast机制。&lt;/p&gt;
&lt;p&gt;记住是有可能，而不是一定。例如：假设存在两个线程（线程1、线程2），线程1通过Iterator在遍历集合A中的元素，在某个时候线程2修改了集合A的结构（是结构上面的修改，而不是简单的修改集合元素的内容），那么这个时候程序就会抛出 ConcurrentModificationException异常，从而产生fail-fast机制。&lt;/p&gt;
&lt;h4 id=&#34;fail-fast示例&#34;&gt;fail-fast示例&lt;/h4&gt;
&lt;p&gt;@desc线程one迭代list @Projecttest @fileFailFastTest.java @Authrochenssy @data2014年7月26日&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class FailFastTest {
    private static ListInteger list = new ArrayList(); 
    
	private static class threadOne extends Thread{
        public void run() {
            IteratorInteger iterator = list.iterator();
            while(iterator.hasNext()){
                int i = iterator.next();
                System.out.println(ThreadOne 遍历 + i);
                try {
                    Thread.sleep(10);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当i == 3时，修改list&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;    private static class threadTwo extends Thread{
        public void run(){
            int i = 0 ; 
            while(i&amp;lt;6){
                System.out.println(ThreadTwo run： + i);
                if(i == 3){
                    list.remove(i);
                }
                i++;
            }
        }
    }
    
    public static void main(String[] args) {
        for(int i = 0 ; i  10;i++){
            list.add(i);
        }
        new threadOne().start();
        new threadTwo().start();
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;运行结果：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;ThreadOne 遍历0
ThreadTwo run：0
ThreadTwo run：1
ThreadTwo run：2
ThreadTwo run：3
ThreadTwo run：4
ThreadTwo run：5
Exception in thread Thread-0 java.util.ConcurrentModificationException
    at java.util.ArrayList$Itr.checkForComodification(Unknown Source)
    at java.util.ArrayList$Itr.next(Unknown Source)
    at test.ArrayListTest$threadOne.run(ArrayListTest.java23)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;fail-fast产生原因&#34;&gt;fail-fast产生原因&lt;/h4&gt;
&lt;p&gt;通过上面的示例和讲解，我初步知道fail-fast产生的原因就在于程序在对 collection 进行迭代时，某个线程对该 collection 在结构上对其做了修改，这时迭代器就会抛出 ConcurrentModificationException 异常信息，从而产生 fail-fast。&lt;/p&gt;
&lt;p&gt;要了解fail-fast机制，我们首先要对ConcurrentModificationException 异常有所了解。当方法检测到对象的并发修改，但不允许这种修改时就抛出该异常。同时需要注意的是，该异常不会始终指出对象已经由不同线程并发修改，如果单线程违反了规则，同样也有可能会抛出改异常。&lt;/p&gt;
&lt;p&gt;诚然，迭代器的快速失败行为无法得到保证，它不能保证一定会出现该错误，但是快速失败操作会尽最大努力抛出ConcurrentModificationException异常，所以因此，为提高此类操作的正确性而编写一个依赖于此异常的程序是错误的做法，正确做法是：ConcurrentModificationException 应该仅用于检测 bug。下面我将以ArrayList为例进一步分析fail-fast产生的原因。&lt;/p&gt;
&lt;p&gt;从前面我们知道fail-fast是在操作迭代器时产生的。现在我们来看看ArrayList中迭代器的源代码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private class Itr implements IteratorE {
        int cursor;
        int lastRet = -1;
        int expectedModCount = ArrayList.this.modCount;

        public boolean hasNext() {
            return (this.cursor != ArrayList.this.size);
        }

        public E next() {
            checkForComodification();
             省略此处代码 
        }

        public void remove() {
            if (this.lastRet&amp;lt;0)
                throw new IllegalStateException();
            checkForComodification();
             省略此处代码 
        }

        final void checkForComodification() {
            if (ArrayList.this.modCount == this.expectedModCount)
                return;
            throw new ConcurrentModificationException();
        }
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从上面的源代码我们可以看出，迭代器在调用next()、remove()方法时都是调用checkForComodification()方法，该方法主要就是检测modCount == expectedModCount 若不等则抛出ConcurrentModificationException 异常，从而产生fail-fast机制。所以要弄清楚为什么会产生fail-fast机制我们就必须要用弄明白为什么modCount != expectedModCount ，他们的值在什么时候发生改变的。&lt;/p&gt;
&lt;p&gt;expectedModCount 是在Itr中定义的：int expectedModCount = ArrayList.this.modCount;所以他的值是不可能会修改的，所以会变的就是modCount。modCount是在 AbstractList 中定义的，为全局变量：&lt;/p&gt;
&lt;p&gt;protected transient int modCount = 0; 那么他什么时候因为什么原因而发生改变呢？请看ArrayList的源码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public boolean add(E paramE) {
    ensureCapacityInternal(this.size + 1);
     省略此处代码 
}

private void ensureCapacityInternal(int paramInt) {
    if (this.elementData == EMPTY_ELEMENTDATA)
        paramInt = Math.max(10, paramInt);
    ensureExplicitCapacity(paramInt);
}

private void ensureExplicitCapacity(int paramInt) {
    this.modCount += 1;    修改modCount
     省略此处代码 
}

private void fastRemove(int paramInt) {
    this.modCount += 1;   修改modCount
     省略此处代码 
}

public void clear() {
    this.modCount += 1;    修改modCount
     省略此处代码 
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从上面的源代码我们可以看出，ArrayList中无论add、remove、clear方法只要是涉及了改变ArrayList元素的个数的方法都会导致modCount的改变。&lt;/p&gt;
&lt;p&gt;所以我们这里可以初步判断由于expectedModCount 得值与modCount的改变不同步，导致两者之间不等从而产生fail-fast机制。知道产生fail-fast产生的根本原因了，我们可以有如下场景：&lt;/p&gt;
&lt;p&gt;有两个线程（线程A，线程B），其中线程A负责遍历list、线程B修改list。线程A在遍历list过程的某个时候（此时expectedModCount = modCount=N），线程启动，同时线程B增加一个元素，这是modCount的值发生改变（modCount + 1 = N + 1）。&lt;/p&gt;
&lt;p&gt;线程A继续遍历执行next方法时，通告checkForComodification方法发现expectedModCount = N ，而modCount = N + 1，两者不等，这时就抛出ConcurrentModificationException 异常，从而产生fail-fast机制。&lt;/p&gt;
&lt;p&gt;所以，直到这里我们已经完全了解了fail-fast产生的根本原因了。知道了原因就好找解决办法了。&lt;/p&gt;
&lt;h4 id=&#34;fail-fast解决办法&#34;&gt;fail-fast解决办法&lt;/h4&gt;
&lt;p&gt;通过前面的实例、源码分析，我想各位已经基本了解了fail-fast的机制，下面我就产生的原因提出解决方案。这里有两种解决方案：&lt;/p&gt;
&lt;p&gt;方案一：在遍历过程中所有涉及到改变modCount值得地方全部加上synchronized或者直接使用Collections.synchronizedList，这样就可以解决。但是不推荐，因为增删造成的同步锁可能会阻塞遍历操作。&lt;/p&gt;
&lt;p&gt;方案二：使用CopyOnWriteArrayList来替换ArrayList。推荐使用该方案。&lt;/p&gt;
&lt;p&gt;CopyOnWriteArrayList为何物？ArrayList 的一个线程安全的变体，其中所有可变操作（add、set 等等）都是通过对底层数组进行一次新的复制来实现的。 该类产生的开销比较大，但是在两种情况下，它非常适合使用。&lt;/p&gt;
&lt;p&gt;1：在不能或不想进行同步遍历，但又需要从并发线程中排除冲突时。&lt;/p&gt;
&lt;p&gt;2：当遍历操作的数量大大超过可变操作的数量时。遇到这两种情况使用CopyOnWriteArrayList来替代ArrayList再适合不过了。那么为什么CopyOnWriterArrayList可以替代ArrayList呢？&lt;/p&gt;
&lt;p&gt;第一、CopyOnWriterArrayList的无论是从数据结构、定义都和ArrayList一样。它和ArrayList一样，同样是实现List接口，底层使用数组实现。在方法上也包含add、remove、clear、iterator等方法。&lt;/p&gt;
&lt;p&gt;第二、CopyOnWriterArrayList根本就不会产生ConcurrentModificationException异常，也就是它使用迭代器完全不会产生fail-fast机制。请看：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private static class COWIteratorE implements ListIteratorE {
         省略此处代码 
        public E next() {
            if (!(hasNext()))
                throw new NoSuchElementException();
            return this.snapshot[(this.cursor++)];
        }

         省略此处代码 
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;CopyOnWriterArrayList的方法根本就没有像ArrayList中使用checkForComodification方法来判断expectedModCount 与 modCount 是否相等。它为什么会这么做，凭什么可以这么做呢？我们以add方法为例：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public boolean add(E paramE) {
        ReentrantLock localReentrantLock = this.lock;
        localReentrantLock.lock();
        try {
            Object[] arrayOfObject1 = getArray();
            int i = arrayOfObject1.length;
            Object[] arrayOfObject2 = Arrays.copyOf(arrayOfObject1, i + 1);
            arrayOfObject2[i] = paramE;
            setArray(arrayOfObject2);
            int j = 1;
            return j;
        } finally {
            localReentrantLock.unlock();
        }
    }


  
    final void setArray(Object[] paramArrayOfObject) {
        this.array = paramArrayOfObject;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;CopyOnWriterArrayList的add方法与ArrayList的add方法有一个最大的不同点就在于，下面三句代码：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Object[] arrayOfObject2 = Arrays.copyOf(arrayOfObject1, i + 1);
arrayOfObject2[i] = paramE;
setArray(arrayOfObject2);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;就是这三句代码使得CopyOnWriterArrayList不会抛ConcurrentModificationException异常。他们所展现的魅力就在于copy原来的array，再在copy数组上进行add操作，这样做就完全不会影响COWIterator中的array了。&lt;/p&gt;
&lt;p&gt;所以CopyOnWriterArrayList所代表的核心概念就是：任何对array在结构上有所改变的操作（add、remove、clear等），CopyOnWriterArrayList都会copy现有的数据，再在copy的数据上修改，这样就不会影响COWIterator中的数据了，修改完成之后改变原有数据的引用即可。同时这样造成的代价就是产生大量的对象，同时数组的copy也是相当有损耗的。&lt;/p&gt;
&lt;h1 id=&#34;comparable-和-comparator&#34;&gt;Comparable 和 Comparator&lt;/h1&gt;
&lt;p&gt;Java 中为我们提供了两种比较机制：Comparable 和 Comparator，他们之间有什么区别呢？今天来了解一下。&lt;/p&gt;
&lt;h2 id=&#34;comparable&#34;&gt;Comparable&lt;/h2&gt;
&lt;p&gt;Comparable 在 java.lang包下，是一个接口，内部只有一个方法 compareTo()：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public interface Comparable&amp;lt;T&amp;gt; {
    public int compareTo(T o);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Comparable 可以让实现它的类的对象进行比较，具体的比较规则是按照 compareTo 方法中的规则进行。这种顺序称为 自然顺序。&lt;/p&gt;
&lt;p&gt;compareTo 方法的返回值有三种情况：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;e1.compareTo(e2)&amp;gt;0 //即 e1 &amp;gt; e2
e1.compareTo(e2) = 0 //即 e1 = e2
e1.compareTo(e2)&amp;lt; 0 //即 e1 &amp;lt; e2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;p&gt;1.由于 null 不是一个类，也不是一个对象，因此在重写 compareTo 方法时应该注意 e.compareTo(null) 的情况，即使 e.equals(null) 返回 false，compareTo 方法也应该主动抛出一个空指针异常 NullPointerException。&lt;/p&gt;
&lt;p&gt;2.Comparable 实现类重写 compareTo 方法时一般要求 e1.compareTo(e2) == 0 的结果要和 e1.equals(e2) 一致。这样将来使用 SortedSet 等根据类的自然排序进行排序的集合容器时可以保证保存的数据的顺序和想象中一致。 有人可能好奇上面的第二点如果违反了会怎样呢？&lt;/p&gt;
&lt;p&gt;举个例子，如果你往一个 SortedSet 中先后添加两个对象 a 和 b，a b 满足 (!a.equals(b) &amp;amp;&amp;amp; a.compareTo(b) == 0)，同时也没有另外指定个 Comparator，那当你添加完 a 再添加 b 时会添加失败返回 false, SortedSet 的 size 也不会增加，因为在 SortedSet 看来它们是相同的，而 SortedSet 中是不允许重复的。&lt;/p&gt;
&lt;p&gt;实际上所有实现了 &lt;strong&gt;Comparable 接口的 Java 核心类的结果都和 equlas 方法保持一致&lt;/strong&gt;。 实现了 Comparable 接口的 List 或则数组可以使用 Collections.sort() 或者 Arrays.sort() 方法进行排序。&lt;/p&gt;
&lt;p&gt;实现了 Comparable 接口的对象才能够直接被用作 SortedMap (SortedSet) 的 key，要不然得在外边指定 Comparator 排序规则。&lt;/p&gt;
&lt;p&gt;因此自己定义的类如果想要使用有序的集合类，需要实现 Comparable 接口，比如：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class BookBean implements Serializable, Comparable {
    private String name;
    private int count;


public BookBean(String name, int count) {
    this.name = name;
    this.count = count;
}

public String getName() {
    return name;
}

public void setName(String name) {
    this.name = name;
}

public int getCount() {
    return count;
}

public void setCount(int count) {
    this.count = count;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;重写 equals&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
public boolean equals(Object o) {
    if (this == o) return true;
    if (!(o instanceof BookBean)) return false;

    BookBean bean = (BookBean) o;

    if (getCount() != bean.getCount()) return false;
    return getName().equals(bean.getName());

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;重写 hashCode 的计算方法 根据所有属性进行 迭代计算，避免重复 计算 hashCode 时 计算因子 31 见得很多，是一个质数，不能再被除&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
public int hashCode() {
    //调用 String 的 hashCode(), 唯一表示一个字符串内容
    int result = getName().hashCode();
    //乘以 31, 再加上 count
    result = 31*result + getCount();
    return result;
}

@Override
public String toString() {
    return BookBean{ +
            name=&#39; + name + &#39;&#39;&#39; +
            , count= + count +
            &#39;}&#39;;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当向 TreeSet 中添加 BookBean 时，会调用这个方法进行排序&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Override
public int compareTo(Object another) {
    if (another instanceof BookBean){
        BookBean anotherBook = (BookBean) another;
        int result;

        //比如这里按照书价排序
        result = getCount() - anotherBook.getCount();     

        if (result == 0){   //当书价一致时，再对比书名。 保证所有属性比较一遍
            result = getName().compareTo(anotherBook.getName());
        }
        return result;
    }
     //一样就返回 0
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上述代码还重写了 equlas(), hashCode() 方法，自定义的类将来可能会进行比较时，建议重写这些方法。&lt;/p&gt;
&lt;p&gt;这里我想表达的是在有些场景下 equals 和 compareTo 结果要保持一致，这时候不重写 equals，使用 Object.equals 方法得到的结果会有问题，比如说 HashMap.put() 方法，会先调用 key 的 equals 方法进行比较，然后才调用 compareTo。&lt;/p&gt;
&lt;p&gt;后面重写 compareTo 时，要判断某个相同时对比下一个属性，把所有属性都比较一次。&lt;/p&gt;
&lt;h3 id=&#34;comparator&#34;&gt;Comparator&lt;/h3&gt;
&lt;p&gt;首先认识一下Comparator：&lt;/p&gt;
&lt;p&gt;Comparator 是javase中的接口，位于java.util包下，该接口抽象度极高，有必要掌握该接口的使用 大多数文章告诉大家Comparator是用来排序，但我想说排序是Comparator能实现的功能之一，他不仅限于排序&lt;/p&gt;
&lt;p&gt;排序例子： 题目描述 输入一个正整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。例如输入数组{3，32，321}，则打印出这三个数字能排成的最小数字为321323。&lt;/p&gt;
&lt;p&gt;代码实现：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;import java.util.ArrayList;
import java.util.Collections;
import java.util.Comparator;
 
public class Solution {
    public String PrintMinNumber(int [] s) {
        if(s==null) return null;
        String s1=&amp;quot;&amp;quot;;
        ArrayList&amp;lt;Integer&amp;gt; list=new ArrayList&amp;lt;Integer&amp;gt;();
        for(int i=0;i&amp;lt;s.length;i++){
             list.add(s[i]);
        }
        Collections.sort(list,new Comparator&amp;lt;Integer&amp;gt;(){
            public int compare(Integer str1,Integer str2){
                String s1=str1+&amp;quot;&amp;quot;+str2;
                String s2=str2+&amp;quot;&amp;quot;+str1;
                return s1.compareTo(s2);
            }
        });
         for(int j:list){
                s1+=j;
             }
        return s1;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一般需要做比较的逻辑都可以使用的上Comparator，最常用的场景就是排序和分组，排序常使用Arrays和Collections的sort方法，而分组则可以使用提供的divider方法。&lt;/p&gt;
&lt;p&gt;排序和分组的区别在于: 排序时，两个对象比较的结果有三种：大于，等于，小于。 分组时，两个对象比较的结果只有两种：等于(两个对象属于同一组)，不等于(两个对象属于不同组)&lt;/p&gt;
&lt;h3 id=&#34;java8中使用lambda实现比较器&#34;&gt;Java8中使用lambda实现比较器&lt;/h3&gt;
&lt;p&gt;今天先看看Lambda 表达式的简单使用： 首先：Lambda表达式的基本语法：(parameters) -&amp;gt; expression或（请注意语句的花括号） (parameters) -&amp;gt; { statements; }&lt;/p&gt;
&lt;p&gt;第一感觉就是这个箭头感觉有点怪，不过多用几次习惯就好，它主要是为了把参数列表与Lambda主体分隔开，箭头左边的是参数列表，右边的是Lambda主体。注意：Lambda表达式可以包含多行语句。 在用Lambda 之前，我们先看看之前写比较器的写法&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Comparator&amp;lt;Developer&amp;gt; byName = new Comparator&amp;lt;Developer&amp;gt;() {
    @Override
    public int compare(Developer o1, Developer o2) {
        return o1.getName().compareTo(o2.getName());
    }
};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;感觉也不是很复杂，没几行代码，再来看看Lambda 表达式的写法：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Comparator&amp;lt;Developer&amp;gt; byName =
    (Developer o1, Developer o2)-&amp;gt;o1.getName().compareTo(o2.getName());
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;比之前要简单许多有木有。 下面再来看看排序功能示例： 先用Collections.sort如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class TestSorting {
    public static void main(String[] args) {
        List&amp;lt;Developer&amp;gt; listDevs = getDevelopers();
        System.out.println(&amp;quot;Before Sort&amp;quot;);
        for (Developer developer : listDevs) {
            System.out.println(developer);
        }
        //安照年龄排序
        Collections.sort(listDevs, new Comparator&amp;lt;Developer&amp;gt;() {
            @Override
            public int compare(Developer o1, Developer o2) {
                return o1.getAge() - o2.getAge();
            }
        });
        System.out.println(&amp;quot;After Sort&amp;quot;);
        for (Developer developer : listDevs) {
            System.out.println(developer);
        }
    }
    private static List&amp;lt;Developer&amp;gt; getDevelopers() {
        List&amp;lt;Developer&amp;gt; result = new ArrayList&amp;lt;Developer&amp;gt;();
        result.add(new Developer(&amp;quot;mkyong&amp;quot;, new BigDecimal(&amp;quot;70000&amp;quot;), 33));
        result.add(new Developer(&amp;quot;alvin&amp;quot;, new BigDecimal(&amp;quot;80000&amp;quot;), 20));
        result.add(new Developer(&amp;quot;jason&amp;quot;, new BigDecimal(&amp;quot;100000&amp;quot;), 10));
        result.add(new Developer(&amp;quot;iris&amp;quot;, new BigDecimal(&amp;quot;170000&amp;quot;), 55));
        return result;
    }
}

输出结果：

Before Sort
Developer [name=mkyong, salary=70000, age=33]
Developer [name=alvin, salary=80000, age=20]
Developer [name=jason, salary=100000, age=10]
Developer [name=iris, salary=170000, age=55]
 
After Sort
Developer [name=jason, salary=100000, age=10]
Developer [name=alvin, salary=80000, age=20]
Developer [name=mkyong, salary=70000, age=33]
Developer [name=iris, salary=170000, age=55]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;看起来整个流程完全没毛病，下面再来看看Lambda的方式:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class TestSorting {
    public static void main(String[] args) {
        List&amp;lt;Developer&amp;gt; listDevs = getDevelopers();
        System.out.println(&amp;quot;Before Sort&amp;quot;);
        for (Developer developer : listDevs) {
            System.out.println(developer);
        }
        System.out.println(&amp;quot;After Sort&amp;quot;);
        //对比上面的代码
        listDevs.sort((Developer o1, Developer o2)-&amp;gt;o1.getAge()-o2.getAge());
        //这样打印感觉也不错
        listDevs.forEach((developer)-&amp;gt;System.out.println(developer));
    }
    private static List&amp;lt;Developer&amp;gt; getDevelopers() {
        List&amp;lt;Developer&amp;gt; result = new ArrayList&amp;lt;Developer&amp;gt;();
        result.add(new Developer(&amp;quot;mkyong&amp;quot;, new BigDecimal(&amp;quot;70000&amp;quot;), 33));
        result.add(new Developer(&amp;quot;alvin&amp;quot;, new BigDecimal(&amp;quot;80000&amp;quot;), 20));
        result.add(new Developer(&amp;quot;jason&amp;quot;, new BigDecimal(&amp;quot;100000&amp;quot;), 10));
        result.add(new Developer(&amp;quot;iris&amp;quot;, new BigDecimal(&amp;quot;170000&amp;quot;), 55));
        return result;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;输出结果：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Before Sort
Developer [name=mkyong, salary=70000, age=33]
Developer [name=alvin, salary=80000, age=20]
Developer [name=jason, salary=100000, age=10]
Developer [name=iris, salary=170000, age=55]

After Sort
Developer [name=jason, salary=100000, age=10]
Developer [name=alvin, salary=80000, age=20]
Developer [name=mkyong, salary=70000, age=33]
Developer [name=iris, salary=170000, age=55]
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;Java 中的两种排序方式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Comparable 自然排序。（实体类实现）
Comparator 是定制排序。（无法修改实体类时，直接在调用方创建）
同时存在时采用 Comparator（定制排序）的规则进行比较。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;对于一些普通的数据类型（比如 String, Integer, Double…），它们默认实现了Comparable 接口，实现了 compareTo 方法，我们可以直接使用。&lt;/p&gt;
&lt;p&gt;而对于一些自定义类，它们可能在不同情况下需要实现不同的比较策略，我们可以新创建 Comparator 接口，然后使用特定的 Comparator 实现进行比较。&lt;/p&gt;
&lt;p&gt;这就是 Comparable 和 Comparator 的区别。&lt;/p&gt;
">Iterator，fail-fast机制与比较器</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/CountLatch/"" data-c="
          &lt;h3 id=&#34;countdownlatch&#34;&gt;CountDownLatch&lt;/h3&gt;
&lt;p&gt;CountDownLatch适用于在多线程的场景需要等待所有子线程全部执行完毕之后再做操作的场景。&lt;/p&gt;
&lt;p&gt;举个例子，早上部门开会，有人在上厕所，这时候需要等待所有人从厕所回来之后才能开始会议。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class CountDownLatchTest {
    private static int num = 3;
    private static CountDownLatch countDownLatch = new CountDownLatch(num);
    private static ExecutorService executorService = Executors.newFixedThreadPool(num);
    public static void main(String[] args) throws Exception{
        executorService.submit(() -&amp;gt; {
            System.out.println(&amp;quot;A在上厕所&amp;quot;);
            try {
                Thread.sleep(4000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }finally {
                countDownLatch.countDown();
                System.out.println(&amp;quot;A上完了&amp;quot;);
            }
        });
        executorService.submit(()-&amp;gt;{
            System.out.println(&amp;quot;B在上厕所&amp;quot;);
            try {
                Thread.sleep(2000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }finally {
                countDownLatch.countDown();
                System.out.println(&amp;quot;B上完了&amp;quot;);
            }
        });
        executorService.submit(()-&amp;gt;{
            System.out.println(&amp;quot;C在上厕所&amp;quot;);
            try {
                Thread.sleep(3000);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }finally {
                countDownLatch.countDown();
                System.out.println(&amp;quot;C上完了&amp;quot;);
            }
        });

        System.out.println(&amp;quot;等待所有人从厕所回来开会...&amp;quot;);
        countDownLatch.await();
        System.out.println(&amp;quot;所有人都好了，开始开会...&amp;quot;);
        executorService.shutdown();

    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;代码执行结果：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;A在上厕所
B在上厕所
等待所有人从厕所回来开会...
C在上厕所
B上完了
C上完了
A上完了
所有人都好了，开始开会...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;初始化一个CountDownLatch实例传参3，因为我们有3个子线程，每次子线程执行完毕之后调用countDown()方法给计数器-1，主线程调用await()方法后会被阻塞，直到最后计数器变为0，await()方法返回，执行完毕。他和join()方法的区别就是join会阻塞子线程直到运行结束，而CountDownLatch可以在任何时候让await()返回，而且用ExecutorService没法用join了，相比起来，CountDownLatch更灵活。&lt;/p&gt;
&lt;p&gt;CountDownLatch基于AQS实现，volatile变量state维持倒数状态，多线程共享变量可见。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;CountDownLatch通过构造函数初始化传入参数实际为AQS的state变量赋值，维持计数器倒数状态&lt;/li&gt;
&lt;li&gt;当主线程调用await()方法时，当前线程会被阻塞，当state不为0时进入AQS阻塞队列等待。&lt;/li&gt;
&lt;li&gt;其他线程调用countDown()时，state值原子性递减，当state值为0的时候，唤醒所有调用await()方法阻塞的线程&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;cyclicbarrier&#34;&gt;CyclicBarrier&lt;/h3&gt;
&lt;p&gt;CyclicBarrier叫做回环屏障，它的作用是&lt;strong&gt;让一组线程全部达到一个状态之后再全部同时执行&lt;/strong&gt;，而且他有一个特点就是所有线程执行完毕之后是可以重用的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class CyclicBarrierTest {
    private static int num = 3;
    private static CyclicBarrier cyclicBarrier = new CyclicBarrier(num, () -&amp;gt; {
        System.out.println(&amp;quot;所有人都好了，开始开会...&amp;quot;);
        System.out.println(&amp;quot;-------------------&amp;quot;);
    });
    private static ExecutorService executorService = Executors.newFixedThreadPool(num);
    public static void main(String[] args) throws Exception{
        executorService.submit(() -&amp;gt; {
            System.out.println(&amp;quot;A在上厕所&amp;quot;);
            try {
                Thread.sleep(4000);
                System.out.println(&amp;quot;A上完了&amp;quot;);
                cyclicBarrier.await();
                System.out.println(&amp;quot;会议结束，A退出&amp;quot;);
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });
        executorService.submit(()-&amp;gt;{
            System.out.println(&amp;quot;B在上厕所&amp;quot;);
            try {
                Thread.sleep(2000);
                System.out.println(&amp;quot;B上完了&amp;quot;);
                cyclicBarrier.await();
                System.out.println(&amp;quot;会议结束，B退出&amp;quot;);
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });
        executorService.submit(()-&amp;gt;{
            System.out.println(&amp;quot;C在上厕所&amp;quot;);
            try {
                Thread.sleep(3000);
                System.out.println(&amp;quot;C上完了&amp;quot;);
                cyclicBarrier.await();
                System.out.println(&amp;quot;会议结束，C退出&amp;quot;);
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });

        executorService.shutdown();

    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;输出结果为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;A在上厕所
B在上厕所
C在上厕所
B上完了
C上完了
A上完了
所有人都好了，开始开会...
-------------------
会议结束，A退出
会议结束，B退出
会议结束，C退出
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从结果来看和CountDownLatch非常相似，初始化传入3个线程和一个任务，线程调用await()之后进入阻塞，计数器-1，当计数器为0时，就去执行CyclicBarrier中构造函数的任务，当任务执行完毕后，唤醒所有阻塞中的线程。这验证了CyclicBarrier&lt;strong&gt;让一组线程全部达到一个状态之后再全部同时执行&lt;/strong&gt;的效果。&lt;/p&gt;
&lt;p&gt;再举个例子来验证CyclicBarrier可重用的效果。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class CyclicBarrierTest2 {
    private static int num = 3;
    private static CyclicBarrier cyclicBarrier = new CyclicBarrier(num, () -&amp;gt; {
        System.out.println(&amp;quot;-------------------&amp;quot;);
    });
    private static ExecutorService executorService = Executors.newFixedThreadPool(num);

    public static void main(String[] args) throws Exception {
        executorService.submit(() -&amp;gt; {
            System.out.println(&amp;quot;A在上厕所&amp;quot;);
            try {
                Thread.sleep(4000);
                System.out.println(&amp;quot;A上完了&amp;quot;);
                cyclicBarrier.await();
                System.out.println(&amp;quot;会议结束，A退出，开始撸代码&amp;quot;);
                cyclicBarrier.await();
                System.out.println(&amp;quot;C工作结束，下班回家&amp;quot;);
                cyclicBarrier.await();
            } catch (Exception e) {
                e.printStackTrace();
            } finally {

            }
        });
        executorService.submit(() -&amp;gt; {
            System.out.println(&amp;quot;B在上厕所&amp;quot;);
            try {
                Thread.sleep(2000);
                System.out.println(&amp;quot;B上完了&amp;quot;);
                cyclicBarrier.await();
                System.out.println(&amp;quot;会议结束，B退出，开始摸鱼&amp;quot;);
                cyclicBarrier.await();
                System.out.println(&amp;quot;B摸鱼结束，下班回家&amp;quot;);
                cyclicBarrier.await();
            } catch (Exception e) {
                e.printStackTrace();
            } finally {

            }
        });
        executorService.submit(() -&amp;gt; {
            System.out.println(&amp;quot;C在上厕所&amp;quot;);
            try {
                Thread.sleep(3000);
                System.out.println(&amp;quot;C上完了&amp;quot;);
                cyclicBarrier.await();
                System.out.println(&amp;quot;会议结束，C退出，开始摸鱼&amp;quot;);
                cyclicBarrier.await();
                System.out.println(&amp;quot;C摸鱼结束，下班回家&amp;quot;);
                cyclicBarrier.await();
            } catch (Exception e) {
                e.printStackTrace();
            } finally {

            }
        });

        executorService.shutdown();

    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;输出结果：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;A在上厕所
B在上厕所
C在上厕所
B上完了
C上完了
A上完了
-------------------
会议结束，A退出，开始撸代码
会议结束，B退出，开始摸鱼
会议结束，C退出，开始摸鱼
-------------------
C摸鱼结束，下班回家
C工作结束，下班回家
B摸鱼结束，下班回家
-------------------
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;从结果来看，每个子线程调用await()计数器减为0之后才开始继续一起往下执行，会议结束之后一起进入摸鱼状态，最后一天结束一起下班，这就是&lt;strong&gt;可重用&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;CyclicBarrier还是基于AQS实现的，内部维护parties记录总线程数，count用于计数，最开始count=parties，调用await()之后count原子递减，当count为0之后，再次将parties赋值给count，这就是复用的原理。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;当子线程调用await()方法时，获取独占锁，同时对count递减，进入阻塞队列，然后释放锁&lt;/li&gt;
&lt;li&gt;当第一个线程被阻塞同时释放锁之后，其他子线程竞争获取锁，操作同1&lt;/li&gt;
&lt;li&gt;直到最后count为0，执行CyclicBarrier构造函数中的任务，执行完毕之后子线程继续向下执行&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;semaphore&#34;&gt;Semaphore&lt;/h3&gt;
&lt;p&gt;Semaphore叫做信号量，和前面两个不同的是，他的计数器是递增的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public class SemaphoreTest {
    private static int num = 3;
    private static int initNum = 0;
    private static Semaphore semaphore = new Semaphore(initNum);
    private static ExecutorService executorService = Executors.newFixedThreadPool(num);
    public static void main(String[] args) throws Exception{
        executorService.submit(() -&amp;gt; {
            System.out.println(&amp;quot;A在上厕所&amp;quot;);
            try {
                Thread.sleep(4000);
                semaphore.release();
                System.out.println(&amp;quot;A上完了&amp;quot;);
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });
        executorService.submit(()-&amp;gt;{
            System.out.println(&amp;quot;B在上厕所&amp;quot;);
            try {
                Thread.sleep(2000);
                semaphore.release();
                System.out.println(&amp;quot;B上完了&amp;quot;);
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });
        executorService.submit(()-&amp;gt;{
            System.out.println(&amp;quot;C在上厕所&amp;quot;);
            try {
                Thread.sleep(3000);
                semaphore.release();
                System.out.println(&amp;quot;C上完了&amp;quot;);
            } catch (Exception e) {
                e.printStackTrace();
            }finally {

            }
        });

        System.out.println(&amp;quot;等待所有人从厕所回来开会...&amp;quot;);
        semaphore.acquire(num);
        System.out.println(&amp;quot;所有人都好了，开始开会...&amp;quot;);

        executorService.shutdown();

    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;输出结果为：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;A在上厕所
B在上厕所
等待所有人从厕所回来开会...
C在上厕所
B上完了
C上完了
A上完了
所有人都好了，开始开会...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;稍微和前两个有点区别，构造函数传入的初始值为0，当子线程调用release()方法时，计数器递增，主线程acquire()传参为3则说明主线程一直阻塞，直到计数器为3才会返回。&lt;/p&gt;
&lt;p&gt;Semaphore还还还是基于AQS实现的，同时获取信号量有公平和非公平两种策略&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;主线程调用acquire()方法时，用当前信号量值-需要获取的值，如果小于0，则进入同步阻塞队列，大于0则通过CAS设置当前信号量为剩余值，同时返回剩余值&lt;/li&gt;
&lt;li&gt;子线程调用release()给当前信号量值计数器+1(增加的值数量由传参决定)，同时不停的尝试因为调用acquire()进入阻塞的线程&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;
&lt;p&gt;CountDownLatch通过计数器提供了比join更灵活的多线程控制方式，CyclicBarrier也可以达到CountDownLatch的效果，而且有可复用的特点，Semaphore则是采用信号量递增的方式，开始的时候并不需要关注需要同步的线程个数，并且提供获取信号的公平和非公平策略。&lt;/p&gt;
">CountDownLatch</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/Jvm/"" data-c="
          &lt;h2 id=&#34;说说jvm的内存布局&#34;&gt;说说JVM的内存布局？&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIdxx34IBCxK8JZLARaNrnvVpOMwS07FaicpOh5E0zEeLfAdT2AyroNdA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;Java虚拟机主要包含几个区域：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;堆&lt;/strong&gt;：堆Java虚拟机中最大的一块内存，是线程共享的内存区域，基本上所有的对象实例数组都是在堆上分配空间。堆区细分为Yound区年轻代和Old区老年代，其中年轻代又分为Eden、S0、S1 3个部分，他们默认的比例是8:1:1的大小。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;栈&lt;/strong&gt;：栈是线程私有的内存区域，每个方法执行的时候都会在栈创建一个栈帧，方法的调用过程就对应着栈的入栈和出栈的过程。每个栈帧的结构又包含局部变量表、操作数栈、动态连接、方法返回地址。&lt;/p&gt;
&lt;p&gt;局部变量表用于存储方法参数和局部变量。当第一个方法被调用的时候，他的参数会被传递至从0开始的连续的局部变量表中。&lt;/p&gt;
&lt;p&gt;操作数栈用于一些字节码指令从局部变量表中传递至操作数栈，也用来准备方法调用的参数以及接收方法返回结果。&lt;/p&gt;
&lt;p&gt;动态连接用于将符号引用表示的方法转换为实际方法的直接引用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;元数据&lt;/strong&gt;：在Java1.7之前，包含方法区的概念，常量池就存在于方法区（永久代）中，而方法区本身是一个逻辑上的概念，在1.7之后则是把常量池移到了堆内，1.8之后移出了永久代的概念(方法区的概念仍然保留)，实现方式则是现在的元数据。它包含类的元信息和运行时常量池。&lt;/p&gt;
&lt;p&gt;Class文件就是类和接口的定义信息。&lt;/p&gt;
&lt;p&gt;运行时常量池就是类和接口的常量池运行时的表现形式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本地方法栈&lt;/strong&gt;：主要用于执行本地native方法的区域&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;程序计数器&lt;/strong&gt;：也是线程私有的区域，用于记录当前线程下虚拟机正在执行的字节码的指令地址&lt;/p&gt;
&lt;h2 id=&#34;知道new一个对象的过程吗&#34;&gt;知道new一个对象的过程吗？&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIUCyy2VR6ZlqTx2Nr5muXb3kjsLYTVDbFibADcK2hict72nXb2RI9K0Wg/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;当虚拟机遇见new关键字时候，实现判断当前类是否已经加载，如果类没有加载，首先执行类的加载机制，加载完成后再为对象分配空间、初始化等。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先校验当前类是否被加载，如果没有加载，执行类加载机制&lt;/li&gt;
&lt;li&gt;加载：就是从字节码加载成二进制流的过程&lt;/li&gt;
&lt;li&gt;验证：当然加载完成之后，当然需要校验Class文件是否符合虚拟机规范，跟我们接口请求一样，第一件事情当然是先做个参数校验了&lt;/li&gt;
&lt;li&gt;准备：为静态变量、常量赋默认值&lt;/li&gt;
&lt;li&gt;解析：把常量池中符号引用(以符号描述引用的目标)替换为直接引用(指向目标的指针或者句柄等)的过程&lt;/li&gt;
&lt;li&gt;初始化：执行static代码块(cinit)进行初始化，如果存在父类，先对父类进行初始化&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;em&gt;Ps：静态代码块是绝对线程安全的，只能隐式被java虚拟机在类加载过程中初始化调用！&lt;/em&gt;(此处该有问题static代码块线程安全吗？)&lt;/p&gt;
&lt;p&gt;当类加载完成之后，紧接着就是对象分配内存空间和初始化的过程&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先为对象分配合适大小的内存空间&lt;/li&gt;
&lt;li&gt;接着为实例变量赋默认值&lt;/li&gt;
&lt;li&gt;设置对象的头信息，对象hash码、GC分代年龄、元数据信息等&lt;/li&gt;
&lt;li&gt;执行构造函数(init)初始化&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;知道双亲委派模型吗&#34;&gt;知道双亲委派模型吗？&lt;/h2&gt;
&lt;p&gt;类加载器自顶向下分为：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Bootstrap ClassLoader启动类加载器：默认会去加载JAVA_HOME/lib目录下的jar&lt;/li&gt;
&lt;li&gt;Extention ClassLoader扩展类加载器：默认去加载JAVA_HOME/lib/ext目录下的jar&lt;/li&gt;
&lt;li&gt;Application ClassLoader应用程序类加载器：比如我们的web应用，会加载web程序中ClassPath下的类&lt;/li&gt;
&lt;li&gt;User ClassLoader用户自定义类加载器：由用户自己定义&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;当我们在加载类的时候，首先都会向上询问自己的父加载器是否已经加载，如果没有则依次向上询问，如果没有加载，则从上到下依次尝试是否能加载当前类，直到加载成功。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIhXK8icwZjLzVpbmwghicmyhrcx4TXWjdTVZ8ONaxrND9HLkFdNkoTgZQ/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;说说有哪些垃圾回收算法&#34;&gt;说说有哪些垃圾回收算法？&lt;/h2&gt;
&lt;h3 id=&#34;标记-清除&#34;&gt;标记-清除&lt;/h3&gt;
&lt;p&gt;统一标记出需要回收的对象，标记完成之后统一回收所有被标记的对象，而由于标记的过程需要遍历所有的GC ROOT，清除的过程也要遍历堆中所有的对象，所以标记-清除算法的效率低下，同时也带来了内存碎片的问题。&lt;/p&gt;
&lt;h3 id=&#34;复制算法&#34;&gt;复制算法&lt;/h3&gt;
&lt;p&gt;为了解决性能的问题，复制算法应运而生，它将内存分为大小相等的两块区域，每次使用其中的一块，当一块内存使用完之后，将还存活的对象拷贝到另外一块内存区域中，然后把当前内存清空，这样性能和内存碎片的问题得以解决。但是同时带来了另外一个问题，可使用的内存空间缩小了一半！&lt;/p&gt;
&lt;p&gt;因此，诞生了我们现在的常见的年轻代+老年代的内存结构：Eden+S0+S1组成，因为根据IBM的研究显示，98%的对象都是朝生夕死，所以实际上存活的对象并不是很多，完全不需要用到一半内存浪费，所以默认的比例是8:1:1。&lt;/p&gt;
&lt;p&gt;这样，在使用的时候只使用Eden区和S0S1中的一个，每次都把存活的对象拷贝另外一个未使用的Survivor区，同时清空Eden和使用的Survivor，这样下来内存的浪费就只有10%了。&lt;/p&gt;
&lt;p&gt;如果最后未使用的Survivor放不下存活的对象，这些对象就进入Old老年代了。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;PS：所以有一些初级点的问题会问你为什么要分为Eden区和2个Survior区？有什么作用？就是为了节省内存和解决内存碎片的问题，这些算法都是为了解决问题而产生的，如果理解原因你就不需要死记硬背了&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;标记-整理&#34;&gt;标记-整理&lt;/h3&gt;
&lt;p&gt;针对老年代再用复制算法显然不合适，因为进入老年代的对象都存活率比较高了，这时候再频繁的复制对性能影响就比较大，而且也不会再有另外的空间进行兜底。所以针对老年代的特点，通过标记-整理算法，标记出所有的存活对象，让所有存活的对象都向一端移动，然后清理掉边界以外的内存空间。&lt;/p&gt;
&lt;h2 id=&#34;那么什么是gc-root有哪些gc-root&#34;&gt;那么什么是GC ROOT？有哪些GC ROOT？&lt;/h2&gt;
&lt;p&gt;上面提到的标记的算法，怎么标记一个对象是否存活？简单的通过引用计数法，给对象设置一个引用计数器，每当有一个地方引用他，就给计数器+1，反之则计数器-1，但是这个简单的算法无法解决循环引用的问题。&lt;/p&gt;
&lt;p&gt;Java通过可达性分析算法来达到标记存活对象的目的，定义一系列的GC ROOT为起点，从起点开始向下开始搜索，搜索走过的路径称为引用链，当一个对象到GC ROOT没有任何引用链相连的话，则对象可以判定是可以被回收的。&lt;/p&gt;
&lt;p&gt;而可以作为GC ROOT的对象包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;栈中引用的对象&lt;/li&gt;
&lt;li&gt;静态变量、常量引用的对象&lt;/li&gt;
&lt;li&gt;本地方法栈native方法引用的对象&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;垃圾回收器了解吗年轻代和老年代都有哪些垃圾回收器&#34;&gt;垃圾回收器了解吗？年轻代和老年代都有哪些垃圾回收器？&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIiaibccybJicW4m2ibAf9lLJNiaUzRC7BxcbwwI1bcuY3LiaTap9zaKebibJjg/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;年轻代的垃圾收集器包含有Serial、ParNew、Parallell，老年代则包括Serial Old老年代版本、CMS、Parallel Old老年代版本和JDK11中的船新的G1收集器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Serial&lt;/strong&gt;：单线程版本收集器，进行垃圾回收的时候会STW（Stop The World），也就是进行垃圾回收的时候其他的工作线程都必须暂停&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ParNew&lt;/strong&gt;：Serial的多线程版本，用于和CMS配合使用&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Parallel Scavenge&lt;/strong&gt;：可以并行收集的多线程垃圾收集器&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Serial Old&lt;/strong&gt;：Serial的老年代版本，也是单线程&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Parallel Old&lt;/strong&gt;：Parallel Scavenge的老年代版本&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CMS（Concurrent Mark Sweep）&lt;/strong&gt;：CMS收集器是以获取最短停顿时间为目标的收集器，相对于其他的收集器STW的时间更短暂，可以并行收集是他的特点，同时他基于标记-清除算法，整个GC的过程分为4步。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初始标记：标记GC ROOT能关联到的对象，需要STW&lt;/li&gt;
&lt;li&gt;并发标记：从GCRoots的直接关联对象开始遍历整个对象图的过程，不需要STW&lt;/li&gt;
&lt;li&gt;重新标记：为了修正并发标记期间，因用户程序继续运作而导致标记产生改变的标记，需要STW&lt;/li&gt;
&lt;li&gt;并发清除：清理删除掉标记阶段判断的已经死亡的对象，不需要STW&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从整个过程来看，并发标记和并发清除的耗时最长，但是不需要停止用户线程，而初始标记和重新标记的耗时较短，但是需要停止用户线程，总体而言，整个过程造成的停顿时间较短，大部分时候是可以和用户线程一起工作的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;G1（Garbage First）&lt;/strong&gt;：G1收集器是JDK9的默认垃圾收集器，而且不再区分年轻代和老年代进行回收。&lt;/p&gt;
&lt;h2 id=&#34;g1的原理了解吗&#34;&gt;G1的原理了解吗？&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIu1KwEcXMxlPbymIicIxbNOWpiav0a4kibkCgaz447ia1naa3EwefOUoe6g/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;G1作为JDK9之后的服务端默认收集器，且不再区分年轻代和老年代进行垃圾回收，他把内存划分为多个Region，每个Region的大小可以通过-XX：G1HeapRegionSize设置，大小为1~32M，对于大对象的存储则衍生出Humongous的概念，超过Region大小一半的对象会被认为是大对象，而超过整个Region大小的对象被认为是超级大对象，将会被存储在连续的N个Humongous Region中，G1在进行回收的时候会在后台维护一个优先级列表，每次根据用户设定允许的收集停顿时间优先回收收益最大的Region。&lt;/p&gt;
&lt;p&gt;G1的回收过程分为以下四个步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初始标记：标记GC ROOT能关联到的对象，需要STW&lt;/li&gt;
&lt;li&gt;并发标记：从GCRoots的直接关联对象开始遍历整个对象图的过程，扫描完成后还会重新处理并发标记过程中产生变动的对象&lt;/li&gt;
&lt;li&gt;最终标记：短暂暂停用户线程，再处理一次，需要STW&lt;/li&gt;
&lt;li&gt;筛选回收：更新Region的统计数据，对每个Region的回收价值和成本排序，根据用户设置的停顿时间制定回收计划。再把需要回收的Region中存活对象复制到空的Region，同时清理旧的Region。需要STW&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总的来说除了并发标记之外，其他几个过程也还是需要短暂的STW，G1的目标是在停顿和延迟可控的情况下尽可能提高吞吐量。&lt;/p&gt;
&lt;h2 id=&#34;什么时候会触发ygc和fgc对象什么时候会进入老年代&#34;&gt;什么时候会触发YGC和FGC？对象什么时候会进入老年代？&lt;/h2&gt;
&lt;p&gt;当一个新的对象来申请内存空间的时候，如果Eden区无法满足内存分配需求，则触发YGC，使用中的Survivor区和Eden区存活对象送到未使用的Survivor区，如果YGC之后还是没有足够空间，则直接进入老年代分配，如果老年代也无法分配空间，触发FGC，FGC之后还是放不下则报出OOM异常。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIXa1JZZ3lzh5GpljeFmBp9IjE2qMa5iaNZbee1fibzSvkJtl97abxIHag/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;YGC之后，存活的对象将会被复制到未使用的Survivor区，如果S区放不下，则直接晋升至老年代。而对于那些一直在Survivor区来回复制的对象，通过-XX：MaxTenuringThreshold配置交换阈值，默认15次，如果超过次数同样进入老年代。&lt;/p&gt;
&lt;p&gt;此外，还有一种动态年龄的判断机制，不需要等到MaxTenuringThreshold就能晋升老年代。如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。&lt;/p&gt;
&lt;h2 id=&#34;频繁fullgc怎么排查&#34;&gt;频繁FullGC怎么排查？&lt;/h2&gt;
&lt;p&gt;这种问题最好的办法就是结合有具体的例子举例分析，如果没有就说一般的分析步骤。发生FGC有可能是内存分配不合理，比如Eden区太小，导致对象频繁进入老年代，这时候通过启动参数配置就能看出来，另外有可能就是存在内存泄露，可以通过以下的步骤进行排查：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;jstat -gcutil或者查看gc.log日志，查看内存回收情况&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuItDPgQsNbficMlvhh6kMYkrTzYrA9UyehPw7bjvoAFicCJZgez01AMmhg/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;S0 S1 分别代表两个Survivor区占比&lt;/p&gt;
&lt;p&gt;E代表Eden区占比，图中可以看到使用78%&lt;/p&gt;
&lt;p&gt;O代表老年代，M代表元空间，YGC发生54次，YGCT代表YGC累计耗时，GCT代表GC累计耗时。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIEw6ltlU85ic71ibQjZC0HZ5kBs3jEccyZibILpUTO2FaibX2a3ibibPzhE9w/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;[GC [FGC 开头代表垃圾回收的类型&lt;/p&gt;
&lt;p&gt;PSYoungGen: 6130K-&amp;gt;6130K(9216K)] 12274K-&amp;gt;14330K(19456K), 0.0034895 secs代表YGC前后内存使用情况&lt;/p&gt;
&lt;p&gt;Times: user=0.02 sys=0.00, real=0.00 secs，user表示用户态消耗的CPU时间，sys表示内核态消耗的CPU时间，real表示各种墙时钟的等待时间&lt;/p&gt;
&lt;p&gt;这两张图只是举例并没有关联关系，比如你从图里面看能到是否进行FGC，FGC的时间花费多长，GC后老年代，年轻代内存是否有减少，得到一些初步的情况来做出判断。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;dump出内存文件在具体分析，比如通过jmap命令jmap -dump:format=b,file=dumpfile pid，导出之后再通过&lt;strong&gt;Eclipse Memory Analyzer&lt;/strong&gt;等工具进行分析，定位到代码，修复&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里还会可能存在一个提问的点，比如CPU飙高，同时FGC怎么办？办法比较类似&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;找到当前进程的pid，top -p pid -H 查看资源占用，找到线程&lt;/li&gt;
&lt;li&gt;printf “%x\n” pid，把线程pid转为16进制，比如0x32d&lt;/li&gt;
&lt;li&gt;jstack pid|grep -A 10 0x32d查看线程的堆栈日志，还找不到问题继续&lt;/li&gt;
&lt;li&gt;dump出内存文件用MAT等工具进行分析，定位到代码，修复&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;jvm调优有什么经验吗&#34;&gt;JVM调优有什么经验吗？&lt;/h2&gt;
&lt;p&gt;要明白一点，所有的调优的目的都是为了用更小的硬件成本达到更高的吞吐，JVM的调优也是一样，通过对垃圾收集器和内存分配的调优达到性能的最佳。&lt;/p&gt;
&lt;h3 id=&#34;简单的参数含义&#34;&gt;简单的参数含义&lt;/h3&gt;
&lt;p&gt;首先，需要知道几个主要的参数含义。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUl4lw1ia9WwR2bceFhiaLsKuIURPJpeCMd0m4KRa2qvL6rMEXchRkgdelvy5m1icKQTYXv8XahTTeJgQ/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ol&gt;
&lt;li&gt;-Xms设置初始堆的大小，-Xmx设置最大堆的大小&lt;/li&gt;
&lt;li&gt;-XX:NewSize年轻代大小，-XX:MaxNewSize年轻代最大值，-Xmn则是相当于同时配置-XX:NewSize和-XX:MaxNewSize为一样的值&lt;/li&gt;
&lt;li&gt;-XX:NewRatio设置年轻代和年老代的比值，如果为3，表示年轻代与老年代比值为1:3，默认值为2&lt;/li&gt;
&lt;li&gt;-XX:SurvivorRatio年轻代和两个Survivor的比值，默认8，代表比值为8:1:1&lt;/li&gt;
&lt;li&gt;-XX:PretenureSizeThreshold 当创建的对象超过指定大小时，直接把对象分配在老年代。&lt;/li&gt;
&lt;li&gt;-XX:MaxTenuringThreshold设定对象在Survivor复制的最大年龄阈值，超过阈值转移到老年代&lt;/li&gt;
&lt;li&gt;-XX:MaxDirectMemorySize当Direct ByteBuffer分配的堆外内存到达指定大小后，即触发Full GC&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;调优&#34;&gt;调优&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;为了打印日志方便排查问题最好开启GC日志，开启GC日志对性能影响微乎其微，但是能帮助我们快速排查定位问题。-XX:+PrintGCTimeStamps -XX:+PrintGCDetails -Xloggc:gc.log&lt;/li&gt;
&lt;li&gt;一般设置-Xms=-Xmx，这样可以获得固定大小的堆内存，减少GC的次数和耗时，可以使得堆相对稳定&lt;/li&gt;
&lt;li&gt;-XX:+HeapDumpOnOutOfMemoryError让JVM在发生内存溢出的时候自动生成内存快照，方便排查问题&lt;/li&gt;
&lt;li&gt;-Xmn设置新生代的大小，太小会增加YGC，太大会减小老年代大小，一般设置为整个堆的1/4到1/3&lt;/li&gt;
&lt;li&gt;设置-XX:+DisableExplicitGC禁止系统System.gc()，防止手动误触发FGC造成问题&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;- END -&lt;/p&gt;
">JVM</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/daliuliang/"" data-c="
          &lt;h2 id=&#34;微服务架构演化&#34;&gt;微服务架构演化&lt;/h2&gt;
&lt;p&gt;在互联网早期的时候，单体架构就足以支撑起日常的业务需求，大家的所有业务服务都在一个项目里，部署在一台物理机器上。所有的业务包括你的交易系统、会员信息、库存、商品等等都夹杂在一起，当流量一旦起来之后，单体架构的问题就暴露出来了，机器挂了所有的业务全部无法使用了。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kk0ialF0DVYbtzN2mqZPMwHIq0h6YiaKegLJWGoO96QM1hlicibxM67D1aSw/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;于是，集群架构的架构开始出现，单机无法抗住的压力，最简单的办法就是水平拓展横向扩容了，这样，通过负载均衡把压力流量分摊到不同的机器上，暂时是解决了单点导致服务不可用的问题。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkcsLoebo42vcUWFAalAMmDINrf7AW0aiaDe74gCOyF6eSsZd8DtbVasA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;但是随着业务的发展，在一个项目里维护所有的业务场景使开发和代码维护变得越来越困难，一个简单的需求改动都需要发布整个服务，代码的合并冲突也会变得越来越频繁，同时线上故障出现的可能性越大。微服务的架构模式就诞生了。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkUxmEr8iasnsfBicbNCSkEIpHr8Ep2yCwvLic6uhSeRR3aceVicUIeXF8GA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;把每个独立的业务拆分开独立部署，开发和维护的成本降低，集群能承受的压力也提高了，再也不会出现一个小小的改动点需要牵一发而动全身了。&lt;/p&gt;
&lt;p&gt;以上的点从高并发的角度而言，似乎都可以归类为通过服务拆分和集群物理机器的扩展提高了整体的系统抗压能力，那么，随之拆分而带来的问题也就是高并发系统需要解决的问题。&lt;/p&gt;
&lt;h2 id=&#34;rpc&#34;&gt;RPC&lt;/h2&gt;
&lt;p&gt;微服务化的拆分带来的好处和便利性是显而易见的，但是与此同时各个微服务之间的通信就需要考虑了。传统HTTP的通信方式对性能是极大的浪费，这时候就需要引入诸如Dubbo类的RPC框架，基于TCP长连接的方式提高整个集群通信的效率。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkPRsicIDaiaLgFzlL3DSxcwTSzTgffDOCvpuIuvw0VvXs0P41BuUI4L2Q/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;我们假设原来来自客户端的QPS是9000的话，那么通过负载均衡策略分散到每台机器就是3000，而HTTP改为RPC之后接口的耗时缩短了，单机和整体的QPS就提升了。而RPC框架本身一般都自带负载均衡、熔断降级的机制，可以更好的维护整个系统的高可用性。&lt;/p&gt;
&lt;p&gt;那么说完RPC，作为基本上国内普遍的选择Dubbo的一些基本原理就是接下来的问题。&lt;/p&gt;
&lt;h3 id=&#34;dubbo工作原理&#34;&gt;Dubbo工作原理&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;服务启动的时候，provider和consumer根据配置信息，连接到注册中心register，分别向注册中心注册和订阅服务&lt;/li&gt;
&lt;li&gt;register根据服务订阅关系，返回provider信息到consumer，同时consumer会把provider信息缓存到本地。如果信息有变更，consumer会收到来自register的推送&lt;/li&gt;
&lt;li&gt;consumer生成代理对象，同时根据负载均衡策略，选择一台provider，同时定时向monitor记录接口的调用次数和时间信息&lt;/li&gt;
&lt;li&gt;拿到代理对象之后，consumer通过代理对象发起接口调用&lt;/li&gt;
&lt;li&gt;provider收到请求后对数据进行反序列化，然后通过代理调用具体的接口实现&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kk41rxicIt92CwqJb5ba5n79lXLuwt4HsUuqGE5WbqoiaibMCFyJ1JKichbA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;dubbo负载均衡策略&#34;&gt;Dubbo负载均衡策略&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;加权随机：假设我们有一组服务器 servers = [A, B, C]，他们对应的权重为 weights = [5, 3, 2]，权重总和为10。现在把这些权重值平铺在一维坐标值上，[0, 5) 区间属于服务器 A，[5, 8) 区间属于服务器 B，[8, 10) 区间属于服务器 C。接下来通过随机数生成器生成一个范围在 [0, 10) 之间的随机数，然后计算这个随机数会落到哪个区间上就可以了。&lt;/li&gt;
&lt;li&gt;最小活跃数：每个服务提供者对应一个活跃数 active，初始情况下，所有服务提供者活跃数均为0。每收到一个请求，活跃数加1，完成请求后则将活跃数减1。在服务运行一段时间后，性能好的服务提供者处理请求的速度更快，因此活跃数下降的也越快，此时这样的服务提供者能够优先获取到新的服务请求。&lt;/li&gt;
&lt;li&gt;一致性hash：通过hash算法，把provider的invoke和随机节点生成hash，并将这个 hash 投射到 [0, 2^32 - 1] 的圆环上，查询的时候根据key进行md5然后进行hash，得到第一个节点的值大于等于当前hash的invoker。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kk1QVvVs2sxZrJeEPQJ4icjpsPET1KdeItR7IGdRcXFSD1lCS0eIIJKlA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;图片来自dubbo官方&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;加权轮询：比如服务器 A、B、C 权重比为 5:2:1，那么在8次请求中，服务器 A 将收到其中的5次请求，服务器 B 会收到其中的2次请求，服务器 C 则收到其中的1次请求。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;集群容错&#34;&gt;集群容错&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Failover Cluster失败自动切换：dubbo的默认容错方案，当调用失败时自动切换到其他可用的节点，具体的重试次数和间隔时间可用通过引用服务的时候配置，默认重试次数为1也就是只调用一次。&lt;/li&gt;
&lt;li&gt;Failback Cluster快速失败：在调用失败，记录日志和调用信息，然后返回空结果给consumer，并且通过定时任务每隔5秒对失败的调用进行重试&lt;/li&gt;
&lt;li&gt;Failfast Cluster失败自动恢复：只会调用一次，失败后立刻抛出异常&lt;/li&gt;
&lt;li&gt;Failsafe Cluster失败安全：调用出现异常，记录日志不抛出，返回空结果&lt;/li&gt;
&lt;li&gt;Forking Cluster并行调用多个服务提供者：通过线程池创建多个线程，并发调用多个provider，结果保存到阻塞队列，只要有一个provider成功返回了结果，就会立刻返回结果&lt;/li&gt;
&lt;li&gt;Broadcast Cluster广播模式：逐个调用每个provider，如果其中一台报错，在循环调用结束后，抛出异常。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;消息队列&#34;&gt;消息队列&lt;/h2&gt;
&lt;p&gt;对于MQ的作用大家都应该很了解了，削峰填谷、解耦。依赖消息队列，同步转异步的方式，可以降低微服务之间的耦合。&lt;/p&gt;
&lt;p&gt;对于一些不需要同步执行的接口，可以通过引入消息队列的方式异步执行以提高接口响应时间。在交易完成之后需要扣库存，然后可能需要给会员发放积分，本质上，发积分的动作应该属于履约服务，对实时性的要求也不高，我们只要保证最终一致性也就是能履约成功就行了。对于这种同类性质的请求就可以走MQ异步，也就提高了系统抗压能力了。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkFWU0aHOicpRW060Dia8mcMrKmkmZn55GsdYzHNS3xVDRhMopSZAjiaRIA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;对于消息队列而言，怎么在使用的时候保证消息的可靠性、不丢失？&lt;/p&gt;
&lt;h3 id=&#34;消息可靠性&#34;&gt;消息可靠性&lt;/h3&gt;
&lt;p&gt;消息丢失可能发生在生产者发送消息、MQ本身丢失消息、消费者丢失消息3个方面。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;生产者丢失&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;生产者丢失消息的可能点在于程序发送失败抛异常了没有重试处理，或者发送的过程成功但是过程中网络闪断MQ没收到，消息就丢失了。&lt;/p&gt;
&lt;p&gt;由于同步发送的一般不会出现这样使用方式，所以我们就不考虑同步发送的问题，我们基于异步发送的场景来说。&lt;/p&gt;
&lt;p&gt;异步发送分为两个方式：&lt;strong&gt;异步有回调和异步无回调&lt;/strong&gt;，无回调的方式，生产者发送完后不管结果可能就会造成消息丢失，而通过异步发送+回调通知+本地消息表的形式我们就可以做出一个解决方案。以下单的场景举例。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;下单后先保存本地数据和MQ消息表，这时候消息的状态是发送中，如果本地事务失败，那么下单失败，事务回滚。&lt;/li&gt;
&lt;li&gt;下单成功，直接返回客户端成功，异步发送MQ消息&lt;/li&gt;
&lt;li&gt;MQ回调通知消息发送结果，对应更新数据库MQ发送状态&lt;/li&gt;
&lt;li&gt;JOB轮询超过一定时间（时间根据业务配置）还未发送成功的消息去重试&lt;/li&gt;
&lt;li&gt;在监控平台配置或者JOB程序处理超过一定次数一直发送不成功的消息，告警，人工介入。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kk9gGB29FSkPy3JjePL6unswd8kLcZPk29SjNNOgjems7SMkbHpRIUrQ/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;一般而言，对于大部分场景来说异步回调的形式就可以了，只有那种需要完全保证不能丢失消息的场景我们做一套完整的解决方案。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MQ丢失&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果生产者保证消息发送到MQ，而MQ收到消息后还在内存中，这时候宕机了又没来得及同步给从节点，就有可能导致消息丢失。&lt;/p&gt;
&lt;p&gt;比如RocketMQ：&lt;/p&gt;
&lt;p&gt;RocketMQ分为同步刷盘和异步刷盘两种方式，默认的是异步刷盘，就有可能导致消息还未刷到硬盘上就丢失了，可以通过设置为同步刷盘的方式来保证消息可靠性，这样即使MQ挂了，恢复的时候也可以从磁盘中去恢复消息。&lt;/p&gt;
&lt;p&gt;比如Kafka也可以通过配置做到：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;acks=all 只有参与复制的所有节点全部收到消息，才返回生产者成功。这样的话除非所有的节点都挂了，消息才会丢失。
replication.factor=N,设置大于1的数，这会要求每个partion至少有2个副本
min.insync.replicas=N，设置大于1的数，这会要求leader至少感知到一个follower还保持着连接
retries=N，设置一个非常大的值，让生产者发送失败一直重试
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;虽然我们可以通过配置的方式来达到MQ本身高可用的目的，但是都对性能有损耗，怎样配置需要根据业务做出权衡。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;消费者丢失&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;消费者丢失消息的场景：消费者刚收到消息，此时服务器宕机，MQ认为消费者已经消费，不会重复发送消息，消息丢失。&lt;/p&gt;
&lt;p&gt;RocketMQ默认是需要消费者回复ack确认，而kafka需要手动开启配置关闭自动offset。&lt;/p&gt;
&lt;p&gt;消费方不返回ack确认，重发的机制根据MQ类型的不同发送时间间隔、次数都不尽相同，如果重试超过次数之后会进入死信队列，需要手工来处理了。（Kafka没有这些）&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkYciaSwqSeS3ibo1ZQ81cQcPd5X9F5Hejic40iaREib8Z0YgCBUtNR6SEibzw/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;消息的最终一致性&#34;&gt;消息的最终一致性&lt;/h3&gt;
&lt;p&gt;事务消息可以达到分布式事务的最终一致性，事务消息就是MQ提供的类似XA的分布式事务能力。&lt;/p&gt;
&lt;p&gt;半事务消息就是MQ收到了生产者的消息，但是没有收到二次确认，不能投递的消息。&lt;/p&gt;
&lt;p&gt;实现原理如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;生产者先发送一条半事务消息到MQ&lt;/li&gt;
&lt;li&gt;MQ收到消息后返回ack确认&lt;/li&gt;
&lt;li&gt;生产者开始执行本地事务&lt;/li&gt;
&lt;li&gt;如果事务执行成功发送commit到MQ，失败发送rollback&lt;/li&gt;
&lt;li&gt;如果MQ长时间未收到生产者的二次确认commit或者rollback，MQ对生产者发起消息回查&lt;/li&gt;
&lt;li&gt;生产者查询事务执行最终状态&lt;/li&gt;
&lt;li&gt;根据查询事务状态再次提交二次确认&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最终，如果MQ收到二次确认commit，就可以把消息投递给消费者，反之如果是rollback，消息会保存下来并且在3天后被删除。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kk5740GsBgdC0hibChyUFECjFkGI1Egk2B7003iauZQtcWTl605rbbeFMA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;数据库&#34;&gt;数据库&lt;/h2&gt;
&lt;p&gt;对于整个系统而言，最终所有的流量的查询和写入都落在数据库上，数据库是支撑系统高并发能力的核心。怎么降低数据库的压力，提升数据库的性能是支撑高并发的基石。主要的方式就是通过读写分离和分库分表来解决这个问题。&lt;/p&gt;
&lt;p&gt;对于整个系统而言，流量应该是一个漏斗的形式。比如我们的日活用户DAU有20万，实际可能每天来到提单页的用户只有3万QPS，最终转化到下单支付成功的QPS只有1万。那么对于系统来说读是大于写的，这时候可以通过读写分离的方式来降低数据库的压力。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkjJm1HxOHS75FLwFmNAXmNqhkwbCeBcUok16Kmr4a4M9rXF93sN1IHQ/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;读写分离也就相当于数据库集群的方式降低了单节点的压力。而面对数据的急剧增长，原来的单库单表的存储方式已经无法支撑整个业务的发展，这时候就需要对数据库进行分库分表了。针对微服务而言垂直的分库本身已经是做过的，剩下大部分都是分表的方案了。&lt;/p&gt;
&lt;h3 id=&#34;水平分表&#34;&gt;水平分表&lt;/h3&gt;
&lt;p&gt;首先根据业务场景来决定使用什么字段作为分表字段(sharding_key)，比如我们现在日订单1000万，我们大部分的场景来源于C端，我们可以用user_id作为sharding_key，数据查询支持到最近3个月的订单，超过3个月的做归档处理，那么3个月的数据量就是9亿，可以分1024张表，那么每张表的数据大概就在100万左右。&lt;/p&gt;
&lt;p&gt;比如用户id为100，那我们都经过hash(100)，然后对1024取模，就可以落到对应的表上了。&lt;/p&gt;
&lt;h3 id=&#34;分表后的id唯一性&#34;&gt;分表后的ID唯一性&lt;/h3&gt;
&lt;p&gt;因为我们主键默认都是自增的，那么分表之后的主键在不同表就肯定会有冲突了。有几个办法考虑：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;设定步长，比如1-1024张表我们分别设定1-1024的基础步长，这样主键落到不同的表就不会冲突了。&lt;/li&gt;
&lt;li&gt;分布式ID，自己实现一套分布式ID生成算法或者使用开源的比如雪花算法这种&lt;/li&gt;
&lt;li&gt;分表后不使用主键作为查询依据，而是每张表单独新增一个字段作为唯一主键使用，比如订单表订单号是唯一的，不管最终落在哪张表都基于订单号作为查询依据，更新也一样。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;主从同步原理&#34;&gt;主从同步原理&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;master提交完事务后，写入binlog&lt;/li&gt;
&lt;li&gt;slave连接到master，获取binlog&lt;/li&gt;
&lt;li&gt;master创建dump线程，推送binglog到slave&lt;/li&gt;
&lt;li&gt;slave启动一个IO线程读取同步过来的master的binlog，记录到relay log中继日志中&lt;/li&gt;
&lt;li&gt;slave再开启一个sql线程读取relay log事件并在slave执行，完成同步&lt;/li&gt;
&lt;li&gt;slave记录自己的binglog&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkqOMKE6hHYp3ia5JSQ92SwMdMeXYkzWSA5WAWjABhckice6Th8dvPo0aQ/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;由于mysql默认的复制方式是异步的，主库把日志发送给从库后不关心从库是否已经处理，这样会产生一个问题就是假设主库挂了，从库处理失败了，这时候从库升为主库后，日志就丢失了。由此产生两个概念。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;全同步复制&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;主库写入binlog后强制同步日志到从库，所有的从库都执行完成后才返回给客户端，但是很显然这个方式的话性能会受到严重影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;半同步复制&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;和全同步不同的是，半同步复制的逻辑是这样，从库写入日志成功后返回ACK确认给主库，主库收到至少一个从库的确认就认为写操作完成。&lt;/p&gt;
&lt;h2 id=&#34;缓存&#34;&gt;缓存&lt;/h2&gt;
&lt;p&gt;缓存作为高性能的代表，在某些特殊业务可能承担90%以上的热点流量。对于一些活动比如秒杀这种并发QPS可能几十万的场景，引入缓存事先预热可以大幅降低对数据库的压力，10万的QPS对于单机的数据库来说可能就挂了，但是对于如redis这样的缓存来说就完全不是问题。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkeOicPzVFSOSE8eeVYOhBkyBO6HgibpicKt4Wjp3XMW4Ribe9tJK8C1Dibsw/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;以秒杀系统举例，活动预热商品信息可以提前缓存提供查询服务，活动库存数据可以提前缓存，下单流程可以完全走缓存扣减，秒杀结束后再异步写入数据库，数据库承担的压力就小的太多了。当然，引入缓存之后就还要考虑缓存击穿、雪崩、热点一系列的问题了。&lt;/p&gt;
&lt;h3 id=&#34;热key问题&#34;&gt;热key问题&lt;/h3&gt;
&lt;p&gt;所谓热key问题就是，突然有几十万的请求去访问redis上的某个特定key，那么这样会造成流量过于集中，达到物理网卡上限，从而导致这台redis的服务器宕机引发雪崩。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkzjJYCCmzPnU7tf0I6ssJeqJkShUfdKv9ASaFZ6ImncF639rV53Mu2A/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;针对热key的解决方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;提前把热key打散到不同的服务器，降低压力&lt;/li&gt;
&lt;li&gt;加入二级缓存，提前加载热key数据到内存中，如果redis宕机，走内存查询&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;缓存击穿&#34;&gt;缓存击穿&lt;/h3&gt;
&lt;p&gt;缓存击穿的概念就是单个key并发访问过高，过期时导致所有请求直接打到db上，这个和热key的问题比较类似，只是说的点在于过期导致请求全部打到DB上而已。&lt;/p&gt;
&lt;p&gt;解决方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;加锁更新，比如请求查询A，发现缓存中没有，对A这个key加锁，同时去数据库查询数据，写入缓存，再返回给用户，这样后面的请求就可以从缓存中拿到数据了。&lt;/li&gt;
&lt;li&gt;将过期时间组合写在value中，通过异步的方式不断的刷新过期时间，防止此类现象。&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkKzFXwdvpY1HiaeiacNQdsPanPTDZF73DqwwnKaWr7a5R1IeXxlthEsxQ/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;缓存穿透&#34;&gt;缓存穿透&lt;/h3&gt;
&lt;p&gt;缓存穿透是指查询不存在缓存中的数据，每次请求都会打到DB，就像缓存不存在一样。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkxbQefhxQibFG1Wmk7jcYJNzia6R8XsQ5QETibvzGyrYibeWYHl9tnFO0Wg/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;针对这个问题，加一层布隆过滤器。布隆过滤器的原理是在你存入数据的时候，会通过散列函数将它映射为一个位数组中的K个点，同时把他们置为1。&lt;/p&gt;
&lt;p&gt;这样当用户再次来查询A，而A在布隆过滤器值为0，直接返回，就不会产生击穿请求打到DB了。&lt;/p&gt;
&lt;p&gt;显然，使用布隆过滤器之后会有一个问题就是误判，因为它本身是一个数组，可能会有多个值落到同一个位置，那么理论上来说只要我们的数组长度够长，误判的概率就会越低，这种问题就根据实际情况来就好了。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;15&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkpxLCYZLDQHHy52F7AlQTZGuFahFqMLtTqEjjgYo24e52oGuxLVk0BQ/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;缓存雪崩&#34;&gt;缓存雪崩&lt;/h3&gt;
&lt;p&gt;当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上，这样可能导致整个系统的崩溃，称为雪崩。雪崩和击穿、热key的问题不太一样的是，他是指大规模的缓存都过期失效了。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;16&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkTib3vhuAVcwaDHfQQj1PA1O4Bvy8xZVkEaxaS2hvxqN6LPzWoKq9hCg/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;针对雪崩几个解决方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;针对不同key设置不同的过期时间，避免同时过期&lt;/li&gt;
&lt;li&gt;限流，如果redis宕机，可以限流，避免同时刻大量请求打崩DB&lt;/li&gt;
&lt;li&gt;二级缓存，同热key的方案。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;稳定性&#34;&gt;稳定性&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;17&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUkwmXhPxzDG71Qc6UYXF5kkwUOehXezU8lZVvC8b9bicpSrymMbJ3niccYoknhboeMoA6AmxkxVRDdA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;熔断&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;比如营销服务挂了或者接口大量超时的异常情况，不能影响下单的主链路，涉及到积分的扣减一些操作可以在事后做补救。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;限流&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对突发如大促秒杀类的高并发，如果一些接口不做限流处理，可能直接就把服务打挂了，针对每个接口的压测性能的评估做出合适的限流尤为重要。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;降级&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;熔断之后实际上可以说就是降级的一种，以熔断的举例来说营销接口熔断之后降级方案就是短时间内不再调用营销的服务，等到营销恢复之后再调用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;预案&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一般来说，就算是有统一配置中心，在业务的高峰期也是不允许做出任何的变更的，但是通过配置合理的预案可以在紧急的时候做一些修改。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;核对&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;针对各种分布式系统产生的分布式事务一致性或者受到攻击导致的数据异常，非常需要核对平台来做最后的兜底的数据验证。比如下游支付系统和订单系统的金额做核对是否正确，如果收到中间人攻击落库的数据是否保证正确性。&lt;/p&gt;
&lt;hr&gt;
">千万流量</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/fenbushisuo/"" data-c="
          &lt;h2 id=&#34;分布式锁有哪些特点呢&#34;&gt;&lt;strong&gt;分布式锁有哪些特点呢？&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;互斥性：&lt;/strong&gt; 分布式锁要保证在多个客户端之间的互斥。&lt;/p&gt;
&lt;p&gt;**可重入性：**同一客户端的相同线程，允许重复多次加锁。&lt;/p&gt;
&lt;p&gt;**锁超时：**和本地锁一样支持锁超时，防止死锁。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;非阻塞：&lt;/strong&gt; 能与 ReentrantLock 一样支持 &lt;code&gt;trylock&lt;/code&gt;() 非阻塞方式获得锁。&lt;/p&gt;
&lt;p&gt;**支持公平锁和非公平锁：**公平锁尴尬，我也不想。是指按照请求加锁的顺序获得锁，非公平锁真好相反请求加锁是无序的。&lt;/p&gt;
&lt;h2 id=&#34;分布式锁家族实现者介绍&#34;&gt;&lt;strong&gt;分布式锁家族实现者介绍&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1、数据库&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;排它锁（悲观锁）：基于 &lt;code&gt;select * from table where xx=yy for update&lt;/code&gt; SQL语句来实现，有很多缺陷。&lt;/p&gt;
&lt;p&gt;乐观锁：表中添加一个时间戳或者版本号的字段来实现，&lt;code&gt;update xx set version = new... where id = y and version = old&lt;/code&gt; 当更新不成功，客户端重试，重新读取最新的版本号或时间戳，再次尝试更新，类似 &lt;code&gt;CAS&lt;/code&gt; 机制，推荐使用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、Redis&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点：&lt;strong&gt;CAP模型属于&lt;/strong&gt;AP&lt;/strong&gt; | 无一致性算法 | &lt;strong&gt;性能好&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;开发常用，如果你的项目中正好使用了redis，不想引入额外的分布式锁组件，推荐使用。&lt;/p&gt;
&lt;p&gt;业界也提供了多个现成好用的框架予以支持分布式锁，比如&lt;code&gt;Redisson&lt;/code&gt;、&lt;strong&gt;spring-integration-redis&lt;/strong&gt;、redis自带的**&lt;code&gt;setnx&lt;/code&gt;**命令，推荐直接使用。&lt;/p&gt;
&lt;p&gt;另外，可基于redis命令和redis &lt;code&gt;lua&lt;/code&gt;支持的原子特性，自行实现分布式锁。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、Zookeeper&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点：&lt;strong&gt;CAP模型属于&lt;/strong&gt;CP&lt;/strong&gt; | &lt;strong&gt;ZAB&lt;/strong&gt;一致性算法实现 | &lt;strong&gt;稳定性好&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;开发常用，如果你的项目中正好使用了&lt;code&gt;zk&lt;/code&gt;集群，推荐使用。&lt;/p&gt;
&lt;p&gt;业界有&lt;strong&gt;Apache Curator&lt;/strong&gt;框架提供了现成的分布式锁功能，现成的，推荐直接使用。&lt;/p&gt;
&lt;p&gt;另外，可基于Zookeeper自身的特性和原生Zookeeper API自行实现分布式锁。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4、其他&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Chubby&lt;/strong&gt;，Google开发的粗粒度分布锁的服务，但是并没有开源，开放出了论文和一些相关文档可以进一步了解，出门百度一下获取文档，不做过多讨论。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;Tair&lt;/code&gt;&lt;/strong&gt;，是阿里开源的一个分布式KV存储方案，没有用过，不做过多讨论。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;Etcd&lt;/code&gt;&lt;/strong&gt;，CAP模型中属于&lt;strong&gt;CP&lt;/strong&gt;，&lt;strong&gt;Raft&lt;/strong&gt;一致性算法实现，没有用过，不做过多讨论。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;Hazelcast&lt;/code&gt;&lt;/strong&gt;，是基于内存的数据网格开源项目，提供弹性可扩展的分布式内存计算，并且被公认是提高应用程序性能和扩展性最好的方案，听上去很牛逼，但是没用过，不做过多讨论。&lt;/p&gt;
&lt;p&gt;当然了，上面推荐的常用分布式锁Zookeeper和Redis，使用时还需要根据具体的业务场景，做下权衡，实现功能上都能达到你要的效果，原理上有很大的不同。&lt;/p&gt;
&lt;h2 id=&#34;分布式锁成员实现原理剖析&#34;&gt;分布式锁成员实现原理剖析&lt;/h2&gt;
&lt;h3 id=&#34;数据库悲观锁实现&#34;&gt;&lt;strong&gt;数据库悲观锁实现&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1、有一张资源锁表&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE TABLE `resource_lock` (
  `id` int(4) NOT NULL AUTO_INCREMENT COMMENT &#39;主键&#39;,
  `resource_name` varchar(64) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;锁定的资源名&#39;,
  `owner` varchar(64) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;锁拥有者&#39;,
  `desc` varchar(1024) NOT NULL DEFAULT &#39;备注信息&#39;,
  `update_time` timestamp NOT NULL DEFAULT &#39;&#39; COMMENT &#39;保存数据时间，自动生成&#39;,
  PRIMARY KEY (`id`),
  UNIQUE KEY `uidx_resource_name` (`resource_name `) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#39;锁定中的资源&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;resource_name 锁资源名称必须有唯一索引。&lt;/p&gt;
&lt;p&gt;必须添加&lt;code&gt;事务&lt;/code&gt;，查询和更新操作保证原子性，在一个事务里完成。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Transaction
public void lock(String name) {
   ResourceLock rlock = exeSql(&amp;quot;select * from resource_lock where resource_name = name for update&amp;quot;);
     if (rlock == null) {
           exeSql(&amp;quot;insert into resource_lock(reosurce_name,owner,count) values (name, &#39;ip&#39;,0)&amp;quot;);
     }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用 &lt;code&gt;for update&lt;/code&gt; 锁定的资源。如果执行成功，会立即返回，执行插入数据库，后续再执行一些其他业务逻辑，直到事务提交，执行结束；如果执行失败，就会一直阻塞着。&lt;/p&gt;
&lt;p&gt;虽然也能实现分布式锁的效果，但是会存在性能瓶颈。&lt;/p&gt;
&lt;h4 id=&#34;悲观锁优缺点&#34;&gt;&lt;strong&gt;悲观锁优缺点&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;**优点：**简单易用，好理解，保障数据强一致性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;缺点&lt;/strong&gt;一大堆，罗列一下：&lt;/p&gt;
&lt;p&gt;1）在 RR 事务级别，select 的 for update 操作是基于&lt;code&gt;间隙锁（gap lock）&lt;/code&gt; 实现的，是一种悲观锁的实现方式，所以存在&lt;code&gt;阻塞问题&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;2）高并发情况下，大量请求进来，会导致大部分请求进行排队，影响数据库稳定性，也会&lt;code&gt;耗费&lt;/code&gt;服务的CPU等&lt;code&gt;资源&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;当获得锁的客户端等待时间过长时，会提示：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[40001][1205] Lock wait timeout exceeded; try restarting transaction
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;高并发情况下，也会造成占用过多的应用线程，导致业务无法正常响应。&lt;/p&gt;
&lt;p&gt;3）如果优先获得锁的线程因为某些原因，一直没有释放掉锁，可能会导致&lt;code&gt;死锁&lt;/code&gt;的发生。&lt;/p&gt;
&lt;p&gt;4）锁的长时间不释放，会一直占用数据库连接，可能会将&lt;code&gt;数据库连接池撑爆&lt;/code&gt;，影响其他服务。&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;&lt;code&gt;MySql&lt;/code&gt;数据库会做查询优化，即便使用了索引，优化时发现全表扫效率更高，则可能会将行锁升级为表锁，此时可能就更悲剧了。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;6）不支持可重入特性，并且超时等待时间是全局的，不能随便改动。&lt;/p&gt;
&lt;h3 id=&#34;数据库乐观锁实现&#34;&gt;&lt;strong&gt;数据库乐观锁实现&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;为表添加一个字段，版本号或者时间戳都可以。通过版本号或者时间戳，来保证多线程同时间操作共享资源的有序性和正确性。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE TABLE `resource` (
  `id` int(4) NOT NULL AUTO_INCREMENT COMMENT &#39;主键&#39;,
  `resource_name` varchar(64) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;资源名&#39;,
  `share` varchar(64) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;状态&#39;,
    `version` int(4) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;版本号&#39;,
  `desc` varchar(1024) NOT NULL DEFAULT &#39;备注信息&#39;,
  `update_time` timestamp NOT NULL DEFAULT &#39;&#39; COMMENT &#39;保存数据时间，自动生成&#39;,
  PRIMARY KEY (`id`),
  UNIQUE KEY `uidx_resource_name` (`resource_name `) USING BTREE
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&#39;资源&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;Resrouce resource = exeSql(&amp;quot;select * from resource where resource_name = xxx&amp;quot;);
boolean succ = exeSql(&amp;quot;update resource set version= &#39;newVersion&#39; ... where resource_name = xxx and version = &#39;oldVersion&#39;&amp;quot;);

if (!succ) {
    // 发起重试
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;乐观锁优缺点&#34;&gt;&lt;strong&gt;乐观锁优缺点&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;优点：简单易用，保障数据一致性。&lt;/p&gt;
&lt;p&gt;缺点：&lt;/p&gt;
&lt;p&gt;1）加行锁的性能上有一定的开销&lt;/p&gt;
&lt;p&gt;2）高并发场景下，线程内的&lt;code&gt;自旋操作&lt;/code&gt; 会耗费一定的CPU资源。&lt;/p&gt;
&lt;p&gt;另外，比如在更新数据状态的一些场景下，不考虑幂等性的情况下，可以直接利用 &lt;code&gt;行锁&lt;/code&gt; 来保证数据一致性，示例：&lt;code&gt;update table set state = 1 where id = xxx and state = 0;&lt;/code&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_png/Ljib4So7yuWjZkibS3JeicL8Ae4h7A7qxrxlNiaiaZSYMq6ajrlIaQGv2utdtZ0BdDsOiaoibKQ2qndicPu97WU1SlmOGA/640?wx_fmt=png&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;基于redis分布式锁实现&#34;&gt;&lt;strong&gt;基于Redis分布式锁实现&lt;/strong&gt;&lt;/h3&gt;
&lt;h5 id=&#34;基于setnx实现分布式锁&#34;&gt;&lt;strong&gt;基于&lt;code&gt;SetNX&lt;/code&gt;实现分布式锁&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;基于Redis实现的分布式锁，性能上是最好的，实现上也是最复杂的。&lt;/p&gt;
&lt;p&gt;Redis 2.6.12 之前的版本中采用 &lt;code&gt;setnx&lt;/code&gt;+ expire 方式实现分布式锁，示例代码如下所示：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static boolean lock(Jedis jedis, String lockKey, String requestId, int expireTime) {
        Long result = jedis.setnx(lockKey, requestId);
        //设置锁
        if (result == 1) {
            //获取锁成功
            //若在这里程序突然崩溃，则无法设置过期时间，将发生死锁
            //通过过期时间删除锁
            jedis.expire(lockKey, expireTime);
            return true;
        }
        return false;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果 &lt;code&gt;lockKey&lt;/code&gt;存在，则返回失败，否则返回成功。设置成功之后，为了能在完成同步代码之后成功释放锁，方法中使用 expire() 方法给 &lt;code&gt;lockKey&lt;/code&gt;设置一个过期时间，确认 key 值删除，避免出现锁无法释放，导致下一个线程无法获取到锁，即死锁问题。&lt;/p&gt;
&lt;p&gt;但是 &lt;code&gt;setnx&lt;/code&gt;+ expire 两个命令放在程序里执行，不是原子操作，容易出事。&lt;/p&gt;
&lt;p&gt;如果程序设置锁之后，此时，在设置过期时间之前，程序崩溃了，如果 &lt;code&gt;lockKey&lt;/code&gt;没有设置上过期时间，将会出现&lt;code&gt;死锁问题&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;解决以上问题 ，有两个办法：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1）方式一：&lt;/strong&gt;&lt;code&gt;lua&lt;/code&gt;脚本&lt;/p&gt;
&lt;p&gt;我们也可以通过 Lua 脚本来实现锁的设置和过期时间的原子性，再通过 &lt;code&gt;jedis&lt;/code&gt;.eval() 方法运行该脚本：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 加锁脚本，KEYS[1] 要加锁的key，ARGV[1]是UUID随机值，ARGV[2]是过期时间
private static final String SCRIPT_LOCK = &amp;quot;if redis.call(&#39;setnx&#39;, KEYS[1], ARGV[1]) == 1 then redis.call(&#39;pexpire&#39;, KEYS[1], ARGV[2]) return 1 else return 0 end&amp;quot;;

// 解锁脚本，KEYS[1]要解锁的key，ARGV[1]是UUID随机值
private static final String SCRIPT_UNLOCK = &amp;quot;if redis.call(&#39;get&#39;, KEYS[1]) == ARGV[1] then return redis.call(&#39;del&#39;, KEYS[1]) else return 0 end&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;**2）方式二：**set原生命令&lt;/p&gt;
&lt;p&gt;在 Redis 2.6.12 版本后 SETNX 增加了过期时间参数：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SET lockKey anystring NX PX max-lock-time
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;程序实现代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public static boolean lock(Jedis jedis, String lockKey, String requestId, int expireTime) {
        String result = jedis.set(lockKey, requestId, &amp;quot;NX&amp;quot;, &amp;quot;PX&amp;quot;, expireTime);
        if (&amp;quot;OK&amp;quot;.equals(result)) {
            return true;
        }
        return false;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;虽然 SETNX 方式能够保证设置锁和过期时间的原子性，但是如果我们设置的过期时间比较短，而执行业务时间比较长，就会存在锁代码块失效的问题，失效后其他客户端也能获取到同样的锁，执行同样的业务，此时可能就会出现一些问题。&lt;/p&gt;
&lt;p&gt;我们需要将过期时间设置得足够长，来保证以上问题不会出现，但是设置多长时间合理，也需要依具体业务来权衡。如果其他客户端必须要阻塞拿到锁，需要设计循环超时等待机制等问题，感觉还挺麻烦的是吧。&lt;/p&gt;
&lt;h3 id=&#34;spring企业集成模式实现分布式锁&#34;&gt;&lt;strong&gt;Spring企业集成模式实现分布式锁&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;除了使用&lt;code&gt;Jedis&lt;/code&gt;客户端之外，完全可以直接用Spring官方提供的&lt;code&gt;企业集成模式&lt;/code&gt;框架，里面提供了很多分布式锁的方式，Spring提供了一个统一的分布式锁抽象，具体实现目前支持：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;Gemfire&lt;/code&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;code&gt;Jdbc&lt;/code&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Zookeeper&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Redis&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;早期，分布式锁的相关代码存在于Spring Cloud的子项目Spring Cloud Cluster中，后来被迁到Spring Integration中。&lt;/p&gt;
&lt;p&gt;Spring Integration 项目地址 ：https://github.com/spring-projects/spring-integration&lt;/p&gt;
&lt;p&gt;Spring强大之处在于此，对&lt;code&gt;Lock&lt;/code&gt;分布式锁做了全局抽象。&lt;/p&gt;
&lt;p&gt;抽象结构如下所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/7kMDE5kKm7zHfMD7O5jpa9P8PZGxYAIHhBtdK45Ef3IpwWPg8Cz8iaznrwVHlHgVEQw2zQNCXClsBQ0IzdQWjfw/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;LockRegistry&lt;/code&gt; 作为顶层抽象接口：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
 * Strategy for maintaining a registry of shared locks
 *
 * @author Oleg Zhurakousky
 * @author Gary Russell
 * @since 2.1.1
 */
@FunctionalInterface
public interface LockRegistry{

    /**
     * Obtains the lock associated with the parameter object.
     * @param lockKey The object with which the lock is associated.
     * @return The associated lock.
     */
    Lock obtain(Object lockKey);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;定义的 &lt;code&gt;obtain()&lt;/code&gt; 方法获得具体的 &lt;code&gt;Lock&lt;/code&gt; 实现类，分别在对应的 &lt;code&gt;XxxLockRegitry&lt;/code&gt;实现类来创建。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;RedisLockRegistry&lt;/code&gt;里obtain()方法实现类为 &lt;code&gt;RedisLock&lt;/code&gt;，&lt;code&gt;RedisLock&lt;/code&gt;内部，在Springboot2.x（Spring5）版本中是通过SET + PEXIPRE 命令结合&lt;code&gt;lua&lt;/code&gt;脚本实现的，在Springboot1.x（Spring4）版本中，是通过SETNX命令实现的。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ZookeeperLockRegistry&lt;/code&gt;里obtain()方法实现类为 &lt;code&gt;ZkLock&lt;/code&gt;，&lt;code&gt;ZkLock&lt;/code&gt;内部基于 Apache Curator 框架实现的。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;JdbcLockRegistry&lt;/code&gt;里obtain()方法实现类为 &lt;code&gt;JdbcLock&lt;/code&gt;，&lt;code&gt;JdbcLock&lt;/code&gt;内部基于一张&lt;code&gt;INT_LOCK&lt;/code&gt;数据库锁表实现的，通过&lt;code&gt;JdbcTemplate&lt;/code&gt;来操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;客户端使用方法：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private final String registryKey = &amp;quot;sb2&amp;quot;;
RedisLockRegistry lockRegistry = new RedisLockRegistry(getConnectionFactory(), this.registryKey);
Lock lock = lockRegistry.obtain(&amp;quot;foo&amp;quot;);
lock.lock();
try {
    // doSth...
}
finally {
    lock.unlock();
}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;下面以目前最新版本的实现，说明加锁和解锁的具体过程。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;RedisLockRegistry&lt;/code&gt;$&lt;code&gt;RedisLock&lt;/code&gt;类lock()加锁流程：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/7kMDE5kKm7zHfMD7O5jpa9P8PZGxYAIHrI5qvEaJicxQVQ5jyrLMJwtpdtukeOr1jlDoN6CBqrnETzz5ZlSQ26w/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;加锁步骤：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1）&lt;code&gt;lockKey&lt;/code&gt;为&lt;code&gt;registryKey:path&lt;/code&gt;，本例中为sb2:foo，客户端C1优先申请加锁。&lt;/p&gt;
&lt;p&gt;2）执行&lt;code&gt;lua&lt;/code&gt;脚本，get &lt;code&gt;lockKey&lt;/code&gt;不存在，则set &lt;code&gt;lockKey&lt;/code&gt;成功，值为&lt;code&gt;clientid&lt;/code&gt;（UUID），过期时间默认60秒。&lt;/p&gt;
&lt;p&gt;3）客户端C1同一个线程重复加锁，&lt;code&gt;pexpire ``lockKey&lt;/code&gt;，重置过期时间为60秒。&lt;/p&gt;
&lt;p&gt;4）客户端C2申请加锁，执行&lt;code&gt;lua&lt;/code&gt;脚本，get &lt;code&gt;lockKey&lt;/code&gt;已存在，并且跟已加锁的&lt;code&gt;clientid&lt;/code&gt;不同，加锁失败&lt;/p&gt;
&lt;p&gt;5）客户端C2挂起，每隔100ms再次尝试加锁。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;RedisLock&lt;/code&gt;#lock()加锁源码实现：&lt;/strong&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/7kMDE5kKm7zHfMD7O5jpa9P8PZGxYAIHrIcVzxrgicjB041TlnNNTK3AxfWOWTvws1akwMlaDzX7oibgsk8LIUOQ/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;大家可以对照上面的流程图配合你理解。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Override
public void lock() {
    this.localLock.lock();
    while (true) {
        try {
            while (!obtainLock()) {
                Thread.sleep(100); //NOSONAR
            }
            break;
        }
        catch (InterruptedException e) {
            /*
             * This method must be uninterruptible so catch and ignore
             * interrupts and only break out of the while loop when
             * we get the lock.
             */
        }
        catch (Exception e) {
            this.localLock.unlock();
            rethrowAsLockException(e);
        }
    }
}

// 基于Spring封装的RedisTemplate来操作的
private boolean obtainLock() {
    Boolean success =
            RedisLockRegistry.this.redisTemplate.execute(RedisLockRegistry.this.obtainLockScript,
                    Collections.singletonList(this.lockKey), RedisLockRegistry.this.clientId,
                    String.valueOf(RedisLockRegistry.this.expireAfter));

    boolean result = Boolean.TRUE.equals(success);

    if (result) {
        this.lockedAt = System.currentTimeMillis();
    }
    return result;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;执行的&lt;code&gt;lua&lt;/code&gt;脚本代码：&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;private static final String OBTAIN_LOCK_SCRIPT =
    &amp;quot;local lockClientId = redis.call(&#39;GET&#39;, KEYS[1])\n&amp;quot; +
            &amp;quot;if lockClientId == ARGV[1] then\n&amp;quot; +
            &amp;quot;  redis.call(&#39;PEXPIRE&#39;, KEYS[1], ARGV[2])\n&amp;quot; +
            &amp;quot;  return true\n&amp;quot; +
            &amp;quot;elseif not lockClientId then\n&amp;quot; +
            &amp;quot;  redis.call(&#39;SET&#39;, KEYS[1], ARGV[1], &#39;PX&#39;, ARGV[2])\n&amp;quot; +
            &amp;quot;  return true\n&amp;quot; +
            &amp;quot;end\n&amp;quot; +
            &amp;quot;return false&amp;quot;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;RedisLockRegistry&lt;/code&gt;$&lt;code&gt;RedisLock&lt;/code&gt;类&lt;strong&gt;unlock()解锁流程：&lt;/strong&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/7kMDE5kKm7zHfMD7O5jpa9P8PZGxYAIHiaCS5BZfnpurITk8EHibV92mAmsyYBic4TsZz8SQwG6N7E4iblicoVztdWg/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;**RedisLock&lt;/code&gt;#unlock()源码实现：**&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@Override
public void unlock() {
    if (!this.localLock.isHeldByCurrentThread()) {
        throw new IllegalStateException(&amp;quot;You do not own lock at &amp;quot; + this.lockKey);
    }
    if (this.localLock.getHoldCount() &amp;gt; 1) {
        this.localLock.unlock();
        return;
    }
    try {
        if (!isAcquiredInThisProcess()) {
            throw new IllegalStateException(&amp;quot;Lock was released in the store due to expiration. &amp;quot; +
                    &amp;quot;The integrity of data protected by this lock may have been compromised.&amp;quot;);
        }

        if (Thread.currentThread().isInterrupted()) {
            RedisLockRegistry.this.executor.execute(this::removeLockKey);
        }
        else {
            removeLockKey();
        }

        if (LOGGER.isDebugEnabled()) {
            LOGGER.debug(&amp;quot;Released lock; &amp;quot; + this);
        }
    }
    catch (Exception e) {
        ReflectionUtils.rethrowRuntimeException(e);
    }
    finally {
        this.localLock.unlock();
    }
}

// 删除缓存Key
private void removeLockKey() {
    if (this.unlinkAvailable) {
        try {
            RedisLockRegistry.this.redisTemplate.unlink(this.lockKey);
        }
        catch (Exception ex) {
            LOGGER.warn(&amp;quot;The UNLINK command has failed (not supported on the Redis server?); &amp;quot; +
                    &amp;quot;falling back to the regular DELETE command&amp;quot;, ex);
            this.unlinkAvailable = false;
            RedisLockRegistry.this.redisTemplate.delete(this.lockKey);
        }
    }
    else {
        RedisLockRegistry.this.redisTemplate.delete(this.lockKey);
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;unlock()解锁方法里发现，并不是直接就调用Redis的DEL命令删除Key，这也是在Springboot2.x版本中做的一个优化，Redis4.0版本以上提供了UNLINK命令。&lt;/p&gt;
&lt;p&gt;换句话说，最新版本分布式锁实现，要求是Redis4.0以上版本才能使用。&lt;/p&gt;
&lt;p&gt;看下Redis官网给出的一段解释：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;This command is very similar to DEL: it removes the specified keys.
Just like DEL a key is ignored if it does not exist. However the
command performs the actual memory reclaiming in a different thread,
so it is not blocking, while DEL is. This is where the command name
comes from: the command just unlinks the keys from the keyspace. The
actual removal will happen later asynchronously.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;DEL始终在阻止模式下释放值部分。但如果该值太大，如对于大型LIST或HASH的分配太多，它会长时间阻止Redis，为了解决这个问题，Redis实现了UNLINK命令，即「非阻塞」删除。如果值很小，则DEL一般与UNLINK效率上差不多。&lt;/p&gt;
&lt;p&gt;本质上，这种加锁方式还是使用的SETNX实现的，而且Spring只是做了一层薄薄的封装，支持可重入加锁，超时等待，可中断加锁。&lt;/p&gt;
&lt;p&gt;但是有个问题，锁的过期时间不能灵活设置，客户端初始化时，创建&lt;code&gt;RedisLockRegistry&lt;/code&gt;时允许设置，但是是全局的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/**
     * Constructs a lock registry with the supplied lock expiration.
     * @param connectionFactory The connection factory.
     * @param registryKey The key prefix for locks.
     * @param expireAfter The expiration in milliseconds.
     */
public RedisLockRegistry(RedisConnectionFactory connectionFactory, String registryKey, long expireAfter) {
    Assert.notNull(connectionFactory, &amp;quot;&#39;connectionFactory&#39; cannot be null&amp;quot;);
    Assert.notNull(registryKey, &amp;quot;&#39;registryKey&#39; cannot be null&amp;quot;);
    this.redisTemplate = new StringRedisTemplate(connectionFactory);
    this.obtainLockScript = new DefaultRedisScript&amp;lt;&amp;gt;(OBTAIN_LOCK_SCRIPT, Boolean.class);
    this.registryKey = registryKey;
    this.expireAfter = expireAfter;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;expireAfter&lt;/code&gt;参数是全局的，同样会存在问题，可能是锁过期时间到了，但是业务还没有处理完，这把锁又被另外的客户端获得，进而会导致一些其他问题。&lt;/p&gt;
&lt;p&gt;经过对源码的分析，其实我们也可以借鉴&lt;code&gt;RedisLockRegistry&lt;/code&gt;实现的基础上，自行封装实现分布式锁，比如：&lt;/p&gt;
&lt;p&gt;1、允许支持按照不同的Key设置过期时间，而不是全局的？&lt;/p&gt;
&lt;p&gt;2、当业务没有处理完成，当前客户端启动个定时任务探测，自动延长过期时间？&lt;/p&gt;
&lt;p&gt;自己实现？嫌麻烦？别急别急！业界已经有现成的实现方案了，那就是 &lt;code&gt;Redisson&lt;/code&gt; 框架，在后文&lt;code&gt;Redisson&lt;/code&gt;部分进一步分析。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_png/Ljib4So7yuWjZkibS3JeicL8Ae4h7A7qxrxlNiaiaZSYMq6ajrlIaQGv2utdtZ0BdDsOiaoibKQ2qndicPu97WU1SlmOGA/640?wx_fmt=png&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;站在redis集群角度看问题&#34;&gt;&lt;strong&gt;站在Redis集群角度看问题&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;从Redis&lt;code&gt;主从&lt;/code&gt;架构上来考虑，依然存在问题。因为 Redis 集群数据同步到各个节点时是异步的，如果在 Master 节点获取到锁后，在没有同步到其它节点时，Master 节点崩溃了，此时新的 Master 节点依然可以获取锁，所以多个应用服务可以同时获取到锁。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;RedLock&lt;/code&gt;算法实现过程分析：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;假设Redis部署模式是Redis Cluster，总共有5个master节点，通过以下步骤获取一把锁：&lt;/p&gt;
&lt;p&gt;1）获取当前时间戳，单位是毫秒&lt;/p&gt;
&lt;p&gt;2）轮流尝试在每个master节点上创建锁，过期时间设置较短，一般就几十毫秒&lt;/p&gt;
&lt;p&gt;3）尝试在大多数节点上建立一个锁，比如5个节点就要求是3个节点（n / 2 +1）&lt;/p&gt;
&lt;p&gt;4）客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了&lt;/p&gt;
&lt;p&gt;5）要是锁建立失败了，那么就依次删除这个锁&lt;/p&gt;
&lt;p&gt;6）只要有客户端创建成功了分布式锁，其他客户端就得不断轮询去尝试获取锁&lt;/p&gt;
&lt;p&gt;以上过程前文也提到了，进一步分析&lt;code&gt;RedLock&lt;/code&gt;算法的实现依然可能存在问题，也是&lt;code&gt;Martain&lt;/code&gt;和&lt;code&gt;Antirez&lt;/code&gt;两位大佬争论的焦点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;问题1：节点崩溃重启&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;节点崩溃重启，会出现多个客户端持有锁。&lt;/p&gt;
&lt;p&gt;假设一共有5个Redis节点：A、B、 C、 D、 E。设想发生了如下的事件序列：&lt;/p&gt;
&lt;p&gt;1）客户端C1成功对Redis集群中A、B、C三个节点加锁成功（但D和E没有锁住）。&lt;/p&gt;
&lt;p&gt;2）节点C &lt;code&gt;Duang&lt;/code&gt;的一下，崩溃重启了，但客户端C1在节点C加锁未持久化完，丢了。&lt;/p&gt;
&lt;p&gt;3）节点C重启后，客户端C2成功对Redis集群中C、D、 E尝试加锁成功了。&lt;/p&gt;
&lt;p&gt;这样，悲剧了吧！客户端C1和C2同时获得了同一把分布式锁。&lt;/p&gt;
&lt;p&gt;为了应对节点重启引发的锁失效问题，&lt;code&gt;Antirez&lt;/code&gt;提出了&lt;code&gt;延迟重启&lt;/code&gt;的概念，即一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，等待的时间大于锁的有效时间。&lt;/p&gt;
&lt;p&gt;采用这种方式，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。&lt;/p&gt;
&lt;p&gt;这其实也是通过人为补偿措施，降低不一致发生的概率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;问题2：时钟跳跃&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;假设一共有5个Redis节点：A、B、 C、 D、 E。设想发生了如下的事件序列：&lt;/p&gt;
&lt;p&gt;1）客户端C1成功对Redis集群中A、B、 C三个节点成功加锁。但因网络问题，与D和E通信失败。&lt;/p&gt;
&lt;p&gt;2）节点C上的时钟发生了向前跳跃，导致它上面维护的锁快速过期。&lt;/p&gt;
&lt;p&gt;3）客户端C2对Redis集群中节点C、 D、 E成功加了同一把锁。&lt;/p&gt;
&lt;p&gt;此时，又悲剧了吧！客户端C1和C2同时都持有着同一把分布式锁。&lt;/p&gt;
&lt;p&gt;为了应对&lt;code&gt;时钟跳跃&lt;/code&gt;引发的锁失效问题，&lt;code&gt;Antirez&lt;/code&gt;提出了应该禁止人为修改系统时间，使用一个不会进行「跳跃式」调整系统时钟的&lt;code&gt;ntpd&lt;/code&gt;程序。这也是通过人为补偿措施，降低不一致发生的概率。&lt;/p&gt;
&lt;p&gt;但是...，&lt;code&gt;RedLock&lt;/code&gt;算法并没有解决，操作共享资源超时，导致锁失效的问题。&lt;/p&gt;
&lt;p&gt;存在这么大争议的算法实现，还是不推荐使用的。&lt;/p&gt;
&lt;p&gt;一般情况下，本文锁介绍的框架提供的分布式锁实现已经能满足大部分需求了。&lt;/p&gt;
&lt;h5 id=&#34;小结&#34;&gt;&lt;strong&gt;小结：&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;上述，我们对spring-integration-redis实现原理进行了深入分析，还对&lt;code&gt;RedLock&lt;/code&gt;存在争议的问题做了分析。&lt;/p&gt;
&lt;p&gt;除此以外，我们还提到了spring-integration中集成了 &lt;code&gt;Jdbc&lt;/code&gt;、Zookeeper、&lt;code&gt;Gemfire&lt;/code&gt;实现的分布式锁，&lt;code&gt;Gemfire&lt;/code&gt;和&lt;code&gt;Jdbc&lt;/code&gt;大家感兴趣可以自行去看下。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;为啥还要提供个&lt;code&gt;Jdbc&lt;/code&gt;分布式锁实现？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;猜测一下，当你的应用并发量也不高，比如是个后台业务，而且还没依赖Zookeeper、Redis等额外的组件，只依赖了数据库。&lt;/p&gt;
&lt;p&gt;但你还想用分布式锁搞点事儿，那好办，直接用spring-integration-&lt;code&gt;jdbc&lt;/code&gt;即可，内部也是基于数据库行锁来实现的，需要你提前建好&lt;code&gt;锁表&lt;/code&gt;，创建表的SQL长这样：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE TABLE INT_LOCK  (
    LOCK_KEY CHAR(36) NOT NULL,
    REGION VARCHAR(100) NOT NULL,
    CLIENT_ID CHAR(36),
    CREATED_DATE DATETIME(6) NOT NULL,
    constraint INT_LOCK_PK primary key (LOCK_KEY, REGION)
) ENGINE=InnoDB;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;具体实现逻辑也非常简单，大家自己去看吧。&lt;/p&gt;
&lt;p&gt;集成的Zookeeper实现的分布式锁，因为是基于Curator框架实现的，不在本节展开，后续会有分析。&lt;/p&gt;
&lt;h3 id=&#34;基于redisson实现分布式锁&#34;&gt;&lt;strong&gt;基于&lt;code&gt;Redisson&lt;/code&gt;实现分布式锁&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Redisson&lt;/code&gt;是 Redis 的 Java 实现的客户端，其 API 提供了比较全面的 Redis 命令的支持。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Jedis&lt;/code&gt;简单使用阻塞的 I/O 和 Redis 交互，&lt;code&gt;Redission&lt;/code&gt; 通过 Netty 支持非阻塞 I/O。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Redisson&lt;/code&gt; 封装了锁的实现，让我们像操作我们的本地 Lock一样来使用，除此之外还有对集合、对象、常用缓存框架等做了友好的封装，易于使用。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Redisson&lt;/code&gt;分布式锁&lt;code&gt;Github&lt;/code&gt;：&lt;/p&gt;
&lt;p&gt;https://github.com/redisson/redisson/wiki/8.-Distributed-locks-and-synchronizers&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Redisson&lt;/code&gt;可以便捷的支持多种Redis部署架构：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Redis 单机&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Master-Slave + Sentinel 哨兵&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Redis-Cluster集群&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// Master-Slave配置
Config config = new Config();
MasterSlaveServersConfig serverConfig = config.useMasterSlaveServers()
            .setMasterAddress(&amp;quot;&amp;quot;)
            .addSlaveAddress(&amp;quot;&amp;quot;)
            .setReadMode(ReadMode.SLAVE)
            .setMasterConnectionPoolSize(maxActiveSize)
            .setMasterConnectionMinimumIdleSize(maxIdleSize)
            .setSlaveConnectionPoolSize(maxActiveSize)
            .setSlaveConnectionMinimumIdleSize(maxIdleSize)
            .setConnectTimeout(CONNECTION_TIMEOUT_MS) // 默认10秒
            .setTimeout(socketTimeout)
            ;

RedissonClient redisson = Redisson.create(config);
RLock lock = redisson.getLock(&amp;quot;myLock&amp;quot;);

// 获得锁
lock.lock();

// 等待10秒未获得锁，自动释放
lock.lock(10, TimeUnit.SECONDS);

// 等待锁定时间不超过100秒
// 10秒后自动释放锁
boolean res = lock.tryLock(100, 10, TimeUnit.SECONDS);
if (res) {
   try {
     ...
   } finally {
       lock.unlock();
   }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用上非常简单，&lt;code&gt;RedissonClient&lt;/code&gt;客户端提供了众多的接口实现，支持可重入锁、公平锁、读写锁、锁超时、&lt;code&gt;RedLock&lt;/code&gt;等都提供了完整实现。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191222200451065.png&#34; alt=&#34;image-20191222200451065&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;lock加锁流程&#34;&gt;&lt;strong&gt;lock()加锁流程：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;为了兼容老的版本，&lt;code&gt;Redisson&lt;/code&gt;里都是通过&lt;code&gt;lua&lt;/code&gt;脚本执行Redis命令的，同时保证了原子性操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;加锁执行的&lt;code&gt;lua&lt;/code&gt;脚本：&lt;/strong&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_png/7kMDE5kKm7zHfMD7O5jpa9P8PZGxYAIHibfZCzUSZCqJ3qlNNCB4qIkYxMJXGJHiaPiaVVu7SaSZtVicd8MXCRZL7Q/640?wx_fmt=png&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;Redis里的Hash散列结构存储的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参数解释：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;**KEY[1]：**要加锁的Key名称，比如示例中的&lt;code&gt;myLock&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;**ARGV[1]：**针对加锁的Key设置的过期时间&lt;/p&gt;
&lt;p&gt;**ARGV[2]：**Hash结构中Key名称，&lt;code&gt;lockName&lt;/code&gt;为UUID:线程ID&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;protected String getLockName(long threadId) {
        return id + &amp;quot;:&amp;quot; + threadId;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;1）客户端C1申请加锁，key为&lt;code&gt;myLock&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;2）如果key不存在，通过&lt;code&gt;hset&lt;/code&gt;设置值，通过&lt;code&gt;pexpire&lt;/code&gt;设置过期时间。同时开启Watchdog任务，默认每隔10秒中判断一下，如果key还在，重置过期时间到30秒。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640-1583055169793.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;开启&lt;code&gt;WatchDog&lt;/code&gt;源码：&lt;/strong&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/7kMDE5kKm7zHfMD7O5jpa9P8PZGxYAIHNaAbIiaU5JkZz7cc2gJibdR8kfORPsSN3D7ypuo2rACVPH4Nq53Y38CA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/7kMDE5kKm7zHfMD7O5jpa9P8PZGxYAIHj2XPHcxmILnANjEianHvU3UfqDo0HnZn7iagVRbUDH853MsqCppl4ngw/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;3）客户端C1相同线程再次加锁，如果key存在，判断Redis里Hash中的&lt;code&gt;lockName&lt;/code&gt;跟当前线程&lt;code&gt;lockName&lt;/code&gt;相同，则将Hash中的&lt;code&gt;lockName&lt;/code&gt;的值加1，代表&lt;strong&gt;支持可重入加锁&lt;/strong&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;incrby myLock  8743c9c0-0795-4907-87fd-6c71a6b4586:1 1
&lt;/code&gt;&lt;/pre&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191222201004906.png&#34; alt=&#34;image-20191222201004906&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;4）客户单C2申请加锁，如果key存在，判断Redis里Hash中的&lt;code&gt;lockName&lt;/code&gt;跟当前线程&lt;code&gt;lockName&lt;/code&gt;不同，则执行&lt;code&gt;pttl&lt;/code&gt;返回剩余过期时间。&lt;/p&gt;
&lt;p&gt;5）客户端C2线程内不断尝试&lt;code&gt;pttl&lt;/code&gt;时间，此处是基于Semaphore信号量实现的，有许可立即返回，否则等到&lt;code&gt;pttl&lt;/code&gt;时间还是没有得到许可，继续重试。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;重试源码：&lt;/strong&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/7kMDE5kKm7zHfMD7O5jpa9P8PZGxYAIHib0lz75huCGMyel4m4RRbWlOVFbq8BqykPdVAP7rcNBUyZnBfjL77Cw/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;Redisson&lt;/code&gt;这样的实现就解决了，当业务处理时间比过期时间长的问题。&lt;/p&gt;
&lt;p&gt;同时，&lt;code&gt;Redisson&lt;/code&gt;还自己扩展 Lock 接口，叫做 &lt;code&gt;RLock&lt;/code&gt; 接口，扩展了锁接口，比如给 Key 设定过期时间，非阻塞+超时时间等。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;void lock(long leaseTime, TimeUnit unit);

boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;redisson&lt;/code&gt;里的&lt;code&gt;WatchDog&lt;/code&gt;（看门狗）逻辑保证了没有死锁发生。&lt;/p&gt;
&lt;p&gt;如果客户端宕机了，&lt;code&gt;WatchDog&lt;/code&gt;任务也就跟着停掉了。此时，不会对Key重置过期时间了，等挂掉的客户端持有的Key过期时间到了，锁自动释放，其他客户端尝试获得这把锁。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;If Redisson instance which acquired lock crashes then such lock could hang forever in acquired state. To avoid this Redisson maintains lock watchdog, it prolongs lock expiration while lock holder Redisson instance is alive. By default lock watchdog timeout is 30 seconds and can be changed through Config.lockWatchdogTimeout setting.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;unlock()解锁过程也是同样的，通过&lt;code&gt;lua&lt;/code&gt;脚本执行一大坨指令的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解锁&lt;code&gt;lua&lt;/code&gt;脚本：&lt;/strong&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/7kMDE5kKm7zHfMD7O5jpa9P8PZGxYAIHGicwKAzXWcNs11eYzyKN7IuZ2ibr8ErFm4lGkxP2MPot810ev9NbeLRw/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;上述redis分布式锁的缺点&#34;&gt;上述Redis分布式锁的缺点&lt;/h4&gt;
&lt;p&gt;其实上面那种方案最大的问题，就是如果你对某个redis master实例，写入了&lt;code&gt;myLock&lt;/code&gt;这种锁key的value，此时会&lt;strong&gt;异步&lt;/strong&gt;复制给对应的master slave实例。&lt;/p&gt;
&lt;p&gt;但是&lt;strong&gt;这个过程中&lt;/strong&gt;一旦发生redis master宕机，主备切换，redis slave变为了redis master。新的master上并没有客户端1的锁记录；&lt;/p&gt;
&lt;p&gt;接着就会导致，客户端2来尝试加锁的时候，在新的redis master上完成了加锁，而客户端1也以为自己成功加了锁。&lt;/p&gt;
&lt;p&gt;此时就会导致多个客户端对一个分布式锁完成了加锁。这时系统在业务语义上一定会出现问题，&lt;strong&gt;导致各种脏数据的产生&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;所以这个就是redis cluster，或者是redis master-slave架构的&lt;strong&gt;主从异步复制&lt;/strong&gt;导致的redis分布式锁的最大缺陷：在redis master实例宕机的时候，可能导致多个客户端同时完成加锁。&lt;/p&gt;
&lt;h3 id=&#34;基于zookeeper实现分布式锁&#34;&gt;&lt;strong&gt;基于Zookeeper实现分布式锁&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Zookeeper 是一种提供「分布式服务协调」的中心化服务，是以 &lt;code&gt;Paxos&lt;/code&gt;算法为基础实现的。Zookeeper数据节点和文件目录类似，同时具有Watch机制，基于这两个特性，得以实现分布式锁功能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据节点：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;顺序临时节点：Zookeeper 提供一个多层级的节点命名空间（节点称为 &lt;strong&gt;&lt;code&gt;Znode&lt;/code&gt;&lt;/strong&gt;），每个节点都用一个以斜杠（/）分隔的路径来表示，而且每个节点都有父节点（根节点除外），非常类似于文件系统。&lt;/p&gt;
&lt;p&gt;节点类型可以分为持久节点（&lt;strong&gt;PERSISTENT&lt;/strong&gt; ）、临时节点（&lt;strong&gt;EPHEMERAL&lt;/strong&gt;），每个节点还能被标记为有序性（&lt;strong&gt;SEQUENTIAL&lt;/strong&gt;），一旦节点被标记为有序性，那么整个节点就具有顺序自增的特点。&lt;/p&gt;
&lt;p&gt;一般我们可以组合这几类节点来创建我们所需要的节点，例如，创建一个持久节点作为父节点，在父节点下面创建临时节点，并标记该临时节点为有序性。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Watch 机制：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Zookeeper 还提供了另外一个重要的特性，Watcher（事件监听器）。&lt;/p&gt;
&lt;p&gt;ZooKeeper 允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知给用户。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;图解Zookeeper实现分布式锁：&lt;/strong&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;15&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/7kMDE5kKm7zHfMD7O5jpa9P8PZGxYAIHTFOtBQDwxgiaMLWakTzD4fsLDL2TeudVun416Bltib8MCSW7LNdeTuRQ/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;首先，我们需要建立一个父节点，节点类型为持久节点（&lt;strong&gt;PERSISTENT&lt;/strong&gt;）如图中的 &lt;code&gt;/locks/lock_name1&lt;/code&gt; 节点 ，每当需要访问共享资源时，就会在父节点下建立相应的顺序子节点，节点类型为临时节点（&lt;strong&gt;EPHEMERAL&lt;/strong&gt;），且标记为有序性（&lt;strong&gt;SEQUENTIAL&lt;/strong&gt;），并且以临时节点名称 + 父节点名称 + 顺序号组成特定的名字，如图中的 &lt;code&gt;/0000000001 /0000000002 /0000000003&lt;/code&gt; 作为临时有序节点。&lt;/p&gt;
&lt;p&gt;在建立子节点后，对父节点下面的所有以临时节点名称 name 开头的子节点进行排序，判断刚刚建立的子节点顺序号是否是最小的节点，如果是最小节点，则获得锁。&lt;/p&gt;
&lt;p&gt;如果不是最小节点，则阻塞等待锁，并且获得该节点的上一顺序节点，为其注册监听事件，等待节点对应的操作获得锁。当调用完共享资源后，删除该节点，关闭 &lt;code&gt;zk&lt;/code&gt;，进而可以触发监听事件，释放该锁。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;// 加锁
InterProcessMutex lock = new InterProcessMutex(client, lockPath);
if ( lock.acquire(maxWait, waitUnit) )
{
    try 
    {
        // do some work inside of the critical section here
    }
    finally
    {
        lock.release();
    }
}

public void acquire() throws Exception
    {
            if ( !internalLock(-1, null) )
            {
                    throw new IOException(&amp;quot;Lost connection while trying to acquire lock: &amp;quot; + basePath);
            }
    }

private boolean internalLock(long time, TimeUnit unit) throws Exception
    {
            /*
                 Note on concurrency: a given lockData instance
                 can be only acted on by a single thread so locking isn&#39;t necessary
            */

            Thread currentThread = Thread.currentThread();

            LockData lockData = threadData.get(currentThread);
            if ( lockData != null )
            {
                    // re-entering
                    lockData.lockCount.incrementAndGet();
                    return true;
            }

            String lockPath = internals.attemptLock(time, unit, getLockNodeBytes());
            if ( lockPath != null )
            {
                    LockData newLockData = new LockData(currentThread, lockPath);
                    threadData.put(currentThread, newLockData);
                    return true;
            }

            return false;
    }
// ... 其他代码略
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;InterProcessMutex&lt;/code&gt;是 Curator 实现的可重入锁，可重入锁源码过程分析：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;加锁流程：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1）可重入锁记录在 &lt;code&gt;ConcurrentMap threadData&lt;/code&gt;这个 Map 里面。&lt;/p&gt;
&lt;p&gt;2）如果 &lt;code&gt;threadData&lt;/code&gt;.get(&lt;code&gt;currentThread&lt;/code&gt;) 是有值的那么就证明是可重入锁，然后记录就会加 1。&lt;/p&gt;
&lt;p&gt;3）资源目录下创建一个节点：比如这里创建一个 /0000000002 这个节点，这个节点需要设置为 EPHEMERAL_SEQUENTIAL 也就是临时节点并且有序。&lt;/p&gt;
&lt;p&gt;4）获取当前目录下所有子节点，判断自己的节点是否是最小的节点。&lt;/p&gt;
&lt;p&gt;5）如果是最小的节点，则获取到锁。如果不是最小的节点，则证明前面已经有人获取到锁了，那么需要获取自己节点的前一个节点。&lt;/p&gt;
&lt;p&gt;6）节点 /0000000002 的前一个节点是 /0000000001，我们获取到这个节点之后，再上面注册 Watcher，Watcher 调用的是 &lt;code&gt;object&lt;/code&gt;.notifyAll()，用来解除阻塞。&lt;/p&gt;
&lt;p&gt;7）&lt;code&gt;object&lt;/code&gt;.wait(timeout) 或 &lt;code&gt;object&lt;/code&gt;.wait() 进行阻塞等待&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;解锁流程：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1）如果可重入锁次数减1后，加锁次数不为 0 直接返回，减1后加锁次数为0，继续。&lt;/p&gt;
&lt;p&gt;2）删除当前节点。&lt;/p&gt;
&lt;p&gt;3）删除 &lt;code&gt;threadDataMap&lt;/code&gt;里面的可重入锁的数据。&lt;/p&gt;
&lt;h2 id=&#34;最后的总结&#34;&gt;最后的总结&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Redisson&lt;/code&gt;和Curator都是自己定义的分布式锁接口实现的，易于扩展。&lt;/p&gt;
&lt;p&gt;Curator里自定义了&lt;code&gt;InterProcessLock&lt;/code&gt;接口，&lt;code&gt;Redisson&lt;/code&gt;里自定义&lt;code&gt;RLock&lt;/code&gt;接口，继承了 java.&lt;code&gt;util&lt;/code&gt;.&lt;code&gt;concurrent&lt;/code&gt;.&lt;code&gt;locks&lt;/code&gt;.&lt;code&gt;Lock&lt;/code&gt;接口。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对于Redis实现的分布式锁：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;大部分需求下，不会遇到「极端复杂场景」，基于Redis实现分布式锁很常用，性能也高。&lt;/p&gt;
&lt;p&gt;它获取锁的方式简单粗暴，获取不到锁直接不断尝试获取锁，比较消耗性能。&lt;/p&gt;
&lt;p&gt;另外来说的话，redis的设计定位决定了它的数据并不是强一致性的，没有一致性算法，在某些极端情况下，可能会出现问题，锁的模型不够健壮。&lt;/p&gt;
&lt;p&gt;即便有了&lt;code&gt;Redlock&lt;/code&gt;算法的实现，但存在争议，某些复杂场景下，也无法保证其实现完全没有问题，并且也是比较消耗性能的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;对于Zookeeper实现的分布式锁:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Zookeeper优点：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;天生设计定位是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。&lt;/p&gt;
&lt;p&gt;如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。&lt;/p&gt;
&lt;p&gt;如果客户端宕机，也没关系，临时节点会自动删除，触发监听器通知下一个节点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Zookeeper缺点：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;若有大量的客户端频繁的申请加锁、释放锁，对于ZK集群的压力会比较大。&lt;/p&gt;
&lt;p&gt;另外，本文对Spring-integration集成Redis实现的分布式锁做了详细剖析，可以直接使用，更推荐直接使用 &lt;code&gt;Redisson&lt;/code&gt;，实现了非常多的分布式锁各种机制，有单独开放&lt;code&gt;Springboot&lt;/code&gt;集成的jar包，使用上也是非常方便的。&lt;/p&gt;
&lt;h4 id=&#34;分布式锁高并发优化&#34;&gt;分布式锁高并发优化&lt;/h4&gt;
&lt;p&gt;当大量线程对同一个字段进行修改时，会基于分布式锁串行化处理，导致没法高并发&lt;/p&gt;
&lt;p&gt;可以使用&lt;strong&gt;分段加锁&lt;/strong&gt;的思路来优化&lt;/p&gt;
&lt;p&gt;把数据分成很多个段，每个段是一个单独的锁，所以多个线程多来并发修改数据的时候，可以并发的修改不同段的数据。不至于说同一时间只能有一个线程独占修改。如果失败则释放锁，自动迁移到下一个分段再次尝试获锁后再处理。&lt;/p&gt;
">分布式锁</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/fenbushixitongyuanli/"" data-c="
          &lt;h1 id=&#34;1-概念&#34;&gt;1 概念&lt;/h1&gt;
&lt;h2 id=&#34;11-模型&#34;&gt;1.1 模型&lt;/h2&gt;
&lt;h3 id=&#34;节点&#34;&gt;节点&lt;/h3&gt;
&lt;p&gt;在具体的工程项目中，一个节点往往是一个操作系统上的进程。在本文的模型中，认为节点是一个完整的、不可分的整体，如果某个程序进程实际上由若干相对独立部分构成，则在模型中可以将一个进程划分为多个节点。&lt;/p&gt;
&lt;h3 id=&#34;异常&#34;&gt;异常&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;机器宕机&lt;/strong&gt;：机器宕机是最常见的异常之一。在大型集群中每日宕机发生的概率为千分之一左右，在实践中，一台宕机的机器恢复的时间通常认为是24 小时，一般需要人工介入重启机器。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;网络异常&lt;/strong&gt;：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;消息丢失，两片节点之间彼此完全无法通信，即出现了“网络分化”；&lt;/p&gt;
&lt;p&gt;消息乱序，有一定的概率不是按照发送时的顺序依次到达目的节点，考虑使用序列号等机制处理网络消息的乱序问题，使得无效的、过期的网络消息不影响系统的正确性；&lt;/p&gt;
&lt;p&gt;数据错误；不可靠的TCP，TCP 协议为应用层提供了可靠的、面向连接的传输服务，但在分布式系统的协议设计中不能认为所有网络通信都基于TCP 协议则通信就是可靠的。TCP协议只能保证同一个TCP 链接内的网络消息不乱序，TCP 链接之间的网络消息顺序则无法保证。&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;分布式三态&lt;/strong&gt;：如果某个节点向另一个节点发起RPC(Remote procedure call)调用，即某个节点A 向另一个节点B 发送一个消息，节点B 根据收到的消息内容完成某些操作，并将操作的结果通过另一个消息返回给节点A，那么这个RPC 执行的结果有三种状态：“成功”、“失败”、“超时（未知）”，称之为分布式系统的三态。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;存储数据丢失&lt;/strong&gt;:对于有状态节点来说，数据丢失意味着状态丢失，通常只能从其他节点读取、恢复存储的状态。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;异常处理原则&lt;/strong&gt;&lt;/em&gt;：被大量工程实践所检验过的异常处理黄金原则是：任何在设计阶段考虑到的异常情况一定会在系统实际运行中发生，但在系统实际运行遇到的异常却很有可能在设计时未能考虑，所以，除非需求指标允许，在系统设计时不能放过任何异常情况。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;12-副本&#34;&gt;1.2 副本&lt;/h2&gt;
&lt;p&gt;副本（replica/copy）指在分布式系统中为数据或服务提供的冗余。&lt;/p&gt;
&lt;p&gt;对于数据副本指在不同的节点上持久化同一份数据，当出现某一个节点的存储的数据丢失时，可以从副本上读到数据。数据副本是分布式系统解决数据丢失异常的唯一手段。&lt;/p&gt;
&lt;p&gt;另一类副本是服务副本，指数个节点提供某种相同的服务，这种服务一般并不依赖于节点的本地存储，其所需数据一般来自其他节点。&lt;/p&gt;
&lt;p&gt;副本协议是贯穿整个分布式系统的理论核心。&lt;/p&gt;
&lt;h3 id=&#34;副本一致性&#34;&gt;副本一致性&lt;/h3&gt;
&lt;p&gt;分布式系统通过副本控制协议，使得从系统外部读取系统内部各个副本的数据在一定的约束条件下相同，称之为副本一致性(consistency)。副本一致性是针对分布式系统而言的，不是针对某一个副本而言。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;强一致性(strong consistency)&lt;/strong&gt;：任何时刻任何用户或节点都可以读到最近一次成功更新的副本数据。强一致性是程度最高的一致性要求，也是实践中最难以实现的一致性。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;单调一致性(monotonic consistency)&lt;/strong&gt;：任何时刻，任何用户一旦读到某个数据在某次更新后的值，这个用户不会再读到比这个值更旧的值。&lt;/p&gt;
&lt;p&gt;单调一致性是弱于强一致性却非常实用的一种一致性级别。因为通常来说，用户只关心从己方视角观察到的一致性，而不会关注其他用户的一致性情况。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;会话一致性(session consistency)&lt;/strong&gt;：任何用户在某一次会话内一旦读到某个数据在某次更新后的值，这个用户在这次会话过程中不会再读到比这个值更旧的值。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;会话一致性通过引入会话的概念，在单调一致性的基础上进一步放松约束，会话一致性只保证单个用户单次会话内数据的单调修改，对于不同用户间的一致性和同一用户不同会话间的一致性没有保障。&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;最终一致性(eventual consistency)&lt;/strong&gt;：最终一致性要求一旦更新成功，各个副本上的数据最终将达 到完全一致的状态，但达到完全一致状态所需要的时间不能保障。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对于最终一致性系统而言，一个用户只要始终读取某一个副本的数据，则可以实现类似单调一致性的效果，但一旦用户更换读取的副本，则无法保障任何一致性。&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;&lt;strong&gt;弱一致性(week consistency)&lt;/strong&gt;：一旦某个更新成功，用户无法在一个确定时间内读到这次更新的值，且即使在某个副本上读到了新的值，也不能保证在其他副本上可以读到新的值。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;弱一致性系统一般很难在实际中使用，使用弱一致性系统需要应用方做更多的工作从而使得系统可用。&lt;/p&gt;
&lt;h2 id=&#34;13-衡量分布式系统的指标&#34;&gt;1.3 衡量分布式系统的指标&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;性能&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;系统的吞吐能力&lt;/strong&gt;，指系统在某一时间可以处理的&lt;strong&gt;数据总量&lt;/strong&gt;，通常可以用系统每秒处理的总的数据量来衡量；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;系统的响应延迟&lt;/strong&gt;，指系统完成某一功能需要使用的时间；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;系统的并发能力&lt;/strong&gt;，指系统可以同时完成某一功能的能力，通常也用QPS(query per second)来衡量。&lt;/p&gt;
&lt;p&gt;上述三个性能指标往往会相互制约，追求高吞吐的系统，往往很难做到低延迟；系统平均响应时间较长时，也很难提高QPS。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;可用性&lt;/strong&gt;：系统的可用性(availability)指系统在面对各种异常时可以正确提供服务的能力。&lt;/p&gt;
&lt;p&gt;系统的可用性可以用&lt;strong&gt;系统停服务的时间与正常服务的时间的比例&lt;/strong&gt;来衡量，也可以用某功能的&lt;strong&gt;失败次数与成功次数&lt;/strong&gt;的比例来衡量。可用性是分布式的重要指标，衡量了系统的鲁棒性，是系统容错能力的体现。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;：系统的可扩展性(scalability)指分布式系统通过扩展集群机器规模提高系统性能（吞吐、延迟、并发）、存储容量、计算能力的特性。好的分布式系统总在追求“线性扩展性”，也就是使得系统的某一指标可以随着集群中的机器数量线性增长。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;一致性&lt;/strong&gt;：分布式系统为了提高可用性，总是不可避免的使用副本的机制，从而引发副本一致性的问题。越是强的一致的性模型，对于用户使用来说使用起来越简单。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&#34;2-分布式系统原理&#34;&gt;2 分布式系统原理&lt;/h1&gt;
&lt;h2 id=&#34;21-数据分布方式&#34;&gt;2.1 数据分布方式&lt;/h2&gt;
&lt;p&gt;所谓分布式系统顾名思义就是利用多台计算机协同解决单台计算机所不能解决的计算、存储等问题。单机系统与分布式系统的最大的区别在于问题的规模，即计算、存储的数据量的区别。&lt;/p&gt;
&lt;p&gt;将一个单机问题使用分布式解决，首先要解决的就是如何将问题拆解为可以使用多机分布式解决，使得分布式系统中的每台机器负责原问题的一个子集。由于无论是计算还是存储，其问题输入对象都是数据，所以如何拆解分布式系统的输入数据成为分布式系统的基本问题。&lt;/p&gt;
&lt;h3 id=&#34;哈希方式&#34;&gt;哈希方式&lt;/h3&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;哈希分布数据的缺点同样明显，突出表现为&lt;strong&gt;可扩展性不高&lt;/strong&gt;，一旦集群规模需要扩展，则几乎所有的数据需要被迁移并重新分布。工程中，扩展哈希分布数据的系统时，往往使得集群规模成倍扩展，按照数据重新计算哈希，这样原本一台机器上的数据只需迁移一半到另一台对应的机器上即可完成扩展。&lt;/p&gt;
&lt;p&gt;针对哈希方式扩展性差的问题，一种思路是不再简单的将哈希值与机器做除法取模映射，而是将对应关系作为元数据由专门的元数据服务器管理.同时，哈希值取模个数往往大于机器个数，这样同一台机器上需要负责多个哈希取模的余数。但需要以较复杂的机制维护大量的元数据。&lt;/p&gt;
&lt;p&gt;哈希分布数据的另一个缺点是，一旦某数据特征值的数据严重不均，容易出现“数据倾斜”（data skew）问题&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640%20(1).webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;按数据范围分布&#34;&gt;按数据范围分布&lt;/h3&gt;
&lt;p&gt;按数据范围分布是另一个常见的数据分布式，将数据按特征值的值域范围划分为不同的区间，使得集群中每台（组）服务器处理不同区间的数据。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640%20(2).webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;工程中，为了数据迁移等负载均衡操作的方便，往往利用动态划分区间的技术，使得每个区间中服务的数据量尽量的一样多。当某个区间的数据量较大时，通过将区间“分裂”的方式拆分为两个区间，使得每个数据区间中的数据量都尽量维持在一个较为固定的阈值之下。&lt;/p&gt;
&lt;p&gt;一般的，往往需要使用专门的服务器在内存中维护数据分布信息，称这种数据的分布信息为一种元信息。甚至对于大规模的集群，由于元信息的规模非常庞大，单台计算机无法独立维护，需要使用多台机器作为元信息服务器。&lt;/p&gt;
&lt;h3 id=&#34;按数据量分布&#34;&gt;按数据量分布&lt;/h3&gt;
&lt;p&gt;数据量分布数据与具体的数据特征无关，而是将数据视为一个顺序增长的文件，并将这个文件按照某一较为固定的大小划分为若干数据块（chunk），不同的数据块分布到不同的服务器上&lt;/p&gt;
&lt;p&gt;与按数据范围分布数据的方式类似的是，按数据量分布数据也需要记录数据块的具体分布情况，并将该分布信息作为元数据使用元数据服务器管理。&lt;/p&gt;
&lt;p&gt;由于与具体的数据内容无关，按数据量分布数据的方式一般没有数据倾斜的问题，数据总是被均匀切分并分布到集群中。&lt;/p&gt;
&lt;p&gt;当集群需要重新负载均衡时，只需通过迁移数据块即可完成。集群扩容也没有太大的限制，只需将部分数据库迁移到新加入的机器上即可以完成扩容。&lt;/p&gt;
&lt;p&gt;按数据量划分数据的缺点是需要管理较为复杂的元信息，与按范围分布数据的方式类似，当集群规模较大时，元信息的数据量也变得很大，高效的管理元信息成为新的课题。&lt;/p&gt;
&lt;h3 id=&#34;一致性哈希&#34;&gt;一致性哈希&lt;/h3&gt;
&lt;p&gt;一致性哈希（consistent hashing）是另一个种在工程中使用较为广泛的数据分布方式。一致性哈希最初在P2P 网络中作为分布式哈希表（DHT）的常用数据分布算法。&lt;/p&gt;
&lt;p&gt;一致性哈希的基本方式是使用一个哈希函数计算数据或数据特征的哈希值，令该哈希函数的输出值域为一个封闭的环，即哈希函数输出的最大值是最小值的前序。将节点随机分布到这个环上，每个节点负责处理从自己开始顺时针至下一个节点的全部哈希值域上的数据。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640%20(3).webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;使用一致性哈希的方式需要将节点在一致性哈希环上的位置作为元信息加以管理，这点比直接使用哈希分布数据的方式要复杂。然而，节点的位置信息只于集群中的机器规模相关，其元信息的量通常比按数据范围分布数据和按数据量分布数据的元信息量要小很多。&lt;/p&gt;
&lt;p&gt;为此一种常见的改进算法是引入虚节点（virtual node）的概念，系统初始时就创建许多虚节点，虚节点的个数一般远大于未来集群中机器的个数，将虚节点均匀分布到一致性哈希值域环上，其功能与基本一致性哈希算法中的节点相同。为每个节点分配若干虚节点。&lt;/p&gt;
&lt;p&gt;操作数据时，首先通过数据的哈希值在环上找到对应的虚节点，进而查找元数据找到对应的真实节点。使用虚节点改进有多个优点。&lt;/p&gt;
&lt;p&gt;首先，一旦某个节点不可用，该节点将使得多个虚节点不可用，从而使得多个相邻的真实节点负载失效节点的压里。同理，一旦加入一个新节点，可以分配多个虚节点，从而使得新节点可以 负载多个原有节点的压力，从全局看，较容易实现扩容时的负载均衡。&lt;/p&gt;
&lt;h3 id=&#34;副本与数据分布&#34;&gt;副本与数据分布&lt;/h3&gt;
&lt;p&gt;分布式系统容错、提高可用性的基本手段就是使用副本。对于数据副本的分布方式主要影响系统的可扩展性。一种基本的数据副本策略是以机器为单位，若干机器互为副本，副本机器之间的数据完全相同。这种策略适用于上述各种数据分布方式。其优点是非常简单，其缺点是恢复数据的效率不高、可扩展性也不高。&lt;/p&gt;
&lt;p&gt;更合适的做法不是以机器作为副本单位，而是将数据拆为较合理的数据段，以数据段为单位作为副本。&lt;/p&gt;
&lt;p&gt;实践中，常常使得每个数据段的大小尽量相等且控制在一定的大小以内。数据段有很多不同的称谓，segment，fragment，chunk，partition 等等。数据段的选择与数据分布方式直接相关。&lt;/p&gt;
&lt;p&gt;对于哈希分数据的方式，每个哈希分桶后的余数可以作为一个数据段，为了控制数据段的大小，常常使得分桶个数大于集群规模。一旦将数据分为数据段，则可以以数据段为单位管理副本，从而副本与机器不再硬相关，每台机器都可以负责一定数据段的副本。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/6401.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;一旦副本分布与机器无关，数据丢失后的恢复效率将非常高。这是因为，一旦某台机器的数据丢失，其上数据段的副本将分布在整个集群的所有机器中，而不是仅在几个副本机器中，从而可以从整个集群同时拷贝恢复数据，而集群中每台数据源机器都可以以非常低的资源做拷贝。作为恢复数据源的机器即使都限速1MB/s，若有100 台机器参与恢复，恢复速度也能达到100MB/s。&lt;/p&gt;
&lt;p&gt;再者，副本分布与机器无关也利于集群容错。如果出现机器宕机，由于宕机机器上的副本分散于整个集群，其压力也自然分散到整个集群。&lt;/p&gt;
&lt;p&gt;最后，副本分布与机器无关也利于集群扩展。理论上，设集群规模 为N 台机器，当加入一台新的机器时，只需从各台机器上迁移1/N – 1/N+1 比例的数据段到新机器即实现了新的负载均衡。由于是从集群中各机器迁移数据，与数据恢复同理，效率也较高。&lt;/p&gt;
&lt;p&gt;工程中，完全按照数据段建立副本会引起需要管理的元数据的开销增大，副本维护的难度也相应增大。一种折中的做法是将某些数据段组成一个数据段分组，按数据段分组为粒度进行副本管理。这样做可以将副本粒度控制在一个较为合适的范围内。&lt;/p&gt;
&lt;h3 id=&#34;本地化计算&#34;&gt;本地化计算&lt;/h3&gt;
&lt;p&gt;在分布式系统中，数据的分布方式也深深影响着计算的分布方式。在分布式系统中计算节点和保存计算数据的存储节点可以在同一台物理机器上，也可以位于不同的物理机器。&lt;/p&gt;
&lt;p&gt;如果计算节点和存储节点位于不同的物理机器则计算的数据需要通过网络传输，此种方式的开销很大，甚至网络带宽会成为系统的总体瓶颈。&lt;/p&gt;
&lt;p&gt;另一种思路是，将计算尽量调度到与存储节点在同一台物理机器上的计算节点上进行，这称之为本地化计算。本地化计算是计算调度的一种重要优化，其体现了一种重要的分布式调度思想：“移动数据不如移动计算”。&lt;/p&gt;
&lt;h3 id=&#34;数据分布方式的选择&#34;&gt;数据分布方式的选择&lt;/h3&gt;
&lt;p&gt;在实际工程实践中，可以根据需求及实施复杂度合理选择数据分布方式。另外，数据分布方式是可以灵活组合使用的，往往可以兼备各种方式的优点，收到较好的综合效果。&lt;/p&gt;
&lt;p&gt;例：数据倾斜问题，在按哈希分数据的基础上引入按数据量分布数据的方式，解决该数据倾斜问题。按用户id 的哈希值分数据，当某个用户id 的数据量特别大时，该用户的数据始终落在某一台机器上。此时，引入按数据量分布数据的方式，统计用户的数据量，并按某一阈值将用户的数据切为多个均匀的数据段，将这些数据段分布到集群中去。由于大部分用户的数据量不会超过阈值，所以元数据中仅仅保存超过阈值的用户的数据段分布信息，从而可以控制元数据的规模。这种哈希分布数据方式与按数据量分布数据方式组合使用的方案，在某真实系统中使用，取得了较好的效果。&lt;/p&gt;
&lt;h2 id=&#34;22-基本副本协议&#34;&gt;2.2 基本副本协议&lt;/h2&gt;
&lt;p&gt;副本控制协议指按特定的协议流程控制副本数据的读写行为，使得副本满足一定的可用性和一致性要求的分布式协议。副本控制协议要具有一定的对抗异常状态的容错能力，从而使得系统具有一定的可用性，同时副本控制协议要能提供一定一致性级别。由CAP 原理可知，要设计一种满足强一致性，且在出现任何网络异常时都可用的副本协议是不可能的。为此，实际中的副本控制协议总是在可用性、一致性与性能等各要素之间按照具体需求折中。&lt;/p&gt;
&lt;p&gt;副本控制协议可以分为两大类：“中心化(centralized)副本控制协议”和“去中心化(decentralized)副本控制协议”。&lt;/p&gt;
&lt;h3 id=&#34;中心化副本控制协议&#34;&gt;中心化副本控制协议&lt;/h3&gt;
&lt;p&gt;中心化副本控制协议的基本思路是由一个中心节点协调副本数据的更新、维护副本之间的一致性。&lt;/p&gt;
&lt;p&gt;图给出了中心化副本协议的通用架构。中心化副本控制协议的优点是协议相对较为简单，所有的副本相关的控制交由中心节点完成。并发控制将由中心节点完成，从而使得一个分布式并发控制问题，简化为一个单机并发控制问题。&lt;/p&gt;
&lt;p&gt;所谓并发控制，即多个节点同时需要修改副本数据时，需要解决“写写”、“读写”等并发冲突。单机系统上常用加锁等方式进行并发控制。对于分布式并发控制，加锁也是一个常用的方法，但如果没有中心节点统一进行锁管理，就需要完全分布式化的锁系统，会使得协议非常复杂。&lt;/p&gt;
&lt;p&gt;中心化副本控制协议的缺点是系统的可用性依赖于中心化节点，当中心节点异常或与中心节点通信中断时，系统将失去某些服务（通常至少失去更新服务），所以中心化副本控制协议的缺点正是存在一定的停服务时间。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/641110.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;primary-secondary-协议&#34;&gt;primary-secondary 协议&lt;/h3&gt;
&lt;p&gt;在primary-secondary 类型的协议中，副本被分为两大类，其中有且仅有一个副本作为primary 副本，除primary 以外的副本都作为secondary 副本。维护primary 副本的节点作为中心节点，中心节点负责维护数据的更新、并发控制、协调副本的一致性。&lt;/p&gt;
&lt;p&gt;Primary-secondary 类型的协议一般要解决四大类问题：数据更新流程、数据读取方式、Primary 副本的确定和切换、数据同步（reconcile）。&lt;/p&gt;
&lt;h5 id=&#34;数据更新基本流程&#34;&gt;数据更新基本流程&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;数据更新都由primary 节点协调完成。&lt;/li&gt;
&lt;li&gt;外部节点将更新操作发给primary 节点&lt;/li&gt;
&lt;li&gt;primary 节点进行并发控制即确定并发更新操作的先后顺序&lt;/li&gt;
&lt;li&gt;primary 节点将更新操作发送给secondary 节点&lt;/li&gt;
&lt;li&gt;primary 根据secondary 节点的完成情况决定更新是否成功并将结果返回外部节点&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/641320.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;在工程实践中，如果由primary 直接同时发送给其他N 个副本发送数据，则每个 secondary 的更新吞吐受限于primary 总的出口网络带宽，最大为primary 网络出口带宽的1/N。&lt;/p&gt;
&lt;p&gt;为了解决这个问题，有些系统（例如，GFS），使用接力的方式同步数据，即primary 将更新发送给第一 个secondary 副本，第一个secondary 副本发送给第二secondary 副本，依次类推。&lt;/p&gt;
&lt;h4 id=&#34;数据读取方式&#34;&gt;数据读取方式&lt;/h4&gt;
&lt;p&gt;数据读取方式也与一致性高度相关。如果只需要最终一致性，则读取任何副本都可以满足需求。&lt;/p&gt;
&lt;p&gt;如果需要会话一致性，则可以为副本设置版本号，每次更新后递增版本号，用户读取副本时验证版本号，从而保证用户读到的数据在会话范围内单调递增。使用primary-secondary 比较困难的是实现强一致性。&lt;/p&gt;
&lt;p&gt;由于数据的更新流程都是由primary 控制的，primary 副本上的数据一定是最新的，所以 如果始终只读primary 副本的数据，可以实现强一致性。如果只读primary 副本，则secondary 副本将不提供读服务。&lt;/p&gt;
&lt;p&gt;实践中，如果副本不与机器绑定，而是按照数据段为单位维护副本，仅有primary 副本提供读服务在很多场景下并不会造出机器资源浪费。&lt;/p&gt;
&lt;p&gt;将副本分散到集群中个，假设primary 也是随机的确定的，那么每台机器上都有一些数据的primary 副本，也有另一些数据段的secondary 副本。从而某台服务器实际都提供读写服务。&lt;/p&gt;
&lt;p&gt;由primary 控制节点secondary 节点的可用性。当primary 更新某个secondary 副本不成功时，primary 将该secondary 副本标记为不可用，从而用户不再读取该不可用的副本。不可用的 secondary 副本可以继续尝试与primary 同步数据，当与primary 完成数据同步后，primary 可以副本标记为可用。&lt;/p&gt;
&lt;p&gt;这种方式使得所有的可用的副本，无论是primary 还是secondary 都是可读的，且在一个确定的时间内，某secondary 副本要么更新到与primary 一致的最新状态，要么被标记为不可用，从而符合较高的一致性要求。这种方式依赖于一个中心元数据管理系统，用于记录哪些副本可用，哪些副本不可用。某种意义上，该方式通过降低系统的可用性来提高系统的一致性。&lt;/p&gt;
&lt;h4 id=&#34;primary-副本的确定与切换&#34;&gt;primary 副本的确定与切换&lt;/h4&gt;
&lt;p&gt;在primary-secondary 类型的协议中，另一个核心的问题是如何确定primary 副本，尤其是在原primary 副本所在机器出现宕机等异常时，需要有某种机制切换primary 副本，使得某个secondary 副本成为新的primary 副本。&lt;/p&gt;
&lt;p&gt;通常的，在primary-secondary 类型的分布式系统中，哪个副本是primary 这一信息都属于元信息，由专门的元数据服务器维护。执行更新操作时，首先查询元数据服务器获取副本的primary 信息，从而进一步执行数据更新流程。&lt;/p&gt;
&lt;p&gt;由于分布式系统中可靠的发现节点异常是需要一定的探测时间的，这样的探测时间通常是10 秒级别，这也意味着一旦primary 异常，最多需要10 秒级别的发现时间，系统才能开始primary 的切换，在这10 秒时间内，由于没有primary，系统不能提供更 新服务，如果系统只能读primary 副本，则这段时间内甚至不能提供读服务。从这里可以看到，primary-backup 类副本协议的最大缺点就是由于primary 切换带来的一定的停服务时间。&lt;/p&gt;
&lt;h4 id=&#34;数据同步&#34;&gt;数据同步&lt;/h4&gt;
&lt;p&gt;不一致的secondary 副本需要与primary 进行同步（reconcile）。&lt;/p&gt;
&lt;p&gt;通常不一致的形式有三种：&lt;/p&gt;
&lt;p&gt;一、由于网络分化等异常，secondary 上的数据落后于primary 上的数据。&lt;/p&gt;
&lt;p&gt;二、在某些协议下，secondary 上的数据有可能是脏数据，需要被丢弃。所谓脏数据是由于primary 副本没有进行某一更新操作，而secondary 副本上反而进行的多余的修改操作，从而造成secondary 副本数据错误。&lt;/p&gt;
&lt;p&gt;三、secondary 是一个新增加的副本，完全没有数据，需要从其他副本上拷贝数据。&lt;/p&gt;
&lt;p&gt;对于第一种secondary 数据落后的情况，常见的同步方式是回放primary 上的操作日志（通常是redo 日志），从而追上primary 的更新进度。&lt;/p&gt;
&lt;p&gt;对于脏数据的情况，较好的做法是设计的分布式协议不产生脏数据。如果协议一定有产生脏数据的可能，则也应该使得产生脏数据的概率降到非常低得情况，从而一旦发生脏数据的情况可以简单的直接丢弃有脏数据的副本，这样相当于副本没有数据。&lt;/p&gt;
&lt;p&gt;另外，也可以设计一些基于undo 日志的方式从而可以删除脏数据。如果secondary 副本完全没有数据，则常见的做法是直接拷贝primary 副本的数据，这种方法往往比回放日志追更新进度的方法快很多。但拷贝数据时primary 副本需要能够继续提供更新服务，这就要求primary 副本支持快照(snapshot)功能。即对某一刻的副本数据形成快照，然后拷贝快照，拷贝完成后使用回放日志的方式追快照形成后的更新操作。&lt;/p&gt;
&lt;h3 id=&#34;去中心化副本控制协议&#34;&gt;去中心化副本控制协议&lt;/h3&gt;
&lt;p&gt;去中心化副本控制协议没有中心节点，协议中所有的节点都是完全对等的，节点之间通过平等协商达到一致。从而去中心化协议没有因为中心化节点异常而带来的停服务等问题。&lt;/p&gt;
&lt;p&gt;去中心化协议的最大的缺点是协议过程通常比较复杂。尤其当去中心化协议需要实现强一致性时，协议流程变得复杂且不容易理解。由于流程的复杂，去中心化协议的效率或者性能一般也较中心化协议低。一个不恰当的比方就是，中心化副本控制协议类似专制制度，系统效率高但高度依赖于中心节点，一旦中心节点异常，系统受到的影响较大；去中心化副本控制协议类似民主制度，节点集体协商，效率低下，但个别节点的异常不会对系统总体造成太大影响。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640323.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;23-lease-机制&#34;&gt;2.3 Lease 机制&lt;/h2&gt;
&lt;p&gt;Lease 机制是最重要的分布式协议，广泛应用于各种实际的分布式系统中。&lt;/p&gt;
&lt;h3 id=&#34;基于lease-的分布式cache-系统&#34;&gt;基于lease 的分布式cache 系统&lt;/h3&gt;
&lt;p&gt;基本的问题背景如下：在一个分布式系统中，有一个中心服务器节点，中心服务器存储、维护着一些数据，这些数据是系统的元数据。系统中其他的节点通过访问中心服务器节点读取、修改其上的元数据。&lt;/p&gt;
&lt;p&gt;由于系统中各种操作都依赖于元数据，如果每次读取元数据的操作都访问中心服务器 节点，那么中心服务器节点的性能成为系统的瓶颈。为此，设计一种元数据cache，在各个节点上 cache 元数据信息，从而减少对中心服务器节点的访问，提高性能。&lt;/p&gt;
&lt;p&gt;另一方面，系统的正确运行严格依赖于元数据的正确，这就要求各个节点上cache 的数据始终与中心服务器上的数据一致，cache 中的数据不能是旧的脏数据。最后，设计的cache 系统要能最大可能的处理节点宕机、网络中断等异常，最大程度的提高系统的可用性。&lt;/p&gt;
&lt;p&gt;为此，利用lease 机制设计一套cache 系统，其基本原理为如下。&lt;/p&gt;
&lt;p&gt;中心服务器在向各节点发送数据时同时向节点颁发一个lease。每个lease 具有一个有效期，和信用卡上的有效期类似，lease 上的 有效期通常是一个明确的时间点，例如12:00:10，一旦真实时间超过这个时间点，则lease 过期失效。这样lease 的有效期与节点收到lease 的时间无关，节点可能收到lease 时该lease 就已经过期失效。这里首先假设中心服务器与各节点的时钟是同步的，在下节中讨论时钟不同步对lease 的影响。中心服务器发出的lease 的含义为：在lease 的有效期内，&lt;strong&gt;中心服务器保证不会修改对应数据的值&lt;/strong&gt;。因此，节点收到数据和lease 后，将数据加入本地Cache，一旦对应的lease 超时，节点将对应的本地cache 数据删除。中心服务器在修改数据时，首先阻塞所有新的读请求，并等待之前为该数据发出的所有lease 超时过期，然后修改数据的值。&lt;/p&gt;
&lt;p&gt;基于lease 的cache，客户端节点读取元数据&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-flow&#34;&gt;st=&amp;gt;start: 客户端节点
op3=&amp;gt;operation: lease缓存
cond=&amp;gt;condition: lease 处于有效期内
cond2=&amp;gt;condition: 收到元数据
sub1=&amp;gt;subroutine: 向中心服务器节点请求读取元数据信息
op1=&amp;gt;inputoutput: 中心服务器
op2=&amp;gt;subroutine: 返回元数据
e=&amp;gt;end: 返回元数据
e1=&amp;gt;end: 失败退出
st-&amp;gt;op3-&amp;gt;cond
cond(yes)-&amp;gt;e
cond(no)-&amp;gt;sub1(right)-&amp;gt;op1-&amp;gt;cond2
cond2(no)-&amp;gt;e1
cond2(yes)-&amp;gt;op3
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;判断元数据是否已经处于本地cache 且lease 处于有效期内&lt;/p&gt;
&lt;p&gt;1.1 是：直接返回cache 中的元数据&lt;/p&gt;
&lt;p&gt;1.2 否：向中心服务器节点请求读取元数据信息&lt;/p&gt;
&lt;p&gt;1.2.1 服务器收到读取请求后，返回元数据及一个对应的lease&lt;/p&gt;
&lt;p&gt;1.2.2 客户端是否成功收到服务器返回的数据&lt;/p&gt;
&lt;p&gt;1.2.2.1 失败或超时：退出流程，读取失败，可重试&lt;/p&gt;
&lt;p&gt;1.2.2.2 成功：将元数据与该元数据的lease 记录到内存中，返回元数据&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;基于lease 的cache，客户端节点修改元数据流程&lt;/p&gt;
&lt;p&gt;2.1 节点向服务器发起修改元数据请求。&lt;/p&gt;
&lt;p&gt;2.2 服务器收到修改请求后，阻塞所有新的读数据请求，即接收读请求，但不返回数据。&lt;/p&gt;
&lt;p&gt;2.3 服务器等待所有与该元数据相关的lease 超时。&lt;/p&gt;
&lt;p&gt;2.4 服务器修改元数据并向客户端节点返回修改成功。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上述机制可以保证各个节点上的cache 与中心服务器上的中心始终一致。这是因为中心服务器节点在发送数据的同时授予了节点对应的lease，在lease 有效期内，服务器不会修改数据，从而客户端节点可以放心的在lease 有效期内cache 数据。上述lease 机制可以容错的关键是：服务器一旦 发出数据及lease，无论客户端是否收到，也无论后续客户端是否宕机，也无论后续网络是否正常，服务器只要等待lease 超时，就可以保证对应的客户端节点不会再继续cache 数据，从而可以放心的修改数据而不会破坏cache 的一致性。&lt;/p&gt;
&lt;p&gt;上述基础流程有一些性能和可用性上的问题，但可以很容易就优化改性。&lt;/p&gt;
&lt;p&gt;优化点一：服务器在修改元数据时首先要阻塞所有新的读请求，造成没有读服务。这是为了防止发出新的lease 从而引起不断有新客户端节点持有lease 并缓存着数据，形成“活锁”。优化的方法很简单，服务器在进入修改数据流程后，一旦收到读请求则只返回数据但不颁发lease。从而造成在修改流程执行的过程中，客户端可以读到元数据，只是不能缓存元数据。进一步的优化是，当进入修改流程，服务器颁发的lease 有效期限选择为已发出的lease 的最大有效期限。这样做，客户端可以继续在服务器进入修改流程后继续缓存元数据，但服务器的等待所有lease 过期的时间也不会因为颁发新的lease 而不断延长。&lt;/p&gt;
&lt;p&gt;最后，cache 机制与多副本机制的区别。Cache 机制与多副本机制的相似之处都 是将一份数据保存在多个节点上。但Cache 机制却要简单许多，对于cache 的数据，可以随时删除丢弃，并命中cache 的后果仅仅是需要访问数据源读取数据；然而副本机制却不一样，副本是不能随意丢弃的，每失去一个副本，服务质量都在下降，一旦副本数下降到一定程度，则往往服务将不再可用。&lt;/p&gt;
&lt;h4 id=&#34;lease-机制的分析&#34;&gt;lease 机制的分析&lt;/h4&gt;
&lt;p&gt;lease 的定义：Lease 是由颁发者授予的在某一有效期内的承诺。颁发者一旦发出lease，则无论接受方是否收到，也无论后续接收方处于何种状态，只要lease 不过期，颁发者一定严守承诺；另一方面，接收方在lease 的有效期内可以使用颁发者的承诺，但一旦lease 过期，接收方一定不能继续使用颁发者的承诺。&lt;/p&gt;
&lt;p&gt;Lease 机制具有很高的容错能力。首先，通过引入有效期，Lease 机制能否非常好的容错网络异常。Lease 颁发过程只依赖于网络可以单向通信，即使接收方无法向颁发者发送消息，也不影响lease 的颁发。&lt;/p&gt;
&lt;p&gt;由于lease 的有效期是一个确定的时间点，lease 的语义与发送lease 的具体时间无关，所以 同一个lease 可以被颁发者不断重复向接受方发送。即使颁发者偶尔发送lease 失败，颁发者也可以 简单的通过重发的办法解决。一旦lease 被接收方成功接受，后续lease 机制不再依赖于网络通信，即使网络完全中断lease 机制也不受影响。&lt;/p&gt;
&lt;p&gt;再者，Lease 机制能较好的容错节点宕机。如果颁发者宕机，则宕机的颁发者通常无法改变之前的承诺，不会影响lease 的正确性。在颁发者机恢复后，如果颁发者恢复出了之前的lease 信息，颁发者可以继续遵守lease 的承诺。如果颁发者无法恢复lease 信息，则只需等待一个最大的lease 超时时间就可以使得所有的lease 都失效，从而不破坏lease机制。&lt;/p&gt;
&lt;p&gt;例如上节中的cache 系统的例子中，一旦服务器宕机，肯定不会修改元数据，重新恢复后，只需等待一个最大的lease 超时时间，所有节点上的缓存信息都将被清空。&lt;/p&gt;
&lt;p&gt;对于接受方宕机的情况，颁发者 不需要做更多的容错处理，只需等待lease 过期失效，就可以收回承诺，实践中也就是收回之前赋予的权限、身份等。最后，lease 机制不依赖于存储。颁发者可以持久化颁发过的lease 信息，从而在 宕机恢复后可以使得在有效期的lease 继续有效。但这对于lease 机制只是一个优化，如之前的分析，即使颁发者没有持久化lease 信息，也可以通过等待一个最大的lease 时间的方式使得之前所有颁发 的lease 失效，从而保证机制继续有效。&lt;/p&gt;
&lt;p&gt;Lease 机制依赖于有效期，这就要求颁发者和接收者的时钟是同步的。一方面，如果颁发者的 时钟比接收者的时钟慢，则当接收者认为lease 已经过期的时候，颁发者依旧认为lease 有效。接收者可以用在lease 到期前申请新的lease 的方式解决这个问题。另一方面，如果颁发者的时钟比接收 者的时钟快，则当颁发者认为lease 已经过期的时候，接收者依旧认为lease 有效，颁发者可能将lease 颁发给其他节点，造成承诺失效，影响系统的正确性。对于这种时钟不同步，实践中的通常做法是将颁发者的有效期设置得比接收者的略大，只需大过时钟误差就可以避免对lease 的有效性的影响。&lt;/p&gt;
&lt;h4 id=&#34;基于lease-机制确定节点状态&#34;&gt;基于lease 机制确定节点状态&lt;/h4&gt;
&lt;p&gt;分布式协议依赖于对节点状态认知的全局一致性，即一旦节点Q 认为某个节点 A 异常，则节点A 也必须认为自己异常，从而节点A 停止作为primary，避免“双主”问题的出现。&lt;/p&gt;
&lt;p&gt;解决这种问题有两种思路，第一、设计的分布式协议可以容忍“双主”错误，即不依赖于对节点状 态的全局一致性认识，或者全局一致性状态是全体协商后的结果；&lt;/p&gt;
&lt;p&gt;第二、利用lease 机制。对于第一 种思路即放弃使用中心化的设计，而改用去中心化设计，超过本节的讨论范畴。下面着重讨论利用 lease 机制确定节点状态。&lt;/p&gt;
&lt;p&gt;由中心节点向其他节点发送lease，若某个节点持有有效的lease，则认为该节点正常可以提供服 务。用于例2.3.1 中，节点A、B、C 依然周期性的发送heart beat 报告自身状态，节点Q 收到heart beat 后发送一个lease，表示节点Q 确认了节点A、B、C 的状态，并允许节点在lease 有效期内正常工 作。节点Q 可以给primary 节点一个特殊的lease，表示节点可以作为primary 工作。一旦节点Q 希望切换新的primary，则只需等前一个primary 的lease 过期，则就可以安全的颁发新的lease 给新的 primary 节点，而不会出现“双主”问题。&lt;/p&gt;
&lt;p&gt;在实际系统中，若用一个中心节点发送lease 也有很大的风险，一旦该中心节点宕机或网络异常，则所有的节点没有lease，从而造成系统高度不可用。为此，实际系统总是使用多个中心节点互为副本，成为一个小的集群，该小集群具有高可用性，对外提供颁发lease 的功能。chubby 和zookeeper 都是基于这样的设计。&lt;/p&gt;
&lt;h4 id=&#34;lease-的有效期时间选择&#34;&gt;lease 的有效期时间选择&lt;/h4&gt;
&lt;p&gt;工程中，常选择的lease 时长是10 秒级别，这是一个经过验证的经验值，实践中可以作为参考并综合选择合适的时长。&lt;/p&gt;
&lt;h2 id=&#34;24-quorum-机制&#34;&gt;2.4 Quorum 机制&lt;/h2&gt;
&lt;p&gt;先做这样的约定：更新操作（write）是一系列顺序的过程，通过其他机制确定更新操作的顺序（例如primary-secondary 架构中由primary 决定顺序），每个更新操作记为&lt;code&gt;wi&lt;/code&gt;， &lt;code&gt;i&lt;/code&gt;为更新操作单调递增的序号，每个&lt;code&gt;wi&lt;/code&gt;执行成功后副本数据都发生变化，称为不同的数据版本，记作vi。假设每个副本都保存了历史上所有版本的数据。&lt;/p&gt;
&lt;h3 id=&#34;write-all-read-one&#34;&gt;write-all-read-one&lt;/h3&gt;
&lt;p&gt;Write-all-read-one（简称WARO）是一种最简单的副本控制规则，顾名思义即在更新时写所有的副本，只有在所有的副本上更新成功，才认为更新成功，从而保证所有的副本一致，这样在读取数据时可以读任一副本上的数据。&lt;/p&gt;
&lt;p&gt;由于更新操作需要在所有的N 个副本上都成功，更新操作才能成 功，所以一旦有一个副本异常，更新操作失败，更新服务不可用。对于更新服务，虽然有N 个副本， 但系统无法容忍任何一个副本异常。另一方面，N 个副本中只要有一个副本正常，系统就可以提供读服务。对于读服务而言，当有N 个副本时，系统可以容忍N-1 个副本异常。从上述分析可以发现WARO 读服务的可用性较高，但更新服务的可用性不高，甚至虽然使用了副本，但更新服务的可用性等效于没有副本。&lt;/p&gt;
&lt;h3 id=&#34;quorum-定义&#34;&gt;Quorum 定义&lt;/h3&gt;
&lt;p&gt;在Quorum 机制下，当某次更新操作&lt;code&gt;wi&lt;/code&gt;一旦在所有N 个副本中的W 个副本上都成功，则就称 该更新操作为“成功提交的更新操作”，称对应的数据为“成功提交的数据”。令R&amp;gt;N-W，由于更新 操作&lt;code&gt;wi&lt;/code&gt;仅在W 个副本上成功，所以在读取数据时，最多需要读取R 个副本则一定能读到wi 更新后 的数据vi 。如果某次更新wi 在W 个副本上成功，由于W+R&amp;gt;N，任意R 个副本组成的集合一定与 成功的W个副本组成的集合有交集，所以读取R 个副本一定能读到wi 更新后的数据vi。&lt;/p&gt;
&lt;p&gt;如图 2-10， Quorum 机制的原理可以文森图表示。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/6402323.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;某系统有5 个副本，W=3，R=3，最初5 个副本的数据一致，都是v1，某次更新操作 w2 在前3 副本上成功，副本情况变成（v2 v2 v2 v1 v1）。&lt;/p&gt;
&lt;p&gt;此时，任意3 个副本组成的集合中一定包括 v2。在上述定义中，令W=N，R=1，就得到WARO，即WARO 是Quorum 机制的一种特例。与分析WARO 相似，分析Quorum 机制的可用性。限制Quorum 参数为W+R=N+1。由于更新 操作需要在W 个副本上都成功，更新操作才能成功，所以一旦N-W+1 个副本异常，更新操作始终无法在W 个副本上成功，更新服务不可用。&lt;/p&gt;
&lt;p&gt;另一方面，一旦N-R+1 个副本异常，则无法保证一定可以读到与W 个副本有交集的副本集合，则读服务的一致性下降。&lt;/p&gt;
&lt;p&gt;再次强调：仅仅依赖quorum 机制是无法保证强一致性的。因为仅有quorum 机制时无法确定最新已成功提交的版本号，除非将最新已提交的版本号作为元数据由特定的元数据服务器或元数据集群管理，否则很难确定最新成功提交的版本号。在下一节中，将讨论在哪些情况下，可以仅仅 通过quorum 机制来确定最新成功提交的版本号。&lt;/p&gt;
&lt;p&gt;Quorum 机制的三个系统参数N、W、R 控制了系统的可用性，也是系统对用户的服务承诺：数据最多有N 个副本，但数据更新成功W 个副本即返回用户成功。对于一致性要求较高的Quorum 系统，系统还应该承诺任何时候不读取未成功提交的数据，即读取到的数据都是曾经在W 个副本上成功的数据。&lt;/p&gt;
&lt;h3 id=&#34;读取最新成功提交的数据&#34;&gt;读取最新成功提交的数据&lt;/h3&gt;
&lt;p&gt;Quorum 机制只需成功更新N 个副本中的W 个，在读取R 个副本时，一定可以读到最新的成功提交的数据。但由于有不成功的更新情况存在，仅仅读取R 个副本却不一定能确定哪个版本的数据 是最新的已提交的数据。对于一个强一致性Quorum 系统，若存在个数据少于W 个，假设为X 个，则继续读取其他副本，直若成功读取到W 个 该版本的副本，则该数据为最新的成功提交的数据；如果在所有副本中该数据的个数肯定不满 足W 个，则R 中版本号第二大的为最新的成功提交的副本。&lt;/p&gt;
&lt;p&gt;例：在读取到（v2 v1 v1）时，继续读取剩余的副本，若读到剩余两个副本 为（v2 v2）则v2 是最新的已提交的副本；若读到剩余的两个副本为（v2 v1）或（v1 v1）则v1 是最新成功提交的版本；若读取后续两个副本有任一超时或失败，则无法判断哪个版本是最新的成功提交的版本。&lt;/p&gt;
&lt;p&gt;可以看出，在单纯使用Quorum 机制时，若要确定最新的成功提交的版本，最多需要读取R+ （W-R-1）=N 个副本，当出现任一副本异常时，读最新的成功提交的版本这一功能都有可能不可用。&lt;/p&gt;
&lt;p&gt;实际工程中，应该尽量通过其他技术手段，回避通过Quorum 机制读取最新的成功提交的版本。例如，当quorum 机制与primary-secondary 控制协议结合使用时，可以通过读取primary 的方式读取到最新的已提交的数据。&lt;/p&gt;
&lt;h3 id=&#34;基于quorum-机制选择primary副本&#34;&gt;基于Quorum 机制选择primary副本&lt;/h3&gt;
&lt;p&gt;读取数据时依照一致性要求的不同可以有不同的做法：如果需要强一致性的立刻读取到最新的成功提交的数据，则可以简单的只读取primary 副本上的数据即可，也可以通过上节的方式读取；&lt;/p&gt;
&lt;p&gt;如果需要会话一致性，则可以根据之前已经读到的数据版本号在各个副本上进行选择性读取；如果只需要弱一致性，则可以选择任意副本读取。&lt;/p&gt;
&lt;p&gt;在primary-secondary 协议中，当primary 异常时，需要选择出一个新的primary，之后secondary 副本与primary 同步数据。&lt;/p&gt;
&lt;p&gt;通常情况下，选择新的primary 的工作是由某一中心节点完成的，在引入 quorum 机制后，常用的primary 选择方式与读取数据的方式类似，即中心节点读取R 个副本，选择 R 个副本中版本号最高的副本作为新的primary。新primary 与至少W 个副本完成数据同步后作为新的primary 提供读写服务。&lt;/p&gt;
&lt;p&gt;首先，R 个副本中版本号最高的副本一定蕴含了最新的成功提交的数据。再者，虽然不能确定最高版本号的数是一个成功提交的数据，但新的primary 在随后与secondary 同 步数据，使得该版本的副本个数达到W，从而使得该版本的数据成为成功提交的数据。&lt;/p&gt;
&lt;p&gt;例：在N=5，W=3，R=3 的系统中，某时刻副本最大版本号为（v2 v2 v1 v1 v1），此时v1 是系统的最新的成功提交的数据，v2 是一个处于中间状态的未成功提交的数据。假设此刻原primary 副本异常，中心节点进行primary 切换工作。这类“中间态”数据究竟作为“脏数据”被删除，还是作为新的数据被同步后成为生效的数据，完全取决于这个数据能否参与新primary 的选举。下面分别分析这两种情况。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/64dwe0.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;第一、如图 2-12，若中心节点与其中3 个副本通信成功，读取到的版本号为（v1 v1 v1），则任 选一个副本作为primary，新primary 以v1 作为最新的成功提交的版本并与其他副本同步，当与第1、第2 个副本同步数据时，由于第1、第2 个副本版本号大于primary，属于脏数据，可以按照2.2.2.4 节中介绍的处理脏数据的方式解决。&lt;/p&gt;
&lt;p&gt;实践中，新primary 也有可能与后两个副本完成同步后就提供数据服务，随后自身版本号也更新到v2，如果系统不能保证之后的v2 与之前的v2 完全一样，则新 primary 在与第1、2 个副本同步数据时不但要比较数据版本号还需要比较更新操作的具体内容是否一样。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/64edwq0.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;第二、若中心节点与其他3 个副本通信成功，读取到的版本号为（v2 v1 v1），则选取版本号为 v2 的副本作为新的primary，之后，一旦新primary 与其他2 个副本完成数据同步，则符合v2 的副 本个数达到W 个，成为最新的成功提交的副本，新primary 可以提供正常的读写服务。&lt;/p&gt;
&lt;h2 id=&#34;25-日志技术&#34;&gt;2.5 日志技术&lt;/h2&gt;
&lt;p&gt;日志技术是宕机恢复的主要技术之一。日志技术最初使用在数据库系统中。严格来说日志技术不是一种分布式系统的技术，但在分布式系统的实践中，却广泛使用了日志技术做宕机恢复，甚 至如&lt;code&gt;BigTable&lt;/code&gt;等系统将日志保存到一个分布式系统中进一步增强了系统容错能力。&lt;/p&gt;
&lt;h3 id=&#34;redo-log-与check-point&#34;&gt;Redo Log 与Check point&lt;/h3&gt;
&lt;p&gt;设计一个高速的单机查询系统，将数据全部存放在内存中以实现高速的数据查询，每次更新操作更新一小部分数据（例如 key-value 中的某一个key）。现在问题为利用日志技术实现该内存查询系统的宕机恢复。与数据库的事务不同的是，这个问题模型中的每个成功的更新操作都会生效。这也等效为数据库的每个事务只有一个更新操作，且每次更新操作都可以也必须立即提交（Auto commit）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h5 id=&#34;redo-log&#34;&gt;Redo Log&lt;/h5&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;将更新操作的结果（例如Set K1=1，则记录K1=1）以追加写（append）的方式写入磁盘的 日志文件&lt;/li&gt;
&lt;li&gt;按更新操作修改内存中的数据&lt;/li&gt;
&lt;li&gt;返回更新成功&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从Redo Log 的流程可以看出，Redo 写入日志的是更新操作完成后的结果（虽然本文不讨论Undo Log，这点是与Undo Log 的区别之一），且由于是顺序追加写日志文件，在磁盘等对顺序写有力的存储设备上效率较高。&lt;/p&gt;
&lt;p&gt;用Redo Log 进行宕机恢复非常简单，只需要“回放”日志即可。&lt;/p&gt;
&lt;p&gt;流程2.5.2：Redo Log 的宕机恢复&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从头读取日志文件中的每次更新操作的结果，用这些结果修改内存中的数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从Redo Log 的宕机恢复流程也可以看出，只有写入日志文件的更新结果才能在宕机后恢复。这也是为什么在Redo Log 流程中需要先更新日志文件再更新内存中的数据的原因。&lt;/p&gt;
&lt;p&gt;假如先更新内存中的数据，那么用户立刻就能读到更新后的数据，一旦在完成内存修改与写入日志之间发生宕机，那么最后一次更新操作无法恢复，但之前用户可能已经读取到了更新后的数据，从而引起不一致的问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h5 id=&#34;check-point&#34;&gt;Check point&lt;/h5&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在简化的模型下，check point 技术的过程即将内存中的数据以某种易于重新加载的数据组织方式完整的dump 到磁盘，从而减少宕机恢复时需要回放的日志数据。&lt;/p&gt;
&lt;p&gt;流程：check point&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;向日志文件中记录“Begin Check Point”&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;将内存中的数据以某种易于重新加载的数据组织方式dump 到磁盘上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;向日志文件中记录“End Check Point” 在check point 流程中，数据可以继续按照流程2.5.1 被更新，这段过程中新更新的数据可以dump 到磁盘也可以不dump 到磁盘，具体取决于实现。例如，check point 开始时k1=v1，check point 过程 中某次更新为k1 = v2，那么dump 到磁盘上的k1 的值可以是v1 也可以是v2。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;流程：基于check point 的宕机恢复流程&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将dump 到磁盘的数据加载到内存。&lt;/li&gt;
&lt;li&gt;从后向前扫描日志文件，寻找最后一个“End Check Point”日志。&lt;/li&gt;
&lt;li&gt;从最后一个“End Check Point”日志向前找到最近的一个“Begin Check Point”日志，并回放该日志之后的所有更新操作日志。&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h4 id=&#34;no-undono-redo-log&#34;&gt;No Undo/No Redo log&lt;/h4&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;若数据维护在磁盘中，某批更新由若干个更新操作组成，这些更新操作需要原子生效，即要么同时生效，要么都不生效。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/64fw0.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;0/1 目录技术中有两个目录结构，称为目录0(Directory 0)和目录1(Directory 1)。另有一个结构称为主记录（Master record）记录当前正在使用的目录称为活动目录。主记录中要么记录使用目录0，要么记录使用目录1。目录0 或目录1 中记录了各个数据的在日志文件中的位置。0/1 目录的数据更新过程始终在非活动目录上进行，只是在数据生效前，将主记录中的0、1 值反转，从而切换主记录。&lt;/p&gt;
&lt;p&gt;流程：0/1 目录数据更新流程&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将活动目录完整拷贝到非活动目录。&lt;/li&gt;
&lt;li&gt;对于每个更新操作，新建一个日志项纪录操作后的值，并在非活动目录中将相应数据的位置修改为新建的日志项的位置。&lt;/li&gt;
&lt;li&gt;原子性修改主记录：反转主记录中的值，使得非活动目录生效。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;0/1 目录的更新流程非常简单，通过0、1 目录的主记录切换使得一批修改的生效是原子的。0/1 目录将批量事务操作的原子性通过目录手段归结到主记录的原子切换。&lt;/p&gt;
&lt;p&gt;由于多条记录的原子修改一般较难实现而单条记录的原子修改往往可以实现，从而降低了问题实现的难度。&lt;/p&gt;
&lt;p&gt;在工程中0/1 目录的思想运用非常广泛，其形式也不局限在上述流程中，可以是内存中的两个数据结构来回切换，也可以是磁盘上的两个文件目录来回生效切换。&lt;/p&gt;
&lt;h2 id=&#34;26-两阶段提交协议&#34;&gt;2.6 两阶段提交协议&lt;/h2&gt;
&lt;p&gt;两阶段提交协议是一种经典的强一致性中心化副本控制协议。虽然在工程中该协议有较多的问题，但研究该协议能很好的理解分布式系统的几个典型问题。&lt;/p&gt;
&lt;h3 id=&#34;流程描述&#34;&gt;流程描述&lt;/h3&gt;
&lt;p&gt;两阶段提交协议是一种典型的“中心化副本控制”协议。在该协议中，参与的节点分为两类：一个中心化协调者节点（coordinator）和N 个参与者节点（participant）。每个参与者节点即上文背景介绍中的管理数据库副本的节点。&lt;/p&gt;
&lt;p&gt;两阶段提交的思路比较简单，在第一阶段，协调者询问所有的参与者是否可以提交事务（请参与者投票），所有参与者向协调者投票。&lt;/p&gt;
&lt;p&gt;在第二阶段，协调者根据所有参与者的投票结果做出是否事务可以全局提交的决定，并通知所有的参与者执行该决定。在一个两阶段提交流程中，参与者不能改变自己的投票结果。&lt;/p&gt;
&lt;p&gt;两阶段提交协议的可以全局提交的前提是所有的参与者都同意提交事务，只要有一个参与者投票选择放弃(abort)事务，则事务必须被放弃。&lt;/p&gt;
&lt;p&gt;流程：两阶段提交&lt;strong&gt;协调者流程&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;写本地日志“begin_commit”，并进入WAIT 状态；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;向所有参与者发送“prepare 消息”；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;等待并接收参与者发送的对“prepare 消息”的响应；&lt;/p&gt;
&lt;p&gt;3.1 若收到任何一个参与者发送的“vote-abort 消息”；&lt;/p&gt;
&lt;p&gt;3.1.1 写本地“global-abort”日志，进入ABORT；&lt;/p&gt;
&lt;p&gt;3.1.2 向所有的参与者发送“global-abort 消息”；&lt;/p&gt;
&lt;p&gt;3.1.3 进入ABORT 状态；&lt;/p&gt;
&lt;p&gt;3.2 若收到所有参与者发送的“vote-commit”消息；&lt;/p&gt;
&lt;p&gt;3.2.1 写本地“global-commit”日志，进入COMMIT 状态；&lt;/p&gt;
&lt;p&gt;3.1.2 向所有的参与者发送“global-commit 消息”；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;等待并接收参与者发送的对“global-abort 消息”或“global-commit 消息”的确认响应消息，一旦收到所有参与者的确认消息，写本地“end_transaction” 日志流程结束。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;流程：两阶段提交协调者流程&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;写本地日志“&lt;code&gt;init&lt;/code&gt;”记录，进入INIT 状态&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;等待并接受协调者发送的“prepare 消息”，收到后&lt;/p&gt;
&lt;p&gt;2.1 若参与者可以提交本次事务&lt;/p&gt;
&lt;p&gt;2.1.1 写本地日志“ready”，进入READY 状态&lt;/p&gt;
&lt;p&gt;2.1.2 向协调者发送“vote-commit”消息&lt;/p&gt;
&lt;p&gt;2.1.4 等待协调者的消息&lt;/p&gt;
&lt;p&gt;2.1.4.1 若收到协调者的“global-abort”消息&lt;/p&gt;
&lt;p&gt;2.1.4.1.1 写本地日志“abort”，进入ABORT 状态&lt;/p&gt;
&lt;p&gt;2.1.4.1.2 向协调者发送对“global-abort”的确认消息&lt;/p&gt;
&lt;p&gt;2.1.4.2 若收到协调者的“global-commit”消息&lt;/p&gt;
&lt;p&gt;2.1.4.1.1 写本地日志“commit”，进入COMMIT 状态&lt;/p&gt;
&lt;p&gt;2.1.4.1.2 向协调者发送对“global-commit”的确认消息  2.2 若参与者无法提交本次事务 2.2.1 写本地日志“abort”，进入ABORT 状态&lt;/p&gt;
&lt;p&gt;2.2.2 向协调者发送“vote-abort”消息&lt;/p&gt;
&lt;p&gt;2.2.3 流程对该参与者结束&lt;/p&gt;
&lt;p&gt;2.2.4 若后续收到协调者的“global-abort”消息可以响应&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;即使流程结束，但任何时候收到协调者发送的“global-abort”消息或“global-commit”消息也都要发送一个对应的确认消息。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;异常处理&#34;&gt;异常处理&lt;/h3&gt;
&lt;h5 id=&#34;宕机恢复&#34;&gt;宕机恢复&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;协调者宕机恢复&lt;/p&gt;
&lt;p&gt;协调者宕机恢复后，首先通过日志查找到宕机前的状态。如果日志中最后是“begin_commit”记录，说明宕机前协调者处于WAIT 状态，协调者可能已经发送过“prepare 消息”也可能还没发送，但协调者一定还没有发送过“global-commit 消息”或“global-abort 消息”，即事务的全局状态还没有确定。此时，协调者可以重新发送“prepare 消息” 继续两阶段提交流程，即使参与者已经发送过对“prepare 消息”的响应，也不过是再次重传之前的响应而不会影响协议的一致性。&lt;/p&gt;
&lt;p&gt;如果日志中最后是“global-commit”或“global-abort”记录，说明宕机前协调者处于COMMIT 或ABORT 状态。此时协调者只需重新向所有的参与者发送“global-commit 消息”或“global-abort 消息”就可以继续两阶段提交流程。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;参与者宕机恢复参与者宕机恢复后，首先通过日志查找宕机前的状态。如果日志中最后是“&lt;code&gt;init&lt;/code&gt;”记录，说明参与者处于INIT 状态，还没有对本次事务做出投票选择，参与者可以继续流程等待协调者发送的“prepare 消息”。&lt;/p&gt;
&lt;p&gt;如果日志中最后是“ready”记录，说明参与者处于REDAY 状态，此时说明参与者已经就本次 事务做出了投票选择，但宕机前参与者是否已经向协调者发送“vote-commit”消息并不可知。所以此时参与者可以向协调者重发“vote-commit”，并继续协议流程。如果日志中最后是“commit”或“abort”记录，说明参与者已经收到过协调者的“global-commit 消息”（处于COMMIT 状态）或者“global-abort 消息”（处于ABORT 状态）。至于是否向协调者发 送过对“global-commit”或“global-abort”的确认消息则未知。但即使没有发送过确认消息，由于协调者会不断重发“global-commit”或“global-abort”，只需在收到这些消息时发送确认消息既可，不影响协议的全局一致性。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;协议分析&#34;&gt;协议分析&lt;/h3&gt;
&lt;p&gt;两阶段提交协议在工程实践中真正使用的较少，主要原因有以下几点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;两阶段提交协议的容错能力较差。从上文的分析可以看出，两阶段提交协议在某些情况下存在流程无法执行下去的情况，且也无法判断流程状态。在工程中好的分布式协议往往总是可以在即使发生异常的情况下也能执行下去。例如，回忆Lease 机制（2.3 ），一旦lease 发出，无论出现任何异常，Lease 服务器节点总是可以通过时间判定出Lease 是否有效，也可以用等待Lease 超时的方法收回Lease 权限，整个Lease 协议的流程不存在任何流程被阻塞而无法执行下去的情况。与Lease 机制的简单有效相比，两阶段提交的协议显得较为复杂且容错能力差。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;两阶段提交协议的性能较差。一次成功的两阶段提交协议流程中，协调者与每个参与者 之间至少需要两轮交互4 个消息“prepare”、“vote-commit”、“global-commit”、“确认global-commit”。过多的交互次数会降低性能。另一方面，协调者需要等待所有的参与者的投票结果，一旦存在较慢的参与者，会影响全局流程执行速度。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;虽然存在一些改进的两阶段提交协议可以提高容错能力和性能，然而这类协议依旧是在工程中使用较少的一类协议，其理论价值大于实践意义。&lt;/p&gt;
&lt;h2 id=&#34;27-mvcc&#34;&gt;2.7 MVCC&lt;/h2&gt;
&lt;p&gt;MVCC(Multi-version &lt;code&gt;Cocurrent&lt;/code&gt;Control，多版本并发控制)技术。MVCC 技术最初也是在数据库系统中被提出，但这种思想并不局限于单机系统，在分布式系统中同样有效。&lt;/p&gt;
&lt;p&gt;MVCC 即多个不同版本的数据实现并发控制的技术，其基本思想是为每次事务生成 一个新版本的数据，在读数据时选择不同版本的数据即可以实现对事务结果的完整性读取。在使用MVCC 时，每个事务都是基于一个已生效的基础版本进行更新，事务可以并行进行，从而可以产生一种图状结构。&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/64ewewe0.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;基础数据的版本为1，同时产生了两个事务：事务A 与事务B。这两个事务都各自对数据进行了一些本地修改（这些修改只有事务自己可见，不影响真正的数据），之后事务A 首先提交，生成数据版本2；基于数据版本2，又发起了事务C，事务C 继续提交，生成了数据版 本3；最后事务B 提交，此时事务B 的结果需要与事务C 的结果合并，如果数据没有冲突，即事务 B 没有修改事务A 与事务C 修改过的变量，那么事务B 可以提交，否则事务B 提交失败。MVCC 的流程过程非常类似于SVN 等版本控制系统的流程，或者说SVN 等版本控制系统就是 使用的MVCC 思想。事务在基于基础数据版本做本地修改时，为了不影响真正的数据，通常有两种做法，&lt;/p&gt;
&lt;p&gt;一是将基础数据版本中的数据完全拷贝出来再修改，SVN 即使用了这种方法，SVN check out 即是拷贝的过程；二是每个事务中&lt;strong&gt;只记录更新操作&lt;/strong&gt;，而不记录完整的数据，读取数据时再将更新操作应用到用基础版本的数据从而计算出结果，这个过程也类似&lt;strong&gt;SVN 的增量提交&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;28-paxos协议&#34;&gt;2.8 &lt;code&gt;Paxos&lt;/code&gt;协议&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Paxos&lt;/code&gt;协议是少数在工程实践中证实的强一致性、高可用的去中心化分布式协议。&lt;code&gt;Paxos&lt;/code&gt;协议的流程较为复杂，但其基本思想却不难理解，类似于人类社会的投票过程。&lt;code&gt;Paxos&lt;/code&gt;协议中，有一组完全对等的参与节点（称为&lt;code&gt;accpetor&lt;/code&gt;），这组节点各自就某一事件做出决议，如果某个决议获得了超过半数节点的同意则生效。&lt;code&gt;Paxos&lt;/code&gt;协议中只要有超过一半的节点正常，就可以工作，能很好对抗宕机、网络分化等异常情况。&lt;/p&gt;
&lt;h3 id=&#34;角色&#34;&gt;角色&lt;/h3&gt;
&lt;p&gt;Proposer：提案者。&lt;/p&gt;
&lt;p&gt;Proposer 可以有多个，Proposer 提出议案（value）。所谓value，在工程中可以是任何操作，例如“修改某个变量的值为某个值”、“设置当前primary 为某个节点”等等。&lt;code&gt;Paxos&lt;/code&gt;协议中统一将这些操作抽象为value。不同的Proposer 可以提出不同的甚至矛盾的value，例如某个Proposer 提议“将变量X 设置为1”，另一个Proposer 提议“将变量X 设置为2”，但对同一轮&lt;code&gt;Paxos&lt;/code&gt; 过程，最多只有一个value 被批准。&lt;/p&gt;
&lt;p&gt;Acceptor：批准者。&lt;/p&gt;
&lt;p&gt;Acceptor 有N 个，Proposer 提出的value 必须获得超过半数(N/2+1)的Acceptor 批准后才能通过。Acceptor 之间完全对等独立。&lt;/p&gt;
&lt;p&gt;Learner：学习者。&lt;/p&gt;
&lt;p&gt;Learner 学习被批准的value。所谓学习就是通过读取各个Proposer 对value 的选择结果，如果某个value 被超过半数Proposer 通过，则Learner 学习到了这个value。回忆（2.4 ） 不难理解，这里类似Quorum 机制，某个value 需要获得W=N/2 + 1 的Acceptor 批准，从而学习者需要至少读取N/2+1 个&lt;code&gt;Accpetor&lt;/code&gt;，至多读取N 个Acceptor 的结果后，能学习到一个通过的value。上述三类角色只是逻辑上的划分，实践中一个节点可以同时充当这三类角色。&lt;/p&gt;
&lt;h3 id=&#34;流程&#34;&gt;流程&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Paxos&lt;/code&gt;协议一轮一轮的进行，每轮都有一个编号。每轮&lt;code&gt;Paxos&lt;/code&gt;协议可能会批准一个value，也可 能无法批准一个value。如果某一轮&lt;code&gt;Paxos&lt;/code&gt;协议批准了某个value，则以后各轮&lt;code&gt;Paxos&lt;/code&gt; 只能批准这个 value。上述各轮协议流程组成了一个&lt;code&gt;Paxos&lt;/code&gt;协议实例，即一次&lt;code&gt;Paxos&lt;/code&gt;协议实例只能批准一个value，这也是&lt;code&gt;Paxos&lt;/code&gt;协议强一致性的重要体现。每轮&lt;code&gt;Paxos&lt;/code&gt;协议分为阶段，准备阶段和批准阶段，在这两个阶段Proposer 和Acceptor 有各自的处理流程。&lt;/p&gt;
&lt;p&gt;流程：Proposer 的流程 （准备阶段）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;向所有的Acceptor 发送消息“Prepare(b)”；这里b 是&lt;code&gt;Paxos&lt;/code&gt;的轮数，每轮递增&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果收到任何一个Acceptor 发送的消息“Reject(B)”，则对于这个Proposer 而言本轮&lt;code&gt;Paxos&lt;/code&gt;失败，将轮数b 设置为B+1 后重新步骤1；（批准阶段，根据收到的Acceptor 的消息作出不同选择）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果接收到的Acceptor 的“Promise(b, &lt;code&gt;v_i&lt;/code&gt;)”消息达到N/2+1 个（N 为Acceptor 总数，除法取整， 下同）；&lt;code&gt;v_i&lt;/code&gt;表示Acceptor 最近一次在&lt;code&gt;i&lt;/code&gt;轮批准过value v。&lt;/p&gt;
&lt;p&gt;3.1 如果收到的“Promise(b, v)”消息中，v 都为空，Proposer 选择一个value v，向所有Acceptor 广播Accept(b, v)；&lt;/p&gt;
&lt;p&gt;3.2 否则，在所有收到的“Promise(b, &lt;code&gt;v_i&lt;/code&gt;)”消息中，选择&lt;code&gt;i&lt;/code&gt;最大的value v，向所有Acceptor 广播消息Accept(b，v)；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果收到&lt;code&gt;Nack&lt;/code&gt;(B)，将轮数b 设置为B+1 后重新步骤1；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;流程：&lt;code&gt;Accpetor&lt;/code&gt;流程 （准备阶段）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;接受某个&lt;code&gt;Propeser&lt;/code&gt;的消息Prepare(b)。参数B 是该Acceptor 收到的最大&lt;code&gt;Paxos&lt;/code&gt;轮数编号；V 是Acceptor 批准的value，可以为空&lt;/p&gt;
&lt;p&gt;1.1 如果b&amp;gt;B，回复Promise(b, V_B)，设置B=b; 表示保证不再接受编号小于b 的提案。\&lt;/p&gt;
&lt;p&gt;1.2 否则，回复Reject(B) （批准阶段）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;接收Accept(b, v)，&lt;/p&gt;
&lt;p&gt;2.1 如果b &amp;lt; B, 回复&lt;code&gt;Nack&lt;/code&gt;(B)，暗示proposer 有一个更大编号的提案被这个Acceptor 接收了&lt;/p&gt;
&lt;p&gt;2.2 否则设置V=v。表示这个Acceptor 批准的Value 是v。广播Accepted 消息。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;例子&#34;&gt;例子&lt;/h3&gt;
&lt;p&gt;基本例子里有5 个Acceptor，1 个Proposer，不存在任何网络、宕机异常。我们着重考察各个&lt;code&gt;Accpetor&lt;/code&gt;上变量B 和变量V 的变化，及Proposer 上变量b 的变化。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;初始状态&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Proposer 向所有&lt;code&gt;Accpetor&lt;/code&gt;发送“Prepare(1)”，所有Acceptor 正确处理，并回复Promise(1, NULL&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640csda.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Proposer 收到5 个Promise(1, NULL)，满足多余半数的Promise 的value 为空，此时发送 Accept(1, v1)，其中v1 是Proposer 选择的Value。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/64wewqeqw0.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;此时，v1 被超过半数的Acceptor 批准，v1 即是本次&lt;code&gt;Paxos&lt;/code&gt; 协议实例批准的Value。如果Learner 学习value，学到的只能是v1&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在同一个&lt;code&gt;Paxos&lt;/code&gt;实例中，批准的Value 是无法改变的，即使后续Proposer 以更高的序号发起&lt;code&gt;Paxos&lt;/code&gt;协议也无法改变value。&lt;code&gt;Paxos&lt;/code&gt;协议的核心就在于“批准的value 无法改变”，这也是整个协议正确性的基础。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Paxos&lt;/code&gt;协议是被人为设计出来，其设计过程也是协议的推导过程。&lt;code&gt;Paxos&lt;/code&gt;协议利用了&lt;code&gt;Quorom&lt;/code&gt;机 制，选择的W=R=N/2+1。&lt;/p&gt;
&lt;p&gt;简单而言，协议就是Proposer 更新Acceptor 的过程，一旦某个Acceptor 成功更新了超过半数的Acceptor，则更新成功。Learner 按Quorum 去读取Acceptor，一旦某个value 在超过半数的Proposer 上被成功读取，则说明这是一个被批准的value。协议通过引入轮次，使得高轮次的提议抢占低轮次的提议来避免死锁。协议设计关键点是如何满足“在一次&lt;code&gt;Paxos&lt;/code&gt;算法实例过程中只批准一个Value”这一约束条件。&lt;/p&gt;
&lt;h2 id=&#34;29-cap&#34;&gt;2.9 CAP&lt;/h2&gt;
&lt;p&gt;CAP 理论的定义很简单，CAP 三个字母分别代表了分布式系统中三个相互矛盾的属性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Consistency (一致性)：CAP 理论中的副本一致性特指强一致性（1.3.4 ）；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;Availiablity&lt;/code&gt;(可用性)：指系统在出现异常时已经可以提供服务；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tolerance to the partition of network (分区容忍)：指系统可以对网络分区（1.1.4.2 ）这种异常情 况进行容错处理；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CAP 理论指出：无法设计一种分布式协议，使得同时完全具备CAP 三个属性，即&lt;/p&gt;
&lt;p&gt;1)该种协议下的副本始终是强一致性，&lt;/p&gt;
&lt;p&gt;2)服务始终是可用的，&lt;/p&gt;
&lt;p&gt;3)协议可以容忍任何网络分区异常；&lt;/p&gt;
&lt;p&gt;分布式系统协议只能在CAP 这三者间所有折中。&lt;/p&gt;
&lt;p&gt;热力学第二定律说明了永动机是不可能存在的，不要去妄图设计永动机。与之类似，CAP 理论的意义就在于明确提出了不要去妄图设计一种对CAP 三大属性都完全拥有的完美系统，因为这种系统在理论上就已经被证明不存在。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lease 机制: Lease 机制牺牲了部分异常情况下的A，从而获得了完全的C 与很好的P。&lt;/li&gt;
&lt;li&gt;Quorum 机制: Quorum 机制，在CAP 三大因素中都各做了折中，有一定的C，有较好的A，也有较好的P，是一种较为平衡的分布式协议。&lt;/li&gt;
&lt;li&gt;两阶段提交协议: 两阶段提交系统具有完全的C，很糟糕的A，很糟糕的P。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Paxos&lt;/code&gt;协议：同样是强一致性协议，&lt;code&gt;Paxos&lt;/code&gt; 在CAP 三方面较之两阶段提交协议要优秀得多。&lt;code&gt;Paxos&lt;/code&gt;协议具有 完全的C，较好的A，较好的P。&lt;code&gt;Paxos&lt;/code&gt;的A 与P 的属性与Quorum 机制类似，因为&lt;code&gt;Paxos&lt;/code&gt;的协议本 身就具有Quorum 机制的因素。&lt;/li&gt;
&lt;/ul&gt;
">分布式系统原理</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/fengbushiwu/"" data-c="
          &lt;h1 id=&#34;分布式事务&#34;&gt;分布式事务&lt;/h1&gt;
&lt;p&gt;分布式事务用于在分布式系统中保证&lt;strong&gt;不同节点之间的数据一致性&lt;/strong&gt;。假设没有分布式事务，如果存在库存和订单两个独立的微服务，每个微服务维护了自己的数据库。在交易系统的业务逻辑中，一个商品在下单之前需要先调用库存服务，进行扣除库存，再调用订单服务，创建订单记录。正常情况下，两个数据库各自更新成功，两边数据维持着一致性但是，在非正常情况下，有可能库存的扣减完成了，随后的订单记录却因为某些原因插入失败。这个时候，两边数据就失去了应有的一致性。&lt;/p&gt;
&lt;h1 id=&#34;xa分布式事务协议&#34;&gt;XA分布式事务协议&lt;/h1&gt;
&lt;h2 id=&#34;两阶段提交2pc&#34;&gt;两阶段提交（2PC）&lt;/h2&gt;
&lt;p&gt;XA协议包含两阶段提交（2PC）和三阶段提交（3PC）两种实现。在XA协议中包含着两个角色：事务协调者和事务参与者。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboard-1577177523915.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;在XA分布式事务的第一阶段，作为事务协调者的节点会首先向所有的参与者节点发送Prepare请求。&lt;/p&gt;
&lt;p&gt;在接到Prepare请求之后，&lt;strong&gt;每一个参与者节点会各自执行与事务有关的数据更新&lt;/strong&gt;，&lt;strong&gt;写入Undo Log和Redo Log&lt;/strong&gt;。如果参与者执行成功，暂时不提交事务，而是向事务协调节点返回“完成”消息。&lt;/p&gt;
&lt;p&gt;当事务协调者接到了所有参与者的返回消息，整个分布式事务将会进入第二阶段。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboard-1577177536302.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;在XA分布式事务的第二阶段，如果事务协调节点在之前所收到都是正向返回，那么它将会向所有事务参与者发出Commit请求。&lt;/p&gt;
&lt;p&gt;接到Commit请求之后，事务参与者节点会各自进行本地的事务提交，并释放锁资源。当本地事务完成提交后，将会向事务协调者返回“完成”消息。&lt;/p&gt;
&lt;p&gt;当事务协调者接收到所有事务参与者的“完成”反馈，整个分布式事务完成。&lt;/p&gt;
&lt;p&gt;失败情况的处理流程：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboard-1577177546219.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboard-1577177556166.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;在XA的第一阶段，如果某个事务参与者反馈失败消息，说明该节点的本地事务执行不成功，必须回滚。&lt;/p&gt;
&lt;p&gt;于是在第二阶段，事务协调节点向所有的事务参与者发送Abort请求。接收到Abort请求之后，各个事务参与者节点需要在本地进行事务的回滚操作，回滚操作依照Undo Log来进行。&lt;/p&gt;
&lt;p&gt;XA两阶段提交的不足：&lt;/p&gt;
&lt;p&gt;1.性能问题&lt;/p&gt;
&lt;p&gt;XA协议遵循强一致性。在事务执行过程中，&lt;strong&gt;各个节点占用着数据库资源&lt;/strong&gt;，只有当所有节点准备完毕，事务协调者才会通知提交，参与者提交后释放资源。这样的过程有着非常明显的性能问题。&lt;/p&gt;
&lt;p&gt;2.协调者单点故障问题&lt;/p&gt;
&lt;p&gt;事务协调者是整个XA模型的核心，一旦事务协调者节点挂掉，参与者收不到提交或是回滚通知，参与者会一直处于中间状态无法完成事务。&lt;/p&gt;
&lt;p&gt;3.丢失消息导致的不一致问题。&lt;/p&gt;
&lt;p&gt;在XA协议的第二个阶段，如果发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就导致了节点之间数据的不一致。&lt;/p&gt;
&lt;h2 id=&#34;xa三阶段提交&#34;&gt;&lt;strong&gt;XA三阶段提交&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;XA三阶段提交在两阶段提交的基础上增加了&lt;code&gt;CanCommit&lt;/code&gt;阶段，并且引入了&lt;strong&gt;超时机制&lt;/strong&gt;。一旦事物参与者迟迟没有接到协调者的commit请求，会自动进行本地commit。这样有效解决了协调者单点故障的问题。但是性能问题和不一致的问题仍然没有根本解决。&lt;/p&gt;
&lt;p&gt;阶段一：&lt;code&gt;canCommit&lt;/code&gt;：只是询问所有参与者是否可可以执行事务操作，并不在本阶段执行事务操作。&lt;/p&gt;
&lt;p&gt;阶段二：&lt;code&gt;preCommit&lt;/code&gt;：执行事务操作；&lt;/p&gt;
&lt;p&gt;阶段三：&lt;code&gt;doCommit&lt;/code&gt;：执行commit或者rollback，如果参与者无法及时接收到来自协调者的&lt;code&gt;doCommit&lt;/code&gt;或者&lt;code&gt;rebort&lt;/code&gt;请求时，会在等待超时之后，会继续进行事务的提交。&lt;/p&gt;
&lt;p&gt;存在的问题：由于网络原因，协调者发送的&lt;strong&gt;abort响应&lt;/strong&gt;没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。&lt;/p&gt;
&lt;h1 id=&#34;mq事务&#34;&gt;&lt;strong&gt;MQ事务&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;利用消息中间件来异步完成事务的后一半更新，实现系统的最终一致性。这个方式避免了像XA协议那样的性能问题。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboard-1577177567628.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;执行步骤如下:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MQ发送方发送远程事务消息到MQ Server;&lt;/li&gt;
&lt;li&gt;MQ Server给予响应, 表明事务消息已成功到达MQ Server.&lt;/li&gt;
&lt;li&gt;MQ发送方Commit本地事务
&lt;ul&gt;
&lt;li&gt;若本地事务Commit成功, 则通知MQ Server&lt;strong&gt;允许对应事务消息被消费&lt;/strong&gt;;&lt;/li&gt;
&lt;li&gt;若本地事务失败, 则通知MQ Server对&lt;strong&gt;应事务消息应被丢弃&lt;/strong&gt;;&lt;/li&gt;
&lt;li&gt;如果消息投递失败，该事务也应该回滚；&lt;/li&gt;
&lt;li&gt;若MQ发送方超时未对MQ Server作出本地事务执行状态的反馈, 那么需要MQ Server向MQ&lt;strong&gt;发送方主动回查事务状态&lt;/strong&gt;, 以决定事务消息是否能被消费.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;当得知本地事务执行成功时, MQ Server允许MQ订阅方消费本条事务消息.&lt;/li&gt;
&lt;li&gt;需要额外说明的一点, 就是事务消息投递到MQ订阅方后, 并不一定能够成功执行， 需要MQ订阅方主动给予消费反馈(ack)；
&lt;ul&gt;
&lt;li&gt;如果MQ订阅方执行远程事务成功, 则给予消费成功的ack, 那么MQ Server可以安全将事务消息&lt;strong&gt;移除&lt;/strong&gt;;&lt;/li&gt;
&lt;li&gt;如果消费者宕机或者消费执行失败, MQ Server利用持久化消息的功能需要对消息&lt;strong&gt;重新投递&lt;/strong&gt;, &lt;strong&gt;直至消费成功；&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;注意事项&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;消息中间件在系统中扮演一个重要的角色, 所有的事务消息都需要通过它来传达, 所以消息中间件也需要支持 HAC 来确保事务消息不丢失.&lt;/p&gt;
&lt;p&gt;根据业务逻辑的具体实现不同，还可能需要对消息中间件增加消息不重复, 不乱序等其它要求.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;保证消费者的幂等性；也就是说如果队列中的消息因为网络异常导致发送多次的情况下，仍然需要保证&lt;strong&gt;消息被应用多次与应用一次产生的效果是一样的&lt;/strong&gt;；&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;通过消费日志表来记录消费状态；增加一个message_applied（msg_id）表，用来&lt;strong&gt;记录已经被成功应用的消息&lt;/strong&gt;。在&lt;strong&gt;目标系统执行更新操作之前，先检测该消息是否已经被消费过，消费完成后通过本地事务控制来更新这个“消费表状态”，用来避免消息重复消费问题&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;适用场景&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;执行周期较长、实时性要求不高&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;跨行转账/汇款业务(两个服务分别在不同的银行中)&lt;/li&gt;
&lt;li&gt;退货/退款业务&lt;/li&gt;
&lt;li&gt;财务, 账单统计业务(先发送到消息中间件, 然后进行批量记账)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;mq事务的高可用方案&#34;&gt;MQ事务的高可用方案&lt;/h2&gt;
&lt;p&gt;虽然MQ本身时高可用的，但是意外也会发生，一旦MQ完全不可用，就会导致业务系统的各个服务之间无法通过MQ来投递消息，导致业务流程中断。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191224172912171.png&#34; alt=&#34;image-20191224172912171&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;1-基于kv存储的队列支持的高可用降级方案&#34;&gt;1、基于KV存储的队列支持的高可用降级方案&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;自行封装MQ客户端组件与故障感知，完成自动降级，比如连续10次尝试投递消息到MQ都发现异常报错，说明MQ故障，此时就可以自动感知以及自动触发降级开关&lt;/li&gt;
&lt;li&gt;可以利用Redis的List结构来代替MQ
&lt;ul&gt;
&lt;li&gt;写入的数据量不要过大，否则会引发严重后果&lt;/li&gt;
&lt;li&gt;不能忘少数几个key中持续写入数据，那样会导致数据热点，使某台机器访问过高，负载过大。可以设计多个key，然后通过hash算法均匀写入&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2、下游服务消费MQ的降级感知&lt;/p&gt;
&lt;p&gt;如果下游的MQ从&lt;code&gt;zk&lt;/code&gt;感知到降级开关打开了，首先就会判断自己能否还能继续从MQ消费到数据，如果不能就开启多个线程并发地从&lt;code&gt;kv&lt;/code&gt;存储的各个队列中不断的获取数据，然后执行&lt;/p&gt;
&lt;p&gt;3、故障的自动恢复&lt;/p&gt;
&lt;p&gt;每隔一段时间尝试给MQ投递消息，看看是否恢复了，如果MQ已经恢复就可以通过&lt;code&gt;zk&lt;/code&gt;关闭降级开关，在确认Redis没有消息之后，完全切换到MQ&lt;/p&gt;
&lt;h1 id=&#34;tcc事务&#34;&gt;&lt;strong&gt;TCC事务&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;TCC事务是Try、Commit、Cancel三种指令的缩写，其逻辑模式类似于XA两阶段提交，但是实现方式是在代码层面来人为实现。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboard-1583055043254.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191224170622409.png&#34; alt=&#34;image-20191224170622409&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;TCC分为三个阶段TRY-CONFIRM-CANCEL。每个阶段做不同的处理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Try&lt;/strong&gt;: 尝试执行业务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​                 • 完成所有业务检查(一致性)&lt;/p&gt;
&lt;p&gt;​                 • &lt;strong&gt;预留必须业务资源&lt;/strong&gt;(准隔离性)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Confirm&lt;/strong&gt;:确认执行业务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​                 • 真正执行业务&lt;/p&gt;
&lt;p&gt;​                 • 不作任何业务检查&lt;/p&gt;
&lt;p&gt;​                 • 只使用Try阶段预留的业务资源&lt;/p&gt;
&lt;p&gt;​                 • Confirm操作要满足幂等性&lt;/p&gt;
&lt;p&gt;TRYI阶段执行成功并开始执行CONFIRM阶段时，默认 CONFIRM阶段是不会出错的。即：只要TRY成功，CONFIRM一定成功。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Cancel&lt;/strong&gt;: 取消执行业务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​                 • 释放Try阶段预留的业务资源&lt;/p&gt;
&lt;p&gt;​                 • Cancel操作要满足幂等性&lt;/p&gt;
&lt;p&gt;以上所有的操作需要满足幂等性，幂等性的定义是：一次和多次请求某一个资源&lt;strong&gt;对于资源本身&lt;/strong&gt;应该具有同样的结果（网络超时等问题除外）。也就是说，&lt;strong&gt;其任意多次执行对资源本身所产生的影响均与一次执行的影响相同&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;幂等性的实现方式可以是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1、通过唯一键值做处理，即每次调用的时候传入唯一键值，通过唯一键值判断业务是否被操作，如果已被操作，则不再重复操作&lt;/li&gt;
&lt;li&gt;2、通过状态机处理，给业务数据设置状态，通过业务状态判断是否需要重复执行&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;p&gt;支付系统接收到会员的支付请求后，需要扣减会员账户余额、增加会员积分（暂时假设需要同步实现）增加商户账户余额，会员系统、商户系统、积分系统是独立的三个子系统，无法通过传统的事务方式进行处理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;TRYING阶段：我们需要做的就是会员资金账户的资金预留，即：冻结会员账户的金额（订单金额）&lt;/li&gt;
&lt;li&gt;CONFIRMING阶段：我们需要做的就是会员积分账户增加积分余额，商户账户增加账户余额&lt;/li&gt;
&lt;li&gt;CANCELING阶段：该阶段需要执行的就是解冻释放我们扣减的会员余额&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;开源的&lt;code&gt;tcc&lt;/code&gt;框架：&lt;code&gt;tcc&lt;/code&gt;-transaction、&lt;code&gt;bytetcc&lt;/code&gt;&lt;/p&gt;
">分布式事务</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/fenkufenbiao/"" data-c="
          &lt;p&gt;&lt;strong&gt;（1）为什么要分库分表？（设计高并发系统的时候，数据库层面该如何设计？）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;分库分表一定是为了支撑高并发、数据量大两个问题的。&lt;/p&gt;
&lt;p&gt;单表数据量太大，会极大影响你的sql执行的性能，到了后面你的sql可能就跑的很慢了。一般来说，单表到几百万的时候，性能就会相对差一些了。&lt;/p&gt;
&lt;p&gt;一个库一般我们经验而言，最多支撑到并发2000，一定要扩容了，而且一个健康的单库并发值你最好保持在每秒1000左右，不要太大。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;（2）用过哪些分库分表中间件？不同的分库分表中间件都有什么优点和缺点？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;比较常见的包括：&lt;code&gt;cobar、TDDL、atlas、sharding-jdbc、mycat&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;cobar&lt;/code&gt;：阿里b2b团队开发和开源的，属于proxy层方案。早些年还可以用，但是最近几年都没更新了，基本没啥人用，差不多算是被抛弃的状态吧。而且不支持读写分离、存储过程、跨库join和分页等操作。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;TDDL：淘宝团队开发的，属于client层方案。不支持join、多表查询等语法，就是基本的crud语法是ok，但是支持读写分离。目前使用的也不多，因为还依赖淘宝的diamond配置管理系统。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;atlas：360开源的，属于proxy层方案，以前是有一些公司在用的，但是确实有一个很大的问题就是社区最新的维护都在5年前了。所以，现在用的公司基本也很少了。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;sharding-jdbc&lt;/code&gt;：当当开源的，属于client层方案。确实之前用的还比较多一些，因为SQL语法支持也比较多，没有太多限制，而且目前推出到了2.0版本，支持分库分表、读写分离、分布式id生成、柔性事务（最大努力送达型事务、TCC事务）。而且确实之前使用的公司会比较多一些（这个在官网有登记使用的公司，可以看到从2017年一直到现在，是不少公司在用的），目前社区也还一直在开发和维护，还算是比较活跃，个人认为算是一个现在也可以选择的方案。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;myca&lt;/code&gt;t：基于&lt;code&gt;cobar&lt;/code&gt;改造的，属于proxy层方案，支持的功能非常完善，而且目前应该是非常火的而且不断流行的数据库中间件，社区很活跃，也有一些公司开始在用了。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;（3）你们具体是如何对数据库如何进行垂直拆分或水平拆分的？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据库分布式核心内容无非就是数据切分（&lt;code&gt;Sharding&lt;/code&gt;），以及切分后对数据的定位、整合。&lt;/p&gt;
&lt;p&gt;数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库操作性能的目的。&lt;/p&gt;
&lt;p&gt;数据切分根据其切分类型，可以分为两种方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;垂直（纵向）切分&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;水平（横向）切分&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;垂直纵向切分&#34;&gt;&lt;strong&gt;垂直（纵向）切分&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;垂直分库&#34;&gt;垂直分库&lt;/h3&gt;
&lt;p&gt;垂直分库就是根据业务耦合性，将&lt;strong&gt;关联度低&lt;/strong&gt;的不同表存储在不同的数据库。做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。&lt;/p&gt;
&lt;p&gt;与&amp;quot;微服务治理&amp;quot;的做法相似，每个微服务使用单独的一个数据库，如下图：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218111935341.png&#34; alt=&#34;image-20191218111935341&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;垂直分表&#34;&gt;垂直分表&lt;/h3&gt;
&lt;p&gt;垂直分表是基于数据库中的&amp;quot;列&amp;quot;进行，某个表字段较多，可以新建一张扩展表，将不经常用或字段长度较大的字段拆分出去到扩展表中。&lt;/p&gt;
&lt;p&gt;在字段很多的情况下（例如一个大表有 100 多个字段），通过&amp;quot;大表拆小表&amp;quot;，更便于开发与维护，也能避免跨页问题，&lt;strong&gt;MySQL 底层是通过数据页存储的，一条记录占用空间过大会导致跨页&lt;/strong&gt;，造成额外的性能开销。&lt;/p&gt;
&lt;p&gt;另外数据库以&lt;strong&gt;行为单位将数据加载到内存&lt;/strong&gt;中，这样&lt;strong&gt;表中字段长度较短且访问频率较高&lt;/strong&gt;，内存能加载更多的数据，命中率更高，减少了磁盘 IO，从而提升了数据库性能。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218112044893.png&#34; alt=&#34;image-20191218112044893&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;垂直切分的优点如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;解决业务系统层面的耦合，业务清晰&lt;/li&gt;
&lt;li&gt;与微服务的治理类似，也能对不同业务的数据进行分级管理、维护、监控、扩展等&lt;/li&gt;
&lt;li&gt;高并发场景下，垂直切分一定程度的提升 IO、数据库连接数、单机硬件资源的瓶颈&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;垂直切分的缺点如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;部分表无法 join，只能通过接口聚合方式解决，提升了开发的复杂度&lt;/li&gt;
&lt;li&gt;分布式事务处理复杂&lt;/li&gt;
&lt;li&gt;依然存在单表数据量过大的问题（需要水平切分）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;水平横向切分&#34;&gt;&lt;strong&gt;水平（横向）切分&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;当一个应用难以再细粒度的垂直切分，或切分后数据量行数巨大，存在单库读写、存储性能瓶颈，这时候就需要进行水平切分了。&lt;/p&gt;
&lt;p&gt;水平切分分为库内分表和分库分表，是根据表内数据内在的逻辑关系，将同一个表按不同的条件分散到多个数据库或多个表中，每个表中只包含一部分数据，从而使得单个表的数据量变小，达到分布式的效果。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218112329261.png&#34; alt=&#34;image-20191218112329261&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;库内分表只解决了单一表数据量过大的问题，但没有将表分布到不同机器的库上。&lt;/p&gt;
&lt;p&gt;因此对于减轻 MySQL 数据库的压力来说，帮助不是很大，大家还是竞争同一个物理机的 CPU、内存、网络 IO，最好通过&lt;strong&gt;分库分表&lt;/strong&gt;来解决。&lt;/p&gt;
&lt;p&gt;水平切分的优点如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不存在单库数据量过大、高并发的性能瓶颈，提升系统稳定性和负载能力&lt;/li&gt;
&lt;li&gt;应用端改造较小，不需要拆分业务模块&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;水平切分的缺点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;跨分片的事务一致性难以保证&lt;/li&gt;
&lt;li&gt;跨库的 join 关联查询性能较差&lt;/li&gt;
&lt;li&gt;数据多次扩展难度和维护量极大&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;水平切分后同一张表会出现在多个数据库/表中，每个库/表的内容不同。&lt;/p&gt;
&lt;h2 id=&#34;几种典型的数据分片规则&#34;&gt;几种典型的数据分片规则：&lt;/h2&gt;
&lt;h3 id=&#34;1-根据数值范围按照时间区间或-id-区间来切分&#34;&gt;**1、根据数值范围：**按照时间区间或 ID 区间来切分。&lt;/h3&gt;
&lt;p&gt;例如：按日期将不同月甚至是日的数据分散到不同的库中；将 &lt;code&gt;userId&lt;/code&gt;为 1~9999 的记录分到第一个库，10000~20000 的分到第二个库，以此类推。&lt;/p&gt;
&lt;p&gt;某种意义上，某些系统中使用的&amp;quot;冷热数据分离&amp;quot;，将一些使用较少的历史数据迁移到其他库中，业务功能上只提供热点数据的查询，也是类似的实践。&lt;/p&gt;
&lt;p&gt;这样的优点在于：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;单表大小可控&lt;/li&gt;
&lt;li&gt;天然便于水平扩展，后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移&lt;/li&gt;
&lt;li&gt;使用分片字段进行范围查找时，连续分片可快速定位分片进行快速查询，有效避免跨分片查询的问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;缺点在于：&lt;strong&gt;热点数据&lt;/strong&gt;成为性能瓶颈。连续分片可能存在数据热点，例如按时间字段分片，有些分片存储最近时间段内的数据，可能会被频繁的读写，而有些分片存储的历史数据，则很少被查询。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218112728686.png&#34; alt=&#34;image-20191218112728686&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;2-根据数值取模一般采用-hash-取模-mod-的切分方式&#34;&gt;**2、根据数值取模：**一般采用 hash 取模 mod 的切分方式。&lt;/h3&gt;
&lt;p&gt;例如：将 Customer 表根据 &lt;code&gt;cusno&lt;/code&gt;字段切分到 4 个库中，余数为 0 的放到第一个库，余数为 1 的放到第二个库，以此类推。&lt;/p&gt;
&lt;p&gt;这样同一个用户的数据会分散到同一个库中，如果查询条件带有 &lt;code&gt;cusno&lt;/code&gt;字段，则可明确定位到相应库去查询。&lt;/p&gt;
&lt;p&gt;优点：数据分片相对比较均匀，不容易出现热点和并发访问的瓶颈&lt;/p&gt;
&lt;p&gt;缺点如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;后期分片集群扩容时，需要迁移旧的数据（使用一致性 hash 算法能较好的避免这个问题）&lt;/li&gt;
&lt;li&gt;使用分片字段进行&lt;strong&gt;范围查找&lt;/strong&gt;时，需要同时向 4 个库发起查询，再在内存中合并数据，取最小集返回给应用，分库反而成为拖累。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218112906208.png&#34; alt=&#34;image-20191218112906208&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;非-uid的查询方法&#34;&gt;&lt;strong&gt;非 &lt;code&gt;uid&lt;/code&gt;的查询方法&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;水平切分后，对于按 &lt;code&gt;uid&lt;/code&gt;查询的需求能很好的满足，可以直接路由到具体数据库。&lt;/p&gt;
&lt;p&gt;而按非 &lt;code&gt;uid&lt;/code&gt;的查询，例如 login_name，就不知道具体该访问哪个库了，此时需要遍历所有库，性能会降低很多。&lt;/p&gt;
&lt;p&gt;对于用户侧，可以采用&amp;quot;建立非 &lt;code&gt;uid&lt;/code&gt;属性到 &lt;code&gt;uid&lt;/code&gt;的映射关系&amp;quot;的方案；对于运营侧，可以采用&amp;quot;前台与后台分离&amp;quot;的方案。&lt;/p&gt;
&lt;h3 id=&#34;建立非-uid属性到-uid的映射关系&#34;&gt;&lt;strong&gt;建立非 &lt;code&gt;uid&lt;/code&gt;属性到 &lt;code&gt;uid&lt;/code&gt;的映射关系&lt;/strong&gt;&lt;/h3&gt;
&lt;h4 id=&#34;映射关系&#34;&gt;&lt;strong&gt;映射关系&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;例如：login_name 不能直接定位到数据库，可以建立 login_name→&lt;code&gt;uid&lt;/code&gt;的映射关系，用索引表或缓存来存储。&lt;/p&gt;
&lt;p&gt;当访问 login_name 时，先通过映射表查询出 login_name 对应的 &lt;code&gt;uid&lt;/code&gt;，再通过 &lt;code&gt;uid&lt;/code&gt;定位到具体的库。&lt;/p&gt;
&lt;p&gt;映射表只有两列，可以承载很多数据，当数据量过大时，也可以对映射表再做水平切分。&lt;/p&gt;
&lt;p&gt;这类 &lt;code&gt;kv&lt;/code&gt;格式的索引结构，可以很好的使用 cache 来优化查询性能，而且映射关系不会频繁变更，缓存命中率会很高。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/955136-20180807105926589-1001810279.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;基因法&#34;&gt;&lt;strong&gt;基因法&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;分库基因，假如通过 &lt;code&gt;uid&lt;/code&gt;分库，分为 8 个库，采用 &lt;code&gt;uid&lt;/code&gt;%8 的方式进行路由，此时是由 &lt;code&gt;uid&lt;/code&gt;的最后 (2^3=8)3bit 来决定这行 User 数据具体落到哪个库上，那么这 3bit 可以看为分库基因。&lt;/p&gt;
&lt;p&gt;上面的映射关系的方法需要额外存储映射表，按非 &lt;code&gt;uid&lt;/code&gt;字段查询时，还需要多一次数据库或 cache 的访问。&lt;/p&gt;
&lt;p&gt;如果想要消除多余的存储和查询，可以通过 f 函数取 login_name 的基因作为 &lt;code&gt;uid&lt;/code&gt;的分库基因。&lt;/p&gt;
&lt;p&gt;生成 &lt;code&gt;uid&lt;/code&gt;时，参考分布式唯一 ID 生成方案，再加上最后 3 位 bit 值=f(login_name)。&lt;/p&gt;
&lt;p&gt;当查询 login_name 时，只需计算 f(login_name)%8 的值，就可以定位到具体的库。&lt;/p&gt;
&lt;p&gt;不过这样需要提前做好容量规划，预估未来几年的数据量需要分多少库，要预留一定 bit 的分库基因。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/955136-20180807131414339-111952151.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640-1582817190077.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;前台与后台分离&#34;&gt;&lt;strong&gt;前台与后台分离&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;对于用户侧，主要需求是以单行查询为主，需要建立 login_name/phone/email 到 &lt;code&gt;uid&lt;/code&gt;的映射关系，可以解决这些字段的查询问题。&lt;/p&gt;
&lt;p&gt;而对于运营侧，很多批量分页且条件多样的查询，这类查询计算量大，返回数据量大，对数据库的性能消耗较高。&lt;/p&gt;
&lt;p&gt;此时，如果和用户侧共用同一批服务或数据库，可能因为后台的少量请求，占用大量数据库资源，而导致用户侧访问性能降低或超时。&lt;/p&gt;
&lt;p&gt;这类业务最好采用&amp;quot;前台与后台分离&amp;quot;的方案，运营侧后台业务抽取独立的 service 和 DB，解决和前台业务系统的耦合。&lt;/p&gt;
&lt;p&gt;由于运营侧对可用性、一致性的要求不高，可以不访问实时库，而是通过 &lt;code&gt;binlog&lt;/code&gt;异步同步数据到运营库进行访问。&lt;/p&gt;
&lt;p&gt;在数据量很大的情况下，还可以使用 ES 搜索引擎或 Hive 来满足后台复杂的查询方式。&lt;/p&gt;
&lt;h2 id=&#34;分库分表带来的问题&#34;&gt;分库分表带来的问题&lt;/h2&gt;
&lt;p&gt;分库分表能有效的缓解单机和单库带来的性能瓶颈和压力，突破网络 IO、硬件资源、连接数的瓶颈，同时也带来了一些问题。下面将描述这些技术挑战以及对应的解决思路。&lt;/p&gt;
&lt;h3 id=&#34;事务一致性问题&#34;&gt;&lt;strong&gt;事务一致性问题&lt;/strong&gt;&lt;/h3&gt;
&lt;h4 id=&#34;1分布式事务&#34;&gt;&lt;strong&gt;①分布式事务&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;当更新内容同时分布在不同库中，不可避免会带来跨库事务问题。跨分片事务也是分布式事务，没有简单的方案，一般可使用&amp;quot;XA 协议&amp;quot;和&amp;quot;两阶段提交&amp;quot;处理。&lt;/p&gt;
&lt;p&gt;分布式事务能最大限度保证了数据库操作的原子性。但在提交事务时需要&lt;strong&gt;协调多个节点&lt;/strong&gt;，推后了提交事务的时间点，&lt;strong&gt;延长了事务的执行时间&lt;/strong&gt;。导致事务在访问共享资源时发生冲突或死锁的概率增高。&lt;/p&gt;
&lt;p&gt;随着数据库节点的增多，这种趋势会越来越严重，从而成为系统在数据库层面上水平扩展的枷 锁。&lt;/p&gt;
&lt;h4 id=&#34;2最终一致性&#34;&gt;&lt;strong&gt;②最终一致性&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;对于那些性能要求很高，但对一致性要求不高的系统，往往不苛求系统的实时一致性，只要在允许的时间段内达到最终一致性即可，可采用&lt;strong&gt;事务补偿&lt;/strong&gt;的方式。&lt;/p&gt;
&lt;p&gt;与事务在执行中发生错误后立即回滚的方式不同，事务补偿是一种事后检查补救的措施。&lt;/p&gt;
&lt;p&gt;一些常见的实现方法有：对数据进行对账检查，基于日志进行对比，定期同标准数据来源进行同步等等。事务补偿还要结合业务系统来考虑。&lt;/p&gt;
&lt;h3 id=&#34;跨节点关联查询-join-问题&#34;&gt;&lt;strong&gt;跨节点关联查询 join 问题&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;切分之前，系统中很多列表和详情页所需的数据可以通过 &lt;code&gt;sql&lt;/code&gt;join 来完成。&lt;/p&gt;
&lt;p&gt;而切分之后，数据可能分布在不同的节点上，此时 join 带来的问题就比较麻烦了，考虑到性能，尽量避免使用 join 查询。&lt;/p&gt;
&lt;p&gt;解决这个问题的一些方法：&lt;/p&gt;
&lt;h4 id=&#34;1全局表&#34;&gt;&lt;strong&gt;①全局表：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;全局表，也可看做是&amp;quot;数据字典表&amp;quot;，就是系统中所有模块都可能依赖的一些表，为了避免跨库 join 查询，可以将这类表在每个数据库中都保存一份。这些数据通常很少会进行修改，所以也不担心一致性的问题。&lt;/p&gt;
&lt;h4 id=&#34;2字段冗余&#34;&gt;&lt;strong&gt;②字段冗余：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;一种典型的反范式设计，利用空间换时间，为了性能而避免 join 查询。&lt;/p&gt;
&lt;p&gt;例如：订单表保存 &lt;code&gt;userId&lt;/code&gt;时候，也将 &lt;code&gt;userName&lt;/code&gt;冗余保存一份，这样查询订单详情时就不需要再去查询&amp;quot;买家 user 表&amp;quot;了。&lt;/p&gt;
&lt;p&gt;但这种方法适用场景也有限，比较适用于依赖字段比较少的情况。而冗余字段的数据一致性也较难保证，就像上面订单表的例子，买家修改了 &lt;code&gt;userName&lt;/code&gt;后，是否需要在历史订单中同步更新呢？这也要结合实际业务场景进行考虑。&lt;/p&gt;
&lt;h4 id=&#34;3数据组装&#34;&gt;&lt;strong&gt;③数据组装：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;在系统层面，分两次查询，第一次查询的结果集中找出关联数据  id，然后根据 id 发起第二次请求得到关联数据。最后将获得到的数据进行字段拼装。&lt;/p&gt;
&lt;h4 id=&#34;4er-分片&#34;&gt;&lt;strong&gt;④ER 分片：&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;关系型数据库中，如果可以先确定表之间的关联关系，并将那些存在关联关系的表记录存放在同一个分片上，那么就能较好的避免跨分片 join 问题。在 1:1 或 1:n 的情况下，通常按照主表的 ID 主键切分。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218113202557.png&#34; alt=&#34;image-20191218113202557&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;这样一来，Data Node1 上面的 order 订单表与 &lt;code&gt;orderdetail&lt;/code&gt;订单详情表就可以通过 &lt;code&gt;orderId&lt;/code&gt;进行局部的关联查询了，Data Node2 上也一样。&lt;/p&gt;
&lt;h3 id=&#34;跨节点分页-排序-函数问题&#34;&gt;&lt;strong&gt;跨节点分页、排序、函数问题&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;跨节点多库进行查询时，会出现 limit 分页、order by 排序等问题。分页需要按照指定字段进行排序，当排序字段就是分片字段时，通过分片规则就比较容易定位到指定的分片；当排序字段非分片字段时，就变得比较复杂了。&lt;/p&gt;
&lt;p&gt;需要先在不同的分片节点中将数据进行排序并返回，然后将不同分片返回的结果集进行汇总和再次排序，最终返回给用户。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218113237804.png&#34; alt=&#34;image-20191218113237804&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;上图中只是取第一页的数据，对性能影响还不是很大。但是如果取得页数很大，情况则变得复杂很多。&lt;/p&gt;
&lt;p&gt;因为各分片节点中的数据可能是随机的，为了排序的准确性，需要将所有节点的前 N 页数据都排序好做合并，最后再进行整体的排序，这样的操作是很耗费 CPU 和内存资源的，所以页数越大，系统的性能也会越差。&lt;/p&gt;
&lt;p&gt;在使用 Max、Min、Sum、Count 之类的函数进行计算的时候，也需要先在每个分片上执行相应的函数，然后将各个分片的结果集进行汇总和再次计算，最终将结果返回。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218113256568.png&#34; alt=&#34;image-20191218113256568&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;全局主键避重问题&#34;&gt;&lt;strong&gt;全局主键避重问题&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;在分库分表环境中，由于表中数据同时存在不同数据库中，主键值平时使用的自增长将无用武之地，某个分区数据库自生成的 ID 无法保证全局唯一。&lt;/p&gt;
&lt;p&gt;因此需要单独设计全局主键，以避免跨库主键重复问题。有一些常见的主键生成策略：&lt;/p&gt;
&lt;h4 id=&#34;1uuid&#34;&gt;&lt;strong&gt;①UUID&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;UUID 标准形式包含 32 个 16 进制数字，分为 5 段，形式为 8-4-4-4-12 的 36 个字符，例如：550e8400-e29b-41d4-a716-446655440000。&lt;/p&gt;
&lt;p&gt;UUID 是主键是最简单的方案，本地生成，性能高，没有网络耗时。但缺点也很明显，由于 UUID 非常长，会占用大量的存储空间。&lt;/p&gt;
&lt;p&gt;另外，作为主键建立索引和基于索引进行查询时都会存在性能问题，在 &lt;code&gt;InnoDB&lt;/code&gt;下，UUID 的无序性会引&lt;strong&gt;起数据位置频繁变动，导致分页&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;2结合数据库维护主键-id-表&#34;&gt;&lt;strong&gt;②结合数据库维护主键 ID 表&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;在数据库中建立 sequence 表：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE TABLE `sequence` (  
  `id` bigint(20) unsigned NOT NULL auto_increment,  
  `stub` char(1) NOT NULL default &#39;&#39;,  
  PRIMARY KEY  (`id`),  
  UNIQUE KEY `stub` (`stub`)  
) ENGINE=MyISAM;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;stub 字段设置为唯一索引，同一 stub 值在 sequence 表中只有一条记录，可以同时为多张表生成全局 ID。&lt;/p&gt;
&lt;p&gt;sequence 表的内容，如下所示：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;+-------------------+------+  
| id                | stub |  
+-------------------+------+  
| 72157623227190423 |    a |  
+-------------------+------+  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用 &lt;code&gt;MyISAM&lt;/code&gt;存储引擎而不是 &lt;code&gt;InnoDB&lt;/code&gt;，以获取更高的性能。&lt;code&gt;MyISAM&lt;/code&gt;使用的是表级别的锁，对表的读写是串行的，所以不用担心在并发时两次读取同一个 ID 值。&lt;/p&gt;
&lt;p&gt;当需要全局唯一的 64 位 ID 时，执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;REPLACE INTO sequence (stub) VALUES (&#39;a&#39;);  
SELECT LAST_INSERT_ID();  
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这两条语句是 Connection 级别的，select last_insert_id() 必须与 replace into 在同一数据库连接下才能得到刚刚插入的新 ID。&lt;/p&gt;
&lt;p&gt;使用 replace into 代替 insert into 好处是避免了表行数过大，不需要另外定期清理。&lt;/p&gt;
&lt;p&gt;此方案较为简单，但缺点也明显：存在单点问题，强依赖 DB，当 DB 异常时，整个系统都不可用。&lt;/p&gt;
&lt;p&gt;配置主从可以增加可用性，但当主库挂了，主从切换时，数据一致性在特殊情况下难以保证。另外性能瓶颈限制在单台 MySQL 的读写性能。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;flickr&lt;/code&gt; 团队使用的一种主键生成策略，与上面的 sequence 表方案类似，但更好的解决了单点和性能瓶颈的问题。&lt;/p&gt;
&lt;p&gt;这一方案的整体思想是：建立 2 个以上的全局 ID 生成的服务器，每个服务器上只部署一个数据库，每个库有一张 sequence 表用于记录当前全局 ID。&lt;/p&gt;
&lt;p&gt;表中 ID 增长的步长是库的数量，起始值依次错开，这样能将 ID 的生成散列到各个数据库上。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218113519582.png&#34; alt=&#34;image-20191218113519582&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;由两个数据库服务器生成 ID，设置不同的 auto_increment 值。第一台 sequence 的起始值为 1，每次步长增长 2，另一台的 sequence 起始值为 2，每次步长增长也是 2。&lt;/p&gt;
&lt;p&gt;结果第一台生成的 ID 都是奇数（1, 3, 5, 7 ...），第二台生成的 ID 都是偶数（2, 4, 6, 8 ...）。&lt;/p&gt;
&lt;p&gt;这种方案将生成 ID 的压力均匀分布在两台机器上。同时提供了系统容错，第一台出现了错误，可以自动切换到第二台机器上获取 ID。&lt;/p&gt;
&lt;p&gt;但有以下几个缺点：系统添加机器，水平扩展时较复杂；每次获取 ID 都要读写一次 DB，DB 的压力还是很大，只能靠堆机器来提升性能。&lt;/p&gt;
&lt;p&gt;可以基于 &lt;code&gt;flickr&lt;/code&gt;的方案继续优化，使用批量的方式降低数据库的写压力，每次获取一段区间的 ID 号段，用完之后再去数据库获取，可以大大减轻数据库的压力。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218113540801.png&#34; alt=&#34;image-20191218113540801&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;还是使用两台 DB 保证可用性，数据库中只存储当前的最大 ID。ID 生成服务每次批量拉取 6 个 ID，先将 max_id 修改为 5，当应用访问 ID 生成服务时，就不需要访问数据库，从号段缓存中依次派发 0~5 的 ID。&lt;/p&gt;
&lt;p&gt;当这些 ID 发完后，再将 max_id 修改为 11，下次就能派发 6~11 的 ID。于是，数据库的压力降低为原来的 1/6。&lt;/p&gt;
&lt;h4 id=&#34;3snowflake-分布式自增-id-算法&#34;&gt;&lt;strong&gt;③Snowflake 分布式自增 ID 算法&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Twitter 的 Snowflake 算法解决了分布式系统生成全局 ID 的需求，生成 64 位的 Long 型数字。&lt;/p&gt;
&lt;p&gt;组成部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;第一位未使用，因为二进制里第一个bit如果是1，那么都是负数，但是我们生成的id都是正数。&lt;/li&gt;
&lt;li&gt;接下来 41 位是毫秒级时间，41 位的长度可以表示 69 年的时间。&lt;/li&gt;
&lt;li&gt;5 位 &lt;code&gt;datacenterId&lt;/code&gt;，5 位 &lt;code&gt;workerId&lt;/code&gt;。10 位的长度最多支持部署 1024 个节点。&lt;/li&gt;
&lt;li&gt;最后 12 位是毫秒内的计数，12 位的计数顺序号支持每个节点每毫秒产生 4096 个 ID 序列。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191218113620635.png&#34; alt=&#34;image-20191218113620635&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;**这样的好处是：**毫秒数在高位，生成的 ID 整体上按时间趋势递增；不依赖第三方系统，稳定性和效率较高。&lt;/p&gt;
&lt;p&gt;理论上 QPS 约为 409.6w/s（1000*2^12），并且整个分布式系统内不会产生 ID 碰撞；可根据自身业务灵活分配 bit 位。&lt;/p&gt;
&lt;p&gt;**不足就在于：**强依赖机器时钟，如果时钟回拨，则可能导致生成 ID 重复。&lt;/p&gt;
&lt;p&gt;综上结合数据库和 Snowflake 的唯一 ID 方案，可以参考业界较为成熟的解法：Leaf——美团点评分布式 ID 生成系统，并考虑到了高可用、容灾、分布式下时钟等问题：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;https://tech.meituan.com/2017/04/21/mt-leaf.html
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;数据迁移-扩容问题&#34;&gt;&lt;strong&gt;数据迁移、扩容问题&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;当业务高速发展，面临性能和存储的瓶颈时，才会考虑分片设计，此时就不可避免的需要考虑历史数据迁移的问题。&lt;/p&gt;
&lt;p&gt;一般做法是先读出历史数据，然后按指定的分片规则再将数据写入到各个分片节点中。&lt;/p&gt;
&lt;p&gt;此外还需要根据当前的数据量和 QPS，以及业务发展的速度，进行容量规划，推算出大概需要多少分片（一般建议单个分片上的单表数据量不超过 1000W）。&lt;/p&gt;
&lt;p&gt;如果采用数值范围分片，只需要添加节点就可以进行扩容了，不需要对分片数据迁移。如果采用的是数值取模分片，则考虑后期的扩容问题就相对比较麻烦。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;水平扩容库（升级从库法）&lt;br&gt;
&lt;img src=&#34;https://images2018.cnblogs.com/blog/955136/201808/955136-20180807222601104-674464032.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;注：扩容是成倍的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;水平扩容表（双写迁移法）&lt;br&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/955136-20180807230203075-707265239.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
第一步：（同步双写）应用配置双写，部署；&lt;br&gt;
第二步：（同步双写）将老库中的老数据复制到新库中；&lt;br&gt;
第三步：（同步双写）以老库为准校对新库中的老数据；&lt;br&gt;
第四步：（同步双写）应用去掉双写，部署；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注：&lt;strong&gt;双写&lt;/strong&gt;是通用方案。&lt;/p&gt;
&lt;h2 id=&#34;什么时候考虑切分&#34;&gt;什么时候考虑切分&lt;/h2&gt;
&lt;p&gt;下面讲述一下什么时候需要考虑做数据切分。&lt;/p&gt;
&lt;h3 id=&#34;1能不切分尽量不要切分&#34;&gt;&lt;strong&gt;①能不切分尽量不要切分&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;并不是所有表都需要进行切分，主要还是看数据的增长速度。切分后会在某种程度上提升业务的复杂度，数据库除了承载数据的存储和查询外，协助业务更好的实现需求也是其重要工作之一。&lt;/p&gt;
&lt;p&gt;不到万不得已不用轻易使用分库分表这个大招，避免&amp;quot;过度设计&amp;quot;和&amp;quot;过早优化&amp;quot;。&lt;/p&gt;
&lt;p&gt;分库分表之前，不要为分而分，先尽力去做力所能及的事情，例如：升级硬件、升级网络、读写分离、索引优化等等。当数据量达到单表的瓶颈时候，再考虑分库分表。&lt;/p&gt;
&lt;h3 id=&#34;2数据量过大正常运维影响业务访问&#34;&gt;&lt;strong&gt;②数据量过大，正常运维影响业务访问&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;这里说的运维指：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对数据库备份，如果单表太大，备份时需要大量的磁盘 IO 和网络 IO。例如 1T 的数据，网络传输占 50MB 时候，需要 20000 秒才能传输完毕，整个过程的风险都是比较高的。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对一个很大的表进行 DDL 修改时，MySQL 会锁住全表，这个时间会很长，这段时间业务不能访问此表，影响很大。&lt;/p&gt;
&lt;p&gt;如果使用 pt-online-schema-change，使用过程中会创建触发器和影子表，也需要很长的时间。在此操作过程中，都算为风险时间。将数据表拆分，总量减少，有助于降低这个风险。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;大表会经常访问与更新，就更有可能出现锁等待。将数据切分，用空间换时间，变相降低访问压力。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;3随着业务发展需要对某些字段垂直拆分&#34;&gt;&lt;strong&gt;③随着业务发展，需要对某些字段垂直拆分&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;举个例子，假如项目一开始设计的用户表如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;id                   bigint             #用户的ID
name                 varchar            #用户的名字
last_login_time      datetime           #最近登录时间
personal_info        text               #私人信息
.....                                   #其他信息字段
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在项目初始阶段，这种设计是满足简单的业务需求的，也方便快速迭代开发。&lt;/p&gt;
&lt;p&gt;而当业务快速发展时，用户量从 10w 激增到 10 亿，用户非常的活跃，每次登录会更新 last_login_name 字段，使得 user 表被不断 update，压力很大。&lt;/p&gt;
&lt;p&gt;而其他字段：id，name，personal_info 是不变的或很少更新的，此时在业务角度，就要将 last_login_time 拆分出去，新建一个 user_time 表。&lt;/p&gt;
&lt;p&gt;personal_info 属性是更新和查询频率较低的，并且 text 字段占据了太多的空间。这时候，就要对此垂直拆分出 user_&lt;code&gt;ext&lt;/code&gt; 表了。&lt;/p&gt;
&lt;h3 id=&#34;4数据量快速增长&#34;&gt;&lt;strong&gt;④数据量快速增长&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;随着业务的快速发展，单表中的数据量会持续增长，当性能接近瓶颈时，就需要考虑水平切分，做分库分表了。此时一定要选择合适的切分规则，提前预估好数据容量。&lt;/p&gt;
&lt;h3 id=&#34;5安全性和可用性&#34;&gt;&lt;strong&gt;⑤安全性和可用性&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;鸡蛋不要放在一个篮子里。在业务层面上垂直切分，将不相关的业务的数据库分隔，因为每个业务的数据量、访问量都不同，不能因为一个业务把数据库搞挂而牵连到其他业务。&lt;/p&gt;
&lt;p&gt;利用水平切分，当一个数据库出现问题时，不会影响到 100% 的用户，每个库只承担业务的一部分数据，这样整体的可用性就能提高。&lt;/p&gt;
">8、分库分表</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/file/"" data-c="
          &lt;h2 id=&#34;1-参数文件&#34;&gt;&lt;strong&gt;1、参数文件&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Mysql实例启动时，数据库会先去读一个配置参数文件，若无法找到，则使用编译MySQL时指定的默认值。&lt;/p&gt;
&lt;p&gt;show variables like .....//查看参数 MySQL数据库中的参数可以分为动态参数和静态参数，静态参数是只读的。 set [global|session] system_var_name=expr;&lt;/p&gt;
&lt;p&gt;set [@@global.|@@session.]system_var_name=expr;&lt;/p&gt;
&lt;p&gt;SELECT [@@global.|@@session.]system_var_name;&lt;/p&gt;
&lt;p&gt;global和session表明该参数是基于当前会话还是整个实例的生命周期,对变量的全局值进行修改是在这次的实例生命周期中有效，但MySQL 实例本身并不会对参数文件中的该值进行修改，下次启动还是会读取参数文件的值&lt;/p&gt;
&lt;h2 id=&#34;2-日志文件&#34;&gt;&lt;strong&gt;2、日志文件&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;日志文件包括：错误日志，二进制日志，慢查询日志，查询日志&lt;/p&gt;
&lt;h3 id=&#34;1-错误日志&#34;&gt;1、错误日志&lt;/h3&gt;
&lt;p&gt;对MySQL的启动、运行、关闭过程进行了记录； SHOW variables like &#39;log_error&#39;\G;//定位错误日志文件&lt;/p&gt;
&lt;h3 id=&#34;2-慢查询日志&#34;&gt;2、慢查询日志&lt;/h3&gt;
&lt;p&gt;超过long_query_time设置阈值的sql语句会被记录到慢查询日志文件中,正好等于这个时间的sql不会被记录。 MySQL数据库默认不启动慢查询日志，需要手工将这个参数设为On&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;show variables like &#39;long_query_time&#39;;
show variables like &#39;log_slow_queries&#39;;
如果运行的SQL语句没有使用索引，则也会记录该语句到慢查询日志文件，首先要确认打开：
show variables like &#39;log_queries_not_using_indexes&#39;;
所有的慢查询日志从MySQL5.1开始放入了一张表中，在mysql架构下，名为slow_log.
参数log_output指定了慢查询数据的格式，默认为file，可以将它设为table
show variables like &#39;log_output&#39;;
set global log_output=&#39;table&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;3-查询日志&#34;&gt;3、查询日志&lt;/h3&gt;
&lt;p&gt;查询日志记录了所有对MySQL数据库的请求的信息，无论这些请求是否得到了正确的执行，默认文件名为主机名.log&lt;/p&gt;
&lt;h3 id=&#34;4-二进制日志&#34;&gt;4、二进制日志&lt;/h3&gt;
&lt;p&gt;二进制日志（binary log)记录了对MySQL数据库执行更改的所有操作，但是不包括select和show这类操作。&lt;/p&gt;
&lt;p&gt;binlog 的三种格式对比：&lt;br&gt;
&lt;strong&gt;statement&lt;/strong&gt;：&lt;strong&gt;记录到 binlog 里的是语句原文&lt;/strong&gt;，最后会有 COMMIT；可能会导致主备不一致，因为limit 、等sql 执行时可能主备优化器选择的索引不一样，排序也不一样。now()执行的结果也不一样。&lt;br&gt;
&lt;strong&gt;row&lt;/strong&gt; ：&lt;strong&gt;记录了操作的事件每一条数据的变化情况&lt;/strong&gt;，最后会有一个 XID event。缺点是太占空间。&lt;br&gt;
&lt;strong&gt;mixed&lt;/strong&gt;：同时使用两种格式，由数据库判断具体某条sql使用哪种格式。但是有选择错误的情况。&lt;/p&gt;
&lt;p&gt;redo log 和 binlog 是怎么关联起来的? 它们有一个共同的数据字段，&lt;strong&gt;叫 XID&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;崩溃恢复的时候，会按顺序扫描 redo log：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；&lt;/li&gt;
&lt;li&gt;如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 &lt;strong&gt;XID 去 binlog 找对应的事务&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;处于 prepare 阶段的 redo log 加上完整 binlog，重启也能恢复，因为 binlog 完整了，那么从库就同步过去了，为了保证主从一致，有完整的 binlog 就算成功。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;write 和 fsync 的时机，是由参数 sync_binlog 控制的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；&lt;/li&gt;
&lt;li&gt;sync_binlog=1 的时候，表示每次提交务都会执行 fsync；&lt;/li&gt;
&lt;li&gt;sync_binlog=N(N&amp;gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;比较常见的是将其设置为 100~1000 中的某个数值。对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;3-套接字文件&#34;&gt;&lt;strong&gt;3、套接字文件&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;show variables like &#39;socket&#39;;&lt;/p&gt;
&lt;h2 id=&#34;4-pid文件&#34;&gt;&lt;strong&gt;4、pid文件&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;当MySQL实例启动时，会将自己的进程ID写入一个文件中：主机名.pid show variables like &#39;pid_file&#39;;&lt;/p&gt;
&lt;h2 id=&#34;5-表结构定义文件&#34;&gt;&lt;strong&gt;5、表结构定义文件&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;因为MySQL插件式存储引擎的体系结构关系，数据的存储是跟进表进行的，每个表都有与之对应的文件，但不论表采用任何存储引擎， MySQL都有一个以frm为后缀名的文件，这个文件记录了该表的表结构定义。 frm还用来存放视图的定义。&lt;/p&gt;
&lt;h2 id=&#34;6-innodb存储引擎文件&#34;&gt;&lt;strong&gt;6、InnoDB存储引擎文件&lt;/strong&gt;&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/1571641455(1).png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;表空间文件&#34;&gt;表空间文件&lt;/h3&gt;
&lt;p&gt;InnoDB采用将存储的数据按表空间（tablespace)进行存放的设计。默认的表空间文件是一个初始为10MB的名为ibdata1的文件。 innodb_data_file_path可以设置其路径；&lt;/p&gt;
&lt;p&gt;可以将多个文件组成一个表空间，同时制定文件的属性；&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;innodb_data_file_path=/db/ibdata1:2000M;/dr2/db/ibdata2:2000M:autoextend; 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;若两个文件在不同的磁盘上，磁盘的负载可能被平均，从而提高性能&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;同时两个文件的文件名之后都跟了属性，表示ibdata1的大小为2000MB, ibdata2的大小为2000MB,并且可以自动增长（autoextend);&lt;/p&gt;
&lt;p&gt;表空间默认是共享表空间，如设置了参数innodb_file_per_table,则使用独立表空间，名字为tableName.ibd。单独的表空间仅存储该表的数据、 索引和插入缓冲BITMAP等信息，其余信息还是存放在默认的表空间中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;表空间理解&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;表空间是数据库的逻辑划分，一个表空间只能属于一个数据库。&lt;/p&gt;
&lt;p&gt;所有的数据库对象都存放在指定的表空间中。但主要存放的是表， 所以称作表空间 例如：便于理解，把oracle数据库看作一个实在房间，表空间可以看作这个房间的空间，是可以自由分配，在这空间里面可以堆放多个箱子 （箱子可以看作数据库文件），箱子里面再装物件（物件看作表）。用户指定表空间也就是你希望把属于这个用户的表放在那个房间（表空间） 里面。 表空间是一个虚拟的概念可以无限大，但是需要由数据文件作为载体。&lt;/p&gt;
&lt;p&gt;一个数据库可以包含多个表空间，一个表空间只能属于一个数据库&lt;/p&gt;
&lt;p&gt;一个表空间包含多个数据文件，一个数据文件只能属于一个表空间&lt;/p&gt;
&lt;p&gt;一个数据库就是Linux下的一个文件夹，表空间文件就是和数据库同名的的一个文件。&lt;/p&gt;
">3、文件</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/index/"" data-c="
          &lt;p&gt;索引是数据库中非常非常重要的概念，它是存储引擎能够快速定位记录的秘密武器，对于提升数据库的性能、减轻数据库服务器的负担有着非常重要的作用；&lt;strong&gt;索引优化是对查询性能优化的最有效手段&lt;/strong&gt;，它能够轻松地将查询的性能提高几个数量级。&lt;/p&gt;
&lt;h3 id=&#34;一-索引的结构&#34;&gt;一、索引的结构&lt;/h3&gt;
&lt;h4 id=&#34;btree索引&#34;&gt;BTREE索引&lt;/h4&gt;
&lt;p&gt;虽说叫 &lt;code&gt;B-Tree&lt;/code&gt; 索引，甚至显示时也是显示成 &lt;code&gt;BTREE&lt;/code&gt;，但其实内部实现多使用的是其变种 &lt;code&gt;B+ 树&lt;/code&gt;索引，大多数 &lt;code&gt;MySQL&lt;/code&gt; 存储引擎都支持这种索引，包括 &lt;code&gt;InnoDB&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;因此，&lt;code&gt;B+ 树&lt;/code&gt;索引实际上就是我们所说的传统意义上的索引，也是目前关系型数据库中最为常用的、最有效的索引类型。&lt;code&gt;B+ 树&lt;/code&gt;在关系型数据库的索引设计中如此流行主要得益于它的&lt;strong&gt;高扇出性&lt;/strong&gt;，&lt;code&gt;B+ 树&lt;/code&gt;索引的高度一般维持在 &lt;code&gt;2 ~ 4&lt;/code&gt; 层，也就是说查询某一键值的行记录最多只需要 &lt;code&gt;2 ~ 4&lt;/code&gt; 次 &lt;code&gt;IO&lt;/code&gt;，极大减少了磁盘操作的次数。&lt;/p&gt;
&lt;h4 id=&#34;hash索引&#34;&gt;Hash索引&lt;/h4&gt;
&lt;p&gt;基于哈希表实现，只有精确&lt;strong&gt;匹配所有列的查询&lt;/strong&gt;才有效。实现方法为，对于每一行数据，存储引擎都会对&lt;strong&gt;所有的索引列&lt;/strong&gt;计算出一个哈希码，哈希码是一个较小的值，哈希索引将所有行算出的哈希码存储在索引中，并为每一个哈希码维护指向具体某一行的指针。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/c3beb895gy1g1cspwzvu4j20rj0almyd.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;MySQL&lt;/code&gt; 中只有 &lt;code&gt;Memory&lt;/code&gt; 引擎显式支持哈希索引。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt; 支持的哈希索引是自适应的，用户无法进行配置，&lt;code&gt;InnoDB&lt;/code&gt; 引擎会根据表的使用情况自动为表生成哈希索引。使用哈希索引的好处在于时间复杂度为 &lt;code&gt;O(1)&lt;/code&gt;，因此哈希索引的查询效率要远高于 &lt;code&gt;BTree&lt;/code&gt; 索引。但是其限制在于：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;只有精确匹配索引所有列的查询才有效,因为哈希索引是利用索引的所有列的字段值来计算哈希值的。&lt;/li&gt;
&lt;li&gt;只支持等值比较查询，不能用于&lt;strong&gt;范围查询&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;哈希索引的数据并不是顺序存储的，&lt;strong&gt;无法用于排序&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;full-text索引&#34;&gt;Full-Text索引&lt;/h4&gt;
&lt;p&gt;全文索引是一种特殊的索引类型，它查找的是文本中的关键词，而不是直接比较索引中的值。它更类似于搜索引擎做的事情，而不是简单的 &lt;code&gt;WHERE&lt;/code&gt; 条件匹配。实现方法是通过建立倒排索引，快速匹配文档，这种实现方式也在 &lt;code&gt;Apache Lucene&lt;/code&gt; 这种全文检索库中出现。&lt;/p&gt;
&lt;h4 id=&#34;空间数据索引&#34;&gt;空间数据索引&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;MyISAM&lt;/code&gt; 存储引擎支持空间索引，可以用作地理数据存储。&lt;/p&gt;
&lt;h3 id=&#34;二-索引的数据结构&#34;&gt;二、索引的数据结构&lt;/h3&gt;
&lt;p&gt;InnoDB 存储引擎在绝大多数情况下使用 B+ 树建立索引，这是关系型数据库中查找最为常用和有效的索引，但是 B+ 树索引并不能找到一个给定键对应的具体值，&lt;strong&gt;它只能找到数据行对应的页&lt;/strong&gt;，然后正如上一节所提到的，数据库把整个页读入到内存中，并在内存中查找具体的数据行。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/B+Tree.jpg&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/B+Tree.jpg&#34; alt=&#34;B+Tree&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;B+ 树是平衡树，它查找任意节点所耗费的时间都是完全相同的，比较的次数就是 B+ 树的高度；&lt;/p&gt;
&lt;h4 id=&#34;缺点&#34;&gt;缺点&lt;/h4&gt;
&lt;p&gt;1.虽然索引大大提高了查询速度，同时却会&lt;strong&gt;降低更新表的速度&lt;/strong&gt;，如对表进行insert、update和delete。因为更新表时，不仅要保存数据，还要保存一下索引文件。&lt;/p&gt;
&lt;p&gt;2.建立索引会占用磁盘空间的索引文件。一般情况这个问题不太严重，但如果你在一个大表上创建了多种组合索引，索引文件的会增长很快。&lt;br&gt;
索引只是提高效率的一个因素，如果有大数据量的表，就需要花时间研究建立最优秀的索引，或优化查询语句。&lt;/p&gt;
&lt;h3 id=&#34;三-聚集索引和辅助索引&#34;&gt;三、聚集索引和辅助索引&lt;/h3&gt;
&lt;p&gt;数据库中的 B+ 树索引可以分为聚集索引（clustered index）和辅助索引（secondary index），它们之间的最大区别就是，&lt;strong&gt;聚集索引中存放着一条行记录的全部信息&lt;/strong&gt;，&lt;strong&gt;而辅助索引中只包含索引列和一个用于查找对应行记录的『书签』&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;聚集索引&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;InnoDB 存储引擎中的表都是使用索引组织的，也就是按照键的顺序存放；&lt;strong&gt;聚集索引就是按照表中主键的顺序构建一颗 B+ 树，并在叶节点中存放表中的行记录数据&lt;/strong&gt;。&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE TABLE users(    
    id INT NOT NULL,    
    first_name VARCHAR(20) NOT NULL,    
    last_name VARCHAR(20) NOT NULL,    
    age INT NOT NULL,    
    PRIMARY KEY(id),    
    KEY(last_name, first_name, age)    
    KEY(first_name));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果使用上面的 SQL 在数据库中创建一张表，B+ 树就会使用 &lt;code&gt;id&lt;/code&gt; 作为索引的键，并在叶子节点中存储一条记录中的&lt;strong&gt;所有&lt;/strong&gt;信息。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/Clustered-Index.jpg&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/Clustered-Index.jpg&#34; alt=&#34;Clustered-Index&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;图中对 B+ 树的描述与真实情况下 B+ 树中的数据结构有一些差别，不过这里想要表达的主要意思是：聚集索引叶节点中保存的是整条行记录，而不是其中的一部分。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;聚集索引与表的物理存储方式有着非常密切的关系，所有正常的表应该&lt;strong&gt;有且仅有一个&lt;/strong&gt;聚集索引（绝大多数情况下都是主键），表中的所有行记录数据都是按照&lt;strong&gt;聚集索引&lt;/strong&gt;的顺序存放的。&lt;/p&gt;
&lt;p&gt;当我们使用聚集索引对表中的数据进行检索时，可以直接获得聚集索引所对应的整条行记录数据所在的页，不需要进行第二次操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;辅助索引&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据库将所有的非聚集索引都划分为辅助索引，但是这个概念对我们理解辅助索引并没有什么帮助；辅助索引也是通过 B+ 树实现的，但是它的叶节点并不包含行记录的全部数据，仅包含索引中的所有键和一个用于查找对应行记录的『书签』，在 InnoDB 中这个&lt;strong&gt;书签就是当前记录的主键&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;辅助索引的存在并不会影响聚集索引，因为聚集索引构成的 B+ 树是&lt;strong&gt;数据实际存储&lt;/strong&gt;的形式，而辅助索引只用于加速数据的查找，所以一张表上往往有多个辅助索引以此来提升数据库的性能。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一张表一定包含一个聚集索引构成的 B+ 树以及若干辅助索引的构成的 B+ 树。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/Secondary-Index.jpg&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/Secondary-Index.jpg&#34; alt=&#34;Secondary-Index&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;如果在表 &lt;code&gt;users&lt;/code&gt; 中存在一个辅助索引 &lt;code&gt;(first_name, age)&lt;/code&gt;，那么它构成的 B+ 树大致就是上图这样，按照 &lt;code&gt;(first_name, age)&lt;/code&gt; 的字母顺序对表中的数据进行排序，当查找到主键时，再通过聚集索引获取到整条行记录。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/Clustered-Secondary-Index.jpg&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/Clustered-Secondary-Index.jpg&#34; alt=&#34;Clustered-Secondary-Index&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;上图展示了一个使用辅助索引查找一条表记录的过程：通过辅助索引查找到对应的主键，最后在聚集索引中使用主键获取对应的行记录，这也是通常情况下行记录的查找方式。&lt;/p&gt;
&lt;h3 id=&#34;四-索引类型&#34;&gt;四、索引类型&lt;/h3&gt;
&lt;h4 id=&#34;1普通索引&#34;&gt;1.普通索引&lt;/h4&gt;
&lt;p&gt;是最基本的索引，它没有任何限制。它有以下几种创建方式：&lt;br&gt;
（1）直接创建索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE INDEX index_name ON table(column(length))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（2）修改表结构的方式添加索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;ALTER TABLE table_name ADD INDEX index_name ON (column(length))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（3）创建表的时候同时创建索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE TABLE `table` (
    `id` int(11) NOT NULL AUTO_INCREMENT ,
    `title` char(255) CHARACTER NOT NULL ,
    `content` text CHARACTER NULL ,
    `time` int(10) NULL DEFAULT NULL , 
    PRIMARY KEY (`id`), 
    INDEX index_name (title(length))
)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（4）删除索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;DROP INDEX index_name ON table
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;2唯一索引&#34;&gt;2.唯一索引&lt;/h4&gt;
&lt;p&gt;与前面的普通索引类似，不同的就是：&lt;strong&gt;索引列的值必须唯一，但允许有空值&lt;/strong&gt;。如果是组合索引，则列值的组合必须唯一。它有以下几种创建方式：&lt;br&gt;
（1）创建唯一索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE UNIQUE INDEX indexName ON table(column(length))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（2）修改表结构&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;ALTER TABLE table_name ADD UNIQUE indexName ON (column(length))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（3）创建表的时候直接指定&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE TABLE `table` (
    `id` int(11) NOT NULL AUTO_INCREMENT ,
    `title` char(255) CHARACTER NOT NULL ,
    `content` text CHARACTER NULL ,
    `time` int(10) NULL DEFAULT NULL , 
    UNIQUE indexName (title(length))
);
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;3主键索引&#34;&gt;3.主键索引&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;是一种特殊的唯一索引&lt;/strong&gt;，&lt;strong&gt;一个表只能有一个主键，不允许有空值&lt;/strong&gt;。一般是在建表的时候同时创建主键索引：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE TABLE `table` (
    `id` int(11) NOT NULL AUTO_INCREMENT ,
    `title` char(255) NOT NULL , PRIMARY KEY (`id`)
);
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;4组合索引&#34;&gt;4.组合索引&lt;/h4&gt;
&lt;p&gt;指多个字段上创建的索引，只有在查询条件中使用了创建索引时的第一个字段，索引才会被使用。使用组合索引时遵循&lt;strong&gt;最左前缀&lt;/strong&gt;集合&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;ALTER TABLE `table` ADD INDEX name_city_age (name,city,age); 
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;5全文索引&#34;&gt;5.全文索引&lt;/h4&gt;
&lt;p&gt;主要用来查找文本中的关键字，而不是直接与索引中的值相比较。fulltext索引跟其它索引大不相同，它更像是一个搜索引擎，而不是简单的where语句的参数匹配。fulltext索引配合match against操作使用，而不是一般的where语句加like。&lt;/p&gt;
&lt;p&gt;它可以在&lt;strong&gt;create table，alter table ，create index使用&lt;/strong&gt;，不过目前只有&lt;strong&gt;char、varchar，text&lt;/strong&gt; 列上可以创建全文索引。值得一提的是，在数据量较大时候，现将数据放入一个没有全局索引的表中，然后再用CREATE index创建fulltext索引，要比先为一张表建立fulltext然后再将数据写入的速度快很多。&lt;br&gt;
（1）创建表的适合添加全文索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE TABLE `table` (
    `id` int(11) NOT NULL AUTO_INCREMENT ,
    `title` char(255) CHARACTER NOT NULL ,
    `content` text CHARACTER NULL ,
    `time` int(10) NULL DEFAULT NULL , PRIMARY KEY (`id`),
    FULLTEXT (content)
);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（2）修改表结构添加全文索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;ALTER TABLE article ADD FULLTEXT index_content(content)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;（3）直接创建索引&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE FULLTEXT INDEX index_content ON article(content)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;五-注意事项&#34;&gt;五、注意事项&lt;/h3&gt;
&lt;p&gt;使用索引时，有以下一些技巧和注意事项：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.索引不会包含有null值的列&lt;/strong&gt;&lt;br&gt;
只要列中包含有null值都将不会被包含在索引中，复合索引中只要有一列含有null值，那么这一列对于此复合索引就是无效的。所以我们在数据库设计时不要让字段的默认值为null。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.使用短索引&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。&lt;/p&gt;
&lt;p&gt;对串列进行索引，如果可能应该指定一个前缀长度。例如，如果有一个char(255)的列，如果在前10个或20个字符内，多数值是惟一的，那么就&lt;strong&gt;不要对整个列进行索引&lt;/strong&gt;。&lt;strong&gt;短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作&lt;/strong&gt;，但是其&lt;strong&gt;缺点是不能用于ORDER BY和GROUP BY操作&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;3.&lt;strong&gt;索引列排序&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;查询只使用一个索引&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作；尽量不要包含多个列的排序，&lt;strong&gt;如果需要最好给这些列创建复合索引&lt;/strong&gt;。对于复合索引Mysql从左到右的使用索引中的字段，一个查询可以只使用索引中的一部份，但只能是最左侧部分。&lt;br&gt;
例如索引是key index (a,b,c). 相当于是创建了a|a,b| a,b,c 3种索引，但不支持 b,c进行查找。&lt;br&gt;
使用联合索引的好处是索引已经对&lt;strong&gt;第二个键值进行了排序，可以避免多一次的排序操作&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;4.&lt;strong&gt;like语句操作&lt;/strong&gt;&lt;br&gt;
一般情况下不推荐使用like操作，如果非使用不可，如何使用也是一个问题。like “%aaa%” 不会使用索引而like “aaa%”可以使用索引。&lt;/p&gt;
&lt;p&gt;5.&lt;strong&gt;不要在列上进行运算&lt;/strong&gt;&lt;br&gt;
这将导致索引失效而进行全表扫描，例如&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;SELECT * FROM table_name WHERE YEAR(column_name)&amp;lt;2017;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;6.&lt;strong&gt;不使用not in和&amp;lt;&amp;gt;操作&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;7、&lt;strong&gt;不同应用中使用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于OLTP应用中，查询操作一般只取一小部分数据，此时建立B+树索引才有意义；在OLAP中需要访问大量的数据，因此索引的列应当是宏观的信息而不是微观的信息。比起名字，日期更适合做索引。&lt;/p&gt;
&lt;p&gt;8、&lt;strong&gt;覆盖索引（covering index）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;覆盖索引（&lt;strong&gt;查询列和索引列尽量一致&lt;/strong&gt;，通俗说就是对A、B列创建了索引，然后查询中也使用A、B列），减少select *的使用。&lt;br&gt;
覆盖索引是select的&lt;strong&gt;数据列只用从辅助索引中就能够取得，不必读取数据行&lt;/strong&gt;，换句话说查询列要被所建的索引覆盖。即从辅助索引中就可以得到查询的记录，而不需要查询聚合索引中的记录。&lt;/p&gt;
&lt;p&gt;使用覆盖索引的一个好处是&lt;strong&gt;辅助索引不包含整行记录的所有信息，故其大小要远小于聚集索引，因此可以减少大量的IO操作。&lt;/strong&gt;&lt;br&gt;
另一个好处是对于某些统计问题而言，&lt;code&gt;SELECT count(*) from tbl_name;InnoDb&lt;/code&gt;并不会选择通过查询聚集索引来统计，而是通过选择辅助索引来减少IO操作。&lt;/p&gt;
&lt;p&gt;9、&lt;strong&gt;索引提示&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MySQL支持索引提示（Index hint),显示地告诉优化器使用哪个索引。&lt;br&gt;
一、当数据库的优化器错误地选择了某个索引，导致SQL语句很慢时（非常少见），可以使用索引提示&lt;br&gt;
二、SQL的索引非常多，优化器选择执行计划时间的开销超过了SQL本身时&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select * from tbl_name USE|FORCE INDEX(index_name ).......
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;10、尽量使用自增字段做主键&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内（大小为一个内存页或磁盘页）的各条数据记录&lt;strong&gt;按主键顺序存放&lt;/strong&gt;，因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子（InnoDB默认为15/16），则开辟一个新的页（节点）。&lt;/p&gt;
&lt;p&gt;如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。如下图所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/13.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/13.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。&lt;/p&gt;
&lt;p&gt;如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/14.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/14.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。&lt;/p&gt;
&lt;p&gt;因此，只要可以，&lt;strong&gt;请尽量在InnoDB上采用自增字段做主键&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;11.尽量选择区分度高的列作为索引&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;区分度的公式是count(distinct col)/count(*)，&lt;strong&gt;表示字段不重复的比例，比例越大我们扫描的记录数越少&lt;/strong&gt;，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;12.尽量的扩展索引，不要新建索引，最佳左前缀法则。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可&lt;/p&gt;
&lt;h1 id=&#34;数据结构及算法基础&#34;&gt;数据结构及算法基础&lt;/h1&gt;
&lt;h2 id=&#34;索引的本质&#34;&gt;索引的本质&lt;/h2&gt;
&lt;p&gt;MySQL官方对索引的定义为：索引（Index）是帮助MySQL高效获取数据的数据结构。提取句子主干，就可以得到索引的本质：索引是数据结构。&lt;/p&gt;
&lt;p&gt;我们知道，数据库查询是数据库的最主要功能之一。我们都希望查询数据的速度能尽可能的快，因此数据库系统的设计者会从查询算法的角度进行优化。最基本的查询算法当然是&lt;a href=&#34;http://en.wikipedia.org/wiki/Linear_search&#34;&gt;顺序查找&lt;/a&gt;（linear search），这种复杂度为O(n)的算法在数据量很大时显然是糟糕的，好在计算机科学的发展提供了很多更优秀的查找算法，例如&lt;a href=&#34;http://en.wikipedia.org/wiki/Binary_search_algorithm&#34;&gt;二分查找&lt;/a&gt;（binary search）、&lt;a href=&#34;http://en.wikipedia.org/wiki/Binary_search_tree&#34;&gt;二叉树查找&lt;/a&gt;（binary tree search）等。如果稍微分析一下会发现，每种查找算法都只能应用于特定的数据结构之上，例如二分查找要求被检索数据有序，而二叉树查找只能应用于&lt;a href=&#34;http://en.wikipedia.org/wiki/Binary_search_tree&#34;&gt;二叉查找树&lt;/a&gt;上，但是数据本身的组织结构不可能完全满足各种数据结构（例如，理论上不可能同时将两列都按顺序进行组织），所以，在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。&lt;/p&gt;
&lt;p&gt;看一个例子：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/1.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/1.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图1展示了一种可能的索引方式。左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上也并不是一定物理相邻的）。为了加快Col2的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指针。&lt;/p&gt;
&lt;p&gt;虽然这是一个货真价实的索引，但是实际的数据库系统几乎没有使用二叉查找树或其进化品种&lt;a href=&#34;http://en.wikipedia.org/wiki/Red-black_tree&#34;&gt;红黑树&lt;/a&gt;（red-black tree）实现的，原因会在下文介绍。&lt;/p&gt;
&lt;h2 id=&#34;b-tree和btree&#34;&gt;B-Tree和B+Tree&lt;/h2&gt;
&lt;p&gt;目前大部分数据库系统及文件系统都采用B-Tree或其变种B+Tree作为索引结构，在本文的下一节会结合存储器原理及计算机存取原理讨论为什么B-Tree和B+Tree在被如此广泛用于索引，这一节先单纯从数据结构角度描述它们。&lt;/p&gt;
&lt;h3 id=&#34;b-tree&#34;&gt;B-Tree&lt;/h3&gt;
&lt;p&gt;为了描述B-Tree，首先定义一条数据记录为一个二元组[key, data]，key为记录的键值，对于不同数据记录，key是互不相同的；data为数据记录除key外的数据。那么B-Tree是满足下列条件的数据结构：&lt;/p&gt;
&lt;p&gt;d为大于1的一个正整数，称为B-Tree的度。&lt;/p&gt;
&lt;p&gt;h为一个正整数，称为B-Tree的高度。&lt;/p&gt;
&lt;p&gt;每个非叶子节点由n-1个key和n个指针组成，其中d&amp;lt;=n&amp;lt;=2d。&lt;/p&gt;
&lt;p&gt;每个叶子节点最少包含一个key和两个指针，最多包含2d-1个key和2d个指针，叶节点的指针均为null 。&lt;/p&gt;
&lt;p&gt;所有叶节点具有相同的深度，等于树高h。&lt;/p&gt;
&lt;p&gt;key和指针互相间隔，节点两端是指针。&lt;/p&gt;
&lt;p&gt;一个节点中的key从左到右非递减排列。&lt;/p&gt;
&lt;p&gt;所有节点组成树结构。&lt;/p&gt;
&lt;p&gt;每个指针要么为null，要么指向另外一个节点。&lt;/p&gt;
&lt;p&gt;如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于。&lt;/p&gt;
&lt;p&gt;图2是一个d=2的B-Tree示意图。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/2.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/2.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图2&lt;/p&gt;
&lt;p&gt;由于B-Tree的特性，在B-Tree中按key检索数据的算法非常直观：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到null指针，前者查找成功，后者查找失败。B-Tree上查找算法的伪代码如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1.  BTree_Search(node, key)  {
2.   if(node ==  null)  return  null;
3.   foreach(node.key)
4.   {
5.   if(node.key[i]  == key)  return node.data[i];
6.   if(node.key[i]  &amp;gt; key)  return  BTree_Search(point[i]-&amp;gt;node);
7.   }
8.   return  BTree_Search(point[i+1]-&amp;gt;node);
9.  }
10.  data =  BTree_Search(root, my_key);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;关于B-Tree有一系列有趣的性质，例如一个度为d的B-Tree，设其索引N个key，从这点可以看出，B-Tree是一个非常有效率的索引数据结构。&lt;/p&gt;
&lt;p&gt;另外，由于插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质，本文不打算完整讨论B-Tree这些内容，因为已经有许多资料详细说明了B-Tree的数学性质及插入删除算法，有兴趣的朋友可以在本文末的参考文献一栏找到相应的资料进行阅读。&lt;/p&gt;
&lt;h3 id=&#34;btree&#34;&gt;B+Tree&lt;/h3&gt;
&lt;p&gt;B-Tree有许多变种，其中最常见的是B+Tree，例如MySQL就普遍使用B+Tree实现其索引结构。&lt;/p&gt;
&lt;p&gt;与B-Tree相比，B+Tree有以下不同点：&lt;/p&gt;
&lt;p&gt;每个节点的指针上限为2d而不是2d+1。&lt;/p&gt;
&lt;p&gt;内节点不存储data，只存储key；叶子节点不存储指针。&lt;/p&gt;
&lt;p&gt;图3是一个简单的B+Tree示意。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/3.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/3.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图3&lt;/p&gt;
&lt;p&gt;由于并不是所有节点都具有相同的域，因此B+Tree中叶节点和内节点一般大小不同。这点与B-Tree不同，虽然B-Tree中不同节点存放的key和指针可能数量不一致，但是每个节点的域和上限是一致的，所以在实现中B-Tree往往对每个节点申请同等大小的空间。&lt;/p&gt;
&lt;p&gt;一般来说，B+Tree比B-Tree更适合实现外存储索引结构，具体原因与外存储器原理及计算机存取原理有关，将在下面讨论。&lt;/p&gt;
&lt;h3 id=&#34;带有顺序访问指针的btree&#34;&gt;带有顺序访问指针的B+Tree&lt;/h3&gt;
&lt;p&gt;一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/4.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/4.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图4&lt;/p&gt;
&lt;p&gt;如图4所示，在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。做这个优化的目的是为了提高区间访问的性能，例如图4中如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。&lt;/p&gt;
&lt;p&gt;这一节对B-Tree和B+Tree进行了一个简单的介绍，下一节结合存储器存取原理介绍为什么目前B+Tree是数据库系统实现索引的首选数据结构。&lt;/p&gt;
&lt;h2 id=&#34;为什么使用b-treebtree&#34;&gt;为什么使用B-Tree（B+Tree）&lt;/h2&gt;
&lt;p&gt;上文说过，红黑树等数据结构也可以用来实现索引，但是文件系统及数据库系统普遍采用B-/+Tree作为索引结构，这一节将结合计算机组成原理相关知识讨论B-/+Tree作为索引的理论基础。&lt;/p&gt;
&lt;p&gt;一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。下面先介绍内存和磁盘存取原理，然后再结合这些原理分析B-/+Tree作为索引的效率。&lt;/p&gt;
&lt;h3 id=&#34;主存存取原理&#34;&gt;主存存取原理&lt;/h3&gt;
&lt;p&gt;目前计算机使用的主存基本都是随机读写存储器（RAM），现代RAM的结构和存取原理比较复杂，这里本文抛却具体差别，抽象出一个十分简单的存取模型来说明RAM的工作原理。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/5.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/5.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图5&lt;/p&gt;
&lt;p&gt;从抽象角度看，主存是一系列的存储单元组成的矩阵，每个存储单元存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元。图5展示了一个4 x 4的主存模型。&lt;/p&gt;
&lt;p&gt;主存的存取过程如下：&lt;/p&gt;
&lt;p&gt;当系统需要读取主存时，则将地址信号放到地址总线上传给主存，主存读到地址信号后，解析信号并定位到指定存储单元，然后将此存储单元数据放到数据总线上，供其它部件读取。&lt;/p&gt;
&lt;p&gt;写主存的过程类似，系统将要写入单元地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，做相应的写操作。&lt;/p&gt;
&lt;p&gt;这里可以看出，主存存取的时间仅与存取次数呈线性关系，因为不存在机械操作，两次存取的数据的“距离”不会对时间有任何影响，例如，先取A0再取A1和先取A0再取D3的时间消耗是一样的。&lt;/p&gt;
&lt;h3 id=&#34;磁盘存取原理&#34;&gt;磁盘存取原理&lt;/h3&gt;
&lt;p&gt;上文说过，索引一般以文件形式存储在磁盘上，索引检索需要磁盘I/O操作。与主存不同，磁盘I/O存在机械运动耗费，因此磁盘I/O的时间消耗是巨大的。&lt;/p&gt;
&lt;p&gt;图6是磁盘的整体结构示意图。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/6.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/6.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图6&lt;/p&gt;
&lt;p&gt;一个磁盘由大小相同且同轴的圆形盘片组成，磁盘可以转动（各个磁盘必须同步转动）。在磁盘的一侧有磁头支架，磁头支架固定了一组磁头，每个磁头负责存取一个磁盘的内容。磁头不能转动，但是可以沿磁盘半径方向运动（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的（不过目前已经有多磁头独立技术，可不受此限制）。&lt;/p&gt;
&lt;p&gt;图7是磁盘结构的示意图。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/7.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/7.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图7&lt;/p&gt;
&lt;p&gt;盘片被划分成一系列同心环，圆心是盘片中心，每个同心环叫做一个磁道，所有半径相同的磁道组成一个柱面。磁道被沿半径线划分成一个个小的段，每个段叫做一个扇区，每个扇区是磁盘的最小存储单元。为了简单起见，我们下面假设磁盘只有一个盘片和一个磁头。&lt;/p&gt;
&lt;p&gt;当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。&lt;/p&gt;
&lt;h3 id=&#34;局部性原理与磁盘预读&#34;&gt;局部性原理与磁盘预读&lt;/h3&gt;
&lt;p&gt;由于存储介质的特性，磁盘本身存取就比主存慢很多，再加上机械运动耗费，磁盘的存取速度往往是主存的几百分分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：&lt;/p&gt;
&lt;p&gt;当一个数据被用到时，其附近的数据也通常会马上被使用。&lt;/p&gt;
&lt;p&gt;程序运行期间所需要的数据通常比较集中。&lt;/p&gt;
&lt;p&gt;由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;预读的长度一般为页（page）的整倍数&lt;/strong&gt;。页是计算机管理存储器的逻辑块，硬件及操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页得大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。&lt;/p&gt;
&lt;h3 id=&#34;b-tree索引的性能分析&#34;&gt;B-/+Tree索引的性能分析&lt;/h3&gt;
&lt;p&gt;到这里终于可以分析B-/+Tree索引的性能了。&lt;/p&gt;
&lt;p&gt;上文说过一般使用磁盘I/O次数评价索引结构的优劣。先从B-Tree分析，根据B-Tree的定义，可知检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：&lt;/p&gt;
&lt;p&gt;每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。&lt;/p&gt;
&lt;p&gt;综上所述，用B-Tree作为索引结构效率是非常高的。&lt;/p&gt;
&lt;p&gt;而红黑树这种结构，h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。&lt;/p&gt;
&lt;p&gt;floor表示向下取整。由于B+Tree内节点去掉了data域，因此可以拥有更大的出度，拥有更好的性能。&lt;/p&gt;
&lt;p&gt;这一章从理论角度讨论了与索引相关的数据结构与算法问题，下一章将讨论B+Tree是如何具体实现为MySQL中索引，同时将结合MyISAM和InnDB存储引擎介绍非聚集索引和聚集索引两种不同的索引实现形式。&lt;/p&gt;
&lt;h2 id=&#34;mysql索引实现&#34;&gt;MySQL索引实现&lt;/h2&gt;
&lt;p&gt;在MySQL中，索引属于存储引擎级别的概念，不同存储引擎对索引的实现方式是不同的，本文主要讨论MyISAM和InnoDB两个存储引擎的索引实现方式。&lt;/p&gt;
&lt;h3 id=&#34;myisam索引实现&#34;&gt;MyISAM索引实现&lt;/h3&gt;
&lt;p&gt;MyISAM引擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址。下图是MyISAM索引的原理图：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;15&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/8.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/8.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图8&lt;/p&gt;
&lt;p&gt;这里设表一共有三列，假设我们以Col1为主键，则图8是一个MyISAM表的主索引（Primary key）示意。可以看出MyISAM的索引文件仅仅保存数据记录的地址。在MyISAM中，主索引和辅助索引（Secondary key）在结构上没有任何区别，&lt;strong&gt;只是主索引要求key是唯一的，而辅助索引的key可以重复&lt;/strong&gt;。如果我们在Col2上建立一个辅助索引，则此索引的结构如下图所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;16&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/9.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/9.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图9&lt;/p&gt;
&lt;p&gt;同样也是一颗B+Tree，data域保存数据记录的地址。因此，MyISAM中索引检索的算法为首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。&lt;/p&gt;
&lt;p&gt;MyISAM的索引方式也叫做“非聚集”的，之所以这么称呼是为了与InnoDB的聚集索引区分。&lt;/p&gt;
&lt;h3 id=&#34;innodb索引实现&#34;&gt;InnoDB索引实现&lt;/h3&gt;
&lt;p&gt;虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。&lt;/p&gt;
&lt;p&gt;第一个重大区别是InnoDB的数据文件本身就是索引文件。从上文知道，MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;17&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/10.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/10.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图10&lt;/p&gt;
&lt;p&gt;图10是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键（MyISAM可以没有），如果没有显式指定，则&lt;strong&gt;MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键&lt;/strong&gt;，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，&lt;strong&gt;这个字段长度为6个字节&lt;/strong&gt;，类型为长整形。&lt;/p&gt;
&lt;p&gt;第二个与MyISAM索引的不同是InnoDB的辅助索引data域存储相应记录&lt;strong&gt;主键的值而不是地址&lt;/strong&gt;。换句话说，InnoDB的所有&lt;strong&gt;辅助索引都引用主键作为data域&lt;/strong&gt;。例如，图11为定义在Col3上的一个辅助索引：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;18&#34;&gt;&lt;a href=&#34;http://blog.codinglabs.org/uploads/pictures/theory-of-mysql-index/11.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/11.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;图11&lt;/p&gt;
&lt;p&gt;这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。&lt;/p&gt;
">4、索引</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/lock/"" data-c="
          &lt;h2 id=&#34;innodb中的事务隔离级别和锁的关系&#34;&gt;Innodb中的事务隔离级别和锁的关系&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;前言:&lt;/p&gt;
&lt;p&gt;我们都知道事务的几种性质，数据库为了维护这些性质，尤其是一致性和隔离性，一般使用加锁这种方式。同时数据库又是个高并发的应用，同一时间会有大量的并发访问，如果加锁过度，会极大的降低并发处理能力。所以对于加锁的处理，可以说就是数据库对于事务处理的精髓所在。这里通过分析MySQL中InnoDB引擎的加锁机制，来抛砖引玉，让读者更好的理解，在事务处理中数据库到底做了什么。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;一次封锁or两段锁？ 因为有大量的并发访问，为了预防死锁，一般应用中推荐使用&lt;strong&gt;一次封锁法&lt;/strong&gt;，就是&lt;strong&gt;在方法的开始阶段，已经预先知道会用到哪些数据，然后全部锁住，在方法运行之后，再全部解锁&lt;/strong&gt;。这种方式可以有效的避免循环死锁，但在数据库中却不适用，因为在事务开始阶段，&lt;strong&gt;数据库并不知道会用到哪些数据&lt;/strong&gt;。 数据库遵循的是两段锁协议，将事务分成两个阶段，加锁阶段和解锁阶段（所以叫两段锁）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;加锁阶段：在该阶段可以进行加锁操作。在对任何数据进行读操作之前要申请并获得S锁（共享锁，其它事务可以继续加共享锁，但不能加排它锁），在进行写操作之前要申请并获得X锁（排它锁，其它事务不能再获得任何锁）。&lt;strong&gt;加锁不成功，则事务进入等待状态，直到加锁成功才继续执行。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;解锁阶段：当事务释放了一个封锁以后，事务进入解锁阶段，在该阶段只能进行解锁操作不能再进行加锁操作。&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;事务&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;加锁/解锁处理&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;begin；&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;insert into test …..&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;加insert对应的锁&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;update test set…&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;加update对应的锁&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;delete from test ….&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;加delete对应的锁&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;commit;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;事务提交时，同时释放insert、update、delete对应的锁&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这种方式虽然&lt;strong&gt;无法避免死锁&lt;/strong&gt;，但是两段锁协议&lt;strong&gt;可以保证事务的并发调度是串行化&lt;/strong&gt;（串行化很重要，尤其是在数据恢复和备份的时候）的。&lt;/p&gt;
&lt;p&gt;我们都知道锁的种类一般分为乐观锁和悲观锁两种，InnoDB 存储引擎中使用的就是悲观锁，而按照锁的粒度划分，也可以分成行锁和表锁。&lt;/p&gt;
&lt;h3 id=&#34;并发控制机制&#34;&gt;并发控制机制&lt;/h3&gt;
&lt;p&gt;乐观锁和悲观锁其实都是并发控制的机制，同时它们在原理上就有着本质的差别；&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;乐观锁是一种思想，它其实并不是一种真正的『锁』，&lt;strong&gt;它会先尝试对资源进行修改，在写回时判断资源是否进行了改变&lt;/strong&gt;，&lt;strong&gt;如果没有发生改变就会写回，否则就会进行重试&lt;/strong&gt;，在整个的执行过程中其实都&lt;strong&gt;没有对数据库进行加锁&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;悲观锁就是一种真正的锁了，它会在获取资源前对资源进行加锁，确保同一时刻只有有限的线程能够访问该资源，其他想要尝试获取资源的操作都会进入等待状态，直到该线程完成了对资源的操作并且释放了锁后，其他线程才能重新操作资源；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虽然乐观锁和悲观锁在本质上并不是同一种东西，一个是一种思想，另一个是一种真正的锁，但是它们都是一种并发控制机制。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/Optimistic-Pessimistic-Locks.jpg&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/Optimistic-Pessimistic-Locks.jpg&#34; alt=&#34;Optimistic-Pessimistic-Locks&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;乐观锁不会存在死锁的问题，但是由于更新后验证，所以当&lt;strong&gt;冲突频率&lt;/strong&gt;和&lt;strong&gt;重试成本&lt;/strong&gt;较高时更推荐使用悲观锁，而需要非常高的&lt;strong&gt;响应速度&lt;/strong&gt;并且&lt;strong&gt;并发量&lt;/strong&gt;非常大的时候使用乐观锁就能较好的解决问题，在这时使用悲观锁就可能出现严重的性能问题；在选择并发控制机制时，需要综合考虑上面的四个方面（冲突频率、重试成本、响应速度和并发量）进行选择。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;锁的类型&#34;&gt;锁的类型&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;MyISAM&lt;/code&gt;采用表级锁(table-level locking)。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;支持行级锁(row-level locking)和表级锁,默认为行级锁&lt;/p&gt;
&lt;h4 id=&#34;表级锁&#34;&gt;表级锁&lt;/h4&gt;
&lt;p&gt;表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为共享锁和排他锁.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;用法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;共享锁(s 锁 读锁)&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640-1583145998710.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;排他锁(x 锁 写锁 )&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640-1583145998738.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;行级锁&#34;&gt;行级锁&lt;/h4&gt;
&lt;p&gt;行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。&lt;/p&gt;
&lt;p&gt;行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。&lt;/p&gt;
&lt;p&gt;行级锁分为共享锁和排他锁.&lt;/p&gt;
&lt;p&gt;MySQL的行锁是针对&lt;strong&gt;索引&lt;/strong&gt;加的锁，不是针对记录加的锁。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;特点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;用法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;共享锁(s 锁 读锁)&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640-1583145917027.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;排他锁(x 锁 写锁 )&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640-1583145917032.webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;虽然使用行级索具有粒度小、并发度高等特点，但是表级锁有时候也是非常必要的：&lt;/p&gt;
&lt;p&gt;1）事务更新大表中的大部分数据直接使用表级锁效率更高；&lt;/p&gt;
&lt;p&gt;2）事务比较复杂，使用行级索很可能引起死锁导致回滚。&lt;/p&gt;
&lt;h4 id=&#34;意向锁&#34;&gt;意向锁&lt;/h4&gt;
&lt;p&gt;无论是共享锁还是互斥锁其实都只是对某一个数据行进行加锁，InnoDB 支持多种粒度的锁，也就是&lt;strong&gt;行锁和表锁&lt;/strong&gt;；为了支持多粒度锁定，InnoDB 存储引擎引入了&lt;strong&gt;意向锁（Intention Lock），意向锁就是一种表级锁&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;与上一节中提到的两种锁的种类相似的是，意向锁也分为两种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;意向共享锁&lt;/strong&gt;：事务想要在获得表中某些记录的共享锁，需要在表上先加意向共享锁；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;意向互斥锁&lt;/strong&gt;：事务想要在获得表中某些记录的互斥锁，需要在表上先加意向互斥锁；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;随着意向锁的加入，锁类型之间的兼容矩阵也变得愈加复杂：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/Lock-Type-Compatibility-Matrix.jpg&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/Lock-Type-Compatibility-Matrix.jpg&#34; alt=&#34;Lock-Type-Compatibility-Matrix&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;意向锁其实不会&lt;strong&gt;阻塞全表扫描之外的任何请求&lt;/strong&gt;，它们的主要目的是为了表示&lt;strong&gt;是否有人请求锁定表中的某一行数据&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;有的人可能会对意向锁的目的并不是完全的理解，我们在这里可以举一个例子：如果没有意向锁，当已经有人使用行锁对表中的某一行进行修改时，如果另外一个请求要对全表进行修改，那么就需要对所有的行是否被锁定进行扫描，在这种情况下，效率是非常低的；不过，在引入意向锁之后，当有人使用行锁对表中的某一行进行修改之前，会先为表添加意向互斥锁（IX），再为行记录添加互斥锁（X），在这时如果有人尝试对全表进行修改就不需要判断表中的每一行数据是否被加锁了，只需要通过等待意向互斥锁被释放就可以了。意向锁是&lt;code&gt;InnoDB&lt;/code&gt;自动 加的，不需要用户干预。IX，IS是表级锁，不会和行级的X，S锁发生冲突，只会和表级的X，S发生冲突。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id=&#34;innodb行锁实现方式&#34;&gt;&lt;code&gt;InnoDB&lt;/code&gt;行锁实现方式&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。 &lt;code&gt;InnoDB&lt;/code&gt;这种行锁实现特点意味着：&lt;strong&gt;只有通过索引条件检索数据&lt;/strong&gt;，&lt;code&gt;InnoDB&lt;/code&gt;才使用行级锁，否则，&lt;code&gt;InnoDB&lt;/code&gt;将使用表锁！&lt;/p&gt;
&lt;p&gt;不同隔离级别下，行锁有不同实现算法：&lt;code&gt;InnoDB&lt;/code&gt;默认的事物隔离级别是REPEATABLE READ，使用Next-key Locking；READ COMMITTED 仅采用Record Lock。&lt;/p&gt;
&lt;h4 id=&#34;1record-lock&#34;&gt;1）&lt;strong&gt;Record Lock&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;对索引项&lt;/strong&gt;加锁，锁定符合条件的行。其他事务不能修改和删除加锁项，如果表在建立的时候没有设置任何一个索引，那么这是&lt;code&gt;InnoDB&lt;/code&gt;会使用&lt;strong&gt;隐式的主键&lt;/strong&gt;来锁定；&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;CREATE TABLE users(    
    id INT NOT NULL AUTO_INCREMENT,    
    last_name VARCHAR(255) NOT NULL,    
    first_name VARCHAR(255),    
    age INT,    
    PRIMARY KEY(id),    
    KEY(last_name),    
    KEY(age));
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果我们使用 &lt;code&gt;id&lt;/code&gt; 或者 &lt;code&gt;last_name&lt;/code&gt; 作为 SQL 中 &lt;code&gt;WHERE&lt;/code&gt; 语句的过滤条件，那么 InnoDB 就可以通过索引建立的 B+ 树找到行记录并添加索引，但是如果使用 &lt;code&gt;first_name&lt;/code&gt; 作为过滤条件时，由于 InnoDB 不知道待修改的记录具体存放的位置，也无法对将要修改哪条记录提前做出判断就会&lt;strong&gt;锁定整个表&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;2gap-lock&#34;&gt;2）&lt;strong&gt;Gap Lock&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;当我们用&lt;strong&gt;范围条件&lt;/strong&gt;而不是相等条件检索数据，并请求共享或排他锁时，&lt;code&gt;InnoDB&lt;/code&gt;会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”；对索引项之间的“间隙”加锁，锁定记录的范围（对第一条记录前的间隙或最后一条将记录后的间隙加锁），不包含索引项本身。&lt;/p&gt;
&lt;h4 id=&#34;3next-key-lock&#34;&gt;3）&lt;strong&gt;Next-key Lock&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;锁定索引项本身和索引范围。即Record Lock和Gap Lock的结合锁定一个SQL申明的范围（eg. id&amp;gt;1），并且锁定记录本身。&lt;code&gt;InnoDB&lt;/code&gt;采用Next-Key Locking来避免幻读。通过对范围加X锁，那么这个范围的插入都是不允许的。&lt;code&gt;InnoDB&lt;/code&gt;使用Next-key Lock的目的，&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;一）为了防止幻读，以满足相关隔离级别的要求，对于上面的例子，要是不使用间隙锁，如果其它事务插入了范围内的任何记录，那么本事务如果再次执行上述语句，就会发生幻读；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;二）为了满足其恢复和复制的需要。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;MySQL 通过 &lt;code&gt;binlog&lt;/code&gt;记录执行成功的 insert、update 、delete 等更新数据的 &lt;code&gt;sql&lt;/code&gt;语句，并由此实现 MySQL数据库的恢复和主从复制。&lt;/p&gt;
&lt;p&gt;MySQL 5.6 支持 3 种 日志格式，即基于语句的日志格式 &lt;code&gt;sbl&lt;/code&gt;，基于行的日志格式 &lt;code&gt;rbl&lt;/code&gt;和混合格式，对基于语句日志格式（&lt;code&gt;sbl&lt;/code&gt;）的恢复和复制而言，由于 MySQL 的 &lt;code&gt;binlog&lt;/code&gt;是按照事务提交的先后顺序记录的，因此要正确恢复或复制数据，就必须满足：**在一个事务未提交前，其他并发事务不能插入满足其锁定条件的任何记录，也就是不允许出现幻读。**这已经超过了“可重复读”隔离级别的要求，实际上是要求事务要串行化。这也是许多情况下， &lt;code&gt;innodb&lt;/code&gt;要用 next-key 锁的原因。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SELECT * FROM tbl_name where col=xxx LOCK IN SHARE MODE; 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如果通过索引查询一个值，并对该行加上一个&lt;code&gt;SLock&lt;/code&gt;，那么即使查询的值不在，其锁定的也是一个范围，因此若没有任何行返回，那么新插入的值一定是唯一的，如果有多个事物并发操作这种唯一性检查机制也不会有问题，因为此时会导致死锁，只有一个事务的插入操作会成功，其余的事物会抛出死锁的错误。&lt;/p&gt;
&lt;p&gt;在实际应用中，要特别注意 &lt;code&gt;innodb&lt;/code&gt; 行锁的这一特性，否则可能导致大量的锁冲突，从而影响并发性能。&lt;/p&gt;
&lt;p&gt;1）在不通过索引条件查询的时候，&lt;code&gt;InnoDB&lt;/code&gt;确实使用的是表锁，而不是行锁。&lt;/p&gt;
&lt;p&gt;2）由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的&lt;/p&gt;
&lt;p&gt;3）当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，&lt;code&gt;InnoDB&lt;/code&gt;都会使用行锁来对数据加锁。&lt;/p&gt;
&lt;p&gt;4）即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下&lt;code&gt;InnoDB&lt;/code&gt;将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;死锁&#34;&gt;死锁&lt;/h3&gt;
&lt;p&gt;MyISAM中是不会产生死锁的，因为MyISAM总是一次性获得所需的全部锁，要么全部满足，要么全部等待。&lt;/p&gt;
&lt;p&gt;而在InnoDB中，锁是逐步获得的，就造成了死锁的可能。在MySQL中，行级锁并不是直接锁记录，而是锁索引。&lt;/p&gt;
&lt;p&gt;索引分为主键索引和非主键索引两种，如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。&lt;/p&gt;
&lt;p&gt;在UPDATE、DELETE操作时，MySQL不仅锁定WHERE条件扫描过的所有索引记录，而且会锁定相邻的键值，即所谓的next-key locking。&lt;/p&gt;
&lt;p&gt;当两个事务同时执行，一个锁住了主键索引，在等待其他相关索引。另一个锁定了非主键索引，在等待主键索引。这样就会发生死锁。&lt;/p&gt;
&lt;p&gt;发生死锁后，InnoDB一般都可以检测到，并使一个事务释放锁回退，另一个获取锁完成事务。&lt;/p&gt;
&lt;h4 id=&#34;1-避免死锁&#34;&gt;1、避免死锁&lt;/h4&gt;
&lt;h5 id=&#34;1通过表级锁来减少死锁产生的概率&#34;&gt;1）通过表级锁来减少死锁产生的概率；&lt;/h5&gt;
&lt;h5 id=&#34;2使用抢占加事务回滚的方式预防死锁&#34;&gt;2）使用抢占加事务回滚的方式预防死锁&lt;/h5&gt;
&lt;p&gt;当事务开始执行时会&lt;strong&gt;先获得一个时间戳&lt;/strong&gt;，数据库程序会根据事务的时间戳决定事务应该等待还是回滚，在这时也有两种机制供我们选择，&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;wait-die 机制&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当执行事务的时间戳小于另一事务时，即事务 A 先于 B 开始，那么它就会等待另一个事务释放对应资源的锁， 否则就会保持当前的时间戳并回滚。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;wound-wait&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当前事务如果先于另一事务执行并请求了另一事务的资源，那么另一事务会立刻回滚，将资源让给先执行的事务，否则就会等待其他事务释放资源：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/climlmlmkpboard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;2-死锁的诊断与解除&#34;&gt;2、死锁的诊断与解除&lt;/h4&gt;
&lt;p&gt;数据库系统中诊断死锁的方法与操作系统类似，一般是用超时法或事务等待图法。&lt;/p&gt;
&lt;h5 id=&#34;1-超时法&#34;&gt;&lt;strong&gt;1、超时法&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;指的是如果一个事务的等待时间超过了规定的时限，就认为发生死锁。&lt;/p&gt;
&lt;p&gt;（一）有可能误判死锁，事务因为其他原因使等待时机超过时限。&lt;/p&gt;
&lt;p&gt;（二）时限若设置得太长，死锁发生后不能及时发现。&lt;/p&gt;
&lt;h5 id=&#34;2-等待图法&#34;&gt;&lt;strong&gt;2、等待图法&lt;/strong&gt;&lt;/h5&gt;
&lt;p&gt;死锁的检测可以通过一个&lt;strong&gt;有向的等待图&lt;/strong&gt;来进行判断，wait-for graph要求数据库&lt;strong&gt;保存锁的信息链表和事务等待链表&lt;/strong&gt;可以构造出一张图，如果一个事务依赖于另一个事务正在处理的数据，那么当前事务就会等待另一个事务结束，这也就是整个等待图中的一条边：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipbmkdsloard2.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;如上图所示，如果在这个有向图中出现了环，就说明当前数据库进入了死锁的状态&lt;code&gt;TransB -&amp;gt; TransE -&amp;gt; TransF -&amp;gt; TransD -&amp;gt; TransB&lt;/code&gt;，在这时就需要死锁恢复机制接入了。&lt;/p&gt;
&lt;p&gt;解决办法就是选择整个环中一个事务进行回滚，以打破整个等待图中的环，在整个恢复的过程中有三个事情需要考虑：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboamomrd2.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;每次出现死锁时其实都会有多个事务被波及，而选择其中哪一个任务进行回滚是必须要做的事情，在选择牺牲品（Victim）时的黄金原则就是&lt;strong&gt;最小化代价&lt;/strong&gt;，所以我们需要综合考虑事务已经计算的时间、使用的数据行以及涉及的事务等因素；&lt;/p&gt;
&lt;p&gt;死锁恢复的过程中，其实还可能出现某些任务在多次死锁时都被选择成为牺牲品，一直都不会成功执行，造成饥饿（Starvation），我们需要保证事务会在有穷的时间内执行，所以要在选择牺牲品时将时间戳加入考虑的范围。&lt;/p&gt;
">5、锁</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/miaosha/"" data-c="
          &lt;h2 id=&#34;系统架构&#34;&gt;系统架构&lt;/h2&gt;
&lt;p&gt;假设今年的双11预估峰值QPS将会有50万(我随便扯的)，而根据我们平时的经验单机8C8G的机器可以达到1000左右的QPS，那么从理论上来说我们只要500台机器就可以抗住了，就有钱任性不行？这么设计的话只能出门右转不送了。&lt;/p&gt;
&lt;h3 id=&#34;流量过滤&#34;&gt;流量过滤&lt;/h3&gt;
&lt;p&gt;本质上，参与秒杀的用户很多，但是商品的数量是有限的，真正能抢到的用户并不多，那么第一步就是要过滤掉大部分无效的流量。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;活动开始前前端页面的Button置灰，防止活动未开始无效的点击产生流量&lt;/li&gt;
&lt;li&gt;前端添加验证码或者答题，防止瞬间产生超高的流量，可以很好的起到错峰的效果，现在的验证码花样繁多，题库有的还要做个小学题，而且题库更新频繁，想暴力破解怕是很难。当然我知道的还有一种人工打码的方式，不过这个也是需要时间的，不像机器无限刷你的接口。&lt;/li&gt;
&lt;li&gt;活动校验，既然是活动，那么活动的参与用户，参加条件，用户白名单之类的要首先做一层校验拦截，还有其他的比如用户终端、IP地址、参与活动次数、黑名单用户的校验。比如活动主要针对APP端的用户校验，那么根据参数其他端的用户将被拦截，针对IP、mac地址、设备ID和用户ID可以对用户参与活动的次数做校验，黑名单根据平时的活动经验拦截掉一部分羊毛党等异常用户。&lt;/li&gt;
&lt;li&gt;非法请求拦截，做了以上拦截如果还有用户能绕过限制，那不得不说太牛X了。比如双11零点开始还做了答题限制，那么正常人怎么也需要1秒的时间来答题吧，就算单身30年手速我想也不能超过0.5秒了，那么针对刚好0点或者在0.5秒以内的请求就可以完全拦截掉。&lt;/li&gt;
&lt;li&gt;限流，假设秒杀10000件商品，我们有10台服务器，单机的QPS在1000，那么理论上1秒就可以抢完，针对微服务就可以做限流配置，避免后续无效的流量打到数据库造成不必要的压力。针对限流还有另外一种栅栏方式限流，这是一种纯靠运气的限流方式，就是在系统约定的请求开始的时间内随机偏移一段时间，针对每个请求的偏移量不同，如果在偏移时间之内就会被拦截，反之通过。&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUliapRxGg2WNiciacicz1h72sfRSo37G91OA0AxKJCCiccGtvaBcfPl0mWYmetaUfxuMHGKdHVBL8W6crg/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;性能优化&#34;&gt;性能优化&lt;/h3&gt;
&lt;p&gt;做完无效流量的过滤，那么可能你的无效请求已经过滤掉了90%，剩下的有效流量会大大的降低系统的压力。之后就是需要针对系统的性能做出优化了。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;页面静态化，参与秒杀活动的商品一般都是已知的，可以针对活动页面做静态化处理，缓存到CDN。假设我们一个页面300K大小，1千万用户的流量是多少？这些请求要请求后端服务器、数据库，压力可想而知，缓存到CDN用户请求不经过服务器，大大减小了服务器的压力。&lt;/li&gt;
&lt;li&gt;活动预热，针对活动的活动库存可以独立出来，不和普通的商品库存共享服务，活动库存活动开始前提前加载到redis，查询全部走缓存，最后扣减库存再视情况而定。&lt;/li&gt;
&lt;li&gt;独立部署，资源充足的情况下可以考虑针对秒杀活动单独部署一套环境，这套环境中可以剥离一些可能无用的逻辑，比如不用考虑使用优惠券、红包、下单后赠送积分的一些场景，或者这些场景可以活动结束后异步的统一发放。这只是一个举例，实际上单独针对秒杀活动的话你肯定有很多无用的业务代码是可以剥离的，这样可以提高不少性能。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;经过这两步之后，最终我们的流量应该是呈漏斗状。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUliapRxGg2WNiciacicz1h72sfRJA3ib69FS9OvfforpzZtWU2DWmSlGCiaVc3c9eurFBibEMU6fUbSeufpQ/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;超卖&#34;&gt;超卖&lt;/h2&gt;
&lt;p&gt;秒杀除开高并发高流量下的服务稳定性之外，剩下的核心大概就是怎么保证库存不超卖了，也可以说要保证的是最终一致性。一般来说，针对下单和库存有两种方式:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;下单即扣库存，这是最常规的大部分的做法。但是可能在活动中会碰到第二点说到的情况。&lt;/li&gt;
&lt;li&gt;支付完成扣库存，这种设计我碰到过就是酒店行业，廉价房放出来之后被黄牛下单抢占库存导致正常用户无法下单，然后黄牛可以用稍高的价格再售卖给用户从中牟利，所以会有在一些活动的时候采取支付成功后才占用库存的做法。&lt;strong&gt;不过这种方式实现起来比较复杂，可能造成大量的无效订单，在秒杀的场景中不太适用&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;针对秒杀建议选择下单扣库存的方式，实现相对简单而且是常规做法。&lt;/p&gt;
&lt;h3 id=&#34;方案&#34;&gt;方案&lt;/h3&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_jpg/ibBMVuDfkZUliapRxGg2WNiciacicz1h72sfRwrwSKwg5bia2tHY45C1UKgRJ2qxUnVEFiaY0rASibNLQwHqLWuoOVObXA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ol&gt;
&lt;li&gt;首先查询redis缓存库存是否充足&lt;/li&gt;
&lt;li&gt;先扣库存再落订单数据，可以防止订单生成了没有库存的超卖问题&lt;/li&gt;
&lt;li&gt;扣库存的时候先扣数据库库存，再扣减redis库存，保证在同一个事务里，无论两者哪一个发生了异常都会回滚。有一个问题是可能redis扣成功了由于网络问题返回失败，事务回滚，导致数据库和缓存不一致，这样实际少卖了，可以放到下轮秒杀去。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这种做法能一定程度上解决问题，但是也有可能会有其他问题。比如当大量请求落在同一条库存记录上去做update时，行锁导致大量的锁竞争会使得数据库的tps急剧下降，性能无法满足要求。&lt;/p&gt;
&lt;p&gt;另外一种做法就是排队，在服务层进行排队，针对同一个商品ID的也就是数据库是一条库存记录的做一个内存队列，串行化去扣减库存，可以一定程度上缓解数据库的并发压力。&lt;/p&gt;
&lt;h2 id=&#34;质量保障&#34;&gt;质量保障&lt;/h2&gt;
&lt;p&gt;为了保证系统的稳定性，防止你的系统被秒杀，一些质量监控就不得不做。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;熔断限流降级，老生常谈，根据压测情况进行限流，可以使用sentinel或者hystrix。另外前端后端都该有降级开关。&lt;/li&gt;
&lt;li&gt;监控，该上的都上，QPS监控、容器监控、CPU、缓存、IO监控等等。&lt;/li&gt;
&lt;li&gt;演练，大型秒杀事前演练少不了，不能冒冒失失的就上了吧。&lt;/li&gt;
&lt;li&gt;核对、预案，事后库存订单 金额、数量核对，是否发生超卖了?金额是否正常？都是必须的。预案可以在紧急情况下进行降级。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;数据统计&#34;&gt;数据统计&lt;/h2&gt;
&lt;p&gt;活动做完了，数据该怎么统计？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;前端埋点&lt;/li&gt;
&lt;li&gt;数据大盘，通过后台服务的打点配合监控系统可以通过大盘直观的看到一些活动的监控和数据&lt;/li&gt;
&lt;li&gt;离线数据分析，事后活动的数据可以同步到离线数仓做进一步的分析统计&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;总的来说，面对巨量的流量我们的方式就是首先通过各种条件先筛选掉无效流量，进行流量错峰，然后再对现有的系统性能做出优化，比如页面静态化，库存商品预热，也可以通过独立部署的方式和其他的环境做隔离，最后还要解决高并发下缓存一致性、库存不能超卖的问题，防止大量的并发打爆你的数据库。&lt;/p&gt;
&lt;p&gt;一个完整的活动从前端到后端是一个完整的链路，中间有事前的演练工作，事后的数据分析等都是必不可少的环节。&lt;/p&gt;
&lt;h3 id=&#34;吞吐量&#34;&gt;吞吐量&lt;/h3&gt;
&lt;p&gt;在了解qps、tps、rt、并发数之前，首先我们应该明确一个系统的吞吐量到底代表什么含义，一般来说，系统吞吐量指的是系统的抗压、负载能力，代表一个系统每秒钟能承受的最大用户访问量。&lt;/p&gt;
&lt;p&gt;一个系统的吞吐量通常由qps（tps）、并发数来决定，每个系统对这两个值都有一个相对极限值，只要某一项达到最大值，系统的吞吐量就上不去了。&lt;/p&gt;
&lt;h3 id=&#34;qps&#34;&gt;QPS&lt;/h3&gt;
&lt;p&gt;Queries Per Second，每秒查询数，即是每秒能够响应的查询次数，注意这里的查询是指用户发出请求到服务器做出响应成功的次数，简单理解可以认为查询=请求request。&lt;/p&gt;
&lt;p&gt;qps=每秒钟request数量&lt;/p&gt;
&lt;h3 id=&#34;tps&#34;&gt;TPS&lt;/h3&gt;
&lt;p&gt;Transactions Per Second 的缩写，每秒处理的事务数。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。&lt;/p&gt;
&lt;p&gt;针对单接口而言，TPS可以认为是等价于QPS的，比如访问一个页面/index.html，是一个TPS，而访问/index.html页面可能请求了3次服务器比如css、js、index接口，产生了3个QPS。&lt;/p&gt;
&lt;p&gt;tps=每秒钟事务数量&lt;/p&gt;
&lt;h3 id=&#34;rt&#34;&gt;RT&lt;/h3&gt;
&lt;p&gt;Response Time缩写，简单理解为系统从输入到输出的时间间隔，宽泛的来说，他代表从客户端发起请求到服务端接受到请求并响应所有数据的时间差。一般取平均响应时间。&lt;/p&gt;
&lt;h3 id=&#34;并发数&#34;&gt;并发数&lt;/h3&gt;
&lt;p&gt;简而言之，系统能同时处理的请求/事务数量。&lt;/p&gt;
&lt;h3 id=&#34;计算方式&#34;&gt;计算方式&lt;/h3&gt;
&lt;p&gt;QPS=并发数/RT 或者 并发数=QPS*RT&lt;/p&gt;
&lt;p&gt;举个栗子：&lt;/p&gt;
&lt;p&gt;假设公司每天早上9点到10点1个小时内都有员工要上厕所，公司有3600个员工，平均每个员工上厕所时间为10分钟，我们来计算一下。&lt;/p&gt;
&lt;p&gt;QPS  = 3600/60*60  1&lt;/p&gt;
&lt;p&gt;RT   = 10*60    600秒&lt;/p&gt;
&lt;p&gt;并发数 = 1 * 600    600&lt;/p&gt;
&lt;p&gt;这样就意味着如果想达到最好的蹲坑体验，公司需要600个坑位来满足员工需求，否则的话上厕所就要排队等待了。&lt;/p&gt;
&lt;h3 id=&#34;性能思考&#34;&gt;性能思考&lt;/h3&gt;
&lt;p&gt;按照QPS=并发数/RT公式，假设我们现在是单线程的场景，那么QPS公式应该是这样：QPS=1/RT，实际上RT应该=CPU time + CPU wait time，如果将线程数提高到2，那么QPS=2/(CPU time + CPU wait time)，那么是否意味着我们只要单纯提高线程数就能提高QPS呢？&lt;/p&gt;
&lt;h3 id=&#34;最佳线程数计算&#34;&gt;最佳线程数计算&lt;/h3&gt;
&lt;p&gt;假设CPU time是49ms，CPU wait time是200ms，那么QPS=1000ms/249ms=4.01，这里200ms的wait时间我们可以认为CPU一直处于等待状态啥也没干，理论上来说200ms还可以接受200/49≈4个请求，不考虑上下文切换和其他开销的话，可以认为总线程数=(200+49)/49=5，如果再考虑上CPU多核和利用率的问题，我们大致可以认为：&lt;strong&gt;最佳线程数=RT/CPUTime * CPU核心数 * CPU利用率&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;那么最大QPS公式推导为：&lt;/p&gt;
&lt;p&gt;最大QPS=最佳线程数*单线程QPS=（&lt;strong&gt;RT/CPU Time * CPU核心数 * CPU利用率）*（1/RT) = CPU核心数*CPU利用率/CPUTime&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;那么这样是否意味着我们只要不停增加CPU核心数就能无限提高QPS呢？&lt;/p&gt;
&lt;h3 id=&#34;阿姆达尔定律amdahl&#34;&gt;阿姆达尔定律Amdahl&lt;/h3&gt;
&lt;p&gt;G.M.Amdahl在1967年提出了Amdahl’s law，针对并行处理的scalability给出了一个模型，指出使用并行处理的提速由问题的可并行的部分所决定。我们可以简单理解为程序通过额外的计算资源，理论上能获得的加速值。&lt;/p&gt;
&lt;p&gt;par为并行计算所占的比例，p为并行处理节点个数&lt;/p&gt;
&lt;p&gt;假设你想从望京去顺义，坐一辆车需要3小时，虽然现在有3辆车，你也不能1小时就到。这里无法并行，所有Par=0%，p=3，加速比还是等于1，并没有提高速度。&lt;/p&gt;
&lt;h3 id=&#34;古斯塔夫森定律gustafson&#34;&gt;古斯塔夫森定律Gustafson&lt;/h3&gt;
&lt;p&gt;斯塔夫森定律又被称为扩展的加速比(scaled speedup)，他说明处理器个数、串行比例和加速比之间的关系，只是和阿姆达尔定律侧重角度有所不同。&lt;/p&gt;
&lt;p&gt;按照阿姆达尔定律和QPS计算公式，在CPUtime 和 CPU利用率不变的情况下，增加CPU核心数就能增加最大QPS，在par不为0即并行的时候，增加并行数量p就能提升效率，但是实际上随着请求数量的增加，带来大量的上下文的切换、gc和锁变化。qps更高，产生对象越多，gc越频繁，cpu time和利用率都受到影响，尤其在串行的时候，锁自旋、自适应、偏向等等也成为影响par的因素。&lt;/p&gt;
">秒杀系统</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/mybatis/"" data-c="
          &lt;p&gt;&lt;strong&gt;1、#{}和${}的区别是什么？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：&lt;span class=&#34;katex&#34;&gt;&lt;span class=&#34;katex-mathml&#34;&gt;&lt;math&gt;&lt;semantics&gt;&lt;mrow&gt;&lt;mrow&gt;&lt;/mrow&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;是&lt;/mi&gt;&lt;mi&gt;P&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;o&lt;/mi&gt;&lt;mi&gt;p&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;r&lt;/mi&gt;&lt;mi&gt;t&lt;/mi&gt;&lt;mi&gt;i&lt;/mi&gt;&lt;mi&gt;e&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;文&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;件&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;中&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;的&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;变&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;量&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;占&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;位&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;符&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;，&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;它&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;可&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;以&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;用&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;于&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;标&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;签&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;属&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;性&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;值&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;和&lt;/mi&gt;&lt;mi&gt;s&lt;/mi&gt;&lt;mi&gt;q&lt;/mi&gt;&lt;mi&gt;l&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;内&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;部&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;，&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;属&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;于&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;静&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;态&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;文&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;本&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;替&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;换&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;，&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;比&lt;/mi&gt;&lt;mi mathvariant=&#34;normal&#34;&gt;如&lt;/mi&gt;&lt;/mrow&gt;&lt;annotation encoding=&#34;application/x-tex&#34;&gt;{}是Properties文件中的变量占位符，它可以用于标签属性值和sql内部，属于静态文本替换，比如&lt;/annotation&gt;&lt;/semantics&gt;&lt;/math&gt;&lt;/span&gt;&lt;span class=&#34;katex-html&#34; aria-hidden=&#34;true&#34;&gt;&lt;span class=&#34;base&#34;&gt;&lt;span class=&#34;strut&#34; style=&#34;height:0.8888799999999999em;vertical-align:-0.19444em;&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord&#34;&gt;&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;是&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.13889em;&#34;&gt;P&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;o&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.02778em;&#34;&gt;r&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;文&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;件&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;中&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;的&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;变&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;量&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;占&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;位&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;符&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;它&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;可&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;以&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;用&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;于&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;标&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;签&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;属&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;性&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;值&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;和&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.03588em;&#34;&gt;q&lt;/span&gt;&lt;span class=&#34;mord mathdefault&#34; style=&#34;margin-right:0.01968em;&#34;&gt;l&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;内&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;部&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;属&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;于&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;静&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;态&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;文&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;本&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;替&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;换&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;，&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;比&lt;/span&gt;&lt;span class=&#34;mord cjk_fallback&#34;&gt;如&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;{driver}会被静态替换为com.mysql.jdbc.Driver。#{}是sql的参数占位符，Mybatis会将sql中的#{}替换为?号，在sql执行前会使用PreparedStatement的参数设置方法，按序给sql的?号占位符设置参数值，比如ps.setInt(0, parameterValue)，#{item.name}的取值方式为使用反射从参数对象中获取item对象的name属性值，相当于param.getItem().getName()。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、Xml映射文件中，除了常见的select|insert|updae|delete标签之外，还有哪些标签？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：还有很多其他的标签，&lt;resultMap&gt;、&lt;parameterMap&gt;、&lt;sql&gt;、&lt;include&gt;、&lt;selectKey&gt;，加上动态sql的9个标签，trim|where|set|foreach|if|choose|when|otherwise|bind等，其中&lt;strong&gt;为sql片段标签，通过标签引入sql片段&lt;/strong&gt;，&lt;selectKey&gt;为不支持自增的主键生成策略标签。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、最佳实践中，通常一个Xml映射文件，都会写一个Dao接口与之对应，请问，这个Dao接口的工作原理是什么？Dao接口里的方法，参数不同时，方法能重载吗？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Dao接口，就是人们常说的Mapper接口，接口的全限名，就是映射文件中的namespace的值，接口的方法名，就是映射文件中&lt;strong&gt;MappedStatement&lt;/strong&gt;的id值，接口方法内的参数，就是传递给sql的参数。Mapper接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为key值，可唯一定位一个MappedStatement，举例：com.mybatis3.mappers.StudentDao.findStudentById，可以唯一找到namespace为com.mybatis3.mappers.StudentDao下面id = findStudentById的MappedStatement。在Mybatis中，每一个&lt;select&gt;、&lt;insert&gt;、&lt;update&gt;、&lt;delete&gt;标签，都会被解析为一个MappedStatement对象。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dao接口里的方法，是不能重载的，因为是全限名+方法名的保存和寻找策略。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Dao接口的工作原理是&lt;strong&gt;JDK动态代理&lt;/strong&gt;，Mybatis运行时会使用JDK动态代理为Dao接口生成代理proxy对象，代理对象proxy会拦截接口方法，转而执行MappedStatement所代表的sql，然后将sql执行结果返回。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4、Mybatis是如何进行分页的？分页插件的原理是什么？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Mybatis使用RowBounds对象进行分页，它是针对ResultSet结果集执行的&lt;strong&gt;内存分页&lt;/strong&gt;，而非物理分页，可以在sql内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。&lt;/p&gt;
&lt;p&gt;分页插件的基本原理是使用Mybatis提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的sql，然后重写sql，根据dialect方言，添加对应的物理分页语句和物理分页参数。&lt;/p&gt;
&lt;p&gt;举例：select * from student，拦截sql后重写为：select t.* from （select * from student）t limit 0，10&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5、简述Mybatis的插件运行原理，以及如何编写一个插件。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Mybatis仅可以编写针对&lt;strong&gt;ParameterHandler、ResultSetHandler、StatementHandler、Executor&lt;/strong&gt;这4种接口的插件，Mybatis使用JDK的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这4种接口对象的方法时，就会进入拦截方法，具体就是InvocationHandler的invoke()方法，当然，只会拦截那些你指定需要拦截的方法。&lt;/p&gt;
&lt;p&gt;实现Mybatis的Interceptor接口并复写intercept()方法，然后在给插件编写注解，指定要拦截哪一个接口的哪些方法即可，记住，别忘了在配置文件中配置你编写的插件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6、Mybatis执行批量插入，能返回数据库主键列表吗？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：能，JDBC都能，Mybatis当然也能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7、Mybatis动态sql是做什么的？都有哪些动态sql？能简述一下动态sql的执行原理不？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Mybatis动态sql可以让我们在Xml映射文件内，以标签的形式编写动态sql，完成逻辑判断和动态拼接sql的功能，Mybatis提供了9种动态sql标签trim|where|set|foreach|if|choose|when|otherwise|bind。&lt;/p&gt;
&lt;p&gt;其执行原理为，使&lt;strong&gt;用OGNL从sql参数对象中计算表达式的值，根据表达式的值动态拼接sql&lt;/strong&gt;，以此来完成动态sql的功能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8、Mybatis是如何将sql执行结果封装为目标对象并返回的？都有哪些映射形式？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：第一种是使用****标签，逐一定义列名和对象属性名之间的映射关系。第二种是使用sql列的别名功能，将列别名书写为对象属性名，比如T_NAME AS NAME，对象属性名一般是name，小写，但是列名不区分大小写，Mybatis会忽略列名大小写，智能找到与之对应对象属性名，你甚至可以写成T_NAME AS NaMe，Mybatis一样可以正常工作。&lt;/p&gt;
&lt;p&gt;有了列名与属性名的映射关系后，Mybatis通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9、Mybatis能执行一对一、一对多的关联查询吗？都有哪些实现方式，以及它们之间的区别。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：能，Mybatis不仅可以执行一对一、一对多的关联查询，还可以执行多对一，多对多的关联查询，多对一查询，其实就是一对一查询，只需要把selectOne()修改为selectList()即可；多对多查询，其实就是一对多查询，只需要把selectOne()修改为selectList()即可。&lt;/p&gt;
&lt;p&gt;关联对象查询，有两种实现方式，一种是单独发送一个sql去查询关联对象，赋给主对象，然后返回主对象。另一种是使用嵌套查询，嵌套查询的含义为使用join查询，一部分列是A对象的属性值，另外一部分列是关联对象B的属性值，好处是只发一个sql查询，就可以把主对象和其关联对象查出来。&lt;/p&gt;
&lt;p&gt;那么问题来了，join查询出来100条记录，如何确定主对象是5个，而不是100个？其去重复的原理是&lt;resultMap&gt;标签内的&lt;id&gt;子标签，指定了唯一确定一条记录的id列，Mybatis根据&lt;id&gt;列值来完成100条记录的去重复功能，&lt;id&gt;可以有多个，代表了联合主键的语意。&lt;/p&gt;
&lt;p&gt;同样主对象的关联对象，也是根据这个原理去重复的，尽管一般情况下，只有主对象会有重复记录，关联对象一般不会重复。&lt;/p&gt;
&lt;p&gt;举例：下面join查询出来6条记录，一、二列是Teacher对象列，第三列为Student对象列，Mybatis去重复处理后，结果为1个老师6个学生，而不是6个老师6个学生。&lt;/p&gt;
&lt;p&gt;​    t_id   t_name      s_id&lt;/p&gt;
&lt;p&gt;|      1 | teacher    |    38 |&lt;/p&gt;
&lt;p&gt;|      1 | teacher    |    39 |&lt;/p&gt;
&lt;p&gt;|      1 | teacher    |    40 |&lt;/p&gt;
&lt;p&gt;|      1 | teacher    |    41 |&lt;/p&gt;
&lt;p&gt;|      1 | teacher    |    42 |&lt;/p&gt;
&lt;p&gt;|      1 | teacher    |    43 |&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10、Mybatis是否支持延迟加载？如果支持，它的实现原理是什么？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Mybatis仅支持association关联对象和collection关联集合对象的延迟加载，association指的就是一对一，collection指的就是一对多查询。在Mybatis配置文件中，可以配置是否启用延迟加载lazyLoadingEnabled=true|false。&lt;/p&gt;
&lt;p&gt;它的原理是，使用CGLIB创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用a.getB().getName()，拦截器invoke()方法发现a.getB()是null值，那么就会单独发送事先保存好的查询关联B对象的sql，把B查询上来，然后调用a.setB(b)，于是a的对象b属性就有值了，接着完成a.getB().getName()方法的调用。这就是延迟加载的基本原理。&lt;/p&gt;
&lt;p&gt;当然了，不光是Mybatis，几乎所有的包括Hibernate，支持延迟加载的原理都是一样的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;11、Mybatis的Xml映射文件中，不同的Xml映射文件，id是否可以重复？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：不同的Xml映射文件，如果配置了namespace，那么id可以重复；如果没有配置namespace，那么id不能重复；毕竟namespace不是必须的，只是最佳实践而已。&lt;/p&gt;
&lt;p&gt;原因就是namespace+id是作为Map&amp;lt;String, MappedStatement&amp;gt;的key使用的，如果没有namespace，就剩下id，那么，id重复会导致数据互相覆盖。有了namespace，自然id就可以重复，namespace不同，namespace+id自然也就不同。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;12、Mybatis中如何执行批处理？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：使用BatchExecutor完成批处理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;13、Mybatis都有哪些Executor执行器？它们之间的区别是什么？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Mybatis有三种基本的Executor执行器，&lt;strong&gt;SimpleExecutor、ReuseExecutor、BatchExecutor。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;**SimpleExecutor：**每执行一次update或select，就开启一个Statement对象，用完立刻关闭Statement对象。&lt;/p&gt;
&lt;p&gt;**ReuseExecutor：**执行update或select，以sql作为key查找Statement对象，存在就使用，不存在就创建，用完后，不关闭Statement对象，而是放置于Map&amp;lt;String, Statement&amp;gt;内，供下一次使用。简言之，就是重复使用Statement对象。&lt;/p&gt;
&lt;p&gt;**BatchExecutor：**执行update（没有select，JDBC批处理不支持select），将所有sql都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个Statement对象，每个Statement对象都是addBatch()完毕后，等待逐一执行executeBatch()批处理。与JDBC批处理相同。&lt;/p&gt;
&lt;p&gt;作用范围：Executor的这些特点，都严格限制在SqlSession生命周期范围内。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;14、Mybatis中如何指定使用哪一种Executor执行器？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：在Mybatis配置文件中，可以指定默认的ExecutorType执行器类型，也可以手动给DefaultSqlSessionFactory的创建SqlSession的方法传递ExecutorType类型参数。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;15、Mybatis是否可以映射Enum枚举类？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Mybatis可以映射枚举类，不单可以映射枚举类，Mybatis可以映射任何对象到表的一列上。映射方式为自定义一个TypeHandler，实现TypeHandler的setParameter()和getResult()接口方法。TypeHandler有两个作用，一是完成从javaType至jdbcType的转换，二是完成jdbcType至javaType的转换，体现为setParameter()和getResult()两个方法，分别代表设置sql问号占位符参数和获取列查询结果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;16、Mybatis映射文件中，如果A标签通过include引用了B标签的内容，请问，B标签能否定义在A标签的后面，还是说必须定义在A标签的前面？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：虽然Mybatis解析Xml映射文件是按照顺序解析的，但是，被引用的B标签依然可以定义在任何地方，Mybatis都可以正确识别。&lt;/p&gt;
&lt;p&gt;原理是，Mybatis解析A标签，发现A标签引用了B标签，但是B标签尚未解析到，尚不存在，此时，Mybatis会将A标签标记为&lt;strong&gt;未解析状态&lt;/strong&gt;，然后继续解析余下的标签，包含B标签，待所有标签解析完毕，Mybatis会重新解析那些被标记为未解析的标签，此时再解析A标签时，B标签已经存在，A标签也就可以正常解析完成了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;17、简述Mybatis的Xml映射文件和Mybatis内部数据结构之间的映射关系？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Mybatis将所有Xml配置信息都封装到All-In-One重量级对象Configuration内部。在Xml映射文件中，&lt;parameterMap&gt;标签会被解析为ParameterMap对象，其每个子元素会被解析为ParameterMapping对象。&lt;strong&gt;标签会被解析为ResultMap对象&lt;/strong&gt;，其每个子元素会被解析为&lt;strong&gt;ResultMapping对象&lt;/strong&gt;。每一个&lt;select&gt;、&lt;insert&gt;、&lt;update&gt;、&lt;delete&gt;标签均会被解析为&lt;strong&gt;MappedStatement&lt;/strong&gt;对象，标签内的sql会被解析为BoundSql对象。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;18、为什么说Mybatis是半自动ORM映射工具？它与全自动的区别在哪里？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;答：Hibernate属于全自动ORM映射工具，使用Hibernate查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。而Mybatis在查询关联对象或关联集合对象时，需要手动编写sql来完成，所以，称之为半自动ORM映射工具。&lt;/p&gt;
&lt;p&gt;19、Mapper原理&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;../$%7Bimages%7D/cl11%E6%97%A5ipboard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;../$%7Bimages%7D/clipboa131231rd.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
">7、mybatis</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/redis/"" data-c="
          &lt;h1 id=&#34;1-为什么要使用redis&#34;&gt;1、为什么要使用&lt;code&gt;Redis&lt;/code&gt;&lt;/h1&gt;
&lt;h2 id=&#34;一性能&#34;&gt;（一）性能&lt;/h2&gt;
&lt;p&gt;我们在碰到需要执行耗时特别久，且结果&lt;strong&gt;不频繁变动&lt;/strong&gt;的SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够迅速响应。&lt;/p&gt;
&lt;h2 id=&#34;二并发&#34;&gt;（二）并发&lt;/h2&gt;
&lt;p&gt;在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用&lt;code&gt;redis&lt;/code&gt;做一个缓冲操作，让请求先访问到&lt;code&gt;redis&lt;/code&gt;，而不是直接访问数据库。&lt;/p&gt;
&lt;h2 id=&#34;为什么要用redis而不用mapguava做缓存&#34;&gt;为什么要用&lt;code&gt;redis&lt;/code&gt;而不用map/guava做缓存？&lt;/h2&gt;
&lt;p&gt;缓存分为本地缓存和分布式缓存。&lt;/p&gt;
&lt;p&gt;以 Java 为例，使用自带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，生命周期随着 &lt;code&gt;jvm&lt;/code&gt;的销毁而结束，没有远程交互开销，性能最好，但是受限于单机容量，一般缓存较小且无法扩展，并且在多实例的情况下，每个实例都需要各自保存一份缓存，&lt;strong&gt;缓存不具有一致性&lt;/strong&gt;。&lt;br&gt;
使用 &lt;code&gt;redis&lt;/code&gt;或 &lt;code&gt;memcached&lt;/code&gt;之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。分布式缓存一般都具有良好的水平扩展能力，对较大数据量的场景也能应付自如。缺点就是需要进行远程请求，性能不如本地缓存。&lt;/p&gt;
&lt;p&gt;为了平衡这种情况，实际业务中一般采用&lt;strong&gt;多级缓存&lt;/strong&gt;，本地缓存只保存访问频率最高的部分热点数据，其他的热点数据放在分布式缓存中。&lt;/p&gt;
&lt;h2 id=&#34;你了解最经典的kv-db读写模式么&#34;&gt;你了解最经典的KV、DB读写模式么？&lt;/h2&gt;
&lt;p&gt;最经典的缓存+数据库读写的模式，就是 &lt;strong&gt;Cache Aside Pattern&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。&lt;/li&gt;
&lt;li&gt;更新的时候，&lt;strong&gt;先更新数据库，然后再删除缓存&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;为什么是删除缓存而不是更新缓存&#34;&gt;为什么是删除缓存，而不是更新缓存？&lt;/h2&gt;
&lt;p&gt;原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。删除缓存，而不是更新缓存，就是一个 Lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算&lt;/p&gt;
&lt;h1 id=&#34;2-redis数据类型&#34;&gt;2、&lt;code&gt;Redis&lt;/code&gt;数据类型&lt;/h1&gt;
&lt;h2 id=&#34;21-redis数据类型实现&#34;&gt;2.1 Redis数据类型实现&lt;/h2&gt;
&lt;p&gt;###1、动态字符串SDS&lt;/p&gt;
&lt;p&gt;Redis 是用 C 语言写的，但是对于Redis的字符串，却不是 C 语言中的字符串，它是自己构建了一种名为简单动态字符串（simple dynamic string,SDS）的抽象类型，并将 SDS 作为 Redis的默认字符串表示，它的特点就是预先分配内存，记录字符串长度，在原字符串数组buf[]中新增一串字符串。优点就是当清空时，并没有真正释放内存，而是将长度字段len值为0，当再次使用时，避免重新分配内存，从而提高效率。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clip_image002-1583381828514.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;2-链表linkedlist&#34;&gt;2、链表linkedlist&lt;/h3&gt;
&lt;p&gt;redis链表是一个双向无环链表结构，很多发布订阅、慢查询、监视器功能都是使用到了链表来实现，每个链表的节点由一个listNode结构来表示，每个节点都有指向前置节点和后置节点的指针，同时表头节点的前置和后置节点都指向NULL。&lt;/p&gt;
&lt;h3 id=&#34;3-整数集合intset&#34;&gt;3、整数集合intset&lt;/h3&gt;
&lt;p&gt;用于保存整数值的集合抽象数据结构，不会出现重复元素，底层实现为数组。&lt;/p&gt;
&lt;p&gt;###4、压缩列表ziplist&lt;/p&gt;
&lt;p&gt;压缩列表是为节约内存而开发的顺序性数据结构，他可以包含多个节点，每个节点可以保存一个字节数组或者整数值。&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clip_image004.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;5-字典hashtable&#34;&gt;5、字典hashtable&lt;/h3&gt;
&lt;p&gt;用于保存键值对的抽象数据结构。redis使用hash表作为底层实现，每个字典带有两个hash表，供平时使用和rehash时使用，hash表使用链地址法来解决键冲突，被分配到同一个索引位置的多个键值对会形成一个单向链表，在对hash表进行扩容或者缩容的时候，为了服务的可用性，rehash的过程不是一次性完成的，而是渐进式的。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clip_image006.png&#34; alt=&#34;图片包含 文字  描述已自动生成&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;6-跳跃表skiplist&#34;&gt;6、跳跃表skiplist&lt;/h3&gt;
&lt;p&gt;跳跃表是有序集合的底层实现之一，redis中在实现有序集合键和集群节点的内部结构中都是用到了跳跃表。redis跳跃表由zskiplist和zskiplistNode组成，zskiplist用于保存跳跃表信息（表头、表尾节点、长度等），zskiplistNode用于表示表跳跃节点，每个跳跃表的层高都是1-32的随机数，在同一个跳跃表中，多个节点可以包含相同的分值，但是每个节点的成员对象必须是唯一的，节点按照分值大小排序，如果分值相同，则按照成员对象的大小排序。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clip_image010.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clip_image012.png&#34; alt=&#34;图片包含 文字  描述已自动生成&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;如上图中，左侧L5层高为3，所在表中位置为5，所以level为5&lt;/p&gt;
&lt;p&gt;基于这些基础的数据结构，redis封装了自己的对象系统，包含字符串对象string、列表对象list、哈希对象hash、集合对象set、有序集合对象zset，每种对象都用到了至少一种基础的数据结构。&lt;/p&gt;
&lt;p&gt;redis通过encoding属性设置对象的编码形式来提升灵活性和效率，基于不同的场景redis会自动做出优化。不同对象的编码如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;字符串对象string：int整数、embstr编码的简单动态字符串、raw简单动态字符串&lt;/li&gt;
&lt;li&gt;列表对象list：ziplist、linkedlist&lt;/li&gt;
&lt;li&gt;哈希对象hash：ziplist、hashtable&lt;/li&gt;
&lt;li&gt;集合对象set：intset、hashtable&lt;/li&gt;
&lt;li&gt;有序集合对象zset：ziplist、skiplist&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;22-redis数据类型应用&#34;&gt;2.2 Redis数据类型应用&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20200305121455058.png&#34; alt=&#34;image-20200305121455058&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;Key-Value结构查询速度更快，时间复杂度为O(1)，但会消耗更多内存，相比之下，Hash更优于Set、String结构，如果单纯的存储和查询，不做集合、排序处理，优先选择Hash结构。List不适合做检索，SortSet为有序集合，采用skiplist结构，检索速度比哈希略慢。&lt;/p&gt;
&lt;h3 id=&#34;1-string字符串&#34;&gt;1、String（字符串）&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;String&lt;/strong&gt;的实际应用场景比较广泛的有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;缓存功能：String&lt;/strong&gt;字符串是最常用的数据类型，不仅仅是**&lt;code&gt;Redis&lt;/code&gt;&lt;strong&gt;，各个语言都是最基本类型，因此，利用&lt;/strong&gt;&lt;code&gt;Redis&lt;/code&gt;&lt;strong&gt;作为缓存，配合其它数据库作为存储层，利用&lt;/strong&gt;&lt;code&gt;Redis&lt;/code&gt;**支持高并发的特点，可以大大加快系统的读写速度、以及降低后端数据库的压力。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;计数器：&lt;strong&gt;许多系统都会使用&lt;/strong&gt;&lt;code&gt;Redis&lt;/code&gt;&lt;strong&gt;作为系统的实时计数器，可以&lt;/strong&gt;快速实现计数和查询&lt;/strong&gt;的功能。而且最终的数据结果可以按照特定的时间落地到数据库或者其它存储介质当中进行永久保存。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;共享用户Session：&lt;strong&gt;用户重新刷新一次界面，可能需要访问一下数据进行重新登录，或者访问页面缓存&lt;/strong&gt;Cookie&lt;/strong&gt;，但是可以利用**&lt;code&gt;Redis&lt;/code&gt;&lt;strong&gt;将用户的&lt;/strong&gt;Session&lt;strong&gt;集中管理，在这种模式只需要保证&lt;/strong&gt;&lt;code&gt;Redis&lt;/code&gt;&lt;strong&gt;的高可用，每次用户&lt;/strong&gt;Session**的更新和获取都可以快速完成。大大提高效率。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;自增序列生成&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;实现类似于RDBMS的Sequence功能，生成一系列唯一的序列号，直接将返回值作为序列使用即可。&lt;/p&gt;
&lt;p&gt;获取一批（如100个）序列值：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;INCRBY sequence 100
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;假设返回值为N，那么[N - 99 ~ N]的数值都是可用的序列值。&lt;/p&gt;
&lt;p&gt;当多个客户端同时向Redis申请自增序列时，Redis能够确保每个客户端得到的序列值或序列范围都是全局唯一的，绝对不会出现不同客户端得到了重复的序列值的情况。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;string 类型是二进制安全的。意思是 &lt;code&gt;redis&lt;/code&gt;的 string 可以包含任何数据。比如jpg图片或者序列化的对象。&lt;br&gt;
string 类型是 &lt;code&gt;Redis&lt;/code&gt;最基本的数据类型，string 类型的值最大能存储 512MB。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SET key value [EX seconds] [PX milliseconds] [NX|XX]
如果 key 已经持有其他值， SET 就覆写旧值， 无视类型。当SET命令对一个带有生存时间（TTL）的键进行设置之后， 该键原有的TTL将被清除。
EX seconds ： 将键的过期时间设置为 seconds 秒。 执行 SET key value EX seconds 的效果等同于执行 SETEX key seconds value 。
PX milliseconds ： 将键的过期时间设置为 milliseconds 毫秒。 执行 SET key value PX milliseconds 的效果等同于执行 PSETEX key milliseconds value 。
NX ： 只在键不存在时， 才对键进行设置操作。 执行 SET key value NX 的效果等同于执行 SETNX key value 
XX ： 只在键已经存在时， 才对键进行设置操作。

GET：获取某个key对应的value，时间复杂度O(1)
GETSET：为一个key设置value，并返回该key的原value，时间复杂度O(1)
MSET：为多个key设置value，时间复杂度O(N)
MSETNX：同MSET，如果指定的key中有任意一个已存在，则不进行任何操作，时间复杂度O(N)
MGET：获取多个key对应的value，时间复杂度O(N)
Redis的基本数据类型只有String，但Redis可以把String作为整型或浮点型数字来使用，主要体现在INCR、DECR类的命令上：

INCR：将key对应的value值自增1，并返回自增后的值。只对可以转换为整型的String数据起作用。时间复杂度O(1)
INCRBY：将key对应的value值自增指定的整型数值，并返回自增后的值。只对可以转换为整型的String数据起作用。时间复杂度O(1)
DECR/DECRBY：同INCR/INCRBY，自增改为自减。

INCR/DECR系列命令要求操作的value类型为String，并可以转换为64位带符号的整型数字，否则会返回错误。
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;2-hash哈希&#34;&gt;2、Hash（哈希）&lt;/h3&gt;
&lt;p&gt;Redis hash 是一个string类型的 field 和 value 的映射表，hash 特别适合用于存储对象，不支持数据类型的嵌套。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;HSET：将key对应的Hash中的field设置为value。如果该Hash不存在，会自动创建一个。时间复杂度O(1)
HGET：返回指定Hash中field字段的值，时间复杂度O(1)
HMSET/HMGET：同HSET和HGET，可以批量操作同一个key下的多个field，时间复杂度：O(N)，N为一次操作的field数量
HSETNX：同HSET，但如field已经存在，HSETNX不会进行任何操作，时间复杂度O(1)
HEXISTS：判断指定Hash中field是否存在，存在返回1，不存在返回0，时间复杂度O(1)
HDEL：删除指定Hash中的field（1个或多个），时间复杂度：O(N)，N为操作的field数量
HINCRBY：同INCRBY命令，对指定Hash中的一个field进行INCRBY，时间复杂度O(1)

应谨慎使用的Hash相关命令：
HGETALL：返回指定Hash中所有的field-value对。返回结果为数组，数组中field和value交替出现。时间复杂度O(N)
HKEYS/HVALS：返回指定Hash中所有的field/value，时间复杂度O(N)
上述三个命令都会对Hash进行完整遍历，Hash中的field数量与命令的耗时线性相关。对于尺寸不可预知的Hash，应严格避免使用上面三个命令，而改为使用HSCAN命令进行游标式的遍历
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;3-list列表&#34;&gt;3、List（列表）&lt;/h3&gt;
&lt;p&gt;Redis 列表是简单的&lt;strong&gt;字符串列表&lt;/strong&gt;，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边），可以用作异步队列。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;消息队列：Redis&lt;/strong&gt;的链表结构，可以轻松实现阻塞队列，可以使用左进右出的命令组成来完成队列的设计。比如：数据的生产者可以通过**&lt;code&gt;Lpush&lt;/code&gt;&lt;strong&gt;命令从左边插入数据，多个数据消费者，可以使用&lt;/strong&gt;&lt;code&gt;BRpop&lt;/code&gt;**命令阻塞的“抢”列表尾部的数据。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;文章列表或者数据分页展示的应用。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;比如，我们常用的博客网站的文章列表，当用户量越来越多时，而且每一个用户都有自己的文章列表，而且当文章多时，都需要分页展示，这时可以考虑使用&lt;strong&gt;Redis&lt;/strong&gt;的列表，列表不但有序同时还支持按照范围内获取元素，可以完美解决分页查询功能。大大提高查询效率。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;LPUSH：向指定List的左侧（即头部）插入1个或多个元素，返回插入后的List长度。时间复杂度O(N)，N为插入元素的数量
RPUSH：同LPUSH，向指定List的右侧（即尾部）插入1或多个元素
LPOP：从指定List的左侧（即头部）移除一个元素并返回，时间复杂度O(1)
RPOP：同LPOP，从指定List的右侧（即尾部）移除1个元素并返回
LPUSHX/RPUSHX：与LPUSH/RPUSH类似，区别在于，LPUSHX/RPUSHX操作的key如果不存在，则不会进行任何操作
LLEN：返回指定List的长度，时间复杂度O(1)
LRANGE：返回指定List中指定范围的元素（双端包含，即LRANGE key 0 10会返回11个元素），时间复杂度O(N)。
LPOP/RPOP : 取数据，当lpop没有消息的时候，要适当sleep一会再重试。
BLPOP/BRPOP 是列表的阻塞式(blocking)弹出原语。它是 LPOP/RPOP key 命令的阻塞版本，当给定列表内没有任何元素可供弹出的时候，连接将被 BLPOP 命令阻塞，直到等待超时或发现可弹出元素为止。当给定多个 key 参数时，按参数 key 的先后顺序依次检查各个列表，弹出第一个非空列表的头元素。

应谨慎使用的List相关命令：

LINDEX：返回指定List指定index上的元素，如果index越界，返回nil。index数值是回环的，即-1代表List最后一个位置，-2代表List倒数第二个位置。时间复杂度O(N)
LSET：将指定List指定index上的元素设置为value，如果index越界则返回错误，时间复杂度O(N)，如果操作的是头/尾部的元素，则时间复杂度为O(1)
LINSERT：向指定List中指定元素之前/之后插入一个新元素，并返回操作后的List长度。如果指定的元素不存在，返回-1。如果指定key不存在，不会进行任何操作，时间复杂度O(N)
由于Redis的List是链表结构的，上述的三个命令的算法效率较低，需要对List进行遍历，命令的耗时无法预估，在List长度大的情况下耗时会明显增加，应谨慎使用。
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;4-set集合&#34;&gt;4、Set（集合）&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Set&lt;/strong&gt; 是无序集合，会自动去重的那种。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SADD：向指定Set中添加1个或多个member，如果指定Set不存在，会自动创建一个。时间复杂度O(N)，N为添加的member个数
SREM：从指定Set中移除1个或多个member，时间复杂度O(N)，N为移除的member个数
SRANDMEMBER：从指定Set中随机返回1个或多个member，时间复杂度O(N)，N为返回的member个数
SPOP：从指定Set中随机移除并返回count个member，时间复杂度O(N)，N为移除的member个数
SCARD：返回指定Set中的member个数，时间复杂度O(1)
SISMEMBER：判断指定的value是否存在于指定Set中，时间复杂度O(1)
SMOVE：将指定member从一个Set移至另一个Set

慎用的Set相关命令：

SMEMBERS：返回指定Hash中所有的member，时间复杂度O(N)
SUNION/SUNIONSTORE：计算多个Set的并集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数
SINTER/SINTERSTORE：计算多个Set的交集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数
SDIFF/SDIFFSTORE：计算1个Set与1或多个Set的差集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数
上述几个命令涉及的计算量大，应谨慎使用，特别是在参与计算的Set尺寸不可知的情况下，应严格避免使用。
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;5-zsetsorted-set有序集合&#34;&gt;5、&lt;code&gt;zset&lt;/code&gt;(sorted set：有序集合)&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Redis zset&lt;/code&gt;和 set 一样也是string类型元素的集合,且不允许重复的成员。不同的是每个元素都会关联一个double类型的分数。&lt;code&gt;redis&lt;/code&gt;正是通过分数来为集合中的成员进行从小到大的排序。&lt;code&gt;zset&lt;/code&gt;的成员是唯一的,但分数(score)却可以重复。如果多个member拥有相同的score，则以字典序进行升序排序。Sorted Set非常适合用于实现排名。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;排行榜：有序集合经典使用场景。例如视频网站需要对用户上传的视频做排行榜，榜单维护可能是多方面：按照时间、按照播放量、按照获得的赞数等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;用&lt;strong&gt;Sorted Sets&lt;/strong&gt;来做&lt;strong&gt;带权重的队列&lt;/strong&gt;，比如普通消息的score为1，重要消息的score为2，然后工作线程可以选择按score的倒序来获取工作任务。让重要的任务优先执行。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;ZADD：向指定Sorted Set中添加1个或多个member，时间复杂度O(Mlog(N))，M为添加的member数量，N为Sorted Set中的member数量
ZREM：从指定Sorted Set中删除1个或多个member，时间复杂度O(Mlog(N))，M为删除的member数量，N为Sorted Set中的member数量
ZCOUNT：返回指定Sorted Set中指定score范围内的member数量，时间复杂度：O(log(N))
ZCARD：返回指定Sorted Set中的member数量，时间复杂度O(1)
ZSCORE：返回指定Sorted Set中指定member的score，时间复杂度O(1)
ZRANK/ZREVRANK：返回指定member在Sorted Set中的排名，ZRANK返回按升序排序的排名，ZREVRANK则返回按降序排序的排名。时间复杂度O(log(N))
ZINCRBY：同INCRBY，对指定Sorted Set中的指定member的score进行自增，时间复杂度O(log(N))

慎用的Sorted Set相关命令：

ZRANGE/ZREVRANGE：返回指定Sorted Set中指定排名范围内的所有member，ZRANGE为按score升序排序，ZREVRANGE为按score降序排序，时间复杂度O(log(N)+M)，M为本次返回的member数
ZRANGEBYSCORE/ZREVRANGEBYSCORE：返回指定Sorted Set中指定score范围内的所有member，返回结果以升序/降序排序，min和max可以指定为-inf和+inf，代表返回所有的member。时间复杂度O(log(N)+M)
ZREMRANGEBYRANK/ZREMRANGEBYSCORE：移除Sorted Set中指定排名范围/指定score范围内的所有member。时间复杂度O(log(N)+M)

上述几个命令，应尽量避免传递[0 -1]或[-inf +inf]这样的参数，来对Sorted Set做一次性的完整遍历，特别是在Sorted Set的尺寸不可预知的情况下。
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;6-hyperloglog&#34;&gt;6、&lt;code&gt;HyperLogLog&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;供不精确的&lt;strong&gt;去重计数功能&lt;/strong&gt;，比较适合用来做大规模数据的去重统计，例如统计 UV；&lt;/p&gt;
&lt;p&gt;是用来做基数统计的算法，&lt;code&gt;HyperLogLog&lt;/code&gt;的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。&lt;/p&gt;
&lt;p&gt;比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;PFADD key element [element ...\]添加指定元素到 HyperLogLog 中。 
PFCOUNT key [key ...\] 返回给定 HyperLogLog 的基数估算值。 
PFMERGE destkey sourcekey [sourcekey ...\] 将多个 HyperLogLog 合并为一个 HyperLogLog 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;7-geo&#34;&gt;7、Geo&lt;/h3&gt;
&lt;p&gt;可以用来保存地理位置，并作&lt;strong&gt;位置距离计算&lt;/strong&gt;或者根据&lt;strong&gt;半径计算位置&lt;/strong&gt;等。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GEOADD key longitude latitude member
将给定的空间元素（纬度、经度、名字）添加到指定的键里面。 这些数据会以有序集合的形式被储存在键里面， 从而使得像 GEORADIUS 和 GEORADIUSBYMEMBER 这样的命令可以在之后通过位置查询取得这些元素。

GEOPOS key member 
从键里面返回所有给定位置元素的位置（经度和纬度）。
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;8-bitmap&#34;&gt;8、&lt;code&gt;BitMap&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;位图是支持按 bit 位来存储信息，可以用来实现 &lt;strong&gt;布隆过滤器（&lt;code&gt;BloomFilter&lt;/code&gt;）&lt;/strong&gt;；&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SETBIT key offset value
对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit)。
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;3-其他命令&#34;&gt;3、其他命令&lt;/h1&gt;
&lt;h2 id=&#34;1-pubsub&#34;&gt;1、Pub/Sub&lt;/h2&gt;
&lt;p&gt;Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息，可以实现 1:N 的消息队列。在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如**&lt;code&gt;RocketMQ&lt;/code&gt;**等。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SUBSCRIBE redisChat

PUBLISH redisChat &amp;quot;Redis is a great caching technique&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;2-pipeline&#34;&gt;&lt;strong&gt;2、Pipeline：&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Redis提供许多批量操作的命令，如MSET/MGET/HMSET/HMGET等等，这些命令存在的意义是减少维护网络连接和传输数据所消耗的资源和时间。例如连续使用5次SET命令设置5个不同的key，比起使用一次MSET命令设置5个不同的key，效果是一样的，但前者会消耗更多的RTT(Round Trip Time)时长，永远应优先使用后者。&lt;/p&gt;
&lt;p&gt;然而，如果客户端要连续执行的多次操作无法通过Redis命令组合在一起，此时便可以使用Redis提供的pipelining功能来实现在一次交互中执行多条命令。&lt;/p&gt;
&lt;p&gt;使用pipelining时，只需要从客户端一次向Redis发送多条命令（以\r\n）分隔，Redis就会依次执行这些命令，并且把每个命令的返回按顺序组装在一起一次返回，比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ (printf &amp;quot;PING\r\nPING\r\nPING\r\n&amp;quot;; sleep 1) | nc localhost 6379
+PONG
+PONG
+PONG
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;大部分的Redis客户端都对Pipelining提供支持，所以开发者通常并不需要自己手工拼装命令列表。&lt;/p&gt;
&lt;h5 id=&#34;pipelining的局限性&#34;&gt;Pipelining的局限性&lt;/h5&gt;
&lt;p&gt;Pipelining只能用于执行&lt;strong&gt;连续且无相关性&lt;/strong&gt;的命令，当某个命令的生成需要依赖于前一个命令的返回时，就无法使用Pipelining了。通过Scripting功能，可以规避这一局限性&lt;/p&gt;
&lt;p&gt;##3、 &lt;code&gt;Redis&lt;/code&gt;键(key)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;DEL key 该命令用于在 key 存在时删除 key。如果键被删除成功，命令执行后输出 (integer) 1，否则将输出 (integer) 0

EXISTS key 检查给定 key 是否存在。

EXPIRE key seconds 为给定 key 设置过期时间
ttl key 获得key的过期时间
type key 去获得这个key的数据结构类型

keys pattern 查找所有符合给定模式 pattern 的 key 
keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。

SCAN cursor ：SCAN 命令是一个基于游标的迭代器（cursor based iterator）： SCAN 命令每次被调用之后， 都会向用户返回一个新的游标， 用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数， 以此来延续之前的迭代过程。
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;4-redis事务命令&#34;&gt;4、Redis事务命令&lt;/h2&gt;
&lt;p&gt;Redis 通过 MULTI、EXEC、WATCH 等命令来实现事务(transaction)功能。事务提供了一种将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制，并且在事务执行期间，&lt;strong&gt;服务器不会中断事务而改去执行其他客户端的命令请求&lt;/strong&gt;，它会将事务中的所有命令都执行完毕，然后才去处理其他客户端的命令请求。同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;服务端收到客户端请求，事务以MULTI开始&lt;/li&gt;
&lt;li&gt;如果客户端正处于事务状态，则会把事务放入队列同时返回给客户端QUEUED，反之则直接执行这个命令&lt;/li&gt;
&lt;li&gt;当收到客户端EXEC命令时，WATCH命令监视整个事务中的key是否有被修改，如果有则返回空回复到客户端表示失败，否则redis会遍历整个事务队列，执行队列中保存的所有命令，最后返回结果给客户端&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在 Redis 中，事务总是具有原子性（Atomicity）、一致性（Consistency）和隔离性（Isolation），并且当 Redis 运行在某种特定的持久化模式下时，事务也具有持久性（Durability）。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;MULTI 标记一个事务块的开始。
EXEC 执行所有事务块内的命令
可以使用DISCARD命令放弃当前的事务，将保存的命令队列清空。
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Redis不提供事务回滚的功能，所以只能通过其他方法进行数据的回滚。&lt;/p&gt;
&lt;h3 id=&#34;通过事务实现cas&#34;&gt;通过事务实现CAS&lt;/h3&gt;
&lt;p&gt;Redis提供了WATCH命令与事务搭配使用，实现CAS乐观锁的机制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;WATCH的机制是&lt;/strong&gt;：被监视的key会被保存到一个链表中。在事务EXEC命令执行时，Redis会检查被WATCH的key，只有被WATCH的key从WATCH起始时至今没有发生过变更，EXEC才会被执行。如果某个key被修改，那么REDIS_DIRTY_CAS标志将会被打开，这时服务器会拒绝执行事务，则EXEC命令会返回失败。&lt;/p&gt;
&lt;p&gt;假设要实现将某个商品的状态改为已售：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if(exec(HGET stock:1001 state) == &amp;quot;in stock&amp;quot;)
    exec(HSET stock:1001 state &amp;quot;sold&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这一伪代码执行时，无法确保并发安全性，有可能多个客户端都获取到了&amp;quot;in stock&amp;quot;的状态，导致一个库存被售卖多次。&lt;/p&gt;
&lt;p&gt;使用WATCH命令和事务可以解决这一问题：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;exec(WATCH stock:1001);
if(exec(HGET stock:1001 state) == &amp;quot;in stock&amp;quot;) {
    exec(MULTI);
    exec(HSET stock:1001 state &amp;quot;sold&amp;quot;);
    exec(EXEC);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;scripting&#34;&gt;Scripting&lt;/h3&gt;
&lt;p&gt;通过EVAL与EVALSHA命令，可以让Redis执行LUA脚本。这就类似于RDBMS的存储过程一样，可以把客户端与Redis之间密集的读/写交互放在服务端进行，避免过多的数据交互，提升性能。&lt;/p&gt;
&lt;p&gt;Scripting功能是作为事务功能的替代者诞生的，事务提供的所有能力Scripting都可以做到。Redis官方推荐使用LUA Script来代替事务，前者的效率和便利性都超过了事务。&lt;/p&gt;
&lt;h1 id=&#34;4-redis-的线程模型&#34;&gt;4、redis 的线程模型&lt;/h1&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://i.loli.net/2020/03/01/jPaFHioVCWIKdz1.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;redis&lt;/code&gt;内部使用文件事件处理器 &lt;code&gt;fileeventhandler&lt;/code&gt;，这个文件事件处理器是单线程的，所以 &lt;code&gt;redis&lt;/code&gt;才叫做单线程的模型。它采用 IO多路复用机制同时监听多个 socket，根据 socket 上的事件来选择对应的事件处理器进行处理。&lt;br&gt;
文件事件处理器的结构包含 4 个部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;h5 id=&#34;多个-socket&#34;&gt;多个 socket&lt;/h5&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h5 id=&#34;io-多路复用程序&#34;&gt;IO 多路复用程序&lt;/h5&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h5 id=&#34;文件事件分派器&#34;&gt;文件事件分派器&lt;/h5&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h5 id=&#34;事件处理器连接应答处理器-命令请求处理器-命令回复处理器&#34;&gt;事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）&lt;/h5&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。&lt;/p&gt;
&lt;h2 id=&#34;单线程的redis为什么这么快&#34;&gt;单线程的redis为什么这么快？&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/eeeee&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Redis&lt;/strong&gt;采用的是基于内存的采用的是单进程单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的&lt;strong&gt;QPS（每秒内查询次数）&lt;/strong&gt;。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;mark&gt;完全基于内存&lt;/mark&gt;，绝大部分请求是纯粹的内存操作，非常快速。它的，数据存在内存中，类似于&lt;strong&gt;HashMap&lt;/strong&gt;，&lt;strong&gt;HashMap&lt;/strong&gt;的优势就是查找和操作的时间复杂度都是O(1)；&lt;/li&gt;
&lt;li&gt;C语言实现，优化过的数据结构，基于几种基础的数据结构，redis做了大量的优化，性能极高；&lt;/li&gt;
&lt;li&gt;采用单线程避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 &lt;strong&gt;CPU&lt;/strong&gt;，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；&lt;/li&gt;
&lt;li&gt;使用多路I/O复用模型，非阻塞IO；&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;那为什么redis60之后又改用多线程呢&#34;&gt;那为什么Redis6.0之后又改用多线程呢?&lt;/h4&gt;
&lt;p&gt;redis使用多线程并非是完全摒弃单线程，redis还是使用单线程模型来处理客户端的请求，只是使用多线程来处理数据的读写和协议解析，执行命令还是使用单线程。&lt;/p&gt;
&lt;p&gt;这样做的目的是因为redis的性能瓶颈在于网络IO而非CPU，使用多线程能提升IO读写的效率，从而整体提高redis的性能。&lt;/p&gt;
&lt;h1 id=&#34;5-redis的过期策略以及内存淘汰机制&#34;&gt;5、redis的过期策略以及内存淘汰机制&lt;/h1&gt;
&lt;h2 id=&#34;最大内存设置&#34;&gt;最大内存设置&lt;/h2&gt;
&lt;p&gt;默认情况下，在32位OS中，Redis最大使用3GB的内存，在64位OS中则没有限制。在使用Redis时，应该对数据占用的最大空间有一个基本准确的预估，并为Redis设定最大使用的内存。否则在64位OS中Redis会无限制地占用内存（当物理内存被占满后会使用swap空间），容易引发各种各样的问题。通过如下配置控制Redis使用的最大内存：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;maxmemory 100mb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;在内存占用达到了maxmemory后，再向Redis写入数据时，Redis会：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;根据配置的数据淘汰策略尝试淘汰数据，释放空间&lt;/li&gt;
&lt;li&gt;如果没有数据可以淘汰，或者没有配置数据淘汰策略，那么Redis会对所有写请求返回错误，但读请求仍然可以正常执行&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在为Redis设置maxmemory时，需要注意：&lt;/p&gt;
&lt;p&gt;如果采用了Redis的主从同步，主节点向从节点同步数据时，会占用掉一部分内存空间&lt;/p&gt;
&lt;p&gt;如果maxmemory过于接近主机的可用内存，会导致数据同步时内存不足。&lt;/p&gt;
&lt;p&gt;所以设置的maxmemory不要过于接近主机可用的内存，留出一部分预留用作主从同步。&lt;/p&gt;
&lt;h3 id=&#34;redis的过期策略有哪些&#34;&gt;Redis的过期策略有哪些？&lt;/h3&gt;
&lt;p&gt;redis主要有2种过期删除策略&lt;/p&gt;
&lt;h4 id=&#34;惰性删除&#34;&gt;惰性删除&lt;/h4&gt;
&lt;p&gt;惰性删除指的是当我们查询key的时候才对key进行检测，如果已经达到过期时间，则删除。显然，他有一个缺点就是如果这些过期的key没有被访问，那么他就一直无法被删除，而且一直占用内存。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20201127173152.jpg&#34; alt=&#34;微信图片_20201127173152&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;定期删除&#34;&gt;定期删除&lt;/h4&gt;
&lt;p&gt;定期删除指的是redis每隔一段时间对数据库做一次检查，删除里面的过期key。由于不可能对所有key去做轮询来删除，所以redis会每次随机取一些key去做检查和删除。&lt;/p&gt;
&lt;h4 id=&#34;为什么不用定时删除策略&#34;&gt;为什么不用定时删除策略?&lt;/h4&gt;
&lt;p&gt;定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略.&lt;/p&gt;
&lt;h2 id=&#34;采用定期删除惰性删除就没其他问题了么&#34;&gt;采用定期删除+惰性删除就没其他问题了么?&lt;/h2&gt;
&lt;p&gt;不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制。&lt;br&gt;
在&lt;code&gt;redis.con&lt;/code&gt;f中有一行配置&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;axmemory-policy allkeys-lru
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;1. volatile-lru：从已设置过期时间的key中，移出最近最少使用的key进行淘汰
2. volatile-ttl：从已设置过期时间的key中，移出将要过期的key
3. volatile-random：从已设置过期时间的key中随机选择key淘汰
4. allkeys-lru：从key中选择最近最少使用的进行淘汰
5. allkeys-random：从key中随机选择key进行淘汰
6. noeviction：当内存达到阈值的时候，新写入操作报错
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用LinkedHashMap实现LRU&lt;br&gt;
LinkedHashMap底层就是用的HashMap加双链表实现的，而且本身已经实现了按照访问顺序的存储。此外，LinkedHashMap中本身就实现了一个方法&lt;code&gt;removeEldestEntry&lt;/code&gt;用于判断是否需要移除最不常读取的数，方法默认是直接返回false，不会移除元素，所以需要重写该方法。即当缓存满后就移除最不常用的数。这个方法会在put的时候调用。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/1232&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h1 id=&#34;6-redis和数据库双写一致性问题&#34;&gt;6、redis和数据库双写一致性问题&lt;/h1&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboard-1577014101951.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;1.如果删除了缓存Redis，还没有来得及写库MySQL，另一个线程就来读取，发现缓存为空，则去数据库中读取数据写入缓存，此时缓存中为脏数据&lt;/p&gt;
&lt;p&gt;2.如果先写了库，在删除缓存前，则也会出现数据不一致情况。&lt;/p&gt;
&lt;p&gt;数据库和缓存双写，就必然会存在不一致的问题。答这个问题，先明白一个前提。就是如果对数据有强一致性要求，不能放缓存。我们所做的一切，只能保证最终一致性。另外，我们所做的方案其实从根本上来说，只能说降低不一致发生的概率，无法完全避免。&lt;br&gt;
缓存和数据库一致性解决方案&lt;/p&gt;
&lt;h2 id=&#34;1第一种方案采用延时双删策略&#34;&gt;1.第一种方案：采用延时双删策略&lt;/h2&gt;
&lt;p&gt;在写库前后都进行&lt;code&gt;redis.del(key)&lt;/code&gt;操作，并且设定合理的超时时间。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;public void write( String key, Object data )
{
    redis.delKey( key );
    db.updateData( data );
    Thread.sleep( 500 );//确保数据库写完
    redis.delKey( key );
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;需要评估自己的项目的读数据业务逻辑的耗时。这么做的目的，就是&lt;strong&gt;确保读请求结束&lt;/strong&gt;，&lt;strong&gt;写请求可以删除读请求造成的缓存脏数据&lt;/strong&gt;。&lt;br&gt;
从理论上来说，给缓存设置过期时间，是保证最终一致性的解决方案。所有的写操作以数据库为准，只要到达缓存过期时间，则后面的读请求自然会从数据库中读取新值然后回填缓存。&lt;br&gt;
该方案的弊端：结合双删策略+缓存超时设置，这样最差的情况就是在超时时间内数据存在不一致，而且又增加了写请求的耗时。&lt;/p&gt;
&lt;h2 id=&#34;2-第二种方案异步更新缓存基于订阅binlog的同步机制&#34;&gt;2、第二种方案：异步更新缓存(基于订阅&lt;code&gt;binlog&lt;/code&gt;的同步机制)&lt;/h2&gt;
&lt;p&gt;MySQL &lt;code&gt;binlog&lt;/code&gt;增量订阅消费+消息队列+增量数据更新到redis&lt;/p&gt;
&lt;p&gt;读取&lt;code&gt;binlog&lt;/code&gt;后分析 ，利用消息队列,推送更新各台的redis缓存数据。&lt;br&gt;
这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把&lt;code&gt;binlog&lt;/code&gt;相关的消息推送至Redis，Redis再根据&lt;code&gt;binlog&lt;/code&gt;中的记录，对Redis进行更新。其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过&lt;code&gt;binlog&lt;/code&gt;来实现的数据一致性。&lt;/p&gt;
&lt;h1 id=&#34;7-如何应对缓存穿透和缓存雪崩问题&#34;&gt;7、如何应对缓存穿透和缓存雪崩问题&lt;/h1&gt;
&lt;h2 id=&#34;1-缓存穿透&#34;&gt;1、缓存穿透&lt;/h2&gt;
&lt;p&gt;缓存穿透是指查询不存在缓存中的数据，每次请求都会打到DB，就像缓存不存在一样。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20201127173303.jpg&#34; alt=&#34;微信图片_20201127173303&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;解决方案:&lt;br&gt;
(一)利用互斥锁，缓存失效的时候，先去获得锁，&lt;strong&gt;得到锁了再去请求数据库&lt;/strong&gt;。没得到锁，则休眠一段时间重试；&lt;br&gt;
(二)采用异步更新策略，无论key是否取到值，都直接返回，不再去读数据库。value值中维护一个缓存失效时间，缓存如果过期，&lt;strong&gt;异步起一个线程去读数据库，更新缓存&lt;/strong&gt;。需要做缓存预热(项目启动前，先加载缓存)操作。&lt;br&gt;
(三)提供一个能迅速判断请求是否有效的拦截机制，比如，利用&lt;strong&gt;布隆过滤器&lt;/strong&gt;，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。&lt;/p&gt;
&lt;p&gt;显然，使用布隆过滤器之后会有一个问题就是误判，因为它本身是一个数组，可能会有多个值落到同一个位置，那么理论上来说只要我们的数组长度够长，误判的概率就会越低，这种问题就根据实际情况来就好了。&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20201127173345.jpg&#34; alt=&#34;微信图片_20201127173345&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;2-缓存雪崩&#34;&gt;2、缓存雪崩&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20201127173417.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;即&lt;strong&gt;缓存同一时间大面积的失效&lt;/strong&gt;，新缓存未到期间，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。&lt;br&gt;
解决方案:&lt;br&gt;
(一)给缓存的失效时间，加上一个随机值，避免集体失效。&lt;br&gt;
(二)使用互斥锁，获取锁后才能去&lt;strong&gt;读数据库&lt;/strong&gt;，但是该方案吞吐量明显下降了。&lt;br&gt;
(三)双缓存。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从缓存A读数据库，有则直接返回&lt;/li&gt;
&lt;li&gt;A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。&lt;/li&gt;
&lt;li&gt;更新线程同时更新缓存A和缓存B。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3-缓存击穿&#34;&gt;&lt;strong&gt;3、缓存击穿&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;缓存击穿&lt;/strong&gt;是指一个Key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个完好无损的桶上凿开了一个洞。这个和热key的问题比较类似，只是说的点在于&lt;strong&gt;过期导致请求全部打到DB上而已&lt;/strong&gt;。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20201127173521.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;解决方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;加锁更新，比如请求查询A，发现缓存中没有，对A这个key加锁，同时去数据库查询数据，写入缓存，再返回给用户，这样后面的请求就可以从缓存中拿到数据了。&lt;/li&gt;
&lt;li&gt;将过期时间组合写在value中，通过异步的方式不断的刷新过期时间，防止此类现象。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;设置热点数据永远不过期&lt;/strong&gt;。或者加上互斥锁就能搞定了&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;4-缓存预热&#34;&gt;4、缓存预热&lt;/h2&gt;
&lt;p&gt;缓存预热这个应该是一个比较常见的概念，缓存预热就是&lt;strong&gt;系统上线后，将相关的缓存数据直接加载到缓存系统&lt;/strong&gt;。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！&lt;br&gt;
解决思路：&lt;br&gt;
1、直接写个缓存刷新页面，上线时手工操作下；&lt;br&gt;
2、数据量不大，可以在项目启动的时候自动进行加载；&lt;br&gt;
3、定时刷新缓存；&lt;/p&gt;
&lt;h2 id=&#34;5-自定义的缓存淘汰&#34;&gt;5、自定义的缓存淘汰&lt;/h2&gt;
&lt;p&gt;除了缓存服务器自带的缓存失效策略之外（Redis默认的有6中策略可供选择），我们还可以根据具体的业务需求进行自定义的缓存淘汰，常见的策略有两种：&lt;br&gt;
（1）定时去清理过期的缓存；&lt;br&gt;
（2）当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。&lt;br&gt;
两者各有优劣，第一种的缺点是维护大量缓存的key是比较麻烦的，第二种的缺点就是每次用户请求过来都要判断缓存失效，逻辑相对比较复杂&lt;/p&gt;
&lt;h2 id=&#34;6-缓存降级&#34;&gt;6、缓存降级&lt;/h2&gt;
&lt;p&gt;当访问量剧增、服务出现问题（如响应时间慢或不响应）或非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有损服务。也就是在高并发高负载情况下，选择&lt;strong&gt;动态的关闭一下不重要的服务，拒绝访问等，来为重要的服务节省资源&lt;/strong&gt;&lt;br&gt;
（1）一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；&lt;br&gt;
（2）警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；&lt;br&gt;
（3）错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；&lt;br&gt;
（4）严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。&lt;/p&gt;
&lt;h1 id=&#34;8-如何解决redis的并发竞争key问题&#34;&gt;8、如何解决redis的并发竞争key问题&lt;/h1&gt;
&lt;p&gt;同时有多个子系统去set一个key。&lt;br&gt;
(1)如果对这个key操作，不要求顺序&lt;br&gt;
这种情况下，准备一个&lt;strong&gt;Zookeeper&lt;/strong&gt; 分布式锁，大家去抢锁，抢到锁就做set操作即可，比较简单。&lt;br&gt;
(2)如果对这个key操作，要求顺序&lt;br&gt;
假设有一个key1,系统A需要将key1设置为&lt;code&gt;valueA&lt;/code&gt;,系统B需要将key1设置为&lt;code&gt;valueB&lt;/code&gt;,系统C需要将key1设置为&lt;code&gt;valueC&lt;/code&gt;.&lt;br&gt;
期望按照key1的value值按照 &lt;code&gt;valueA&lt;/code&gt;--&amp;gt;&lt;code&gt;valueB&lt;/code&gt;--&amp;gt;&lt;code&gt;valueC&lt;/code&gt;的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;系统A key 1 {valueA 3:00}
系统B key 1 {valueB 3:05}
系统C key 1 {valueC 3:10}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;假设这会系统B先抢到锁，将key1设置为{&lt;code&gt;valueB&lt;/code&gt;3:05}。接下来系统A抢到锁，发现自己的&lt;code&gt;valueA&lt;/code&gt;的时间戳早于缓存中的时间戳，那就不做set操作了。&lt;/p&gt;
&lt;h1 id=&#34;9-redis-和-memcached的区别&#34;&gt;9、redis 和 &lt;code&gt;memcached&lt;/code&gt;的区别&lt;/h1&gt;
&lt;p&gt;1、redis支持更丰富的数据类型（支持更复杂的应用场景）：Redis不仅仅支持简单的k/v类型的数据，同时还提供list，set，&lt;code&gt;zset&lt;/code&gt;，hash等数据结构的存储。&lt;code&gt;memcache&lt;/code&gt;支持简单的数据类型，String。&lt;br&gt;
2、Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用,而&lt;code&gt;Memecache&lt;/code&gt;把数据全部存在内存之中。&lt;br&gt;
3、集群模式：&lt;code&gt;memcached&lt;/code&gt;没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 redis 目前是原生支持 cluster 模式的.&lt;br&gt;
4、&lt;code&gt;Memcached&lt;/code&gt;是多线程，非阻塞IO复用的网络模型；Redis使用单线程的多路 IO 复用模型。&lt;/p&gt;
&lt;h1 id=&#34;10-redis-持久化机制&#34;&gt;10、redis 持久化机制&lt;/h1&gt;
&lt;h2 id=&#34;1-快照持久化rdb&#34;&gt;1、快照持久化（RDB）&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;RDB&lt;/strong&gt; 持久化机制，是对 &lt;strong&gt;Redis&lt;/strong&gt; 中的数据执行&lt;strong&gt;周期性&lt;/strong&gt;的持久化。采用RDB持久方式，Redis会定期保存数据快照至一个rbd文件中，并在启动时自动加载rdb文件，恢复之前保存的数据。&lt;/p&gt;
&lt;p&gt;可以通过SAVE或者BGSAVE来生成RDB文件。&lt;/p&gt;
&lt;p&gt;SAVE命令会阻塞redis进程，直到RDB文件生成完毕，在进程阻塞期间，redis不能处理任何命令请求，这显然是不合适的。&lt;/p&gt;
&lt;p&gt;BGSAVE则是会fork出一个子进程，然后由子进程去负责生成RDB文件，父进程还可以继续处理命令请求，不会阻塞进程。&lt;/p&gt;
&lt;h4 id=&#34;优点&#34;&gt;优点：&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;对性能影响最小。如前文所述，Redis在保存RDB快照时会fork出子进程进行，几乎不影响Redis处理客户端请求的效率。&lt;/li&gt;
&lt;li&gt;每次快照会生成一个完整的数据快照文件，所以可以辅以其他手段保存多个时间点的快照（例如把每天0点的快照备份至其他存储媒介中），作为非常可靠的灾难恢复手段。&lt;/li&gt;
&lt;li&gt;使用RDB文件进行数据恢复比使用AOF要快很多。&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;缺点&#34;&gt;缺点：&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;快照是定期生成的，所以在Redis crash时或多或少会丢失一部分数据。&lt;/li&gt;
&lt;li&gt;如果数据集非常大且CPU不够强（比如单核CPU），Redis在fork子进程时可能会消耗相对较长的时间（长至1秒），影响这期间的客户端请求。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2-aof持久化&#34;&gt;2、AOF持久化&lt;/h2&gt;
&lt;p&gt;采用AOF持久方式时，Redis会把每一个写请求都记录在一个日志文件里。在Redis重启时，会把AOF文件中记录的所有写操作顺序执行一遍，确保数据恢复到最新。&lt;/p&gt;
&lt;p&gt;AOF默认是关闭的，如要开启，进行如下配置：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;appendonly yes
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;AOF通过追加、写入、同步三个步骤来实现持久化机制。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;当AOF持久化处于激活状态，服务器执行完写命令之后，写命令将会被追加append到aof_buf缓冲区的末尾&lt;/li&gt;
&lt;li&gt;在服务器每结束一个事件循环之前，将会调用flushAppendOnlyFile函数决定是否要将aof_buf的内容保存到AOF文件中，可以通过配置appendfsync来决定。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;AOF提供了三种fsync配置，always/everysec/no，通过配置项[appendfsync]指定：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;appendfsync no&lt;/strong&gt;：不进行fsync，将flush文件的时机交给OS决定，速度最快&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;appendfsync always&lt;/strong&gt;：每写入一条日志就进行一次fsync操作，数据安全性最高，但速度最慢&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;appendfsync everysec&lt;/strong&gt;：折中的做法，交由后台线程每秒fsync一次&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;随着AOF不断地记录写操作日志，必定会出现一些无用的日志，例如某个时间点执行了命令&lt;strong&gt;SET key1 &amp;quot;abc&amp;quot;&lt;/strong&gt;，在之后某个时间点又执行了&lt;strong&gt;SET key1 &amp;quot;bcd&amp;quot;&lt;/strong&gt;，那么第一条命令很显然是没有用的。大量的无用日志会让AOF文件过大，也会让数据恢复的时间过长。&lt;/p&gt;
&lt;p&gt;所以Redis提供了&lt;strong&gt;AOF rewrite&lt;/strong&gt;功能，可以重写AOF文件，只保留能够把数据恢复到最新状态的最小写操作集。&lt;/p&gt;
&lt;p&gt;AOF rewrite可以通过&lt;strong&gt;BGREWRITEAOF&lt;/strong&gt;命令触发，也可以配置Redis定期自动进行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;上面两行配置的含义是，Redis在每次AOF rewrite时，会记录完成rewrite后的AOF日志大小，当AOF日志大小在该基础上增长了100%后，自动进行AOF rewrite。同时如果增长的大小没有达到64mb，则不会进行rewrite。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AOF的优点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最安全，在启用appendfsync always时，任何已写入的数据都不会丢失，使用在启用appendfsync everysec也至多只会丢失1秒的数据。&lt;/li&gt;
&lt;li&gt;AOF文件在发生断电等问题时也不会损坏，即使出现了某条日志只写入了一半的情况，也可以使用redis-check-aof工具轻松修复。&lt;/li&gt;
&lt;li&gt;AOF文件易读，可修改，在进行了某些错误的数据清除操作后，只要AOF文件没有rewrite，就可以把AOF文件备份出来，把错误的命令删除，然后恢复数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;AOF的缺点：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AOF文件通常比RDB文件更大&lt;/li&gt;
&lt;li&gt;性能消耗比RDB高&lt;/li&gt;
&lt;li&gt;数据恢复速度比RDB慢&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;11-怎么实现redis的高可用&#34;&gt;11、怎么实现Redis的高可用？&lt;/h1&gt;
&lt;p&gt;要想实现高可用，一台机器肯定是不够的，而redis要保证高可用，有2个可选方案。&lt;/p&gt;
&lt;h2 id=&#34;主从架构&#34;&gt;主从架构&lt;/h2&gt;
&lt;p&gt;主从模式是最简单的实现高可用的方案，核心就是主从同步。主从同步的原理如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;slave发送sync命令到master&lt;/li&gt;
&lt;li&gt;master收到sync之后，执行bgsave，生成RDB全量文件&lt;/li&gt;
&lt;li&gt;master把slave的写命令记录到缓存&lt;/li&gt;
&lt;li&gt;bgsave执行完毕之后，发送RDB文件到slave，slave执行&lt;/li&gt;
&lt;li&gt;master发送缓存中的写命令到slave，slave执行&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20201127173646.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;这里我写的这个命令是sync，但是在redis2.8版本之后已经使用psync来替代sync了，原因是sync命令非常消耗系统资源，而psync的效率更高。&lt;/p&gt;
&lt;h2 id=&#34;哨兵&#34;&gt;哨兵&lt;/h2&gt;
&lt;p&gt;基于主从方案的缺点还是很明显的，假设master宕机，那么就不能写入数据，那么slave也就失去了作用，整个架构就不可用了，除非你手动切换，主要原因就是因为没有自动故障转移机制。而哨兵(sentinel)的功能比单纯的主从架构全面的多了，它具备自动故障转移、集群监控、消息通知等功能。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;15&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20201127173711.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;哨兵可以同时监视多个主从服务器，并且在被监视的master下线时，自动将某个slave提升为master，然后由新的master继续接收命令。整个过程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初始化sentinel，将普通的redis代码替换成sentinel专用代码&lt;/li&gt;
&lt;li&gt;初始化masters字典和服务器信息，服务器信息主要保存ip:port，并记录实例的地址和ID&lt;/li&gt;
&lt;li&gt;创建和master的两个连接，命令连接和订阅连接，并且订阅sentinel:hello频道&lt;/li&gt;
&lt;li&gt;每隔10秒向master发送info命令，获取master和它下面所有slave的当前信息&lt;/li&gt;
&lt;li&gt;当发现master有新的slave之后，sentinel和新的slave同样建立两个连接，同时每个10秒发送info命令，更新master信息&lt;/li&gt;
&lt;li&gt;sentinel每隔1秒向所有服务器发送ping命令，如果某台服务器在配置的响应时间内连续返回无效回复，将会被标记为下线状态&lt;/li&gt;
&lt;li&gt;选举出领头sentinel，领头sentinel需要半数以上的sentinel同意&lt;/li&gt;
&lt;li&gt;领头sentinel从已下线的的master所有slave中挑选一个，将其转换为master&lt;/li&gt;
&lt;li&gt;让所有的slave改为从新的master复制数据&lt;/li&gt;
&lt;li&gt;将原来的master设置为新的master的从服务器，当原来master重新回复连接时，就变成了新master的从服务器&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;sentinel会每隔1秒向所有实例（包括主从服务器和其他sentinel）发送ping命令，并且根据回复判断是否已经下线，这种方式叫做主观下线。当判断为主观下线时，就会向其他监视的sentinel询问，如果超过半数的投票认为已经是下线状态，则会标记为客观下线状态，同时触发故障转移。&lt;/p&gt;
&lt;p&gt;主从复制，是指将一台&lt;code&gt;Redis&lt;/code&gt;服务器的数据，复制到其他的&lt;code&gt;Redis&lt;/code&gt;服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。借助Redis的主从复制，可以实现读写分离和高可用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;实时性要求不是特别高的读请求，可以在Slave上完成，提升效率。特别是一些周期性执行的统计任务，这些任务可能需要执行一些长耗时的Redis命令，可以专门规划出1个或几个Slave用于服务这些统计任务&lt;/li&gt;
&lt;li&gt;借助Redis Sentinel可以实现高可用，当Master crash后，Redis Sentinel能够自动将一个Slave晋升为Master，继续提供服务&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;集群&#34;&gt;集群&lt;/h2&gt;
&lt;p&gt;为何要做集群分片：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Redis中存储的数据量大，一台主机的物理内存已经无法容纳&lt;/li&gt;
&lt;li&gt;Redis的写请求并发量大，一个Redis实例以无法承载&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当上述两个问题出现时，就必须要对Redis进行分片了。Redis的分片方案有很多种，例如很多Redis的客户端都自行实现了分片功能，也有像Twemproxy这样的以代理方式实现的Redis分片方案。然而首选的方案还应该是Redis官方在3.0版本中推出的Redis Cluster分片方案。&lt;/p&gt;
&lt;h3 id=&#34;redis-cluster的能力&#34;&gt;Redis Cluster的能力&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;能够自动将数据分散在多个节点上&lt;/li&gt;
&lt;li&gt;当访问的key不在当前分片上时，能够自动将请求转发至&lt;strong&gt;正确的分片&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;当集群中部分节点失效时仍能提供服务&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中第三点是基于主从复制来实现的，Redis Cluster的每个数据分片都采用了主从复制的结构，原理和前文所述的主从复制完全一致。唯一的区别是省去了Redis Sentinel这一额外的组件，由Redis Cluster负责进行一个分片内部的节点监控和自动failover。&lt;/p&gt;
&lt;h3 id=&#34;节点&#34;&gt;节点&lt;/h3&gt;
&lt;p&gt;一个redis集群由多个节点node组成，而多个node之间通过cluster meet命令来进行连接，节点的握手过程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;节点A收到客户端的cluster meet命令&lt;/li&gt;
&lt;li&gt;A根据收到的IP地址和端口号，向B发送一条meet消息&lt;/li&gt;
&lt;li&gt;节点B收到meet消息返回pong&lt;/li&gt;
&lt;li&gt;A知道B收到了meet消息，返回一条ping消息，握手成功&lt;/li&gt;
&lt;li&gt;最后，节点A将会通过gossip协议把节点B的信息传播给集群中的其他节点，其他节点也将和B进行握手&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;16&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20201127173742.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;redis-cluster分片原理&#34;&gt;Redis Cluster分片原理&lt;/h4&gt;
&lt;p&gt;Redis Cluster中共有16384个&lt;strong&gt;hash slot&lt;/strong&gt;，Redis会计算每个key的&lt;strong&gt;CRC16，将结果与16384取模&lt;/strong&gt;，来决定该key存储在哪一个hash slot中，同时需要指定Redis Cluster中每个数据分片负责的Slot数，Slot的分配在任何时间点都可以进行重新分配。&lt;/p&gt;
&lt;p&gt;当数据库16384个slot都有节点在处理时，集群处于上线状态，反之只要有一个slot没有得到处理都会处理下线状态。通过cluster addslots命令可以将slot指派给对应节点处理。&lt;/p&gt;
&lt;p&gt;slot是一个位数组，数组的长度是16384/8=2048，而数组的每一位用1表示被节点处理，0表示不处理，如图所示的话表示A节点处理0-7的slot。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;17&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20201127173823568.png&#34; alt=&#34;image-20201127173823568&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;客户端在对key进行读写操作时，可以连接Cluster中的任意一个分片，如果操作的key不在此分片负责的Slot范围内，则会返回一个MOVED命令到客户端指引客户端转向正确的节点。（MOVED过程是自动的）&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;18&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20201127173836578.png&#34; alt=&#34;image-20201127173836578&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;如果增加或者移出节点，对于slot的重新分配也是非常方便的，redis提供了工具帮助实现slot的迁移，整个过程是完全在线的，不需要停止服务。&lt;/p&gt;
&lt;h4 id=&#34;hash-tags&#34;&gt;hash tags&lt;/h4&gt;
&lt;p&gt;在基础的分片原则上，Redis还支持hash tags功能，以hash tags要求的格式明明的key，将会确保进入&lt;strong&gt;同一个Slot中&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;例如：{uiv}user:1000和{uiv}user:1001拥有同样的hash tag {uiv}，会保存在同一个Slot中。&lt;/p&gt;
&lt;p&gt;使用Redis Cluster时，pipelining、事务和LUA Script功能涉及的key必须在同一个数据分片上，否则将会返回错误。&lt;/p&gt;
&lt;p&gt;如要在Redis Cluster中使用上述功能，就必须通过hash tags来确保一个pipeline或&lt;strong&gt;一个事务中操作的所有key都位于同一个Slot中&lt;/strong&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;有一些客户端（如Redisson）实现了集群化的pipelining操作，可以自动将一个pipeline里的命令按key所在的分片进行分组，分别发到不同的分片上执行。&lt;/p&gt;
&lt;p&gt;但是Redis不支持跨分片的事务，事务和LUA Script还是必须遵循所有key在一个分片上的规则要求。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;故障转移&#34;&gt;故障转移&lt;/h3&gt;
&lt;p&gt;如果节点A向节点B发送ping消息，节点B没有在规定的时间内响应pong，那么节点A会标记节点B为pfail疑似下线状态，同时把B的状态通过消息的形式发送给其他节点，如果超过半数以上的节点都标记B为pfail状态，B就会被标记为fail下线状态，此时将会发生故障转移，优先从复制数据较多的从节点选择一个成为主节点，并且接管下线节点的slot，整个过程和哨兵非常类似，都是基于Raft协议做选举。&lt;/p&gt;
&lt;h3 id=&#34;主从复制-vs-集群分片&#34;&gt;主从复制 vs 集群分片&lt;/h3&gt;
&lt;p&gt;在设计软件架构时，要如何在主从复制和集群分片两种部署方案中取舍呢？&lt;/p&gt;
&lt;p&gt;从各个方面看，Redis Cluster都是优于主从复制的方案&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Redis Cluster能够解决单节点上&lt;strong&gt;数据量过大&lt;/strong&gt;的问题&lt;/li&gt;
&lt;li&gt;Redis Cluster能够解决单节点&lt;strong&gt;访问压力过大&lt;/strong&gt;的问题&lt;/li&gt;
&lt;li&gt;Redis Cluster包含了&lt;strong&gt;主从复制的能力&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;软件架构永远不是越复杂越好，复杂的架构在带来显著好处的同时，一定也会带来相应的弊端。采用Redis Cluster的弊端包括：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、维护难度增加&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在使用Redis Cluster时，需要维护的Redis实例数倍增，需要监控的主机数量也相应增加，数据备份/持久化的复杂度也会增加。同时在进行分片的增减操作时，还需要进行reshard操作，远比主从模式下增加一个Slave的复杂度要高。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、客户端资源消耗增加&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当客户端使用连接池时，需要为每一个数据分片维护一个连接池，客户端同时需要保持的连接数成倍增多，加大了客户端本身和操作系统资源的消耗。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、性能优化难度增加&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;你可能需要在多个分片上查看Slow Log和Swap日志才能定位性能问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4、事务和LUA Script的使用成本增加&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在Redis Cluster中使用事务和LUA Script特性有严格的限制条件&lt;/p&gt;
&lt;p&gt;事务和Script中操作的key必须位于同一个分片上，这就使得在开发时必须对相应场景下涉及的key进行额外的规划和规范要求。&lt;/p&gt;
&lt;p&gt;如果应用的场景中大量涉及事务和Script的使用，如何在保证这两个功能的正常运作前提下把数据平均分到多个数据分片中就会成为难点。&lt;/p&gt;
&lt;p&gt;所以，在主从复制和集群分片两个方案中做出选择时，应该从应用软件的功能特性、数据和访问量级、未来发展规划等方面综合考虑，只在&lt;strong&gt;确实有必要&lt;/strong&gt;引入数据分片时再使用Redis Cluster。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;下面是一些建议：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;需要在Redis中存储的数据有多大？未来2年内可能发展为多大？这些数据是否都需要长期保存？是否可以使用LRU算法进行非热点数据的淘汰？综合考虑前面几个因素，评估出Redis需要使用的物理内存。&lt;/li&gt;
&lt;li&gt;用于部署Redis的主机物理内存有多大？有多少可以分配给Redis使用？对比(1)中的内存需求评估，是否足够用？&lt;/li&gt;
&lt;li&gt;Redis面临的并发写压力会有多大？在不使用pipelining时，Redis的写性能可以超过10万次/秒（更多的benchmark可以参考 https://redis.io/topics/benchmarks ）&lt;/li&gt;
&lt;li&gt;在使用Redis时，是否会使用到pipelining和事务功能？使用的场景多不多？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;综合上面几点考虑，如果单台主机的可用物理内存完全足以支撑对Redis的容量需求，且Redis面临的并发写压力距离Benchmark值还尚有距离，建议采用主从复制的架构，可以省去很多不必要的麻烦。&lt;/p&gt;
&lt;p&gt;同时，如果应用中大量使用pipelining和事务，也建议尽可能选择主从复制架构，可以减少设计和开发时的复杂度。&lt;/p&gt;
&lt;h1 id=&#34;12-热点缓存&#34;&gt;12、&lt;strong&gt;热点缓存&lt;/strong&gt;&lt;/h1&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;19&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191226191608229.png&#34; alt=&#34;image-20191226191608229&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;所谓热key问题就是，突然有几十万的请求去访问redis上的某个特定key，那么这样会造成流量过于集中，达到物理网卡上限，导致缓存机器会过度操劳而宕机的，那么如果缓存集群开始出现机器的宕机，读请求发现读不到数据，会从数据库里提取原始数据，然后放入剩余的其他缓存机器里去。但是接踵而来的每秒20万请求，会再次压垮其他的缓存机器。以此类推，最终导致缓存集群全盘崩溃，引发系统整体宕机。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;20&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191226191809323.png&#34; alt=&#34;image-20191226191809323&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;​	针对热key的解决方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;提前把热key打散到不同的服务器，降低压力&lt;/li&gt;
&lt;li&gt;加入二级缓存，提前加载热key数据到内存中，如果redis宕机，走内存查询&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;基于流式计算技术的缓存热点自动发现&#34;&gt;&lt;strong&gt;基于流式计算技术的缓存热点自动发现&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;就是对于这种热点缓存，你的系统需要能够在热点缓存突然发生的时候，直接发现他，然后瞬间立马实现毫秒级的自动负载均衡。&lt;/p&gt;
&lt;h3 id=&#34;如何自动发现热点缓存问题&#34;&gt;如何自动发现热点缓存问题？&lt;/h3&gt;
&lt;p&gt;此时完全可以基于大数据领域的流式计算技术来进行实时数据访问次数的统计，比如spark streaming，这些技术都是可以的。&lt;/p&gt;
&lt;p&gt;然后一旦在实时数据访问次数统计的过程中，比如发现一秒之内，某条数据突然访问次数超过了1000，就直接立马把这条数据判定为是热点数据，可以将这个发现出来的热点数据写入比如zookeeper中。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;21&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191226192117134.png&#34; alt=&#34;image-20191226192117134&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;热点缓存自动加载为jvm本地缓存&#34;&gt;&lt;strong&gt;热点缓存自动加载为JVM本地缓存&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;我们自己的系统可以对&lt;strong&gt;zookeeper&lt;/strong&gt;指定的热点缓存对应的&lt;strong&gt;znode&lt;/strong&gt;进行监听，如果有变化他立马就可以感知到了。&lt;/p&gt;
&lt;p&gt;此时系统层就可以立马把相关的缓存数据从数据库加载出来，然后直接放在自己系统内部的本地缓存里即可。那么每个机器本地都会有一份热点缓存的副本。&lt;/p&gt;
&lt;p&gt;然后接下来对热点缓存的读操作，直接系统本地缓存读出来就给返回了，不用再走缓存集群了。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;22&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191226192254878.png&#34; alt=&#34;image-20191226192254878&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;限流熔断保护&#34;&gt;&lt;strong&gt;限流熔断保护&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;在每个系统内部，其实还应该专门加一个对热点数据访问的限流熔断保护措施。每个系统实例内部，都可以加一个熔断保护机制，假设缓存集群最多每秒承载4万读请求，那么你一共有100个系统实例。你自己就该限制好，每个系统实例每秒最多请求缓存集群读操作不超过400次，一超过就可以熔断掉，不让请求缓存集群，直接返回一个空白信息，然后用户稍后会自行再次重新刷新页面之类的。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;23&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/image-20191226192409935.png&#34; alt=&#34;image-20191226192409935&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h1 id=&#34;13-redis性能调优&#34;&gt;13、Redis性能调优&lt;/h1&gt;
&lt;p&gt;尽管Redis是一个非常快速的内存数据存储媒介，也并不代表Redis不会产生性能问题。前文中提到过，Redis采用单线程模型，所有的命令都是由一个线程串行执行的。所以当某个命令执行耗时较长时，会拖慢其后的所有命令，这使得Redis对每个任务的执行效率更加敏感。&lt;/p&gt;
&lt;h3 id=&#34;长耗时命令&#34;&gt;长耗时命令&lt;/h3&gt;
&lt;p&gt;Redis绝大多数读写命令的时间复杂度都在O(1)到O(N)之间，O(1)的命令是安全的，O(N)命令在使用时需要注意，如果N的数量级不可预知，则应避免使用。&lt;/p&gt;
&lt;p&gt;例如对一个field数未知的Hash数据执行HGETALL/HKEYS/HVALS命令，通常来说这些命令执行的很快，但如果这个Hash中的field数量极多，耗时就会成倍增长。又如使用SUNION对两个Set执行Union操作，或使用SORT对List/Set执行排序操作等时，都应该严加注意。&lt;/p&gt;
&lt;p&gt;避免在使用这些O(N)命令时发生问题主要有几个办法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;不要把List当做列表使用，仅当做队列来使用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;通过机制严格控制Hash、Set、Sorted Set的大小&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;可能的话，将排序、并集、交集等操作放在客户端执行&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;绝对禁止使用KEYS命令&lt;/p&gt;
&lt;p&gt;避免一次性遍历集合类型的所有成员，而应使用SCAN类的命令进行分批的，游标式的遍历。Redis提供了SCAN命令，可以对Redis中存储的所有key进行游标式的遍历，避免使用KEYS命令带来的性能问题。同时还有SSCAN/HSCAN/ZSCAN等命令，分别用于对Set/Hash/Sorted Set中的元素进行游标式遍历。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Redis提供了Slow Log功能，可以自动记录耗时较长的命令。相关的配置参数有两个：&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;slowlog-log-slower-than xxxms  #执行时间慢于xxx毫秒的命令计入Slow Log
slowlog-max-len xxx  #Slow Log的长度，即最大纪录多少条Slow Log
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用&lt;strong&gt;SLOWLOG GET [number]&lt;strong&gt;命令，可以输出最近进入Slow Log的number条命令。&lt;br&gt;
使用&lt;/strong&gt;SLOWLOG RESET&lt;/strong&gt;命令，可以重置Slow Log&lt;/p&gt;
&lt;h3 id=&#34;网络引发的延迟&#34;&gt;网络引发的延迟&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;尽可能使用长连接或连接池，避免频繁创建销毁连接&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;客户端进行的批量数据操作，应使用Pipeline特性在一次交互中完成。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据持久化引发的延迟&#34;&gt;数据持久化引发的延迟&lt;/h3&gt;
&lt;p&gt;Redis的数据持久化工作本身就会带来延迟，需要根据数据的安全级别和性能要求制定合理的持久化策略：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AOF + fsync always的设置虽然能够绝对确保数据安全，但每个操作都会触发一次fsync，会对Redis的性能有比较明显的影响。&lt;/li&gt;
&lt;li&gt;AOF + fsync every second是比较好的折中方案，每秒fsync一次&lt;/li&gt;
&lt;li&gt;AOF + fsync never会提供AOF持久化方案下的最优性能&lt;/li&gt;
&lt;li&gt;使用RDB持久化通常会提供比使用AOF更高的性能，但需要注意RDB的策略配置&lt;/li&gt;
&lt;li&gt;每一次RDB快照和AOF Rewrite都需要Redis主进程进行fork操作。fork操作本身可能会产生较高的耗时，与CPU和Redis占用的内存大小有关。根据具体的情况合理配置RDB快照和AOF Rewrite时机，避免过于频繁的fork带来的延迟&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;swap引发的延迟&#34;&gt;Swap引发的延迟&lt;/h3&gt;
&lt;p&gt;当Linux将Redis所用的内存分页移至swap空间时，将会阻塞Redis进程，导致Redis出现不正常的延迟。&lt;/p&gt;
&lt;p&gt;Swap通常在物理内存不足或一些进程在进行大量I/O操作时发生，应尽可能避免上述两种情况的出现。&lt;/p&gt;
&lt;h3 id=&#34;数据淘汰引发的延迟&#34;&gt;数据淘汰引发的延迟&lt;/h3&gt;
&lt;p&gt;当同一秒内有大量key过期时，也会引发Redis的延迟。在使用时应尽量将key的失效时间错开。&lt;/p&gt;
&lt;h3 id=&#34;引入读写分离机制&#34;&gt;引入读写分离机制&lt;/h3&gt;
&lt;p&gt;Redis的主从复制能力可以实现一主多从的多节点架构，在这一架构下，主节点接收所有写请求，并将数据同步给多个从节点。&lt;br&gt;
在这一基础上，我们可以让从节点提供对实时性要求不高的读请求服务，以减小主节点的压力。尤其是针对一些使用了长耗时命令的统计类任务，完全可以指定在一个或多个从节点上执行，避免这些长耗时命令影响其他请求的响应。&lt;/p&gt;
&lt;h1 id=&#34;14-redis-java客户端的选择&#34;&gt;14、Redis Java客户端的选择&lt;/h1&gt;
&lt;p&gt;Redis的Java客户端很多，官方推荐的有三种：Jedis、Redisson和lettuce。&lt;/p&gt;
&lt;h2 id=&#34;jedis&#34;&gt;Jedis：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;轻量，简洁，便于集成和改造&lt;/li&gt;
&lt;li&gt;支持连接池&lt;/li&gt;
&lt;li&gt;支持pipelining、事务、LUA Scripting、Redis Sentinel、Redis Cluster&lt;/li&gt;
&lt;li&gt;不支持读写分离，需要自己实现&lt;/li&gt;
&lt;li&gt;文档差（真的很差，几乎没有……）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;redisson&#34;&gt;Redisson：&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;基于Netty实现，采用非阻塞IO，性能高&lt;/li&gt;
&lt;li&gt;支持异步请求&lt;/li&gt;
&lt;li&gt;支持连接池&lt;/li&gt;
&lt;li&gt;支持pipelining、LUA Scripting、Redis Sentinel、Redis Cluster&lt;/li&gt;
&lt;li&gt;不支持事务，官方建议以LUA Scripting代替事务&lt;/li&gt;
&lt;li&gt;支持在Redis Cluster架构下使用pipelining&lt;/li&gt;
&lt;li&gt;支持读写分离，支持读负载均衡，在主从复制和Redis Cluster架构下都可以使用&lt;/li&gt;
&lt;li&gt;内建Tomcat Session Manager，为Tomcat 6/7/8提供了会话共享功能&lt;/li&gt;
&lt;li&gt;可以与Spring Session集成，实现基于Redis的会话共享&lt;/li&gt;
&lt;li&gt;文档较丰富，有中文文档&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于Jedis和Redisson的选择，同样应遵循前述的原理，尽管Jedis比起Redisson有各种各样的不足，但也应该在需要使用Redisson的高级特性时再选用Redisson，避免造成不必要的程序复杂度提升。&lt;/p&gt;
">Redis笔记</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/resume/"" data-c="
          &lt;p&gt;&lt;strong&gt;1、MySQL的复制原理以及流程&lt;/strong&gt;&lt;br&gt;
MySQL 主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。&lt;br&gt;
MySQL 默认采用异步复制方式，这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。&lt;/p&gt;
&lt;p&gt;MySQL主从复制主要用途&lt;br&gt;
a、读写分离&lt;br&gt;
在开发工作中，有时候会遇见某个sql语句需要锁表，导致暂时不能使用读的服务，这样就会影响现有业务，使用主从复制，让主库负责写，从库负责读，这样即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作；&lt;br&gt;
b、数据实时备份，当系统中某个节点发生故障时，可以方便的故障切换；&lt;br&gt;
c、架构扩展&lt;br&gt;
随着系统中业务访问量的增大，如果是单机部署数据库，就会导致I/O访问频率过高。有了主从复制，增加多个数据存储节点，将负载分布在多个从节点上，降低单机磁盘I/O访问的频率，提高单个机器的I/O性能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MySQL 主从形式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;a、一主一从&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/26a37e68_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;b、一主多从，提高系统的读性能&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/a6a5b2ba_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;一主一从和一主多从是最常见的主从架构，实施起来简单并且有效，不仅可以实现HA，而且还能读写分离，进而提升集群的并发能力。&lt;/p&gt;
&lt;p&gt;c、多主一从&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/343b9114_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;多主一从可以将多个mysql数据库备份到一台存储性能比较好的服务器上。&lt;/p&gt;
&lt;p&gt;d、双主复制&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/486367e1_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;双主复制，也就是互做主从复制，每个master既是master，又是另外一台服务器的slave。这样任何一方所做的变更，都会通过复制应用到另外 一方的数据库中。&lt;/p&gt;
&lt;p&gt;e、级联复制&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/b4c48ad7_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;级联复制模式下，部分slave的数据同步不连接主节点，而是连接从节点。因为如果主节点有太多的从节点，就会损耗一部分性能用于 replication，那么我们可以让3~5个从节点连接主节点，其它从节点作为二级或者三级与从节点连接，这样不仅可以缓解主节点的压力，并且对 数据一致性没有负面影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MySQL 主从复制原理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MySQL主从复制涉及到三个线程，一个运行在主节点（log dump thread），其余两个(I/O thread, SQL thread)运行在从节点，如下图所示:&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/59b0ca24_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;1、主节点 binary log dump 线程 当从节点连接主节点时，主节点会创建一个log dump 线程，用于发送bin-log的内容。在读取bin-log中的操作时，此线程会对主节点上的 bin-log加锁，当读取完成，甚至在发送给从节点之前，锁会被释放。&lt;/p&gt;
&lt;p&gt;2、从节点I/O线程 当从节点上执行&lt;code&gt;start slave&lt;/code&gt;命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的bin-log。I/O线程接收到主节点 binlog dump 进程发来的更新之后，保存在本地relay-log中。&lt;/p&gt;
&lt;p&gt;3、从节点SQL线程 SQL线程负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。&lt;/p&gt;
&lt;p&gt;对于每一个主从连接，都需要三个线程来完成。当主节点有多个从节点时，主节点会为每一个当前连接的从节点建一个binary log dump 进程， 而每个从节点都有自己的I/O线程，SQL线程。从节点用两个线程将从主库拉取更新和执行分成独立的任务，这样在执行同步数据任务的时候， 不会降低读操作的性能。比如，如果从节点没有运行，此时I/O进程可以很快从主节点获取更新，尽管SQL线程还没有执行。如果在SQL进程执行 之前从节点服务停止，至少I/O进程已经从主节点拉取到了最新的变更并且保存在本地relay日志中，当服务再次起来之后，就可以完成数据的同 步。&lt;/p&gt;
&lt;p&gt;要实施复制，首先必须打开Master 端的binary log（bin-log）功能，否则无法实现。 因为整个复制过程实际上就是Slave 从Master 端获取该日志然后再在自己身上完全顺序的执行日志中所记录的各种操作。如下图所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/d055bed7_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;复制的基本过程如下：&lt;/p&gt;
&lt;p&gt;1、从节点上的I/O 进程连接主节点，并请求从指定日志文件的指定位置（或者从最开始的日志）之后的日志内容；&lt;/p&gt;
&lt;p&gt;2、主节点接收到来自从节点的I/O请求后，通过负责复制的I/O进程根据请求信息读取指定日志指定位置之后的日志信息，返回给从节点。 返回信息中除了日志所包含的信息之外，还包括本次返回的信息的bin-log file 的以及bin-log position；从节点的I/O进程接收到内容后， 将接收到的日志内容更新到本机的relay log中，并将读取到的binary log文件名和位置保存到master-info 文件中，以便在下一次读取的 时候能够清楚的告诉Master“我需要从某个bin-log 的哪个位置开始往后的日志内容，请发给我”；&lt;/p&gt;
&lt;p&gt;3、Slave 的 SQL线程检测到relay-log 中新增加了内容后，会将relay-log的内容解析成在主节点上实际执行过的操作，并在本数据库中执行&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MySQL 主从复制模式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MySQL 主从复制默认是异步的模式。MySQL增删改操作会全部记录在binary log中，当slave节点连接master时，会主动从master处获取最新的 bin log文件。并把bin log中的sql relay。&lt;/p&gt;
&lt;p&gt;1、 异步模式（mysql async-mode）&lt;/p&gt;
&lt;p&gt;主库将事务 Binlog 事件写入到 Binlog 文件中，此时主库只会通知一下 Dump 线程发送这些新的 Binlog，然后主库就会继续处理提交操作， 而此时不会保证这些 Binlog 传到任何一个从库节点上。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/eebfcaac_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;2、半同步模式(mysql semi-sync)&lt;/p&gt;
&lt;p&gt;这种模式下主节点只需要接收到其中一台从节点的返回信息，就会commit；否则需要等待直到超时时间然后切换成异步模式再提交；这样做 的目的可以使主从数据库的数据延迟缩小，可以提高数据安全性，确保了事务提交后，binlog至少传输到了一个从节点上，不能保证从节点将 此事务更新到db中。性能上会有一定的降低，响应时间会变长。如下图所示：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/e089f0d5_hd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;半同步模式不是mysql内置的，从mysql 5.5开始集成，需要master 和slave 安装插件开启半同步模式。&lt;/p&gt;
&lt;p&gt;3、 全同步模式&lt;/p&gt;
&lt;p&gt;全同步模式是指主节点和从节点全部执行了commit并确认才会向客户端返回成功。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、MySQL中myisam与innodb的区别，至少5点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(1)、问5点不同；&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1&amp;gt;.InnoDB支持事务，而MyISAM不支持事&lt;/p&gt;
&lt;p&gt;2&amp;gt;.InnoDB支持行级锁，而MyISAM支持表级锁&lt;/p&gt;
&lt;p&gt;3&amp;gt;.InnoDB支持MVCC, 而MyISAM不支持&lt;/p&gt;
&lt;p&gt;4&amp;gt;.InnoDB支持外键，而MyISAM不支持&lt;/p&gt;
&lt;p&gt;5&amp;gt;.InnoDB关注事务，而MyISAM关注性能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(3)、2者selectcount(*)哪个更快，为什么&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;myisam更快，因为myisam内部维护了一个计数器，可以直接调取。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、MySQL中varchar与char的区别以及varchar(50)中的50代表的涵义&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;(1)、varchar与char的区别 char是一种固定长度的类型，varchar则是一种可变长度的类型&lt;/p&gt;
&lt;p&gt;(2)、varchar(50)中50的涵义 最多存放50个字符，varchar(50)和(200)存储hello所占空间一样，但后者在排序时会消耗更多内存，因为order by col采用fixed_length计 算col长度(memory引擎也一样)&lt;/p&gt;
&lt;p&gt;(3)、int（20）中20的涵义 是指显示字符的长度 但要加参数的，最大为255，比如它是记录行数的id,插入10笔资料，它就显示00000000001 ~~~00000000010，当字符的位数超过11,它也只 显示11位，如果你没有加那个让它未满11位就前面加0的参数，它不会在前面加020表示最大显示宽度为20，但仍占4字节存储，存储范围不变；&lt;/p&gt;
&lt;p&gt;(4)、mysql为什么这么设计 对大多数应用没有意义，只是规定一些工具用来显示字符的个数；int(1)和int(20)存储和计算均一样；&lt;/p&gt;
&lt;h3 id=&#34;怎么复制一张表&#34;&gt;&lt;strong&gt;怎么复制一张表&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1、mysqldump 方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用 mysqldump 命令将数据导出成一组 INSERT 语句。你可以使用下面的命令：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;mysqldump -hport -u$user --add-locks=0 --no-create-info --single-transaction --set-gtid-purged=OFF db1 t --where=&amp;quot;a&amp;gt;900&amp;quot; --result-file=/client_tmp/t.sql&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;然后可以通过下面这条命令，将这些 INSERT 语句放到 db2 库里去执行。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;mysql -h127.0.0.1 -P13000 -uroot db2 -e &amp;quot;source /client_tmp/t.sql&amp;quot;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;2、导出 CSV 文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;直接将结果导出成.csv 文件。MySQL 提供了下面的语法，用来将查询结果导出到服务端本地目录：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;select * from db1.t where a&amp;gt;900 into outfile &#39;/server_tmp/t.csv&#39;;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;然后用下面的 load data 命令将数据导入到目标表 db2.t 中。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;load data infile &#39;/server_tmp/t.csv&#39; into table db2.t;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;3、物理拷贝方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;直接拷贝文件是不行的，需要在数据字典中注册。&lt;/p&gt;
&lt;p&gt;MySQL 5.6 版本引入了可传输表空间(transportable tablespace) 的方法，，可以通过导出 + 导入表空间的方式，实现物理拷贝表的功能。&lt;/p&gt;
&lt;p&gt;mysqldump中备份出来的sql，如果我想sql文件中，一行只有一个insert….value()的话，怎么办？如果备份需要带上master的复制点信息怎么办？&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mysqldump 是用于转存储 mysql 数据库的实用程序。主要产生一个 SQL 脚本，其中包含从头重新创建数据库的所有命令。
导出脚本过程大概如下：创建数据库判断语句、删除表、创建表、锁表、禁用索引、插入数据、启用索引、解锁表。

# game 是库名
# 完整导出一个库
# 包括建库语句、表结构、数据
mysqldump -uroot -proot --host=127.0.0.1 --port=3306 --databases game &amp;gt; test.sql

# 只导出表结构
mysqldump -uroot -proot --host=127.0.0.1 --port=3306 -d game &amp;gt; test.sql

# 只导出数据
mysqldump -uroot -proot --host=127.0.0.1 --port=3306 -t game &amp;gt; test.sql

# 导出一个数据库中多个表的数据和结构
mysqldump -uroot -proot --host=127.0.0.1 game --tables articles users &amp;gt; test.sql
mysqldump -uroot -proot --host=127.0.0.1 game articles users &amp;gt; test.sql

# 恢复导出数据
mysql -u username -proot databse &amp;lt; backup.sql

--extended-insert,  -e
使用具有多个VALUES列的INSERT语法。这样使导出文件更小，并加速导入时的速度。默认为打开状态，使用--skip-extended-insert取消选项
将当前服务器的binlog的位置和文件名追加到输出文件，--master-data
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;删除数据为何表文件大小不变&#34;&gt;&lt;strong&gt;删除数据，为何表文件大小不变&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;​    **delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。**也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。&lt;/p&gt;
&lt;p&gt;​    实际上，不止是删除数据会造成空洞，插入数据也会。如果数据是随机插入的，就可能造成索引的数据页分裂。更新索引上的值，可以理解为删除一个旧的值，再插入一个新值。不难理解，这也是会造成空洞的。&lt;/p&gt;
&lt;p&gt;​    也就是说，&lt;strong&gt;经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。而重建表，就可以达到这样的目的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;使用 alter table A engine=InnoDB 命令来重建表。MySQL 会自动完成转存数据、交换表名、删除旧表的操作。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    重建表的时候，InnoDB 不会把整张表占满，每个页留了 1/16 给后续的更新用。也就是说，其实重建表之后不是“最”紧凑的。&lt;/p&gt;
&lt;h3 id=&#34;误删数据怎么办&#34;&gt;&lt;strong&gt;误删数据怎么办&lt;/strong&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;delete 语句误删数据行：Flashback工具过闪回把数据恢复回来。 原理是修改 binlog 的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保 binlog_format=row 和 binlog_row_image=FULL。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如何预防：把 sql_safe_updates 参数设置为 on。，delete 或者 update 语句必须有where条件，否则执行会报错。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;误删库 / 表：全量备份，加增量日志，在应用日志的时候，需要跳过 12 点误操作的那个语句的 binlog：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;如果原实例没有使用 GTID 模式，只能在应用到包含 12 点的 binlog 文件的时候，先用–stop-position 参数执行到误操作之前的日志，然后再用–start-position 从误操作之后的日志继续执行；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果实例使用了 GTID 模式，就方便多了。假设误操作命令的 GTID 是 gtid1，那么只需要执行 set gtid_next=gtid1;begin;commit; 先把这个 GTID 加到临时实例的 GTID 集合，之后按顺序执行 binlog 的时候，就会自动跳过误操作的语句。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如何加速恢复：使用 mysqlbinlog 命令时，加上一个–database 参数，用来指定误删表所在的库。&lt;br&gt;
在 start slave 之前，先通过执行﻿ ﻿change replication filter replicate_do_table = (tbl_name) 命令，就可以让临时库只同步误操作的表；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​    &lt;strong&gt;延迟复制备库&lt;/strong&gt;，一般的主备复制结构存在的问题是，如果主库上有个表被误删了，这个命令很快也会被发给所有从库，进而导致所有从库的数据表也都一起被误删了。延迟复制的备库是一种特殊的备库，通过 CHANGE MASTER TO MASTER_DELAY = N 命令，可以指定这个备库持续保持跟主库有 N 秒的延迟。&lt;/p&gt;
&lt;p&gt;​    比如把 N 设置为 3600，这就代表了如果主库上有数据被误删了，并且在 1 小时内发现了这个误操作命令，这个命令就还没有在这个延迟复制的备库执行。这时候到这个备库上执行 stop slave，再通过之前介绍的方法，跳过误操作命令，就可以恢复出需要的数据。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;预防误删库 / 表的方法，制定操作规范。这样做的目的，是避免写错要删除的表名。&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。&lt;/li&gt;
&lt;li&gt;改表名的时候，要求给表名加固定的后缀（比如加_to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;自增id用完怎么办&#34;&gt;&lt;strong&gt;自增id用完怎么办&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1、主键id&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    **再申请下一个 id 时，得到的值保持不变。**所以到最大值之后，再申请id，由于id不变，所以插入会报主键冲突，如果数据量比较大，主键id应该用 bigint unsigned。默认是无符号整型 (unsigned int) ，4 个字节232-1（4294967295）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、系统row_id&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    **如果创建的 InnoDB 表没有指定主键，那么 InnoDB 会创建一个不可见的，长度为 6 个字节的 row_id。**InnoDB 维护了一个全局的 dict_sys.row_id 值，所有无主键的 InnoDB 表，每插入一行数据，都把当前的 dict_sys.row_id 值作为要插入数据的 row_id，然后把 dict_sys.row_id 的值加 1。&lt;/p&gt;
&lt;p&gt;​    实际上，在代码实现时 row_id 是一个长度为 8 字节的无符号长整型 (bigint unsigned)。但是，InnoDB 在设计时，给 row_id 留的只是 6 个节的长度，这样写到数据表中时只放了最后 6 个字节，所以 row_id 能写到数据表中的值，就有两个特征：&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;248-1到 264 之间，row_id 会是0，264 之后会从0开始。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;在 InnoDB 逻辑里，申请到 row_id=N 后，就将这行数据写入表中；如果表中已经存在 row_id=N 的行，新写入的行就会覆盖原有的行。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;覆盖数据，就意味着数据丢失，影响的是数据可靠性；报主键冲突，是插入失败，影响的是可用性。而一般情况下，可靠性优先于可用性。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、Xid&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    redo log 和 binlog 相配合的时候，提到了有一个共同的字段叫作 Xid。它在 MySQL 中是用来对应事务的。&lt;/p&gt;
&lt;p&gt;​    MySQL 内部维护了一个全局变量 global_query_id，每次执行语句的时候将它赋值给 Query_id，然后给这个变量加 1。如果当前语句是这个事务执行的第一条语句，那么 MySQL 还会同时把 Query_id 赋值给这个事务的 Xid。&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;而 global_query_id 是一个纯内存变量，重启之后就清零了。所以就知道了，在同一个数据库实例中，不同事务的 Xid 也是有可能相同的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;但是 MySQL 重启之后会重新生成新的 binlog 文件，这就保证了，同一个 binlog 文件里，Xid 一定是惟一的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;但是 global_query_id 定义的长度是 8 个字节，这个自增值的上限是 264-1。理论上也是可能重复的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4、trx_id&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;Xid 是由 server 层维护的。InnoDB 内部使用 Xid，就是为了能够在 InnoDB 事务和 server 之间做关联。但是，InnoDB 自己的 trx_id，是另外维护的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    InnoDB 内部维护了一个 max_trx_id 全局变量，每次需要申请一个新的 trx_id 时，就获得 max_trx_id 的当前值，然后并将 max_trx_id 加 1。&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;InnoDB 数据可见性的核心思想是：每一行数据都记录了更新它的 trx_id，当一个事务读到一行数据的时候，判断这个数据是否可见的方法，就是通过事务的一致性视图与这行数据的 trx_id 做对比。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;对于正在执行的事务，可以从 information_schema.innodb_trx 表中看到事务的 trx_id。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;update 和 delete 语句除了事务本身，还涉及到标记删除旧数据，也就是要把数据放到 purge 队列里等待后续物理删除，这个操作也会把 max_trx_id+1， 因此在一个事务中至少加 2；&lt;/p&gt;
&lt;p&gt;InnoDB 的后台操作，比如表的索引信息统计这类操作，也是会启动内部事务的，因此你可能看到，trx_id 值并不是按照加 1 递增的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;​    **只读事务会分配一个特殊的，比较大的id，**把当前事务的 trx 变量的指针地址转成整数，再加上 248，使用这个算法，就可以保证以下两点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;因为同一个只读事务在执行期间，它的指针地址是不会变的，所以不论是在 innodb_trx 还是在 innodb_locks 表里，同一个只读事务查出来的 trx_id 就会是一样的。&lt;/li&gt;
&lt;li&gt;如果有并行的多个只读事务，每个事务的 trx 变量的指针地址肯定不同。这样，不同的并发只读事务，查出来的 trx_id 就是不同的。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​    加上248是为了保证只读事务显示的 trx_id 值比较大，正常情况下就会区别于读写事务的 id。理论情况下也可能只读事务与读写事务相等，但是没有影响。&lt;/p&gt;
&lt;p&gt;​    max_trx_id 会持久化存储，重启也不会重置为 0，那么从理论上讲，只要一个 MySQL 服务跑得足够久，就&lt;strong&gt;可能出现 max_trx_id 达到 248-1 的上限，然后从 0 开始的情况。当达到这个状态后，MySQL 就会持续出现一个脏读的 bug。因为后续的trx_id肯定比末尾那些trx_id大，能看到这些数据。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5、thread_id&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    系统保存了一个全局变量 thread_id_counter，每新建一个连接，就将 thread_id_counter 赋值给这个新连接的线程变量。定义的大小是 4 个字节，因此达到 232-1 后，它就会重置为 0，然后继续增加。但是，在 show processlist 里不会看到两个相同的 thread_id。因为 MySQL 设计了一个唯一数组的逻辑，给新线程分配 thread_id 的时候，逻辑代码是这样的：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;do {&lt;br&gt;
new_id= thread_id_counter++;&lt;br&gt;
} while (!thread_ids.insert_unique(new_id).second);&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;count-语句分析&#34;&gt;&lt;strong&gt;count(*) 语句分析&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;​    MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；&lt;/p&gt;
&lt;p&gt;​    InnoDB 引擎就麻烦了，执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。因为多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。&lt;/p&gt;
&lt;p&gt;​    count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。&lt;br&gt;
​    所以，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;按照效率排序的话，count(字段) &amp;lt; count(主键id) &amp;lt; count(1) &amp;lt; count(*)，所以建议，尽量使用count(*)。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;order-by-语句分析&#34;&gt;&lt;strong&gt;order by 语句分析&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;​    MySQL 会给每个线程分配一块内存用于&lt;strong&gt;快速排序&lt;/strong&gt;，称为 &lt;strong&gt;sort_buffer&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;​    explain 结果里的 Extra 这个字段中的“Using filesort”表示的就是需要排序。&lt;/p&gt;
&lt;p&gt;​    sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序。&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;建立联合索引，甚至覆盖索引，可以避免排序过程。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;join-语句分析&#34;&gt;&lt;strong&gt;join 语句分析&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;​    直接使用 join 语句，MySQL 优化器可能会选择表 t1 或 t2 作为驱动表，改用 straight_join 让 MySQL 使用固定的连接方式执行查询，这样优化器只会按照指定的方式去 join。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;select * from t1 straight_join t2 on (t1.a=t2.a);&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://segmentfault.com/img/bVbxvfJ?w=1394&amp;amp;h=163&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
在这条语句里，&lt;strong&gt;被驱动表 t2 的字段 a 上有索引，join 过程用上了这个索引，因此效率是很高的。称之为“Index Nested-Loop Join”，简称 NLJ。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;如果被驱动表 t2 的字段 a 上没有索引，那每次到 t2 去匹配的时候，就要做一次全表扫描。这个效率很低。这个算法叫做“Simple Nested-Loop Join”的算法，简称 BNL。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    所以在判断要不要使用 join 语句时，就是看 explain 结果里面，Extra 字段里面有没有出现“Block Nested Loop”字样。&lt;/p&gt;
&lt;p&gt;​    在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是“小表”，应该作为驱动表。&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;Multi-Range Read 优化，这个优化的主要目的是尽量使用顺序读盘。因为大多数的数据都是按照主键递增顺序插入得到的，所以可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;select * from t1 where a&amp;gt;=1 and a&amp;lt;=100;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://segmentfault.com/img/bVbxvfN?w=1583&amp;amp;h=149&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;strong&gt;Batched Key Access(BKA) 算法。这个 BKA 算法，其实就是对 NLJ 算法的优化。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    NLJ 算法执行的逻辑是：从驱动表 t1，一行行地取出 a 的值，再到被驱动表 t2 去做 join。也就是说，对于表 t2 来说，每次都是匹配一个值。这时，MRR 的优势就用不上了。&lt;/p&gt;
&lt;p&gt;​    既然如此，就把表 t1 的数据取出来一部分，先放到一个临时内存。这个临时内存就是 join_buffer。&lt;/p&gt;
&lt;h3 id=&#34;自增主键&#34;&gt;&lt;strong&gt;自增主键&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://segmentfault.com/img/bVbxvfO?w=1430&amp;amp;h=542&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
表定义里面出现了一个 AUTO_INCREMENT=2，表示下一次插入数据时，如果需要自动生成自增值，会生成 id=2。&lt;/p&gt;
&lt;p&gt;实际上，表的结构定义存放在后缀名为.frm 的文件中，但是并不会保存自增值。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MyISAM 引擎的自增值保存在数据文件中。&lt;/li&gt;
&lt;li&gt;InnoDB 引擎的自增值，其实是保存在了内存里，MySQL 8.0 版本后，才有了“自增值持久化”的能力。
&lt;ul&gt;
&lt;li&gt;MySQL 5.7 及之前的版本，自增值保存在内存里，并没有持久化。每次重启后，第一次打开表的时候，都会去找自增值的最大值 max(id)，然后将 max(id)+1 作为这个表当前的自增值。&lt;/li&gt;
&lt;li&gt;MySQL 8.0 版本，将自增值的变更记录在了 redo log 中，重启的时候依靠 redo log 恢复重启之前的值。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;自增值修改机制&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果插入数据时 id 字段指定为 0、null 或未指定值，那么就把这个表当前的 AUTO_INCREMENT 值填到自增字段；&lt;/li&gt;
&lt;li&gt;如果插入数据时 id 字段指定了具体的值 X ，就直接使用语句里指定的值 Y。
&lt;ul&gt;
&lt;li&gt;如果 X &amp;lt; Y，那么这个表的自增值不变；&lt;/li&gt;
&lt;li&gt;如果 X≥Y，就需要把当前自增值修改为新的自增值。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​    &lt;strong&gt;新的自增值生成算法是：从 auto_increment_offset 开始，以 auto_increment_increment 为步长，持续叠加，直到找到第一个大于 X 的值，作为新的自增值。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;自增值的修改时机&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;执行器调用 InnoDB 引擎接口写入一行，传入的这一行的值(0,1,1);&lt;/li&gt;
&lt;li&gt;InnoDB 发现用户没有指定自增 id 的值，获取表 t 当前的自增值 2；&lt;/li&gt;
&lt;li&gt;将传入的行的值改成 (2,1,1);&lt;/li&gt;
&lt;li&gt;将表的自增值改成 3；&lt;/li&gt;
&lt;li&gt;继续执行插入数据操作，由于已经存在 c=1 的记录，所以报 Duplicate key error，语句返回。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​    所以，sql执行报错了，自增值已经改变了，&lt;strong&gt;唯一键冲突是导致自增主键 id 不连续的第一种原因。同样地，事务回滚也会产生类似的现象，这就是第二种原因。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;批量插入的时候，由于系统预先不知道要申请多少个自增 id，所以就先申请一个，然后两个，然后四个，直到够用。这是主键 id 出现自增 id 不连续的第三种原因。&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;备份恢复&#34;&gt;备份恢复&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;保存一定时间的binlog，同时系统会定期做整库备份。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当需要恢复到指定的某一秒时，&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;首先，找到最近的一次全量备份，如果运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库&lt;/li&gt;
&lt;li&gt;然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到指定的那个时刻。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​    **redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。**这个参数建议设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。&lt;/p&gt;
&lt;p&gt;​    **binlog用于备份恢复和从库同步。sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。**这个参数也建议设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。&lt;/p&gt;
&lt;h3 id=&#34;主备同步&#34;&gt;&lt;strong&gt;主备同步&lt;/strong&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。&lt;/li&gt;
&lt;li&gt;在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。&lt;/li&gt;
&lt;li&gt;主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。&lt;/li&gt;
&lt;li&gt;备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。&lt;/li&gt;
&lt;li&gt;sql_thread 读取中转日志，解析出日志里的命令，并执行。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://segmentfault.com/img/bVbxvfj?w=1142&amp;amp;h=856&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
一主一备结构，需要注意主备切换，备库设置只读，避免切换bug造成双写不一致问题（设置 readonly 对超级用户是无效的，同步更新的线程有超级权限，所以还能写入同步数据）。&lt;/p&gt;
&lt;p&gt;​    双主结构，要避免循环更新问题，因为MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的 server id。所以可以规定两个库的 server id 必须不同，每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。&lt;/p&gt;
&lt;h3 id=&#34;主备延迟&#34;&gt;&lt;strong&gt;主备延迟&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;​    **可以在备库上执行 show slave status 命令，它的返回结果里面会显示 seconds_behind_master，用于表示当前备库延迟了多少秒。**每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间； 备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 seconds_behind_master。&lt;/p&gt;
&lt;p&gt;主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢。&lt;/p&gt;
&lt;p&gt;主备延迟的来源&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;考虑到主备切换，主备机器一般都一样了，但是还可能备库读的压力太大，&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一主多从，或者通过binlog输出到外部系统(比如Hadoop)，让外部系统提供部分统计查询能力。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;大事务，如果事务执行十分钟，那就会导致主从延迟十分钟。&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;主备复制策略&#34;&gt;&lt;strong&gt;主备复制策略&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;​    &lt;strong&gt;在官方的 5.6 版本之前，MySQL 只支持单线程复制&lt;/strong&gt;，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。&lt;/p&gt;
&lt;p&gt;​    并行复制策略有按表并行分发策略，按行并行分发策略，但是按行分发在决定线程分发的时候，需要消耗更多的计算资源。这两个方案其实都有一些约束条件：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；&lt;/li&gt;
&lt;li&gt;表必须有主键；&lt;/li&gt;
&lt;li&gt;不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​    **官方 MySQL5.6 版本，支持了并行复制，只是支持的粒度是按库并行。**相比于按表和按行分发，这个策略有两个优势：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;构造 hash 值的时候很快，只需要库名；而且一个实例上 DB 数也不会很多，不会出现需要构造 100 万个项这种情况。&lt;/li&gt;
&lt;li&gt;不要求 binlog 的格式。因为 statement 格式的 binlog 也可以很容易拿到库名。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​    &lt;strong&gt;MariaDB 的并行复制策略，伪模拟主库并发度&lt;/strong&gt;，主库 redo log 组提交 (group commit) 优化，同一组提交会记录commit_id，备库把同一个commit_id分发到多个worker执行。&lt;/p&gt;
&lt;p&gt;官方的 MySQL5.7 版本，由参数 slave-parallel-type 来控制并行复制策略：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；&lt;/li&gt;
&lt;li&gt;配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​    **MySQL 5.7.22 版本里，MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。**对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。&lt;/p&gt;
&lt;h3 id=&#34;union和union-all&#34;&gt;&lt;strong&gt;Union和Union All&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Union：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序；&lt;/p&gt;
&lt;p&gt;Union All：对两个结果集进行并集操作，包括重复行，不进行排序；&lt;/p&gt;
&lt;h3 id=&#34;join&#34;&gt;Join&lt;/h3&gt;
&lt;p&gt;1.inner join（内连接），在两张表进行连接查询时，只保留两张表中完全匹配的结果集。&lt;/p&gt;
&lt;p&gt;2.left join,在两张表进行连接查询时，会返回左表所有的行，即使在右表中没有匹配的记录。&lt;/p&gt;
&lt;p&gt;3.right join,在两张表进行连接查询时，会返回右表所有的行，即使在左表中没有匹配的记录。&lt;/p&gt;
&lt;p&gt;4.full join,在两张表进行连接查询时，返回左表和右表中所有没有匹配的行。&lt;/p&gt;
&lt;h3 id=&#34;1-能说下myisam-和-innodb的区别吗&#34;&gt;1. 能说下myisam 和 innodb的区别吗？&lt;/h3&gt;
&lt;p&gt;myisam引擎是5.1版本之前的默认引擎，支持全文检索、压缩、空间函数等，但是不支持事务和行级锁，所以一般用于有大量查询少量插入的场景来使用，而且myisam不支持外键，并且索引和数据是分开存储的。&lt;/p&gt;
&lt;p&gt;innodb是基于聚簇索引建立的，和myisam相反它支持事务、外键，并且通过MVCC来支持高并发，索引和数据存储在一起。&lt;/p&gt;
&lt;h3 id=&#34;2-说下mysql的索引有哪些吧聚簇和非聚簇索引又是什么&#34;&gt;2. 说下mysql的索引有哪些吧，聚簇和非聚簇索引又是什么？&lt;/h3&gt;
&lt;p&gt;索引按照数据结构来说主要包含B+树和Hash索引。&lt;/p&gt;
&lt;p&gt;假设我们有张表，结构如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;create table user(
 id int(11) not null,
  age int(11) not null,
  primary key(id),
  key(age)
);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;B+树是左小右大的顺序存储结构，节点只包含id索引列，而叶子节点包含索引列和数据，这种数据和索引在一起存储的索引方式叫做聚簇索引，一张表只能有一个聚簇索引。假设没有定义主键，InnoDB会选择一个唯一的非空索引代替，如果没有的话则会隐式定义一个主键作为聚簇索引。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485UNAyaZCiad9IZyfFcMfMt8CogYojcicbYW5QlqqrrQg9w7osRKEGUP9lw/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;这是主键聚簇索引存储的结构，那么非聚簇索引的结构是什么样子呢？非聚簇索引(二级索引)保存的是主键id值，这一点和myisam保存的是数据地址是不同的。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485U5M1te7Go4icEIby6ft9UXYoicNjIiaEP6tJ5OqDnAMX8Nd52uib8PXOibGg/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;最终，我们一张图看看InnoDB和Myisam聚簇和非聚簇索引的区别&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485USVnE4tGnV2JQtwibibRib1wt5q01ibiaWibDG2d7UZwdbSJOEzIbT0U691mA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;3-那你知道什么是覆盖索引和回表吗&#34;&gt;3. 那你知道什么是覆盖索引和回表吗？&lt;/h3&gt;
&lt;p&gt;覆盖索引指的是在一次查询中，如果一个索引包含或者说覆盖所有需要查询的字段的值，我们就称之为覆盖索引，而不再需要回表查询。&lt;/p&gt;
&lt;p&gt;而要确定一个查询是否是覆盖索引，我们只需要explain sql语句看Extra的结果是否是“Using index”即可。&lt;/p&gt;
&lt;p&gt;以上面的user表来举例，我们再增加一个name字段，然后做一些查询试试。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;explain select * from user where age=1; //查询的name无法从索引数据获取
explain select id,age from user where age=1; //可以直接从索引获取
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;4-锁的类型有哪些呢&#34;&gt;4. 锁的类型有哪些呢&lt;/h3&gt;
&lt;p&gt;mysql锁分为&lt;strong&gt;共享锁&lt;/strong&gt;和&lt;strong&gt;排他锁&lt;/strong&gt;，也叫做读锁和写锁。&lt;/p&gt;
&lt;p&gt;读锁是共享的，可以通过lock in share mode实现，这时候只能读不能写。&lt;/p&gt;
&lt;p&gt;写锁是排他的，它会阻塞其他的写锁和读锁。从颗粒度来区分，可以分为&lt;strong&gt;表锁&lt;/strong&gt;和&lt;strong&gt;行锁&lt;/strong&gt;两种。&lt;/p&gt;
&lt;p&gt;表锁会锁定整张表并且阻塞其他用户对该表的所有读写操作，比如alter修改表结构的时候会锁表。&lt;/p&gt;
&lt;p&gt;行锁又可以分为&lt;strong&gt;乐观锁&lt;/strong&gt;和&lt;strong&gt;悲观锁&lt;/strong&gt;，悲观锁可以通过for update实现，乐观锁则通过版本号实现。&lt;/p&gt;
&lt;h3 id=&#34;5-你能说下事务的基本特性和隔离级别吗&#34;&gt;5. 你能说下事务的基本特性和隔离级别吗？&lt;/h3&gt;
&lt;p&gt;事务基本特性ACID分别是：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;原子性&lt;/strong&gt;指的是一个事务中的操作要么全部成功，要么全部失败。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一致性&lt;/strong&gt;指的是数据库总是从一个一致性的状态转换到另外一个一致性的状态。比如A转账给B100块钱，假设中间sql执行过程中系统崩溃A也不会损失100块，因为事务没有提交，修改也就不会保存到数据库。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;隔离性&lt;/strong&gt;指的是一个事务的修改在最终提交前，对其他事务是不可见的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;持久性&lt;/strong&gt;指的是一旦事务提交，所做的修改就会永久保存到数据库中。&lt;/p&gt;
&lt;p&gt;而隔离性有4个隔离级别，分别是：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;read uncommit&lt;/strong&gt; 读未提交，可能会读到其他事务未提交的数据，也叫做脏读。&lt;/p&gt;
&lt;p&gt;用户本来应该读取到id=1的用户age应该是10，结果读取到了其他事务还没有提交的事务，结果读取结果age=20，这就是脏读。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485UADTzKMibJwb1picAytaqIIyWLQM0UeocSSKymzm6e8ChYlI3tVzialCicA/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;read commit&lt;/strong&gt; 读已提交，两次读取结果不一致，叫做不可重复读。&lt;/p&gt;
&lt;p&gt;不可重复读解决了脏读的问题，他只会读取已经提交的事务。&lt;/p&gt;
&lt;p&gt;用户开启事务读取id=1用户，查询到age=10，再次读取发现结果=20，在同一个事务里同一个查询读取到不同的结果叫做不可重复读。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485UeiaLx7HFnfbuiaTUlrib9k9117AQ2noW6Q10iaefPG3OxXSviakGjqiaTVMw/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;repeatable read&lt;/strong&gt; 可重复复读，这是mysql的默认级别，就是每次读取结果都一样，但是有可能产生幻读。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;serializable&lt;/strong&gt; 串行，一般是不会使用的，他会给每一行读取的数据加锁，会导致大量超时和锁竞争的问题。&lt;/p&gt;
&lt;h3 id=&#34;6-那acid靠什么保证的呢&#34;&gt;6. 那ACID靠什么保证的呢？&lt;/h3&gt;
&lt;p&gt;A原子性由undo log日志保证，它记录了需要回滚的日志信息，事务回滚时撤销已经执行成功的sql&lt;/p&gt;
&lt;p&gt;C一致性一般由代码层面来保证&lt;/p&gt;
&lt;p&gt;I隔离性由MVCC来保证&lt;/p&gt;
&lt;p&gt;D持久性由内存+redo log来保证，mysql修改数据同时在内存和redo log记录这次操作，事务提交的时候通过redo log刷盘，宕机的时候可以从redo log恢复&lt;/p&gt;
&lt;h3 id=&#34;7-那你说说什么是幻读什么是mvcc&#34;&gt;7. 那你说说什么是幻读，什么是MVCC？&lt;/h3&gt;
&lt;p&gt;要说幻读，首先要了解MVCC，MVCC叫做多版本并发控制，实际上就是保存了数据在某个时间节点的快照。&lt;/p&gt;
&lt;p&gt;我们每行数实际上隐藏了两列，创建时间版本号，过期(删除)时间版本号，每开始一个新的事务，版本号都会自动递增。&lt;/p&gt;
&lt;p&gt;还是拿上面的user表举例子，假设我们插入两条数据，他们实际上应该长这样。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;name&lt;/th&gt;
&lt;th&gt;create_version&lt;/th&gt;
&lt;th&gt;delete_version&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;张三&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;李四&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;这时候假设小明去执行查询，此时current_version=3&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select * from user where id&amp;lt;=3;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;同时，小红在这时候开启事务去修改id=1的记录，current_version=4&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;update user set name=&#39;张三三&#39; where id=1;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;执行成功后的结果是这样的&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;name&lt;/th&gt;
&lt;th&gt;create_version&lt;/th&gt;
&lt;th&gt;delete_version&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;张三&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;李四&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;张三三&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;如果这时候还有小黑在删除id=2的数据，current_version=5，执行后结果是这样的。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;name&lt;/th&gt;
&lt;th&gt;create_version&lt;/th&gt;
&lt;th&gt;delete_version&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;张三&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;李四&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;张三三&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;由于MVCC的原理是查找创建版本小于或等于当前事务版本，删除版本为空或者大于当前事务版本，小明的真实的查询应该是这样&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;select * from user where id&amp;lt;=3 and create_version&amp;lt;=3 and (delete_version&amp;gt;3 or delete_version is null);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;所以小明最后查询到的id=1的名字还是&#39;张三&#39;，并且id=2的记录也能查询到。这样做是&lt;strong&gt;为了保证事务读取的数据是在事务开始前就已经存在的，要么是事务自己插入或者修改的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;明白MVCC原理，我们来说什么是幻读就简单多了。举一个常见的场景，用户注册时，我们先查询用户名是否存在，不存在就插入，假定用户名是唯一索引。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;小明开启事务current_version=6查询名字为&#39;王五&#39;的记录，发现不存在。&lt;/li&gt;
&lt;li&gt;小红开启事务current_version=7插入一条数据，结果是这样：&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;create_version&lt;/th&gt;
&lt;th&gt;delete_version&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;张三&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;李四&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;王五&lt;/td&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ol&gt;
&lt;li&gt;小明执行插入名字&#39;王五&#39;的记录，发现唯一索引冲突，无法插入，这就是幻读。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;8-那你知道什么是间隙锁吗&#34;&gt;8. 那你知道什么是间隙锁吗？&lt;/h3&gt;
&lt;p&gt;间隙锁是可重复读级别下才会有的锁，结合MVCC和间隙锁可以解决幻读的问题。我们还是以user举例，假设现在user表有几条记录&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;id&lt;/th&gt;
&lt;th&gt;Age&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;当我们执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;begin;
select * from user where age=20 for update;

begin;
insert into user(age) values(10); #成功
insert into user(age) values(11); #失败
insert into user(age) values(20); #失败
insert into user(age) values(21); #失败
insert into user(age) values(30); #失败
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;只有10可以插入成功，那么因为表的间隙mysql自动帮我们生成了区间(左开右闭)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(negative infinity，10],(10,20],(20,30],(30,positive infinity)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;由于20存在记录，所以(10,20]，(20,30]区间都被锁定了无法插入、删除。&lt;/p&gt;
&lt;p&gt;如果查询21呢？就会根据21定位到(20,30)的区间(都是开区间)。&lt;/p&gt;
&lt;p&gt;需要注意的是唯一索引是不会有间隙索引的。&lt;/p&gt;
&lt;h3 id=&#34;9-你们数据量级多大分库分表怎么做的&#34;&gt;9. 你们数据量级多大？分库分表怎么做的？&lt;/h3&gt;
&lt;p&gt;首先分库分表分为垂直和水平两个方式，一般来说我们拆分的顺序是先垂直后水平。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;垂直分库&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;基于现在微服务拆分来说，都是已经做到了垂直分库了&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;15&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485Ub7GrOacc0Pr1CE9NTjg0XDyLOLhQ8A7rslyKvRW42QLTib3cjqSP1Uw/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;垂直分表&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果表字段比较多，将不常用的、数据较大的等等做拆分&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;16&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485Uk3OKhn3leSJuRg7X6tIU8LvHM0v5N5yCF2JeiagD1q19pvvliaxLteXg/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;水平分表&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先根据业务场景来决定使用什么字段作为分表字段(sharding_key)，比如我们现在日订单1000万，我们大部分的场景来源于C端，我们可以用user_id作为sharding_key，数据查询支持到最近3个月的订单，超过3个月的做归档处理，那么3个月的数据量就是9亿，可以分1024张表，那么每张表的数据大概就在100万左右。&lt;/p&gt;
&lt;p&gt;比如用户id为100，那我们都经过hash(100)，然后对1024取模，就可以落到对应的表上了。&lt;/p&gt;
&lt;h3 id=&#34;10-那分表后的id怎么保证唯一性的呢&#34;&gt;10. 那分表后的ID怎么保证唯一性的呢？&lt;/h3&gt;
&lt;p&gt;因为我们主键默认都是自增的，那么分表之后的主键在不同表就肯定会有冲突了。有几个办法考虑：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;设定步长，比如1-1024张表我们设定1024的基础步长，这样主键落到不同的表就不会冲突了。&lt;/li&gt;
&lt;li&gt;分布式ID，自己实现一套分布式ID生成算法或者使用开源的比如雪花算法这种&lt;/li&gt;
&lt;li&gt;分表后不使用主键作为查询依据，而是每张表单独新增一个字段作为唯一主键使用，比如订单表订单号是唯一的，不管最终落在哪张表都基于订单号作为查询依据，更新也一样。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;11-分表后非sharding_key的查询怎么处理呢&#34;&gt;11. 分表后非sharding_key的查询怎么处理呢？&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;可以做一个mapping表，比如这时候商家要查询订单列表怎么办呢？不带user_id查询的话你总不能扫全表吧？所以我们可以做一个映射关系表，保存商家和用户的关系，查询的时候先通过商家查询到用户列表，再通过user_id去查询。&lt;/li&gt;
&lt;li&gt;打宽表，一般而言，商户端对数据实时性要求并不是很高，比如查询订单列表，可以把订单表同步到离线（实时）数仓，或者基于其他如es提供查询服务。&lt;/li&gt;
&lt;li&gt;数据量不是很大的话，比如后台的一些查询之类的，也可以通过多线程扫表，然后再聚合结果的方式来做。或者异步的形式也是可以的。&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;List&amp;lt;Callable&amp;lt;List&amp;lt;User&amp;gt;&amp;gt;&amp;gt; taskList = Lists.newArrayList();
for (int shardingIndex = 0; shardingIndex &amp;lt; 1024; shardingIndex++) {
    taskList.add(() -&amp;gt; (userMapper.getProcessingAccountList(shardingIndex)));
}
List&amp;lt;ThirdAccountInfo&amp;gt; list = null;
try {
    list = taskExecutor.executeTask(taskList);
} catch (Exception e) {
    //do something
}

public class TaskExecutor {
    public &amp;lt;T&amp;gt; List&amp;lt;T&amp;gt; executeTask(Collection&amp;lt;? extends Callable&amp;lt;T&amp;gt;&amp;gt; tasks) throws Exception {
        List&amp;lt;T&amp;gt; result = Lists.newArrayList();
        List&amp;lt;Future&amp;lt;T&amp;gt;&amp;gt; futures = ExecutorUtil.invokeAll(tasks);
        for (Future&amp;lt;T&amp;gt; future : futures) {
            result.add(future.get());
        }
        return result;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;12-说说mysql主从同步怎么做的吧&#34;&gt;12. 说说mysql主从同步怎么做的吧？&lt;/h3&gt;
&lt;p&gt;首先先了解mysql主从同步的原理&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;master提交完事务后，写入binlog&lt;/li&gt;
&lt;li&gt;slave连接到master，获取binlog&lt;/li&gt;
&lt;li&gt;master创建dump线程，推送binglog到slave&lt;/li&gt;
&lt;li&gt;slave启动一个IO线程读取同步过来的master的binlog，记录到relay log中继日志中&lt;/li&gt;
&lt;li&gt;slave再开启一个sql线程读取relay log事件并在slave执行，完成同步&lt;/li&gt;
&lt;li&gt;slave记录自己的binglog&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;17&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/sz_mmbiz_jpg/IaIwEngZ4c1icho1EzwGZawVIXic9r485U1uHePukqQsKN6zKibICaRz1Zj3msDFIjNrFX4lkCVjYoibbib6LaU2XKw/640?wx_fmt=jpeg&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;由于mysql默认的复制方式是异步的，主库把日志发送给从库后不关心从库是否已经处理，这样会产生一个问题就是假设主库挂了，从库处理失败了，这时候从库升为主库后，日志就丢失了。由此产生两个概念。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;全同步复制&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;主库写入binlog后强制同步日志到从库，所有的从库都执行完成后才返回给客户端，但是很显然这个方式的话性能会受到严重影响。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;半同步复制&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;和全同步不同的是，半同步复制的逻辑是这样，从库写入日志成功后返回ACK确认给主库，主库收到至少一个从库的确认就认为写操作完成。&lt;/p&gt;
&lt;h3 id=&#34;13-那主从的延迟怎么解决呢&#34;&gt;13. 那主从的延迟怎么解决呢？&lt;/h3&gt;
&lt;p&gt;这个问题貌似真的是个无解的问题，只能是说自己来判断了，需要走主库的强制走主库查询。&lt;/p&gt;
">mysql面试</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/sql-yuanli/"" data-c="
          &lt;h3 id=&#34;第一步连接器连接到数据库&#34;&gt;第一步，连接器连接到数据库&lt;/h3&gt;
&lt;p&gt;连接器负责跟客户端建立连接、获取权限、维持和管理连接。&lt;/p&gt;
&lt;p&gt;连接完成后，如果没有后续的动作，这个连接就处于空闲状态，可以在&lt;strong&gt;show processlist&lt;/strong&gt;命令中看到它。文本中这个图是show processlist的结果，其中的Command列显示为&amp;quot;Sleep&amp;quot;的这一行，就表示现在系统里面有一个空闲连接。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/3164013193-5d765911bd997_articlex.png&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;​    客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数&lt;strong&gt;wait timeout&lt;/strong&gt;控制的，默认值是8小时。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;断开后再执行sql会报错：Lost connection to MySQL server during query&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;​    建立连接的过程通常是比较复杂的，所以建议在使用中要尽量减少建立连接的动作，也就是&lt;strong&gt;尽量使用长连接。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    但是 MySQL 在执行过程中临时使用的&lt;strong&gt;内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放&lt;/strong&gt;。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启。&lt;/p&gt;
&lt;p&gt;怎么解决这个问题呢？可以考虑以下两种方案。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;如果用的是MySQL 5.7或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql reset connection来重新初始化连接资源。这个过程不需要重连和重新做权限验证但是会将连接恢复到刚刚创建完时的状态。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第二步查询语句会先查询缓存&#34;&gt;第二步，查询语句会先查询缓存&lt;/h3&gt;
&lt;p&gt;之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。&lt;/p&gt;
&lt;p&gt;​    但是&lt;strong&gt;查询缓存利大于弊&lt;/strong&gt;，因为&lt;strong&gt;查询缓存的失效非常频繁&lt;/strong&gt;，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。&lt;/p&gt;
&lt;p&gt;​    除非是静态配置表才适合用查询缓存。&lt;strong&gt;可以将参数 query_cache_type 设置成DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。SQL_CACHE 显式指定使用查询缓存。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;select SQL_CACHE * from T where ID=10；&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;​    但是，&lt;strong&gt;MySQL 8.0版本彻底删除了查询缓存功能。&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第三步分析语句先是词法分析&#34;&gt;第三步，分析语句，先是词法分析&lt;/h3&gt;
&lt;p&gt;找出select，表名，列名等关键字；然后是语法分析，判断语法是否正确。&lt;strong&gt;表名列名不对的sql，会在语法分析时报错。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;语法错误：ERROR 1064 (42000): You have an error in your SQL syntax;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第四步优化器&#34;&gt;&lt;strong&gt;第四步&lt;/strong&gt;，优化器&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;决定使用哪个索引，join的时候决定各个表的连接顺序。&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;第五步-执行器&#34;&gt;第五步、执行器&lt;/h3&gt;
&lt;p&gt;​    &lt;strong&gt;先判断对当前表是否有权限（如果命中查询缓存，会在返回结果时验证权限）。&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ERROR 1142 (42000): SELECT command denied to user &#39;b&#39;@&#39;localhost&#39; for table &#39;T&#39;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;​    如：select * from T where ID=10; 执行过程&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；&lt;/li&gt;
&lt;li&gt;调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。&lt;/li&gt;
&lt;li&gt;执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;慢查询日志中有一行 rows_examined 字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。但是引擎扫描行数跟 rows_examined 并不是完全相同的。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;查询的数据如何返回&#34;&gt;&lt;strong&gt;查询的数据如何返回&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对一个200G的大表做全表扫描，而内存只有16G，会不会把数据库主机的内存用光了？&lt;/p&gt;
&lt;p&gt;实际上，MySQL不是取到全部数据再返回客户端。取数据和发数据的流程是这样的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。&lt;/li&gt;
&lt;li&gt;重复获取行，直到 net_buffer 写满，调用网络接口发出去。&lt;/li&gt;
&lt;li&gt;如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。&lt;/li&gt;
&lt;li&gt;如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MySQL 客户端发送请求后，接收服务端返回结果的方式有两种：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;一种是本地缓存，也就是在本地开一片内存，先把结果存起来。如果用 API 开发，对应的就是 mysql_store_result 方法。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;另一种是不缓存，读一个处理一个。如果用 API 开发，对应的就是 mysql_use_result 方法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;MySQL 客户端默认采用第一种方式，而如果加上–quick 参数，就会使用第二种不缓存的方式。&lt;/p&gt;
&lt;p&gt;采用不缓存的方式时，如果本地处理得慢，就会导致服务端发送结果被阻塞，因此会让服务端变慢。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​    &lt;strong&gt;MySQL 是“边读边发的”。这就意味着，如果客户端接收得慢，会导致 MySQL 服务端由于结果发不出去，这个事务的执行时间变长。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;对于正常的线上业务来说，如果一个查询的返回结果不会很多的话，都建议使用 mysql_store_result 这个接口，直接把查询结果保存到本地内存。&lt;/strong&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;sql语句的执行顺序&#34;&gt;SQL语句的执行顺序&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;sql&lt;/code&gt;语句的执行顺序可通过下图了解，注意&lt;code&gt;sql&lt;/code&gt;是从from开始执行的。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/51-966027615.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;FROM 
WHERE 
GROUP BY 
HAVING 
SELECT 
DISTINCT 
UNION 
ORDER BY 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;1、FROM 才是 SQL 语句执行的第一步，并非 SELECT 。数据库在执行 SQL 语句的第一步是将数据从硬盘加载到数据缓冲区中， 以便对这些数据进行操作。&lt;/p&gt;
&lt;p&gt;2、SELECT 是在大部分语句执行了之后才执行的，严格的说是在 FROM 和 GROUP BY 之后执行的。理解这一点是非常重要的，这就是你 不能在 WHERE 中使用在 SELECT 中设定别名的字段作为判断条件的原因。&lt;/p&gt;
&lt;p&gt;3、无论在语法上还是在执行顺序上， UNION 总是排在 ORDER BY 之前。很多人认为每个 UNION 段都能使用 ORDER BY 排序，但是根据  SQL 语言标准和各个数据库 SQL 的执行差异来看，这并不是真的。尽管某些数据库允许 SQL 语句对子查询（subqueries）或者派生表 （derived tables）进行排序，但是这并不说明这个排序在 UNION 操作过后仍保持排序后的顺序。&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;更新语句执行过程&#34;&gt;更新语句执行过程&lt;/h2&gt;
&lt;p&gt;比如：update T set c=c+1 where ID=2;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;执行器先找引擎取 ID=2 这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。&lt;/li&gt;
&lt;li&gt;执行器拿到引擎给的行数据，把这个值加上 1，得到新的一行数据，再调用引擎接口写入这行新数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;执行器生成这个操作的 binlog，并把 binlog 写入磁盘。&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里给出这个 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。&lt;strong&gt;其实就是把redo log 和binlog 做两阶段提交，为了让两份日志之间的逻辑一致。&lt;/strong&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/2966732684-5d76598f95aad_articlex.png&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
">1、sql原理</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/table/"" data-c="
          &lt;h2 id=&#34;数据库的定义&#34;&gt;数据库的定义&lt;/h2&gt;
&lt;p&gt;很多开发者在最开始时其实都对数据库有一个比较模糊的认识，觉得数据库就是一堆数据的集合，但是实际却比这复杂的多，数据库领域中有两个词非常容易混淆，也就是_数据库&lt;em&gt;和&lt;/em&gt;实例_：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据库：物理操作文件系统或其他形式文件类型的集合；&lt;/li&gt;
&lt;li&gt;实例：MySQL 数据库由后台线程以及一个共享内存区组成；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;数据库和实例&#34;&gt;数据库和实例&lt;/h3&gt;
&lt;p&gt;在 MySQL 中，实例和数据库往往都是一一对应的，而我们也无法直接操作数据库，而是要通过数据库实例来操作数据库文件，可以理解为数据库实例是数据库为上层提供的一个专门用于操作的接口。&lt;/p&gt;
&lt;p&gt;在 Unix 上，启动一个 MySQL 实例往往会产生两个进程，&lt;code&gt;mysqld&lt;/code&gt; 就是真正的数据库服务守护进程，而 &lt;code&gt;mysqld_safe&lt;/code&gt; 是一个用于检查和设置 &lt;code&gt;mysqld&lt;/code&gt; 启动的控制程序，它负责监控 MySQL 进程的执行，当 &lt;code&gt;mysqld&lt;/code&gt; 发生错误时，&lt;code&gt;mysqld_safe&lt;/code&gt; 会对其状态进行检查并在合适的条件下重启。&lt;/p&gt;
&lt;h3 id=&#34;mysql-的架构&#34;&gt;MySQL 的架构&lt;/h3&gt;
&lt;p&gt;MySQL 从第一个版本发布到现在已经有了 20 多年的历史，在这么多年的发展和演变中，整个应用的体系结构变得越来越复杂：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/Logical-View-of-MySQL-Architecture.jpg&#34; alt=&#34;Logical-View-of-MySQL-Architecture&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;最上层用于连接、线程处理的部分并不是 MySQL 『发明』的，很多服务都有类似的组成部分；第二层中包含了大多数 MySQL 的核心服务，包括了对 SQL 的解析、分析、优化和缓存等功能，存储过程、触发器和视图都是在这里实现的；而第三层就是 MySQL 中真正负责数据的存储和提取的存储引擎，例如：&lt;a href=&#34;https://en.wikipedia.org/wiki/InnoDB&#34;&gt;InnoDB&lt;/a&gt;、&lt;a href=&#34;https://en.wikipedia.org/wiki/MyISAM&#34;&gt;MyISAM&lt;/a&gt; 等，文中对存储引擎的介绍都是对 InnoDB 实现的分析。&lt;/p&gt;
&lt;h3 id=&#34;如何存储表&#34;&gt;如何存储表&lt;/h3&gt;
&lt;p&gt;MySQL 使用 InnoDB 存储表时，会将&lt;strong&gt;表的定义&lt;/strong&gt;和&lt;strong&gt;数据索引&lt;/strong&gt;等信息分开存储，其中前者存储在 &lt;code&gt;.frm&lt;/code&gt; 文件中，后者存储在 &lt;code&gt;.ibd&lt;/code&gt; 文件中，这一节就会对这两种不同的文件分别进行介绍。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;.frm 文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;无论在 MySQL 中选择了哪个存储引擎，所有的 MySQL 表都会在硬盘上创建一个 &lt;code&gt;.frm&lt;/code&gt; 文件用来描述表的格式或者说定义；&lt;code&gt;.frm&lt;/code&gt; 文件的格式在不同的平台上都是相同的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE TABLE test_frm(    column1 CHAR(5),    column2 INTEGER);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;当我们使用上面的代码创建表时，会在磁盘上的 &lt;code&gt;datadir&lt;/code&gt; 文件夹中生成一个 &lt;code&gt;test_frm.frm&lt;/code&gt; 的文件，这个文件中就包含了表结构相关的信息：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/frm-file-hex.png&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/frm-file-hex.png&#34; alt=&#34;frm-file-hex&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;.ibd 文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;InnoDB 中用于存储数据的文件总共有两个部分，一是&lt;strong&gt;系统表空间文件&lt;/strong&gt;，包括 &lt;code&gt;ibdata1&lt;/code&gt;、&lt;code&gt;ibdata2&lt;/code&gt; 等文件，其中存储了 InnoDB 系统信息和用户数据库表数据和索引，是所有表公用的。&lt;/p&gt;
&lt;p&gt;当打开 &lt;code&gt;innodb_file_per_table&lt;/code&gt; 选项时，&lt;code&gt;.ibd&lt;/code&gt; 文件就是每一个表独有的表空间，文件存储了当前表的数据和相关的索引数据。&lt;/p&gt;
&lt;h3 id=&#34;索引组织表&#34;&gt;&lt;strong&gt;索引组织表&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;在InnoDb存储引擎中，表都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表（index organized table）。在InnoDB存储引擎表中，每张表都有个主键（primary key)，如果在创建表时没有显示地定义主键，则InnoDB存储引擎会按如下方式选择或创建主键：&lt;/p&gt;
&lt;p&gt;1、首先判断表中是否有非空的唯一索引（unique not null),以该列为主键&lt;/p&gt;
&lt;p&gt;2、否则自动创建一个6字节大小的指针&lt;/p&gt;
&lt;p&gt;当表中有多个非空唯一索引时，选择建表时&lt;strong&gt;第一个定义&lt;/strong&gt;的非空唯一索引为主键。&lt;strong&gt;主键的选择根据的是定义索引的顺序，而不是建表时列的顺序&lt;/strong&gt;。 _rowid可以显示表（单个列为主键时）的主键。&lt;/p&gt;
&lt;p&gt;MySQL查询过程&lt;/p&gt;
&lt;p&gt;1、InnoDb通过B+Tree聚集索引搜索时，只能找到该记录所在的索引页(index page)，而不能到具体的行记录。&lt;/p&gt;
&lt;p&gt;2、找到该索引页(index page)后将该页加载入内存。&lt;/p&gt;
&lt;p&gt;3、通过key在索引页(index page)的directory slots中进行二分查找（binary search），找到key对应的slot。&lt;/p&gt;
&lt;p&gt;4、因为slot是管理多条记录，普通的slot最少管辖4条,最多管辖8条,所以会再根据KEY在对应的slot管理的记录中顺序（linear search） 查找，找到最终结果。&lt;/p&gt;
&lt;h3 id=&#34;innodb逻辑存储结构&#34;&gt;&lt;strong&gt;InnoDB逻辑存储结构&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;从InnoDB存储引擎的逻辑存储结构看，所有数据都被逻辑的存放在一个空间中，称为表空间（tablespace）。表空间（tablespace）是存储引擎中最高的存储逻辑单位。表空间又由段（segment），区（extent),页（page)组成。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboar111d.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;表空间&#34;&gt;表空间&lt;/h4&gt;
&lt;p&gt;如果启动了innodb_file_per_table的参数，需要注意的是每张表的表空间内存放的只是数据、索引和插入缓冲Bitmap页，而其他数据如回滚（undo）信息，插入缓冲索引页，系统事务信息，二次写缓冲（double write buffer）还是放在共享表空间内，共享表空间还是会不断地增加大小。&lt;/p&gt;
&lt;p&gt;共享表空间和独立表空间的区别&lt;/p&gt;
&lt;h5 id=&#34;共享表空间&#34;&gt;共享表空间&lt;/h5&gt;
&lt;p&gt;&lt;strong&gt;优点&lt;/strong&gt;：可以将表空间分成多个文件存放到各个磁盘上（表空间文件大小不受表大小的限制，如一个表可以分布在不同的文件上）。&lt;/p&gt;
&lt;p&gt;缺点： 所有的数据和索引存放到一个文件中，虽然可以把一个大文件分成多个小文件，但是多个表及索引在表空间中混合存储，这样对于一个表做了大量删除操作后表空间中将会有大量的空隙；共享表空间分配后不能回缩，&lt;strong&gt;当出现临时建索引&lt;/strong&gt;或是&lt;strong&gt;创建一个临时表&lt;/strong&gt;的操作表空间扩大后，就是删除相关的表也没办法回缩那部分空间了（可以理解为oracle的表空间10G，但是才使用10M，但是操作系统显示mysql的表空间为10G），进行数据库的冷备很慢；&lt;/p&gt;
&lt;h5 id=&#34;独立表空间&#34;&gt;独立表空间&lt;/h5&gt;
&lt;p&gt;优点：&lt;/p&gt;
&lt;p&gt;1.每个表都有自已独立的表空间。&lt;/p&gt;
&lt;p&gt;2.每个表的数据和索引都会存在自已的表空间中。&lt;/p&gt;
&lt;p&gt;3.可以实现单表在不同的数据库中移动。&lt;/p&gt;
&lt;p&gt;4.空间可以回收（除drop table操作外，表空不能自已回收）&lt;/p&gt;
&lt;p&gt;缺点： 单表增加过大，当单表占用空间过大时，存储空间不足，只能从操作系统层面思考解决方法；&lt;/p&gt;
&lt;p&gt;推荐使用独立表空间的原因：共享表空间在Insert操作上少有优势。其它都没独立表空间表现好。&lt;/p&gt;
&lt;h4 id=&#34;段&#34;&gt;&lt;strong&gt;段&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;InnoDB存储引擎表是索引组织的（indexed organized），因此数据即索引，索引即数据。那么数据段即为B+树的叶子节点（leaf node  segment)，索引段即为B+树的非叶子节点（Non-leaf node segment)&lt;/p&gt;
&lt;h4 id=&#34;区&#34;&gt;&lt;strong&gt;区&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;区是由连续页组成的空间，在任何情况下每个区的大小都为1MB。为了保证区中页的连续性，InnoDB存储引擎一次从磁盘中申请4~5个区， 默认每个页的大小为16KB。这连续的数据页是在逻辑上是连续的，有可能在物理磁盘上是分散。一旦区间分配给某个对象（表、索引及簇）， 则该区间就不能再分配给其它的对象.&lt;/p&gt;
&lt;h4 id=&#34;页&#34;&gt;&lt;strong&gt;页&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;同一个数据库实例的所有表空间都有相同的页大小；默认情况下，表空间中的页大小都为 16KB，当然也可以通过改变 innodb_page_size  选项对默认大小进行修改，需要注意的是不同的页大小最终也会导致区大小的不同。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/cliphjhjhboard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;innodb数据页结构&#34;&gt;&lt;strong&gt;InnoDB数据页结构&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;页是 InnoDB 存储引擎管理数据的最小磁盘单位，而 B-Tree 节点就是实际存放表中数据的页面；fileheader、pageHeader、 fileTrailer的大小是固定的，分别是38,56,8字节。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboard123.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboard2413.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;内部的 &lt;strong&gt;Page Header/Page Directory 关心的是页的状态信息，而 Fil Header/Fil Trailer 关心的是记录页的头信息&lt;/strong&gt;。在File header中 ，FIL+PAGE_PREV,FIL_PAGE_NEXT两个表示当前页的上一页和下一页，由此可以看出&lt;strong&gt;叶子节点是双向链表串起来的&lt;/strong&gt;。&lt;/p&gt;
&lt;h3 id=&#34;infimum-supremum&#34;&gt;Infimum + Supremum&lt;/h3&gt;
&lt;p&gt;在InnoDB中，每个数据页中有两个虚拟的行记录，&lt;strong&gt;用来限定记录的边界&lt;/strong&gt;。Infimum记录的是比该页数据中 任何主键值都小的值，Supremum指比任何可能大的值还要大的值。这两个值在页创建时被建立，并且在任何情 况下不会被删除。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipweweboard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;user-records-和-free-space-user-records&#34;&gt;User Records 和 Free Space User Records&lt;/h3&gt;
&lt;p&gt;整个页面中真正用于存放行记录的部分，而 Free Space 就是空余空间了，它是一个&lt;strong&gt;链表的数据结构&lt;/strong&gt;，为了保证插入和删除的效率，整个页面并&lt;strong&gt;不会按照主键顺序对所有记录进行排序&lt;/strong&gt;，它会自动&lt;strong&gt;从左侧向右寻找空白节点进行插入&lt;/strong&gt;，&lt;strong&gt;行记录在物理存储上并不是按照顺序的 ，它们之间的顺序是由 next_record 这一指针控制的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;B+ 树在查找对应的记录时，并不会直接从树中找出对应的行记录，&lt;strong&gt;它只能获取记录所在的页&lt;/strong&gt;，将整个页加载到内存中，再通过 Page Directory 中存储的稀疏索引和 n_owned、next_record 属性进行二叉查找取出对应的记录，不过因为这一操作是在内存中进行的，所以通常会忽略这部分查找的耗时。&lt;/p&gt;
&lt;p&gt;完全空闲的页是没有 User Records部分的； 插入数据时，从Free Space分配空间给User Records，直到Free Space没有空间或空间不够分配新的记录，这时需要申请新的页&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipbohhkshfard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;page-directory&#34;&gt;Page Directory&lt;/h3&gt;
&lt;p&gt;存放了&lt;strong&gt;记录的相对位置&lt;/strong&gt;（页相对位置，不是偏移量），这些记录指针称为（slots)或目录槽（Directory Slots) 。&lt;strong&gt;InnoDB并不是每个记录拥有一个槽，InnoDB的槽是一个稀疏目录&lt;/strong&gt;（sparse directory),即一个槽中可能包含多个记录。&lt;/p&gt;
&lt;p&gt;在Slots中&lt;strong&gt;记录按照索引键值从小到大顺序存放的一个数组&lt;/strong&gt;，这样可以利用二叉查找迅速找到记录的指针。然而二叉查找的结果只是一个粗略结果 ，因此InnoDB引擎必须通过recorderheader中的next_recored来继续查找相关记录。&lt;/p&gt;
&lt;p&gt;从上图可以看出Page Directory包含至少两个infimum slot,supermum slot，slot指向record(rec)指针(pointer to ‘A’), n_owned代表的是向前有多少个rec属于这个slot，中间被管辖的rec的n_owned = 0。 通过directory的二分查找只能查到对应记录所属的slot，还需要通过slot内部的二分查找才能精确定位到对应的记录。&lt;strong&gt;这种设计的做法可以减小directory对page空间的占用，又能有很好查找的效率。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;innodb行记录结构&#34;&gt;&lt;strong&gt;InnoDB行记录结构&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;与现有的大多数存储引擎一样，InnoDB 使用页作为磁盘管理的最小单位；数据在 InnoDB 存储引擎中都是按行存储的，每个 16KB 大小的页中可以存放 2-200 行的记录。&lt;/p&gt;
&lt;p&gt;当 InnoDB 存储数据时，它可以使用不同的行格式进行存储；MySQL 5.7 版本支持以下格式的行存储方式：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;a href=&#34;https://raw.githubusercontent.com/Draveness/Analyze/master/contents/Database/images/mysql/Antelope-Barracuda-Row-Format.jpg&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/Antelope-Barracuda-Row-Format.jpg&#34; alt=&#34;Antelope-Barracuda-Row-Format&#34; loading=&#34;lazy&#34;&gt;&lt;/a&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;Antelope 是 InnoDB 最开始支持的文件格式，它包含两种行格式 Compact 和 Redundant，它最开始并没有名字；Antelope 的名字是在新的文件格式 Barracuda 出现后才起的，Barracuda 的出现引入了两种新的行格式 Compressed 和 Dynamic；InnoDB 对于文件格式都会向前兼容，而官方文档中也对之后会出现的新文件格式预先定义好了名字：Cheetah、Dragon、Elk 等等。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;两种行记录格式 Compact 和 Redundant 在磁盘上按照以下方式存储：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipbouduiodard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;Compact 和 Redundant 格式最大的不同就是记录格式的第一个部分；&lt;strong&gt;在 Compact 中，行记录的第一部分倒序存放了一行数据中列的长度 （Length），而 Redundant 中存的是每一列的偏移量（Offset）&lt;/strong&gt;，从总体上上看，Compact 行记录格式相比 Redundant 格式能够减少20% 的存储空间。&lt;/p&gt;
&lt;h4 id=&#34;1-变长字段长度列表&#34;&gt;1、变长字段长度列表&lt;/h4&gt;
&lt;p&gt;Compact行记录格式的首部是一个非NULL变长字段长度列表，并且是按照列的顺序的逆序放置的，其长度为： 若列的长度小于255字节，用1字节表示； 若列的长度大于255字节，用2字节表示。变长字段的长度最大不可以超过2字节，因为Varchar类型的最大长度限制为65535.&lt;/p&gt;
&lt;h4 id=&#34;2-null标志位&#34;&gt;2、NULL标志位&lt;/h4&gt;
&lt;p&gt;用一个字节来表示，指示了该行数据中是否有NULL值，有则用1表示，同样是逆序放置。&lt;/p&gt;
&lt;h4 id=&#34;3-记录头信息&#34;&gt;3、记录头信息&lt;/h4&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/cliphhjhboard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipbojhjhard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h5 id=&#34;delete_mask&#34;&gt;delete_mask&lt;/h5&gt;
&lt;p&gt;被删除的记录值为1, 正常记录为0。delete 语句后的记录不会被立刻删除,而是将这条记录的delete_mask置1, 称为delete mask操作，与真正的直接删除要区分开（update不更新主键且不能就地更新时直接删除，也就是改完delete_mask后直接加入到垃圾链表中）&lt;/p&gt;
&lt;h5 id=&#34;n_owned&#34;&gt;n_owned&lt;/h5&gt;
&lt;p&gt;在页面内为了快速搜索（二分查找）会分组，只有&lt;strong&gt;组内最大记录此字段有值&lt;/strong&gt;，记录组内记录数，除了最小记录,大小一般在4-8区间&lt;/p&gt;
&lt;h5 id=&#34;heap_no&#34;&gt;heap_no&lt;/h5&gt;
&lt;p&gt;记录在页面内其实会组成一个单链表，从头到尾，此属性依次增加. 最小记录为0，最大记录为1，真正记录的这个值从2开始&lt;/p&gt;
&lt;h5 id=&#34;record_type&#34;&gt;record_type&lt;/h5&gt;
&lt;p&gt;0就是我们的一般意义上的记录，1是索引用到的，2是最小记录、3 是最大记录&lt;/p&gt;
&lt;h5 id=&#34;next_record&#34;&gt;next_record&lt;/h5&gt;
&lt;p&gt;本记录的真正数据到下一条记录的真正数据的偏移量（可以当做存了个指针，向后是额外信息，向前是具体的列） 根据这个属性，页面内所有记录都串了一个单链表，&lt;strong&gt;单链表按主键排序&lt;/strong&gt;，从小到大，最小记录与最大记录分别为头结点和尾节点&lt;/p&gt;
&lt;h4 id=&#34;4-正式数据部分&#34;&gt;4、正式数据部分&lt;/h4&gt;
&lt;p&gt;a、表中没有指定主键且没有Unique列, MySQL会为我们添加一个row_id 作为主键,唯一标识一条记录&lt;/p&gt;
&lt;p&gt;b、trx_id 表示最近修改该行数据的事务ID&lt;/p&gt;
&lt;p&gt;c、roll_pointer 则表示指向该行回滚段的指针，该行上所有旧的版本，在undo中都通过链表的形式组织，而该值，正式指向undo中该行的历史记录链表&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;null不占该部分任何空间，即NULL除了占有NULL标志位，实际存储不占有任何空间。&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&#34;5-行溢出数据&#34;&gt;5、行溢出数据&lt;/h4&gt;
&lt;p&gt;当 InnoDB 使用 Compact 或者 Redundant 格式存储极长的 VARCHAR 或者 BLOB 这类大对象时，我们并不会直接将所有的内容都存放在数据 页节点中，而是将行数据中的前 768 个字节存储在数据页中，后面会通过偏移量指向溢出页。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboard-1582816818483.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;但是当我们使用新的行记录格式 Compressed 或者 Dynamic 时都只会在行记录中保存 20 个字节的指针，实际的数据都会存放在溢出页面中。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipdfdboard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h1 id=&#34;约束&#34;&gt;&lt;strong&gt;约束&lt;/strong&gt;&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;约束可以保证数据库中数据的完整性：
1、实体完整性保证表中有一个主键
2、域完整性保证每列的值满足特定的条件
3、参照完整性保证两张表之间的关系。

主键约束的默认名为PRIMARY，Unique Key默认约束名和列名一样，也可以人为指定名字。
select constraint_name,consraint_type from infomation_schema.table_constraints where table_schema=&#39;&#39; and table_name=&#39;&#39;;
alter table tbl_name add unique key keyname(col);

索引和约束的区别
约束是一个逻辑的概念，用来保证数据的完整性，而索引是一个数据结构，即有逻辑上的概念，在数据库中还代表着物理存储的方式。

某些情况下MySQL允许非法的或不正确的数据插入或更新，这就需要设置sql_mode来严格审核输入的参数
set sql_mode=&#39;STRICT_TRANS_TABLES&#39;;

ENUM约束
create table a(sex ENUM(&#39;male&#39;,&#39;female&#39;));ENUM约束只对离散值有效。

触发器的作用是在执行INSERT,DELETE,UPDATE命令之前或之后自动调用SQL命令或存储过程。通过触发器也是实现约束的一种手段和方法。
具备super权限的用户才能创建触发器
CREATE [difiner={user|CURRENT_USER}] TRIGGER trigger_name BEFORE|AFTER INSERT|UPDATE|DELERE ON tbl_name FOR 
EACH ROW trigger_stmt;
最多可以为一个表建立6个触发器，分别为INSERT,UPDATA和DELETE的BEFORE和AFTER各定义一个。Mysql只支持FOR EACH ROW.
mysql&amp;gt;DELIMITER $$
mysql&amp;gt;CREATE TRIGGER tgr_usercash_update BEFORE UPDATE ON usercash FOR EACH ROW 
-----&amp;gt;BEGIN
-----&amp;gt;IF new.cash - old.cash &amp;gt; 0 THEN
-----&amp;gt;INSERT INTO ........
-----&amp;gt;END IF
-----&amp;gt;END;
-----&amp;gt;$$
mysql&amp;gt;DELIMITER $$

外键约束

外键用来保证参照完整性，MySQL的MyISAM本身不支持外键，对于外键的定义只是起到一个注释的作用，而InnoDB则完整支持外键约束。
[CONSTRAINT [symbol]] FOREIGN KEY [index_name] (index_col_name,...) REFERENCES tbl_name （index_col_name,....)
[ON DELETE reference_option]
[ON UPDATE reference_option]
reference_option:
RESTRICT|//父表发生delete或update时,抛出错误，不允许此类操作发生。未设置时，此项为默认
CASCADE|//父表发生delete或update时，相应的字表中的数据页进行delete或update操作
SET NULL|//父表发生delete或update时,相应子表中的数据被更新为NULL值，但是子表中的相对应的列必须允许为NULL
NO ACTION//父表发生delete或update时,抛出错误，不允许此类操作发生。
一般来说被引用的表为父表，引用的表称为字表。ON DELETE和ON UPDATE 表示在对父表进行DELETE和UPDATE操作时，对子表做的操作。
create table child(id INT, parent_id INT,FOREGIN KEY(parent_id) REFERENCES parent(id))ENGINE=InnoDB;
InnoDB在建立外键时会自动对该列加一个索引，从而很好地避免外键列上无索引而导致的死锁问题。
对于参照完整性约束，外键能起到一个非常好的作用，但是对于数据的导入操作，外键往往导致在外键约束的检查上花费大量的时间，因为MySQL的外键时即时检查的，所以对导入的每一行都会进行外键检查。但是用户可以忽略外键的检查
set foreign_key_checks=0;
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;临时表&#34;&gt;临时表&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;临时表只在&lt;strong&gt;当前连接可见&lt;/strong&gt;，当关闭连接时，Mysql会自动删除表并释放所有空间,也可以在当前连接未关闭时，手动删除临时表。&lt;/li&gt;
&lt;li&gt;不同连接可以各自创建名字一样的临时表，不会相互冲突，这点不同于 Memory的引擎表&lt;/li&gt;
&lt;li&gt;你应该测试临时表看看它们是否真的比对大量数据库运行查询快。如果数据很好地索引,临时表可能一点不快。&lt;/li&gt;
&lt;li&gt;临时表默认的存储引擎是Innodb，数据存储在磁盘里面，且不会使用索引，即使该列在原表中有索引也不会使用&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;使用场景：临时表主要用于对大数据量的表上作一个子集，提高查询效率。普通临时表，从大表中捞取部分的数据，可以在一个连接内重复使用，提速&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-csharp&#34;&gt;CREATE TEMPORARY TABLE user_tem as select * from user where id&amp;lt;200;
DROP TEMPORARY TABLE IF EXISTS temp_tb;
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;视图&#34;&gt;&lt;strong&gt;视图&lt;/strong&gt;&lt;/h1&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;视图是一个命名的虚表，他由一个SQL查询来定义，可以当做表使用，视图中的数据没有实际的物理存储。

视图主要被用作一个抽象装置，程序不关心表的结构，只需要按照视图定义来取数据或更新数据。
CREATE [OR REPALCE] [ALGORITHM={UNDEFINED|MERGE|TEMPTABLE}] [DEFINER={user|CURRENT_USER}] [SQL SECURITY {DEFINER |
INVOKER}]
VIEW view_name [(colum_list)]
AS select_statement
[with[CASCADED|LOCAL] CHECK OPTION]
用户可以对某些视图进行更新操作，其本质是通过视图的定义来更新基本表。一般称可以更新的视图为可更新视图（updatable view)。视图定义中的with check option就是针对可更新视图的，即更新的值是否需要检查。

物化视图
ORACLE物化视图不是基于表的虚表，而是根据基表实际存在的实表，即物化视图的数据存储在非易失的存储设备上。物化视图可以用于预先计算并保存多表的耗时较多的SQL操作结果，从而快速得到结果。
BUILD IMMEDIATE是默认的创建方式，在创建物化视图的时候就生成数据，而BUILD DEFERRED则在创建物化视图时不生成数据，以后根据需要再生成数据。
查询重写是指当对物化视图的基表进行查询时，数据库会自动判断能否通过查询物化视图来直接得到结果。
物化视图的刷新是指当基表发生了DML操作后，物化视图何时采用哪种方式进行同步：
ON DEMAND意味着在用户需要时进行，ON COMMITE 意味着对基表的DML操作提交的同时进行刷新。
刷新的办法：
FAST//采用增量刷新，值刷新上次刷新以后进行的修改
COMPLETE//对整个物化视图进行完全的刷新
FORCE//数据库在刷新时会去判断是否可以进行FAST刷新，如果可以就采用FAST,不行就采用COMPLETE
NEVER//不刷新

MySQL本身不支持物化视图，即MySQL中的视图总是虚拟的。但可以通过一定的方式来实现。
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;分区&#34;&gt;&lt;strong&gt;分区&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;不是所有引擎都支持分区。分区的过程是将一个表或索引分解为多个更小、更可管理的部分。&lt;/p&gt;
&lt;p&gt;就访问数据库而言，从逻辑上将，只有一个表或一个索引，但是在物理上这个表或索引可能由数十个物理分区组成，每个分区都是独立的对象，可以独自处理，也可以作为一个更大对象的一部分进行处理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MYSQL只支持水平分区（将同一个表中不同行的记录分配到不同的物理文件中），不支持垂直分区（将同一表中不同列的记录分配到不同的物理文件中）。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MySQL的分区是&lt;strong&gt;局部分区索引&lt;/strong&gt;，一个分区中既存放了&lt;strong&gt;数据又存放了索引&lt;/strong&gt;。而全分区是指，数据存放在各个分区中，但所有数据的索引放在一个对象中。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;show variables like &#39;%partition%&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;分区可能会给某些SQL语句性能带来提高，但分区主要用于数据库高可用性的管理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;RANGE分区&lt;/strong&gt;：行数据基于属于一个给定连续区间的列值被放入分区,主要用于日期列的分区；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;LIST分区&lt;/strong&gt;：和RANGE分区类似，只是LIST分区面向的是离散的值；不同于RANGE用的是value less than ,list用的是 values in;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;HASH分区&lt;/strong&gt;：使用MySQL数据库提供的哈希函数来进行分区。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;KEY分区&lt;/strong&gt;：根据用户自定义的表达式的返回值来进行分区，返回值不能为负数；&lt;/p&gt;
&lt;p&gt;如果表中存在主键或唯一索引时，&lt;strong&gt;分区列表key是唯一索引的一个组成部分&lt;/strong&gt;。唯一索引可以是允许NULL值的，并且分区列只要是唯一索引的一个组成部分，不需要整个唯一索引列都是分区列。如果没有指定主键或唯一索引，则可以指定任何一个列为分区列。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;create table t(
    id INT
)ENGINE=INNODB
PARTITION BY RANGE(id){
    partition p0 values less than (10),
    partition p1 values less than(20);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;启用分区之后，表不再是由一个ibd文件组成了，而是由建立时的各个分区ibd文件组成。&lt;br&gt;
当插入一个不在分区中定义的值时，会抛出错误，所以可以定义一个MAXVALUE值的分区&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;partition p2 values less than maxvalue

mysql&amp;gt;EXPLAIN PARTITION select * from ....
通过EXPLAIN PARTITION，SQL优化器只需要搜索对应的分区，故查询速度得到了大幅度提升。优化器只能对YEAR(),TO_DAYS(),TO_SECONDS(),UNIX_TIMESTAMP()进行优化。

create table t_hash(
    a Int,
    b DATATIME
)ENGINE=INNODB
PARTITION BY HASH(YEAR(b))
PARTITONS 4;//表示分几个区，默认为1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;COLUMNS&lt;/strong&gt;分区&lt;br&gt;
RANGE\LIST\HASH\KEY分区的条件是数据必须是整型，否则需要转化。而columns分区可以直接使用非整型的数据进行分区。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;create table xx(
    b DATETIME
)ENGINE=INNODB
PARTITION BY RANG COLUMNS(b)(
    partition0 .....
)

alter table xx remove partition//删除分区
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;子分区&lt;/strong&gt;&lt;br&gt;
在分区的基础上再分区。MySQL允许在RANGE和LIST分区上再进行HASH或KEY的子分区。&lt;br&gt;
每个子分区的数量必须相同；要在一个分区表的任何分区上使用SUBPARTITION来明确定义任何子分区，就必须定义所有的子分区。每个SUBPARTITION子句必须包括子分区的一个名字。子分区的名字必须是唯一的。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;create table xx(
    a INT,
    b DATE
)ENGINE=innodb
partition by RANGE(YEAR(b))
SUBPARTITION BY HASH(TO_DAYS(b)) PARTITIONS 2
(
    PARTITION p0 values less than (1990),
    PARTITION p1 values less than （2000），
    PARTITION p2 values less than maxvalue
);此时有3*2=6个分区
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;分区中的NULL值&lt;/strong&gt;&lt;br&gt;
MySQL允许对null分区，将其视为小于任何的一个非null值。如果是RANGE分区，则会将该值放在最左边的分区，也就是最小的分区。如果是LIST的分区，就必须显示的指定在哪个分区中放入NULL值，否则会报错。&lt;br&gt;
HASH和KEY分区则是将null值的记录返回为0.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分区和性能&lt;/strong&gt;&lt;br&gt;
数据库的应用分为OLTP(在线事物处理)和OLAP(在线分析处理)。&lt;br&gt;
对于OLAP,分区确实可以很好地提高查询的性能，因为OLAP应用大多需要频繁地扫描一张大表，因此只需要扫描对应的分区即可。&lt;br&gt;
而OLTP通常不会获取一张大表中10%的数据，大部分都是通过索引返回几条记录，而B+树索引对一张大表只需要2~3次的IO，因此可以很好的完成操作，不需要分区。但是如果查询条件中使用非索引的其他key，那么对于其他key来说则会进行所有分区的扫描，这时的IO次数就变成了了2*分区数，不仅不会更快，反而变慢了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在表和分区之间交换数据&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ALTER TABLE tbl_name EXCHANGE PARTITION px WITH TABLE tbl_name2.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;该语句允许分区或子分区中的数据与另一个非分区的表中的数据进行交换。如果非分区表中的数据为空，那么相当于将分区中的数据移动到非分区表中，如果分区表中的数据为空，则相当于将外部表中的数据导入到分区中&lt;br&gt;
1、要交换的表需和分区表有着相同的表结构，但是表不能含有分区；&lt;br&gt;
2、在非分区表中的数据必须在交换的分区定义内&lt;br&gt;
3、被交换的表中不能含有外键，或者其他的表含有对该表的外键引用&lt;br&gt;
4、用户除了需要ALTER,INSERT和CREATE权限外，好需要DROP的权限，使用该语句时，不会触发交换表和被交换表上的触发器AUTO_INCREMENT列将被重置&lt;/p&gt;
&lt;p&gt;该语句允许分区或子分区中的数据与另一个非分区的表中的数据进行交换。如果非分区表中的数据为空，那么相当于将分区中的数据移动到非分区表中，如果分区表中的数据为空，则相当于将外部表中的数据导入到分区中&lt;br&gt;
1、要交换的表需和分区表有着相同的表结构，但是表不能含有分区；&lt;br&gt;
2、在非分区表中的数据必须在交换的分区定义内&lt;br&gt;
3、被交换的表中不能含有外键，或者其他的表含有对该表的外键引用&lt;br&gt;
4、用户除了需要ALTER,INSERT和CREATE权限外，好需要DROP的权限，使用该语句时，不会触发交换表和被交换表上的触发器&lt;/p&gt;
&lt;p&gt;AUTO_INCREMENT列将被重置&lt;/p&gt;
">2、表</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/tanscation/"" data-c="
          &lt;h1 id=&#34;1-认识事务&#34;&gt;&lt;strong&gt;1、认识事务&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;事务其实就是并发控制的基本单位;&lt;/p&gt;
&lt;p&gt;事务可由一条非常简单的SQL语句组成，也可以由一组复杂得SQL组成。事务是访问并更新数据库中各种数据项的一个程序执行单元。在事务中的 操作，要么都做修改，要么都不做，这就是事务的目的。&lt;/p&gt;
&lt;h2 id=&#34;原子性atomicity&#34;&gt;原子性（atomicity)&lt;/h2&gt;
&lt;p&gt;指整个数据库事务是不可分割的工作单位。只有使事务中所有的数据库操作都执行成功才算整个事务成功。任何一个SQL 执行失败，已经执行成功的SQL也必须撤销，数据库状态应该退回到执行事务前的状态。&lt;/p&gt;
&lt;h2 id=&#34;一致性consistency&#34;&gt;一致性（consistency）&lt;/h2&gt;
&lt;p&gt;数据库总是从一个一致性状态转换到另一个一致状态。就是一组SQL执行之前，数据必须是准确的，执行之后，数据也必须是准确的。&lt;/p&gt;
&lt;h2 id=&#34;隔离性isolation&#34;&gt;隔离性（isolation）&lt;/h2&gt;
&lt;p&gt;这个就是说多个事务在跑的时候不能互相干扰，别事务A操作个数据，弄到一半儿还没弄好呢，结果事务B来改了这个数据，导致事务A的操作出错了，那不就搞笑了。&lt;/p&gt;
&lt;h2 id=&#34;持久性durability&#34;&gt;持久性（durability）&lt;/h2&gt;
&lt;p&gt;事务一旦提交，其结果就是永久的，无法再回滚。&lt;/p&gt;
&lt;h1 id=&#34;2-事务的分类&#34;&gt;2、事务的分类&lt;/h1&gt;
&lt;h2 id=&#34;扁平事务&#34;&gt;扁平事务&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/1293895-622edf781c29f57f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1104/format/webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;所有操作都处于同一层次，其由BEGIN WORK开始，由COMMIT WORK或ROLLBACK WORK结束，期间的操作都是原子的。扁平事务是应用程序成为原子操作的基本组成模块。 扁平事务的主要限制是不能提交或回滚事务的某一部分，或者分几个步骤提交。&lt;/p&gt;
&lt;h2 id=&#34;带保存点的扁平事务&#34;&gt;带保存点的扁平事务&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/1293895-5028ad0258fa5359.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1018/format/webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;某些事务可能在执行过程中出现的错误并&lt;strong&gt;不会导致所有的操作都无效，放弃整个事务不合乎要求&lt;/strong&gt;，开销也太大。保存点（&lt;code&gt;savepoint&lt;/code&gt;）用来通知 系统记录当前的处理状态。当出现问题时，保存点能用作内部的重启动点，根据应用逻辑，决定是回到最近一个保存点还是其他更早的保存点。&lt;/p&gt;
&lt;p&gt;对扁平事务来说，其隐式地设置了一个保存点。然而在整个事务中，只有这一个保存点，回滚只能回滚到事务开始时的状态。保存点用 SAVE WORK函数来建立，通知系统记录当前的处理状态。&lt;/p&gt;
&lt;p&gt;保存点在事务内部是递增的，ROLLBACK不影响保存点的计数。&lt;/p&gt;
&lt;h2 id=&#34;链事务&#34;&gt;链事务&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://upload-images.jianshu.io/upload_images/1293895-17257fc0fc5dd905.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1174/format/webp&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;保存点模式的一种变种。带保存点的扁平事务在系统发生崩溃时，所有的保存点都将消失，因为其保存点是易失的（volatile），而非持久的 （persistent)。这就意味着当进行恢复时，事务需要从开始处重新执行，而不能从最近的一个保存点继续执行。&lt;/p&gt;
&lt;p&gt;链事务的思想是：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。提交事务操作和开始下 一个事务操作将合并为一个原子操作。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中进行的一样。&lt;/p&gt;
&lt;p&gt;与带保存点的扁平事务不同的是，带保存点的事务能回滚到任意正确的保存点。而链事务的回滚&lt;strong&gt;仅限于当前事务&lt;/strong&gt;，即只能恢复到最近的一个保存 点。对于锁的处理也不相同，链事务在执行COMMIT后释放了当前事务所持有的锁，而带保存点的扁平事务不影响持有的锁。&lt;/p&gt;
&lt;h2 id=&#34;嵌套事务&#34;&gt;嵌套事务&lt;/h2&gt;
&lt;p&gt;由一个顶层事务控制着各个层次的事务。顶层事务之下嵌套的事务被称为子事务（&lt;code&gt;subtransaction&lt;/code&gt;）,其控制着每一个局部的变换。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipbomosdmard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;实际的工作是交由叶子节点来完成的，只有叶子节点的事务才能访问数据。而高层的事务仅负责逻辑控制，决定何时调用相关的子事务。即使一个 系统不支持嵌套事务，用户也可以通过保存点技术来模拟嵌套事务。&lt;/p&gt;
&lt;h2 id=&#34;分布式事务distributed-transaction&#34;&gt;分布式事务（Distributed Transaction)&lt;/h2&gt;
&lt;p&gt;是一个在分布式环境下运行的扁平事务，因此需要根据数据所在的位置访问网络中的不同节点。&lt;/p&gt;
&lt;h1 id=&#34;3-事务的隔离级别&#34;&gt;3、事务的隔离级别&lt;/h1&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://pic4.zhimg.com/v2-17425f8aaf39eb83a451f9c8a8133427_r.jpg&#34; alt=&#34;preview&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h2 id=&#34;读未提交&#34;&gt;读未提交&lt;/h2&gt;
&lt;p&gt;该级别引发的问题是——脏读(Dirty Read)：读取到了未提交的数据&lt;/p&gt;
&lt;p&gt;脏页指的是在&lt;strong&gt;缓冲池&lt;/strong&gt;中已被修改的页，但是还没有刷新到磁盘，即数据库实例内存中的页和磁盘中的页的数据不一致，当然在刷新到磁盘之前，日志都已被写入到了重做日志文件中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;脏页&lt;/strong&gt;并不影响数据的一致性，并且脏页刷新都是异步的，不影响数据库的可用性，因此可以带来性能的提高；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;脏数据&lt;/strong&gt;是指事务对缓冲池中的&lt;strong&gt;记录的修改，并且还没有被提交&lt;/strong&gt;，也就是当前事务可以读到另外事务未提交的数据。&lt;/p&gt;
&lt;h2 id=&#34;读已提交&#34;&gt;&lt;strong&gt;读已提交&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;这种隔离级别出现的问题是——不可重复读(&lt;code&gt;Nonrepeatable Read&lt;/code&gt;)：不可重复读意味着我们在&lt;strong&gt;同一个事务中&lt;/strong&gt;执行完全相同的select语句时可能看到不一样的结果。&lt;/p&gt;
&lt;p&gt;就是说事务A在跑的时候， 先查询了一个数据是值1，然后过了段时间，事务B把那个数据给修改了一下还提交了，此时事务A再次查询这个数据就成了值2了，这是读了人家事务提交的数据啊，所以是读已提交。就是所谓的&lt;strong&gt;一个事务内对一个数据两次读&lt;/strong&gt;，可能会读到不一样的值。如图：&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_png/1J6IbIcPCLbraGeVNtE1GticOiaJia71SicHHVrXQKSDaibdc7cR89IxYQEUPBWzPRiatNB2Ry9Pos1ouhPervMzDVoA/640?wx_fmt=png&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;可重复读&#34;&gt;&lt;strong&gt;可重复读&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。就是说事务A在执行过程中，对某个数据的值，无论读多少次都是值1；哪怕这个过程中事务B修改了数据的值还提交了，但是事务A读到的还是自己事务开始时这个数据的值。如图：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://mmbiz.qpic.cn/mmbiz_png/1J6IbIcPCLbraGeVNtE1GticOiaJia71SicHXIULuYfxYLaulKtU5YK1GCvBD7aSibnqPibYz1ggVYQ2qTtNWPfYmSibA/640?wx_fmt=png&amp;amp;tp=webp&amp;amp;wxfrom=5&amp;amp;wx_lazy=1&amp;amp;wx_co=1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;此级别可能出现的问题——幻读(Phantom Read)：当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;幻读&lt;/strong&gt;：不可重复读和可重复读都是针对两个事务&lt;strong&gt;同时对某条数据在修改&lt;/strong&gt;，但是&lt;strong&gt;幻读针对的是插入&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;存储引擎通过多版本并发控制(MVCC，&lt;code&gt;Multiversion&lt;/code&gt;Concurrency Control)机制解决幻读问题；&lt;code&gt;InnoDB&lt;/code&gt;还通过&lt;strong&gt;间隙锁&lt;/strong&gt;解决幻读问题。&lt;/p&gt;
&lt;h3 id=&#34;多版本并发控制&#34;&gt;**多版本并发控制 **&lt;/h3&gt;
&lt;p&gt;MVCC的实现是通过&lt;strong&gt;保存数据在某一个时间点快照来实现的&lt;/strong&gt;。也就是说不管实现时间多长，每个事物看到的数据都是一致的。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;MySQL&lt;/code&gt; 中 &lt;code&gt;InnoDB&lt;/code&gt; 引擎支持 &lt;code&gt;MVCC&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;应对高并发事务, &lt;code&gt;MVCC&lt;/code&gt; 比单纯的加行锁更有效, 开销更小&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MVCC&lt;/code&gt; 在读已提交&lt;code&gt;（Read Committed）&lt;/code&gt;和可重复读&lt;code&gt;（Repeatable Read）&lt;/code&gt;隔离级别下起作用
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;RC&lt;/code&gt;、&lt;code&gt;RR&lt;/code&gt; 两种隔离级别的事务在执行普通的读操作时，通过访问版本链的方法，使得事务间的读写操作得以并发执行，从而提升系统性能。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RC&lt;/code&gt;、&lt;code&gt;RR&lt;/code&gt; 这两个隔离级别的一个很大不同就是生成 &lt;code&gt;ReadView&lt;/code&gt; 的时间点不同，
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;RC&lt;/code&gt; 在&lt;strong&gt;每一次&lt;/strong&gt; &lt;code&gt;SELECT&lt;/code&gt; 语句前都会生成一个 &lt;code&gt;ReadView&lt;/code&gt;，事务期间会更新，因此在其他事务提交前后所得到的 &lt;code&gt;m_ids&lt;/code&gt; 列表&lt;strong&gt;可能发生变化&lt;/strong&gt;，使得先前不可见的版本后续又突然可见了。&lt;/li&gt;
&lt;li&gt;而 &lt;code&gt;RR&lt;/code&gt; 只在事务的&lt;strong&gt;第一个&lt;/strong&gt; &lt;code&gt;SELECT&lt;/code&gt; 语句时生成一个 &lt;code&gt;ReadView&lt;/code&gt;，事务操作期间&lt;strong&gt;不更新&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MVCC&lt;/code&gt; 既可以基于&lt;strong&gt;乐观锁&lt;/strong&gt;又可以基于&lt;strong&gt;悲观锁&lt;/strong&gt;来实现&lt;/li&gt;
&lt;/ol&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://pic3.zhimg.com/80/v2-e1844f5816a332018183559d1573d80e_hd.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;在InnoDB中，每一行都有2个隐藏列DATA_TRX_ID和DATA_ROLL_PTR(如果没有定义主键，则还有个隐藏主键列)：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;DATA_TRX_ID&lt;/code&gt;：记录最近更新这条行记录的&lt;code&gt;事务 ID&lt;/code&gt;，大小为 &lt;code&gt;6&lt;/code&gt; 个字节&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DATA_ROLL_PTR&lt;/code&gt;：表示指向该行回滚段&lt;code&gt;（rollback segment）&lt;/code&gt;的指针，大小为 &lt;code&gt;7&lt;/code&gt; 个字节，&lt;code&gt;InnoDB&lt;/code&gt; 便是通过这个指针找到之前版本的数据。该行记录上所有旧版本，在 &lt;code&gt;undo&lt;/code&gt; 中都通过链表的形式组织。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;如何组织-undo-log-链&#34;&gt;&lt;strong&gt;如何组织 Undo Log 链&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;在多个事务并行操作某行数据的情况下，不同事务对该行数据的 UPDATE 会产生&lt;strong&gt;多个版本&lt;/strong&gt;，然后通过回滚指针组织成一条 &lt;code&gt;Undo Log&lt;/code&gt; 链。&lt;/p&gt;
&lt;p&gt;事务 &lt;code&gt;A&lt;/code&gt; 对值 &lt;code&gt;x&lt;/code&gt; 进行更新之后，该行即产生一个新版本和旧版本。假设之前插入该行的事务 &lt;code&gt;ID&lt;/code&gt; 为 &lt;code&gt;100&lt;/code&gt;，事务 &lt;code&gt;A&lt;/code&gt; 的 &lt;code&gt;ID&lt;/code&gt; 为 &lt;code&gt;200&lt;/code&gt;，该行的隐藏主键为 &lt;code&gt;1&lt;/code&gt;。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://pic4.zhimg.com/80/v2-759e2202ee64b45fb4bc8cdea640c813_hd.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;事务 &lt;code&gt;A&lt;/code&gt; 的操作过程为：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对 &lt;code&gt;DB_ROW_ID = 1&lt;/code&gt; 的这行记录加排他锁&lt;/li&gt;
&lt;li&gt;把该行原本的值拷贝到 &lt;code&gt;undo log&lt;/code&gt; 中，&lt;code&gt;DB_TRX_ID&lt;/code&gt; 和 &lt;code&gt;DB_ROLL_PTR&lt;/code&gt; 都不动&lt;/li&gt;
&lt;li&gt;修改该行的值这时产生一个新版本，更新 &lt;code&gt;DATA_TRX_ID&lt;/code&gt; 为修改记录的事务 &lt;code&gt;ID&lt;/code&gt;，将 &lt;code&gt;DATA_ROLL_PTR&lt;/code&gt; 指向刚刚拷贝到 &lt;code&gt;undo log&lt;/code&gt; 链中的旧版本记录，这样就能通过 &lt;code&gt;DB_ROLL_PTR&lt;/code&gt; 找到这条记录的历史版本。如果对同一行记录执行连续的 &lt;code&gt;UPDATE&lt;/code&gt;，&lt;code&gt;Undo Log&lt;/code&gt; 会组成一个链表，遍历这个链表可以看到这条记录的变迁&lt;/li&gt;
&lt;li&gt;记录 &lt;code&gt;redo log&lt;/code&gt;，包括 &lt;code&gt;undo log&lt;/code&gt; 中的修改&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;那么 &lt;code&gt;INSERT&lt;/code&gt; 和 &lt;code&gt;DELETE&lt;/code&gt; 会怎么做呢？其实相比 &lt;code&gt;UPDATE&lt;/code&gt; 这二者很简单，&lt;code&gt;INSERT&lt;/code&gt; 会产生一条新纪录，它的 &lt;code&gt;DATA_TRX_ID&lt;/code&gt; 为当前插入记录的事务 &lt;code&gt;ID&lt;/code&gt;；&lt;code&gt;DELETE&lt;/code&gt; 某条记录时可看成是一种特殊的 &lt;code&gt;UPDATE&lt;/code&gt;，其实是软删，真正执行删除操作会在 &lt;code&gt;commit&lt;/code&gt; 时，&lt;code&gt;DATA_TRX_ID&lt;/code&gt; 则记录下删除该记录的事务 &lt;code&gt;ID&lt;/code&gt;。&lt;/p&gt;
&lt;h4 id=&#34;readview&#34;&gt;ReadView&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;ReadView&lt;/code&gt; 中是&lt;strong&gt;当前活跃的事务&lt;/strong&gt; &lt;code&gt;ID&lt;/code&gt; 列表，称之为 &lt;code&gt;m_ids&lt;/code&gt;，其中最小值为 &lt;code&gt;up_limit_id&lt;/code&gt;，最大值为 &lt;code&gt;low_limit_id&lt;/code&gt;，事务 &lt;code&gt;ID&lt;/code&gt; 是事务开启时 &lt;code&gt;InnoDB&lt;/code&gt; 分配的，其大小决定了事务开启的先后顺序，因此我们可以通过 &lt;code&gt;ID&lt;/code&gt; 的大小关系来决定版本记录的可见性。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如果被访问版本的 &lt;code&gt;trx_id&lt;/code&gt; 小于 &lt;code&gt;m_ids&lt;/code&gt; 中的最小值 &lt;code&gt;up_limit_id&lt;/code&gt;，说明生成该版本的事务在 &lt;code&gt;ReadView&lt;/code&gt; 生成前就已经提交了，所以该版本可以被当前事务访问。&lt;/li&gt;
&lt;li&gt;如果被访问版本的 &lt;code&gt;trx_id&lt;/code&gt; 大于 &lt;code&gt;m_ids&lt;/code&gt; 列表中的最大值 &lt;code&gt;low_limit_id&lt;/code&gt;，说明生成该版本的事务在生成 &lt;code&gt;ReadView&lt;/code&gt; 后才生成，所以该版本不可以被当前事务访问。需要根据 &lt;code&gt;Undo Log&lt;/code&gt; 链找到前一个版本，然后根据该版本的 DB_TRX_ID 重新判断可见性。&lt;/li&gt;
&lt;li&gt;如果被访问版本的 &lt;code&gt;trx_id&lt;/code&gt; 属性值在 &lt;code&gt;m_ids&lt;/code&gt; 列表中最大值和最小值之间（包含），那就需要判断一下 &lt;code&gt;trx_id&lt;/code&gt; 的值是不是在 &lt;code&gt;m_ids&lt;/code&gt; 列表中。如果在，说明创建 &lt;code&gt;ReadView&lt;/code&gt; 时生成该版本所属事务还是活跃的，因此该版本不可以被访问，需要查找 Undo Log 链得到上一个版本，然后根据该版本的 &lt;code&gt;DB_TRX_ID&lt;/code&gt; 再从头计算一次可见性；如果不在，说明创建 &lt;code&gt;ReadView&lt;/code&gt; 时生成该版本的事务已经被提交，该版本可以被访问。&lt;/li&gt;
&lt;li&gt;此时经过一系列判断我们已经得到了这条记录相对 &lt;code&gt;ReadView&lt;/code&gt; 来说的可见结果。此时，如果这条记录的 &lt;code&gt;delete_flag&lt;/code&gt; 为 &lt;code&gt;true&lt;/code&gt;，说明这条记录已被删除，不返回。否则说明此记录可以安全返回给客户端。&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;​	https://zhuanlan.zhihu.com/p/64576887&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;串行化&#34;&gt;串行化&lt;/h2&gt;
&lt;p&gt;它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之,它是在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争&lt;/p&gt;
&lt;h1 id=&#34;4-事务的实现&#34;&gt;4、事务的实现&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;redo_log 实现持久化和原子性，而undo_log实现一致性&lt;/strong&gt;，二种日志均可以视为一种恢复操作，redo_log是恢复&lt;strong&gt;提交事务修改的页操作&lt;/strong&gt;，而undo_log是&lt;strong&gt;回滚行记录到特定版本&lt;/strong&gt;。二者记录的内容也不同，redo_log是物理日志，记录页的&lt;strong&gt;物理修改操作&lt;/strong&gt;，而undo_log是逻辑日志，根据每行记录进行记录。&lt;/p&gt;
&lt;h2 id=&#34;redo-log&#34;&gt;&lt;strong&gt;redo log&lt;/strong&gt;&lt;/h2&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://user-gold-cdn.xitu.io/2019/4/21/16a3e7576b55c19f?imageView2/0/w/1280/h/960/format/webp/ignore-error/1&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;redo日志用来实现事务的持久性，在事务提交后数据没来得及写会磁盘就宕机时，在下次重新启动后能够成功恢复数据（持久性）， 由两部分组成：&lt;/p&gt;
&lt;p&gt;一是内存中的重做日志缓冲（redo &lt;code&gt;logbuffer&lt;/code&gt;）；&lt;/p&gt;
&lt;p&gt;二是重做日志文件（redo log file).&lt;/p&gt;
&lt;p&gt;当我们在一个事务中尝试对数据进行修改时，它会先将数据从磁盘读入内存，并更新内存中缓存的数据，然后生成一条重做日志并写入重做日志缓存，当事务真正提交时，MySQL 会将重做日志缓存中的内容刷新到重做日志文件，再将内存中的数据更新到磁盘上，图中的第 4、5 步就是在 事务提交时执行的。&lt;/p&gt;
&lt;p&gt;为了确保每次日志都写入重做日志文件，在每次将重做日志缓冲写入重做日志文件后，&lt;code&gt;InnoDB&lt;/code&gt;都需要调用一次&lt;code&gt;fsync&lt;/code&gt;操作。&lt;code&gt;fsync&lt;/code&gt;的效率取决于 磁盘的性能，因此磁盘的性能决定了事务提交的性能，也就是数据的性能。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;InnoDb&lt;/code&gt;允许用户手工设置非持久性的情况发生，以此提高数据的性能。即当事务提交时，日志不写入重做日志文件，而是等一个时间周期后再执行&lt;code&gt;fsync&lt;/code&gt;，但是发生宕机时会丢失最后一段时间的事务。&lt;/p&gt;
&lt;h3 id=&#34;与二进制日志的区别&#34;&gt;与二进制日志的区别&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;重做日志是&lt;code&gt;InnoDB&lt;/code&gt;存储引擎层产生，而二进制日志是在MySQL数据库的上层产生，并且二进制日志不仅仅针对&lt;code&gt;InnoDB&lt;/code&gt;存储引擎，MySQL数据库中任何存储引擎对于数据库的编个都会产生二进制日志&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;两种日志记录的内容形式不一样，MySQL数据库上层的二进制日志是一种&lt;strong&gt;逻辑日志&lt;/strong&gt;，其记录的是对应的&lt;strong&gt;SQL语句&lt;/strong&gt;，而&lt;code&gt;InnoDB&lt;/code&gt;存储引擎层面的重做日志是&lt;strong&gt;物理格式日志&lt;/strong&gt;，其记录的是&lt;strong&gt;每个页的修改&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;两种日志记录写入磁盘的时间点不同，如图，二进制日志只在&lt;strong&gt;事务提交完成后&lt;/strong&gt;进行一次写入，而&lt;code&gt;InnoDB&lt;/code&gt;存储引擎的&lt;strong&gt;重做日志在事务进行中不断地被写入&lt;/strong&gt;，这表现为日志并不是随事务提交的顺序进行写入的&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://images2015.cnblogs.com/blog/754297/201602/754297-20160205112427569-810454883.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;二进制日志近在事务提交时记录，并且对每一个事务，仅包含&lt;strong&gt;对应事务的一个日志&lt;/strong&gt;，而对于&lt;code&gt;InnoDB&lt;/code&gt;存储引擎的重做日志，由于其记录的是&lt;strong&gt;物理操作日志&lt;/strong&gt;，因此每个&lt;strong&gt;事务对应多个日志条目&lt;/strong&gt;，并且事务的重做日志是并发的，并非在事务提交时写入，故其在文件中的记录顺序并非是事务的开始顺序。*T1 * T2 *T3表示事务提交时的日志&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;log-block&#34;&gt;log block&lt;/h3&gt;
&lt;p&gt;在 &lt;code&gt;InnoDB&lt;/code&gt;中，重做日志都是以 512 字节的块的形式进行存储的，同时因为块的大小与磁盘扇区大小相同，所以重做日志的写入可以保证原子性，不会由于机器断电导致重做日志仅写入一半并留下脏数据。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboardfsfacd.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;日志块由三部分组成：日志块头（log &lt;code&gt;block&lt;/code&gt;header),日志内容（log body),日志块尾（log block &lt;code&gt;tailer&lt;/code&gt;)。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipfsmfskboard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;log buffer是由log block组成，在内部log buffer好似一个数据。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;log header:
LOG_BLOCK_HDR_NO用来标记这个数组中的位置，其是递增并循环使用的，占用4个字节，但是由于第一给我用来判断是否是flush bit，所以最大值是2G
LOG_BLOCK_HDR_DATA_LEN表示log block所占用的大小。
LOG_BLOCK_FIRST_REC_GROUP表示log block中第一个日志所在的偏移量。
LOG_BLOCK_CHECKPOINT_NO表示该log  block最后被写入时的检查点第4字节的值。

log tailer:
LOG_BLOCK_TRL_NO:与LOG_BLOCK_HDR_NO的值相同。
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;log-group&#34;&gt;log group&lt;/h3&gt;
&lt;p&gt;log group是一个&lt;strong&gt;逻辑上的概念&lt;/strong&gt;，并没有一个实际存储的物理文件来表示log group信息。&lt;/p&gt;
&lt;p&gt;InnoDB存储引擎的数据目录下有两个名为ib_logfile0和ib_logfile1的文件，即是重做日志文件（redo log file)，记录了对于InnoDB 存储引擎的事物日志。在日志组中每个重做日志文件的大小一致，并以循环写入的方式运行。先写日志1，再写日志2，然后再写日志1.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;innoDB_log_file_size//每个重做日志的大小 
innoDB_log_file_in_group//每个组中重做日志的数量 
innoDB_mirrored_log_groups//日志镜像文件组的数量，默认为1，表示没有镜像 innodb_log_group_home_dir//日志文件组的路径 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;一方面重做日志不能设置得太大，否则恢复时需要很长的时间；&lt;/p&gt;
&lt;p&gt;另一方面也不能太小，否则会导致一个事物的日志需要多次切换重做日志文件。 也会频繁地发生async checkpoint，导致性能抖动。&lt;/p&gt;
&lt;p&gt;重做日志文件中存储的就是之前在log buffer中保存的log block，也是根据块的方式进行物理存储的管理。，每个块的大小与log block一样，同样为512字节，在&lt;code&gt;InnoDB&lt;/code&gt;存储引擎运行过程中，&lt;code&gt;logbuffer&lt;/code&gt;根据一定的规则将内存 中的log block 刷新到磁盘：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;事务提交时；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;log buffer中有一半的内存被使用时&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;log checkpoint时&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对log block的写入追加在redo log file的最后部分，当一个redo log file被写满时，会写入下一个redo log file，是使用方式是 round-robin.&lt;/p&gt;
&lt;p&gt;对redo log file的写入并不是顺序的，因为redo log file除了保存log buffer刷新到磁盘的log block，还保存了一些其他的信息，这些信息一共占用2KB大小，即每个redo log file的前2KB的部分不保存log block信息，对于log group中的&lt;strong&gt;第一个redo log file&lt;/strong&gt;,其前2KB的部分保存4个512字节大小的块&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://images2015.cnblogs.com/blog/754297/201602/754297-20160205174138835-1834182063.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;其余的redo log file &lt;strong&gt;仅保留这些空间，不保存上述信息&lt;/strong&gt;。后续的写入还要&lt;strong&gt;更新这2k的信息&lt;/strong&gt;，这些信息对于&lt;code&gt;InnoDB&lt;/code&gt;的恢复操作非常关键，所以对redo log file的写入 并不是完全顺序。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://images2015.cnblogs.com/blog/754297/201602/754297-20160205175120913-1624661049.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;log filer header后面的部分为&lt;code&gt;InnoDB&lt;/code&gt;保存的checkpoint值，其设计是交替写入，这样是为了避免因介质失败而导致无法找到可用的 checkpoint的情况。&lt;/p&gt;
&lt;h3 id=&#34;重做日志格式&#34;&gt;重做日志格式&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;的存储管理是基于页的，故其重做日志格式也是基于页的。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;15&#34;&gt;&lt;img src=&#34;https://images2015.cnblogs.com/blog/754297/201602/754297-20160205175450335-1884721475.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;redo_log_type:重做日志的类型；&lt;/p&gt;
&lt;p&gt;space:表空间的ID&lt;/p&gt;
&lt;p&gt;page_no:页的偏移量&lt;/p&gt;
&lt;p&gt;之后就是redo log body的部分，根据重做日志类型的不对，会有不同的存储内容，例如，对于页上记录的插入和删除操作，分别对应的如图的格式&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;16&#34;&gt;&lt;img src=&#34;https://images2015.cnblogs.com/blog/754297/201602/754297-20160205175732710-743525968.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;lsn&#34;&gt;LSN&lt;/h3&gt;
&lt;p&gt;LSN是Log Sequence Number的缩写，代表的是日志序列号,表示事务写入重做日志字节的总量。占用8字节，单调递增。例如当前重做日志的LSN为1000，有一个事务T1写入了100字节的重做日志，那么LSN久变成1100，若又有事务T2写入200字节的重做日志，那么LSN久变为1300&lt;/p&gt;
&lt;p&gt;表示的含义有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;重做日志写入的总量&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;checkpoint的位置&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;页的版本&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;**LSN不仅记录在重做日志中，还存在每个页中，在每个页的头部，**有一个值FIL_PAGE_LSN，记录了该页的LSN，在页中，LSN表示该页最后刷新时LSN的大小。因为重做日志记录的是每个页的日志，因此页中的LSN可以判断页是否需要进行恢复操作。例如，页P1的LSN诶10000，而数据库启动时，&lt;code&gt;InnoDB&lt;/code&gt;检测到写入重做日志中的LSN为13000，并且事务已经提交，那么数据库需要进行恢复操作。将重做日志应用到P1页中，同样的，对于重做日志中LSN小于P1页的LSN，不需要进行重做，因为P1页中的LSN标示已经被刷新到该位置&lt;/p&gt;
&lt;h3 id=&#34;恢复&#34;&gt;恢复&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;存储引擎在启动时&lt;strong&gt;不管上次数据运行是否正常关闭，都会尝试进行恢复操作&lt;/strong&gt;，因为重做日志记录的是&lt;strong&gt;物理日志&lt;/strong&gt;，因此恢复的速度比逻辑日志，如二进制日志要快的多，于此同时，&lt;code&gt;InnoDB&lt;/code&gt;存储引擎自身也对恢复进行了一定程度的优化，如顺序读取及并行应用重做日志，这样可以进一步提高数据库恢复的速度&lt;/p&gt;
&lt;p&gt;由于checkpoint表示已经刷新到磁盘页上的LSN，因此在恢复过程中仅需恢复checkpoint开始的日志部分。对于图中的例子，当数据库在checkpoint的LSN为10 000时发生宕机，恢复操作仅恢复LSN 10000~13000范围内的日志&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;17&#34;&gt;&lt;img src=&#34;https://images2015.cnblogs.com/blog/754297/201602/754297-20160206111237913-1571379281.jpg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;再来想想，redo log为什么可以实现事务的原子性和持久性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;原子性，是redo log记录了事务期间操作的物理日志，事务提交之前，并没有写入磁盘，保存在内存里，如果事务失败，数据库磁盘不会有影响，回滚掉事务内存部分即可&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;持久性，redo log 会在事务提交时将日志存储到磁盘redo log file，保证日志的持久性&lt;/strong&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;undo-log&#34;&gt;undo log&lt;/h2&gt;
&lt;p&gt;undo log有两个作用：&lt;strong&gt;提供回滚和多个行版本控制(MVCC)&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;1、想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行回滚，而在 MySQL 中，恢复机制是通过回滚日志（undo log）实现的 ，所有事务进行的修改都会先记录到这个回滚日志中，然后在对数据库中的对应行进行写入。&lt;/p&gt;
&lt;p&gt;2、undo log 存在于 undo log segments 中，undo log segments 位在于 rollback segments 中，rollback segment默认值为128个。每个回滚段中有1024个undo log segment。而 rollback segments 则可能存在于系统系统表空间(system tablespace)、临时表空间( temporary tablespace)、撤销表空间(undo tablespaces)中。 具体的分配策略如下：&lt;/p&gt;
&lt;p&gt;undo log默认存放在共享表空间中，如果开启了&lt;code&gt;innodb_file_per_table&lt;/code&gt;，将放在每个表的.&lt;code&gt;ibd&lt;/code&gt;文件中。&lt;/p&gt;
&lt;p&gt;3、回滚日志并不能将数据库物理地恢复到执行语句或者事务之前的样子；它是逻辑日志，当回滚日志被使用时，它只会按照日志逻辑地将数据库中的修改撤销掉，可以理解为，我们在事务中使用的每一条 INSERT 都对应了一条 DELETE，每一条 UPDATE 也都对应一条相反的 UPDATE  语句。&lt;/p&gt;
&lt;p&gt;4、undo的另一个作用是&lt;code&gt;mvcc&lt;/code&gt;。当用户读取一段记录时，若该行记录被其他事务所占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读取。&lt;/p&gt;
&lt;p&gt;5、&lt;strong&gt;undo也会产生redo log&lt;/strong&gt;，因为undo log也需要持久性的保护。&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;事务提交&#34;&gt;事务提交&lt;/h3&gt;
&lt;p&gt;当事务提交的时候，&lt;code&gt;innodb&lt;/code&gt;不会立即删除undo log，因为后续还可能会用到undo log，如隔离级别为repeatable read时，事务读取的都是开启事务时的最新提交行版本，只要该事务不结束，该行版本就不能删除，即undo log不能删除。&lt;/p&gt;
&lt;p&gt;但是在事务提交的时候，会将该事务对应的undo log放入到删除列表中，未来通过purge来删除。并且提交事务时，还会判断undo log分配的页是否可以重用，如果可以重用，则会分配给后面来的事务，避免为每个独立的事务分配独立的undo log页而浪费存储空间和性能。&lt;/p&gt;
&lt;p&gt;通过undo log记录delete和update操作的结果发现：(insert操作无需分析，就是插入行而已)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;delete操作实际上不会直接删除，而是将delete对象打上delete flag，标记为删除，最终的删除操作是purge线程完成的。&lt;/li&gt;
&lt;li&gt;update分为两种情况：update的列是否是主键列。
&lt;ul&gt;
&lt;li&gt;如果不是主键列，在undo log中直接反向记录是如何update的。即update是直接进行的。&lt;/li&gt;
&lt;li&gt;如果是主键列，update分两部执行：先删除该行，再插入一行目标行。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;清理&#34;&gt;清理&lt;/h3&gt;
&lt;p&gt;delete和update 操作可能并不会直接删除原有数据，delete 操作只是将聚集索引列的 delete flag 置为 1 ，记录仍然存在于 B+ 树中， 最终的删除在 purge 线程中完成（这样的设计是因为其它事务可能引用这行，所以不能立刻删除）。&lt;/p&gt;
&lt;h3 id=&#34;history-list&#34;&gt;history list&lt;/h3&gt;
&lt;p&gt;history list 根据事务提交的顺序将 undo log 进行链接，先提交的事务总是在 history list 的尾部，同一 undo page 中的 undo log  也总是按照顺序排列的。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;18&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipbomslfdslard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;具体清理过程为 &lt;code&gt;innoDB&lt;/code&gt; 会默认从 history list 中找到第一个需要被清理的数据tx1，清理成功之后清理线程会继续在 tx1 所在页中继续查找需要被清理的 __undo log (即 tx3，注意这里并不会从 history list 继续查找tx2)，之后继续向后查找，找到 tx5，此时发现  tx5 被其它事务引用不能清理(&lt;code&gt;trx&lt;/code&gt;no 比当前 purge 到的位置更大)，所以再次去 history list 中查找尾部记录，此时为tx2 重复以上步骤&lt;/p&gt;
&lt;h1 id=&#34;5-事务使用&#34;&gt;5、事务使用&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;START TRANSACTION | BEGIN [WORK] 
COMMIT [WORK] [AND [NO] CHAIN] [[NO] RELEASE] 
ROLLBACK [WORK] [AND [NO] CHAIN] [[NO] RELEASE] 
SET AUTOCOMMIT = {0 | 1}
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;START TRANSACTION 或 BEGIN 语句：开始一项新的事务。&lt;/li&gt;
&lt;li&gt;COMMIT 和 ROLLBACK：用来提交或者回滚事务。&lt;/li&gt;
&lt;li&gt;CHAIN 和 RELEASE 子句：分别用来定义在事务提交或者回滚之后的操作，CHAIN 会立即启动一个新事物，并且和刚才的事务具有相同的隔离级别，RELEASE 则会断开和客户端的连接。&lt;/li&gt;
&lt;li&gt;SET AUTOCOMMIT 可以修改当前连接的提交方式， 如果设置了 SET AUTOCOMMIT=0，则设置之后的所有事务都需要通过明确的命令进行提交或者回滚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;自动提交（&lt;code&gt;autocommit&lt;/code&gt;）：&lt;/strong&gt;&lt;br&gt;
&lt;code&gt;Mysql&lt;/code&gt;默认采用自动提交模式，可以通过设置&lt;code&gt;autocommit&lt;/code&gt;变量来启用或禁用自动提交模式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;隐式锁定&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;在事务执行过程中，使用两阶段锁协议：&lt;/p&gt;
&lt;p&gt;随时都可以执行锁定，&lt;code&gt;InnoDB&lt;/code&gt;会根据隔离级别在需要的时候自动加锁；&lt;/p&gt;
&lt;p&gt;锁只有在执行commit或者rollback的时候才会释放，并且所有的锁都是在&lt;strong&gt;同一时刻&lt;/strong&gt;被释放。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;显式锁定&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;也支持通过特定的语句进行显示锁定（存储引擎层）：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;select ... lock in share mode //共享锁 
select ... for update //排他锁 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;MySQL Server层的显示锁定：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-text&#34;&gt;lock table和unlock table
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;6-分布式事务&#34;&gt;6、分布式事务&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;InnoDB&lt;/code&gt;提供了对XA事务的支持，并通过XA事务来支持分布式事务的实现。分布式事务是允许多个独立的事务资源（transaction resources） 参与到一个全局的事务中。在使用分布式事务时，&lt;code&gt;InnoDb&lt;/code&gt;的事务隔离季节必须设置为SERIALIZABLE。&lt;/p&gt;
&lt;p&gt;XA事务允许不同数据库之间的分布式事务。XA事务有一个或多个资源管理、一个事务管理器以及一个应用程序组成。&lt;/p&gt;
&lt;p&gt;资源管理器：提供范围事务资源的方法。通常一个数据库就是一个资源管理器；&lt;/p&gt;
&lt;p&gt;事务管理器：协调参与全局事务中的各个事务。需要和参与全局事务的所有资源管理器通信。&lt;/p&gt;
&lt;p&gt;应用程序：定义事务的边界，指定全局事务中的操作。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;19&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipb223oard.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;分布式事务使用两段式提交（two-phase commit)。在第一阶段，所有参与全局事务的节点开始准备（prepare),告诉事务管理器他们准备好 提交了。在第二阶段，事务管理器告诉资源管理器执行ROLLBACK或COMMIT。如果任何一个节点显示不能提交，则所有节点都回滚。&lt;/p&gt;
">6、事务</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/tiaoyou/"" data-c="
          &lt;p&gt;除非单表数据未来会一直不断上涨，否则不要一开始就考虑拆分，拆分会带来逻辑、部署、运维的各种复杂度，一般以整型值为主的表在&lt;code&gt;千万级&lt;/code&gt;以下，字符串为主的表在&lt;code&gt;五百万&lt;/code&gt;以下是没有太大问题的。而事实上很多时候MySQL单表的性能依然有不少优化空间，甚至能正常支撑千万级以上的数据量：&lt;/p&gt;
&lt;h2 id=&#34;字段&#34;&gt;字段&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;尽量使用&lt;code&gt;TINYINT&lt;/code&gt;、&lt;code&gt;SMALLINT&lt;/code&gt;、&lt;code&gt;MEDIUM_INT&lt;/code&gt;作为整数类型而非&lt;code&gt;INT&lt;/code&gt;，如果非负则加上&lt;code&gt;UNSIGNED&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;VARCHAR&lt;/code&gt;的长度只分配真正需要的空间&lt;/li&gt;
&lt;li&gt;使用枚举或整数代替字符串类型&lt;/li&gt;
&lt;li&gt;尽量使用&lt;code&gt;TIMESTAMP&lt;/code&gt;而非&lt;code&gt;DATETIME&lt;/code&gt;，&lt;/li&gt;
&lt;li&gt;单表不要有太多字段，建议在20以内&lt;/li&gt;
&lt;li&gt;避免使用NULL字段，很难查询优化且占用额外索引空间&lt;/li&gt;
&lt;li&gt;用整型来存IP&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;索引&#34;&gt;索引&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;索引并不是越多越好，要根据查询有针对性的创建，考虑在&lt;code&gt;WHERE&lt;/code&gt;和&lt;code&gt;ORDER BY&lt;/code&gt;命令上涉及的列建立索引，可根据&lt;code&gt;EXPLAIN&lt;/code&gt;来查看是否用了索引还是全表扫描&lt;/li&gt;
&lt;li&gt;应尽量避免在&lt;code&gt;WHERE&lt;/code&gt;子句中对字段进行&lt;code&gt;NULL&lt;/code&gt;值判断，否则将导致引擎放弃使用索引而进行全表扫描&lt;/li&gt;
&lt;li&gt;值分布很稀少的字段不适合建索引，例如”性别”这种只有两三个值的字段&lt;/li&gt;
&lt;li&gt;字符字段只建前缀索引&lt;/li&gt;
&lt;li&gt;字符字段最好不要做主键&lt;/li&gt;
&lt;li&gt;不用外键，由程序保证约束&lt;/li&gt;
&lt;li&gt;尽量不用&lt;code&gt;UNIQUE&lt;/code&gt;，由程序保证约束&lt;/li&gt;
&lt;li&gt;使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;查询sql&#34;&gt;查询SQL&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;可通过开启&lt;strong&gt;慢查询日志&lt;/strong&gt;来找出较慢的SQL&lt;/li&gt;
&lt;li&gt;不做列运算：&lt;code&gt;SELECT id WHERE age + 1 = 10&lt;/code&gt;，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边&lt;/li&gt;
&lt;li&gt;sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库&lt;/li&gt;
&lt;li&gt;不用&lt;code&gt;SELECT *&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;OR&lt;/code&gt;改写成&lt;code&gt;IN&lt;/code&gt;：&lt;code&gt;OR&lt;/code&gt;的效率是n级别，&lt;code&gt;IN&lt;/code&gt;的效率是log(n)级别，in的个数建议控制在200以内&lt;/li&gt;
&lt;li&gt;不用函数和触发器，在应用程序实现&lt;/li&gt;
&lt;li&gt;避免&lt;code&gt;%xxx&lt;/code&gt;式查询&lt;/li&gt;
&lt;li&gt;少用&lt;code&gt;JOIN&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;使用同类型进行比较，比如用&lt;code&gt;&#39;123&#39;&lt;/code&gt;和&lt;code&gt;&#39;123&#39;&lt;/code&gt;比，&lt;code&gt;123&lt;/code&gt;和&lt;code&gt;123&lt;/code&gt;比&lt;/li&gt;
&lt;li&gt;尽量避免在&lt;code&gt;WHERE&lt;/code&gt;子句中使用!=或&amp;lt;&amp;gt;操作符，否则将引擎放弃使用索引而进行全表扫描&lt;/li&gt;
&lt;li&gt;对于连续数值，使用&lt;code&gt;BETWEEN&lt;/code&gt;不用&lt;code&gt;IN&lt;/code&gt;：&lt;code&gt;SELECT id FROM t WHERE num BETWEEN 1 AND 5&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;列表数据不要拿全表，要使用&lt;code&gt;LIMIT&lt;/code&gt;来分页，每页数量也不要太大&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;引擎&#34;&gt;引擎&lt;/h2&gt;
&lt;p&gt;目前广泛使用的是MyISAM和InnoDB两种引擎：&lt;/p&gt;
&lt;h3 id=&#34;myisam&#34;&gt;MyISAM&lt;/h3&gt;
&lt;p&gt;MyISAM引擎是MySQL 5.1及之前版本的默认引擎，它的特点是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不支持行锁，读取时对需要读到的所有表加锁，写入时则对表加排它锁&lt;/li&gt;
&lt;li&gt;不支持事务&lt;/li&gt;
&lt;li&gt;不支持外键&lt;/li&gt;
&lt;li&gt;不支持崩溃后的安全恢复&lt;/li&gt;
&lt;li&gt;在表有读取查询的同时，支持往表中插入新纪录&lt;/li&gt;
&lt;li&gt;支持&lt;code&gt;BLOB&lt;/code&gt;和&lt;code&gt;TEXT&lt;/code&gt;的前500个字符索引，支持全文索引&lt;/li&gt;
&lt;li&gt;支持延迟更新索引，极大提升写入性能&lt;/li&gt;
&lt;li&gt;对于不会进行修改的表，支持压缩表，极大减少磁盘空间占用&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;innodb&#34;&gt;InnoDB&lt;/h3&gt;
&lt;p&gt;InnoDB在MySQL 5.5后成为默认索引，它的特点是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持行锁，采用MVCC来支持高并发&lt;/li&gt;
&lt;li&gt;支持事务&lt;/li&gt;
&lt;li&gt;支持外键&lt;/li&gt;
&lt;li&gt;支持崩溃后的安全恢复&lt;/li&gt;
&lt;li&gt;不支持全文索引&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;总体来讲，MyISAM适合&lt;code&gt;SELECT&lt;/code&gt;密集型的表，而InnoDB适合&lt;code&gt;INSERT&lt;/code&gt;和&lt;code&gt;UPDATE&lt;/code&gt;密集型的表&lt;/p&gt;
&lt;h2 id=&#34;创建必要的索引&#34;&gt;创建必要的索引&lt;/h2&gt;
&lt;p&gt;在经常需要进行检索的字段上创建索引，比如要按照姓名进行检索，那么就应该在姓名字段上创建索引，如果经常要按照员工部门和员工岗位级别 进行检索，那么就应该在员工部门和员工岗位级别这两个字段上创建索引。创建索引给检索带来的性能提升往往是巨大的，因此在发现检索速度过 慢的时候应该首先想到的就是创建索引。&lt;/p&gt;
&lt;h2 id=&#34;使用预编译查询&#34;&gt;使用预编译查询&lt;/h2&gt;
&lt;p&gt;程序中通常是根据用户的输入来动态执行SQL，这时应该尽量使用参数化SQL,这样不仅可以避免SQL注入漏洞攻击，最重要数据库会对这些参数化 SQL进行预编译，这样第一次执行的时候DBMS会为这个SQL语句进行查询优化并且执行预编译，这样以后再执行这个SQL的时候就直接使用预编译的 结果，这样可以大大提高执行的速度。&lt;/p&gt;
&lt;h2 id=&#34;调整where字句中的连接顺序&#34;&gt;调整Where字句中的连接顺序&lt;/h2&gt;
&lt;p&gt;DBMS一般采用自下而上的顺序解析where字句，根据这个原理表连接最好写在其他where条件之前，那些可以过滤掉最大数量记录。&lt;/p&gt;
&lt;h2 id=&#34;index-condition-pushdownicp优化&#34;&gt;Index Condition Pushdown（ICP)优化&lt;/h2&gt;
&lt;p&gt;MySQL在取出&lt;strong&gt;索引的同时判断是否可以进行where条件的过滤&lt;/strong&gt;，也就是将where的部分过滤操作放在了存储引擎层，某些查询下可以减少上层SQL层对记录的索取，从而提高性能。当然where可以过滤的条件是要该索引可以覆盖到的范围。&lt;br&gt;
ICP支持range、ref、eq_ref、ref_or_null类型的查询，支持MyISAM和InnoDB，当优化器选择ICP时，可在执行计划的列Extra看到Using index condition提示。&lt;/p&gt;
&lt;h2 id=&#34;尽量将多条sql语句压缩到一句&#34;&gt;尽量将多条SQL语句压缩到一句&lt;/h2&gt;
&lt;p&gt;SQL中每次执行SQL的时候都要建立网络连接、进行权限校验、进行SQL语句的查询优化、发送执行结果，这个过程是非常耗时的，因此应该尽量 避免过多的执行SQL语句，能够压缩到一句SQL执行的语句就不要用多条来执行。&lt;/p&gt;
&lt;h2 id=&#34;用where字句替换having字句&#34;&gt;用where字句替换HAVING字句&lt;/h2&gt;
&lt;p&gt;避免使用HAVING字句，因为&lt;strong&gt;HAVING只会在检索出所有记录之后才对结果集进行过滤&lt;/strong&gt;，而&lt;strong&gt;where则是在聚合前刷选记录&lt;/strong&gt;，如果能通过where字句限制记录的数目，那就能减少这方面的开销。HAVING中的条件一般用于聚合函数的过滤，除此之外，应该将条件写在where字句中。&lt;/p&gt;
&lt;h2 id=&#34;使用表的别名&#34;&gt;使用表的别名&lt;/h2&gt;
&lt;p&gt;当在SQL语句中连接多个表时，请使用表的别名并把别名前缀于每个列名上。这样就可以减少解析的时间并减少哪些友列名歧义引起的语法错误。&lt;/p&gt;
&lt;h2 id=&#34;在in和exists中通常情况下使用exists因为in不走索引&#34;&gt;在in和exists中通常情况下使用EXISTS，因为in不走索引。&lt;/h2&gt;
&lt;h2 id=&#34;避免在索引上使用计算&#34;&gt;避免在索引上使用计算&lt;/h2&gt;
&lt;p&gt;在where字句中，如果索引列是计算或者函数的一部分，DBMS的优化器将不会使用索引而使用全表查询,函数属于计算的一种 效率低：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;select * from Employee where dsalary*12&amp;gt;2500.0(dsalary是索引列,索引不起作用) 效率高：

select * from Employee where dsalary&amp;gt;2500.0/12(dsalary是索引列) 
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;用union-all替换union&#34;&gt;用union all替换union&lt;/h2&gt;
&lt;p&gt;当SQL 语句需要UNION 两个查询结果集合时,这两个结果集合会以UNION-ALL 的方式被&lt;/p&gt;
&lt;p&gt;合并, 然后在输出最终结果前进行排序.&lt;strong&gt;如果用UNION ALL 替代UNION, 这样排序就不是必要了&lt;/strong&gt;. 效率就会因此得到提高.&lt;/p&gt;
&lt;h2 id=&#34;避免sql中出现隐式类型转换&#34;&gt;避免SQL中出现隐式类型转换&lt;/h2&gt;
&lt;p&gt;当某一张表中的索引字段在作为where条件的时候，如果&lt;strong&gt;进行了隐式类型转换，则此索引字段将会不被识别，因为隐式类型转换也属于计算&lt;/strong&gt;，所以 此时DBMS会使用全表扫面。&lt;/p&gt;
&lt;h2 id=&#34;防止检索范围过宽&#34;&gt;防止检索范围过宽&lt;/h2&gt;
&lt;p&gt;如果DBMS优化器认为检索范围过宽，那么将放弃索引查找而使用全表扫描。下面几种可能造成检索范围过宽的情况。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a、使用is not null或者不等于判断，可能造成优化器假设匹配的记录数太多。&lt;/li&gt;
&lt;li&gt;b、使用like运算符的时候，“a%”将会使用索引，而“a%c”和“%a”则会使用全表扫描，因此“a%c”和“%a”不能被有效的评估匹配的数量，&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;用小表驱动大表in和exist&#34;&gt;&lt;strong&gt;用小表驱动大表IN和EXIST&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;1、驱动表的定义&lt;/p&gt;
&lt;p&gt;当进行多表连接查询时， [驱动表] 的定义为：&lt;/p&gt;
&lt;p&gt;1）&lt;strong&gt;指定了联接条件时&lt;/strong&gt;，满足查询条件的记录行数少的表为[驱动表]&lt;/p&gt;
&lt;p&gt;2）未指定联接条件时，&lt;strong&gt;行数少的表为&lt;/strong&gt;[驱动表]（Important!）&lt;/p&gt;
&lt;p&gt;忠告：如果你搞不清楚该让谁做驱动表、谁 join 谁，请让 MySQL 运行时自行判断&lt;/p&gt;
&lt;p&gt;2、mysql关联查询的概念:&lt;/p&gt;
&lt;p&gt;MySQL 表关联的算法是 Nest Loop Join，&lt;strong&gt;是通过驱动表的结果集作为循环基础数据&lt;/strong&gt;，然后一条一条地通过该结果集中的数据作为过滤条件到 下一个表中查询数据，然后合并结果。&lt;/p&gt;
&lt;p&gt;优化的目标是尽可能减少JOIN中Nested Loop的循环次数。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/clipboa1313rd.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;pre&gt;&lt;code&gt;select * from tbl_name where EXIST (subquery);
可以理解为将主查询的数据，放到子查询中做条件验证，根据结果（TRUE或FALSE)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;orderby优化&#34;&gt;&lt;strong&gt;ORDERBY优化&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;在使用order by时，经常出现Using filesort，因此对于此类sql语句需尽力优化，使其尽量使用Using index。&lt;/p&gt;
&lt;p&gt;①MySQL支持两种方式的排序filesort和index，Using index是指MySQL扫描索引本身完成排序。index效率高，filesort效率低。&lt;/p&gt;
&lt;p&gt;②order by满足两种情况会使用Using index。&lt;/p&gt;
&lt;p&gt;1.&lt;strong&gt;order by语句使用索引最左前列&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;2.使用where子句与order by子句条件列组合满足索引最左前列。&lt;/p&gt;
&lt;p&gt;③尽量在索引列上完成排序，遵循索引建立（索引创建的顺序）时的最佳左前缀法则。&lt;/p&gt;
&lt;p&gt;④如果order by的条件不在索引列上，就会产生Using filesort。&lt;/p&gt;
&lt;p&gt;1.filesort有两种排序算法：双路排序和单路排序。&lt;/p&gt;
&lt;p&gt;​       双路排序：在MySQL4.1之前使用双路排序，就是两次磁盘扫描，得到最终数据。读取行指针和order by列，对他们进行排序，然后扫描已经排好序的列表，按照列表中的值重新从列表中读取对应的数据输出。即从磁盘读取排序字段，在buffer进行排序，再从磁盘取其他字段。&lt;br&gt;
​    如果使用双路排序，取一批数据要对磁盘进行两次扫描，众所周知，I/O操作是很耗时的，因此在MySQL4.1以后，出现了改进的算法：单路排序。&lt;br&gt;
​    单路排序：从磁盘中查询所需的列，按照order by列在buffer中对它们进行排序，然后扫描排序后的列表进行输出。它的效率更高一些，避免了第二次读取数据，并且把随机I/O变成了顺序I/O，但是会使用更多的空间，因为它把每一行都保存在内存中了。&lt;br&gt;
​&lt;/p&gt;
&lt;p&gt;2.单路排序出现的问题。&lt;/p&gt;
&lt;p&gt;​     当读取数据超过sort_buffer的容量时，就会导致多次读取数据，并创建临时表，最后多路合并，产生多次I/O，反而增加其I/O运算。&lt;br&gt;
​    解决方式：&lt;br&gt;
​    a.增加sort_buffer_size参数的设置。&lt;br&gt;
​    b.增大max_length_for_sort_data参数的设置。&lt;br&gt;
⑤提升order by速度的方式：&lt;/p&gt;
&lt;p&gt;1.在使用order by时，不要用select *，只查询所需的字段。&lt;/p&gt;
&lt;p&gt;​    因为当查询字段过多时，会导致sort_buffer不够，从而使用多路排序或进行多次I/O操作。&lt;/p&gt;
&lt;p&gt;2.尝试提高sort_buffer_size。&lt;/p&gt;
&lt;p&gt;3.尝试提高max_length_for_sort_data。&lt;/p&gt;
&lt;p&gt;⑦group by与order by很类似，其实质是先排序后分组，遵照索引创建顺序的最佳左前缀法则。当无法使用索引列的时候，也要对sort_buffer_size和max_length_for_sort_data参数进行调整。注意where高于having，能写在where中的限定条件就不要去having限定了。&lt;/p&gt;
&lt;h2 id=&#34;使用主键索引来优化数据分页&#34;&gt;使用主键索引来优化数据分页&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-mysql&#34;&gt;select * from user where id&amp;gt;(select id from user where id&amp;gt;=**100000** limit **1**) limit **20**;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;##使用explain&lt;/p&gt;
&lt;h4 id=&#34;有什么用&#34;&gt;有什么用？&lt;/h4&gt;
&lt;p&gt;在MySQL中，当数据量增长的特别大的时候就需要用到索引来优化SQL语句，而如何才能判断我们辛辛苦苦写出的SQL语句是否优良？这时候&lt;strong&gt;explain&lt;/strong&gt;就派上了用场。&lt;/p&gt;
&lt;h4 id=&#34;怎么使用&#34;&gt;怎么使用？&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;explain + SQL语句即可 如：explain select * from table;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;如下&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/640&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;相信第一次使用explain参数的朋友一定会疑惑这一大堆参数究竟有什么用呢？笔者搜集了一些资料，在这儿做一个总结希望能够帮助大家理解。&lt;/p&gt;
&lt;p&gt;explain（执行计划），使用explain关键字可以模拟优化器执行sql查询语句，从而知道MySQL是如何处理sql语句。 explain主要用于分析查询语句或表结构的性能瓶颈。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;id&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;id的值表示select子句或表的执行顺序，id相同，执行顺序从上到下，id不同，值越大的执行优先级越高。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;select_type&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;SIMPLE&lt;/p&gt;
&lt;p&gt;简单的select查询，查询中不包含子查询或union查询。&lt;/p&gt;
&lt;p&gt;PRIMARY&lt;/p&gt;
&lt;p&gt;查询中若包含任何复杂的子部分，最外层查询为PRIMARY，也就是最后加载的就是PRIMARY。&lt;/p&gt;
&lt;p&gt;SUBQUERY&lt;/p&gt;
&lt;p&gt;在select或where列表中包含了子查询，就为被标记为SUBQUERY。&lt;/p&gt;
&lt;p&gt;DERIVED&lt;/p&gt;
&lt;p&gt;在from列表中包含的子查询会被标记为DERIVED(衍生)，MySQL会递归执行这些子查询，将结果放在临时表中。    UNION&lt;/p&gt;
&lt;p&gt;若第二个select出现在union后，则被标记为UNION，若union包含在from子句的子查询中，外层select将被标记为DERIVED。&lt;/p&gt;
&lt;p&gt;UNION RESULT&lt;/p&gt;
&lt;p&gt;从union表获取结果的select。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;type&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;表示查询所使用的访问类型，该值表示查询的sql语句好坏，从最好到最差依次为：system&amp;gt;const&amp;gt;eq_ref&amp;gt;ref&amp;gt;range&amp;gt;index&amp;gt;ALL。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;1.system    表只有一行记录（等于系统表），是const的特例类型，平时不会出现，可以忽略不计。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;2.const    表示通过一次索引就找到了结果，常出现于primary key或unique索引。因为只匹配一行数据，所以查询非常快。    如将主键置于where条件中，MySQL就能将查询转换为一个常量。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;3.eq_ref：唯一索引扫描，对于每个索引键，表中只有一条记录与之匹配。常见主键或唯一索引扫描。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;4.ref：非唯一性索引扫描，返回匹配某个单独值的所有行。本质上也是一种索引访问，返回匹配某值（某条件）的多行值，属于查找和扫描的    混合体。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;5.range：只检索给定范围的行，使用一个索引来检索行，可以在key列中查看使用的索引，一般出现在where语句的条件中，如使用between、&amp;gt;、&amp;lt;、    in等查询。    这种索引的范围扫描比全索引扫描要好，因为索引的开始点和结束点都固定，范围相对较小。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;6.index：全索引扫描，index和ALL的区别：index只遍历索引树，通常比ALL快，因为索引文件通常比数据文件小。虽说index和ALL都是全表扫描，    但是index是从索引中读取，ALL是从磁盘中读取。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;7.ALL：全表扫描。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;哪些索引可以使用。（对应possible_keys）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;哪些索引被实际使用。（对应key）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;表直接的引用。（对应ref）显示关联的字段。如果使用常数等值查询，则显示const，如果是连接查询，则会显示关联的字段。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;每张表有多少行被优化器查询。（对应rows）根据表统计信息及索引选用情况大致估算出找到所需记录所要读取的行数。当然该值越小越好。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Extra&lt;/strong&gt;&lt;br&gt;
1.Using filesort&lt;/p&gt;
&lt;p&gt;Using filesort表明mysql会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。    mysql中无法利用索引完成的排序操作称为“文件排序”。    出现Using filesort就非常危险了，在数据量非常大的时候几乎“九死一生”。出现Using filesort尽快优化sql语句。&lt;br&gt;
2.Using temporary&lt;/p&gt;
&lt;p&gt;使用了临时表保存中间结果，常见于排序order by和分组查询group by。非常危险，“十死无生”，急需优化。&lt;/p&gt;
&lt;p&gt;3.Using index&lt;/p&gt;
&lt;p&gt;表明相应的select操作中使用了覆盖索引，避免访问表的额外数据行，效率不错。&lt;/p&gt;
&lt;p&gt;如果同时出现了Using where，表明索引被用来执行索引键值的查找。（where deptid=1）    如果没有同时出现Using where，表明索引用来读取数据而非执行查找动作。&lt;/p&gt;
&lt;h2 id=&#34;change-buffer&#34;&gt;&lt;strong&gt;change buffer&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就&lt;strong&gt;不需要从磁盘中读入这个数据页了&lt;/strong&gt;。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。&lt;strong&gt;虽然是只更新内存，但是在事务提交的时候，把 change buffer 的操作也记录到 redo log 里了，所以崩溃恢复的时候，change buffer 也能找回来。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了**访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。**在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。&lt;/p&gt;
&lt;p&gt;​    显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式能够避免占用内存，提高内存利用率。&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。&lt;/p&gt;
&lt;p&gt;如果要在这张表中插入一个新记录 (4,400) 的话，InnoDB 的处理流程是怎样的。&lt;/p&gt;
&lt;p&gt;第一种情况是，这个记录要&lt;strong&gt;更新的目标页在内存中&lt;/strong&gt;。这时，InnoDB 的处理流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;对于唯一索引来说，找到 3 和 5 之间的位置，&lt;strong&gt;判断到没有冲突&lt;/strong&gt;，插入这个值，语句执行结束；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;第二种情况是，这个记录要&lt;strong&gt;更新的目标页不在内存中&lt;/strong&gt;。这时，InnoDB 的处理流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;​    将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。&lt;/p&gt;
&lt;p&gt;​    &lt;strong&gt;change buffer 适用于写多读少的业务，比如账单类、日志类的系统。因为会记录很多change buffer（写的时候） 才会merge（读的时候）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​    反过来，读多写少的业务，几乎每次把更新记录在change buffer 后，就会&lt;strong&gt;立即出发merge&lt;/strong&gt;，这样随机访问 IO 的次数不会减少，反而增加了change buffer 的维护代价。&lt;/p&gt;
&lt;p&gt;所以，对于身份证号这类字段，如果业务已经保证不会写入重复数据，不需要数据库做约束，加普通索引比加主键索引要好，如果所有的更新后面，都马上伴随着对这个记录的查询，那么应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。&lt;/p&gt;
&lt;p&gt;在实际使用中，可以发现，&lt;strong&gt;普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的，特别是在使用机械硬盘时。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;change buffer 和 redo log 对比&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;insert into t(id,k) values(id1,k1),(id2,k2);&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这条更新语句做了如下操作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Page 在内存中，直接更新内存；&lt;/li&gt;
&lt;li&gt;Page 没有在内存中，就在内存的 change buffer 区域，记录下“要往 Page 插入一行”这个信。&lt;/li&gt;
&lt;li&gt;将上述两个动作记入 redo log 中。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;后续的更新操作&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Page 在内存中，会直接从内存返回。&lt;/li&gt;
&lt;li&gt;Page 不在内容中，需要把 Page 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;所以，如果要简单地对比这两个机制在提升更新性能上的收益的话，&lt;strong&gt;redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;优化器如何选择索引&#34;&gt;&lt;strong&gt;优化器如何选择索引&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;优化器结合&lt;strong&gt;是否扫描行数、是否使用临时表、是否排序&lt;/strong&gt;等因素进行综合判断。&lt;/p&gt;
&lt;p&gt;MySQL 在真正开始执行语句之前，并不能精确地知道满足条件的记录有多少条，而只能根据统计信息来估算记录数。&lt;/p&gt;
&lt;p&gt;这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;可以使用 show index 方法，看到一个索引的基数。&lt;/strong&gt;&lt;br&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/bVbxvfx&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;p&gt;MySQL 采样统计的方法获得基数，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。当变更的数据行数超过 1/M 的时候，会自动触发重新做一次索引统计。&lt;strong&gt;analyze table t 命令，可以用来重新统计索引信息。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。&lt;/li&gt;
&lt;li&gt;设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其实索引统计只是一个输入，对于一个具体的语句来说，优化器还要判断，执行这个语句本身要扫描多少行。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/bVbxvfy&#34; alt=&#34;clipboard.png&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;rows 这个字段表示的是预计扫描行数。&lt;/p&gt;
&lt;h2 id=&#34;二次写double-write&#34;&gt;二次写(double write)&lt;/h2&gt;
&lt;p&gt;doublewrite组成： 内存中的doublewrite buffer,大小2M。 物理磁盘上&lt;strong&gt;共享表空间&lt;/strong&gt;中连续的128个页，即2个区（extend），大小同样为2M。&lt;/p&gt;
&lt;p&gt;Doublewrite缓存是位于&lt;strong&gt;系统表空间的存储区域&lt;/strong&gt;，对缓冲池的脏页进行刷新时，不是直接写磁盘，而是会通过memcpy()函数将脏页先&lt;strong&gt;复制到内存中的doublewrite buffer&lt;/strong&gt;，因为doublewrite页是连续的，因此这个过程是顺序写的，开销并不是很大。&lt;/p&gt;
&lt;p&gt;在完成doublewrite页的写入后，再将doublewrite buffer 中的页再分两次，每次1M顺序地写入各个表空间文件中，此时的写入则是离散的。&lt;/p&gt;
&lt;p&gt;如果操作系统在将页写入磁盘的过程中发生了崩溃，在恢复过程中，innodb可以 从系统表空间中的doublewrite中找到该页的一个副本，将其复制到表空间文件，再应用重做日志。&lt;/p&gt;
">9、Mysql调优</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/weifuwujiagouyuanli/"" data-c="
          &lt;p&gt;&lt;strong&gt;1、从传统单体架构到服务化架构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.1 JEE架构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;JEE将企业级软件架构分为三个层级 ： Web 层、业务逻辑层和数据存取层。对应的职能团队，主要包括：用户 交互 UI 团队、后台业务逻辑处理团&lt;/p&gt;
&lt;p&gt;队、 数据存取 ORM 团队与 DBA 团队等。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/9b6398a0011.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;1.2 SSH架构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MVC模型：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/c1a8e40f00d.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;SSH架构层次：实现交互 UI 接口的 Web MVC 层、实现业务逻辑的 Spring 层及实现对象关系映射的 Hibernate层。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/102cef46a9c.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;每个层级的实现比JEE对应的层次更简单、更轻量级 ，不需要开启整个应用服务器即可测试和验证，极大提高了开发效率，这得益于 Spring 框架的控制翻转理念。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.3 服务化架构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;从 JEE 时代到 SSH 时代，服务的特点仍然是单体化，业务逻辑仍然糯合在一个项目中。传统 JEE 和 SSH 无法满足对海量用户发起的高井发请求进行处理的需求，无法突破稿合在一起的模块化组件的性能瓶颈，单一进程己经无法满足需求，并且水平扩展的能力也是很有限的。于是SOA 出现了， &lt;strong&gt;SOA&lt;/strong&gt; 代表&lt;strong&gt;面向服务的架构&lt;/strong&gt;，俗称服务化。&lt;/p&gt;
&lt;p&gt;SOA特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;良好的对外接口，通过网络协议对外提供服务。服务之间松耦合。&lt;/li&gt;
&lt;li&gt;单个服务发生改变，不影响整个流程。只要接口不变，对外是透明的。&lt;/li&gt;
&lt;li&gt;通信格式XML，后来被JSON取代。&lt;/li&gt;
&lt;li&gt;服务的可重用性。&lt;/li&gt;
&lt;li&gt;SOA可以最大化使用内部和外部的公共服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SOA 的两个主流实现方式： &lt;strong&gt;Web Service 和 ESB&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;Web Service技术使每个服务之间是对等的，并且互相是解耦的，通过 WSDL 定义的服务发现接口进行访问 ，并通过 SOAP 协议进行通信 。 &lt;strong&gt;SOAP 协议&lt;/strong&gt;通常是一种在 HTTP 或者 HTTPS通道上传输 X岛伍数据来实现的协议，但是每个服务都要依赖中心化 Web Service 目录来发现现存的服务。&lt;/p&gt;
&lt;p&gt;ESB 的核心在于企业服务总线的功能和职责。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;监控和控制服务之间的消息路由。&lt;/li&gt;
&lt;li&gt;控制可插拔的服务化。&lt;/li&gt;
&lt;li&gt;解析服务之间通信的内容和格式。&lt;/li&gt;
&lt;li&gt;统一编排信息处理流程。&lt;/li&gt;
&lt;li&gt;冗余备份。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2、从服务化到微服务&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.1 微服务架构的产生&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Web Service 的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;依赖中心化的服务发现机制。&lt;/li&gt;
&lt;li&gt;SOAP使用XML冗余大。&lt;/li&gt;
&lt;li&gt;服务化管理和治理设施不完善。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ESB 的问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ESB 虽然是 SOA 实现的一种方式，却更多地体现了系统集成的便利性，通过统一的服务总线将服务组合在一起，并提供组合的业务流程服务。&lt;/li&gt;
&lt;li&gt;组合在 ESB 上的服务本身可能是一个过重的整体服务，或者是传统的 JEE 服务等。&lt;/li&gt;
&lt;li&gt;ESB 视图通过总线来隐藏系统内部的复杂性，但是系统内部的复杂性仍然存在。&lt;/li&gt;
&lt;li&gt;对于总线本身的中心化的管理模型，系统变更影响的范围经常会随之扩大。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;微服务架构&lt;/strong&gt;倡导将软件应用设计成多个&lt;strong&gt;可独立开发、可配置、可运行和可维护的子服务&lt;/strong&gt;，子服务之间通过良好的接口定义通信机制，通常使用 &lt;strong&gt;RESTful 风格的 API 形式来通信&lt;/strong&gt; ，因为RESTful 风格的 API 通常是在 HTTP 或者 HTTPS 通道上传输 JSON 格式的数据来实现的， HTTP协议有跨语言、跨异构系统的优点，当然，也可以通过底层的二进制协议、消息队列协议等进行交互。这些服务不需要中心化的统一管理，每个服务的功能可自治，并且可以由不同的语言、系统和平台实现 。&lt;/p&gt;
&lt;p&gt;微服务架构并不是为了拆分而拆分，真正的目的是通过对微服务进行&lt;strong&gt;水平扩展&lt;/strong&gt;解决传统的单体应用在业务急剧增长时遇到的问题，而且由于拆分的微服务系统中专业的人做专业的事，人员和项目的&lt;strong&gt;职责单一、低藕合、高内聚&lt;/strong&gt;，所以产生问题的概率就会降到最小。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.2 微服务架构与传统单体架构的对比&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;微服务的架构：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/20443cbe60c.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;微服务把每一个职责单一的功能放在一个独立的服务中 。&lt;/li&gt;
&lt;li&gt;每个服务运行在一个单独的进程中。&lt;/li&gt;
&lt;li&gt;每个服务有多个实例运行。运行在容器化的平台，可以平滑伸缩。&lt;/li&gt;
&lt;li&gt;每个服务有自己的数据存储。独立的数据，缓存，消息队列等。&lt;/li&gt;
&lt;li&gt;每个服务有独立的运营平台。每个服务高度自治，内部变化对外透明。&lt;/li&gt;
&lt;li&gt;每个服务可以根据性能独立地水平伸缩。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;传统单体架构的伸缩架构：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/fa843cb38f0.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;传统单体架构将所有模块化组件混合后运行在同一个服务JVM进程中 。&lt;/li&gt;
&lt;li&gt;可对包含多个模块化组件的整体JVM进程进行水平扩展，而无法对某个模块化组件进行水平扩展。&lt;/li&gt;
&lt;li&gt;某个模块化组件发生变化时，需要所有的模块化组件进行编译、打包和上线。&lt;/li&gt;
&lt;li&gt;模块间的依赖将会不清晰，互相糯合、互相依赖。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.3 微服务架构与 SOA 服务化的对比&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;微服务架构与 SOA 服务化虽然一脉相承，却略有不同。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目的不同。SOA强调异构服务之间协作和集成。微服务目的是拆分，实现敏捷开发部署。&lt;/li&gt;
&lt;li&gt;部署方式不同。拆分成多个小服务，使用敏捷扩容，Docker实现自动化容器管理。SOA服务将多个服务打包在一起，部署在一个服务器上。&lt;/li&gt;
&lt;li&gt;服务粒度不同。微服务拆分粒度更细，职责单一。通过服务组合实现业务流程。SOA对粒度没有要求，通常是粗粒度的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3、微服务架构的核心要点和实现原理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.1 微服务架构中职能团队的划分&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;微服务架构按照业务的功能进行划分，每个单一的业务功能叫作一个服务，每个服务对应一个独立的职能团队，团队里包含用户交互UI设计师、后台服务开发人员、DBA、运营和运维人员。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.2 微服务的去中心化治理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;微服务架构倡导去中心化的服务管理和治理，尽量不设置中心化的管理服务，最差也需要在中心化的管理服务宕机时有替代方案和设计。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.3 微服务的交互模式&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;读者容错模式：微服务化中服务提供者和消费者之间如何对接口的改变进行容错。&lt;/li&gt;
&lt;li&gt;消费者驱动契约模式：用来定义服务化中服务之间交互接口改变的最佳规则。&lt;/li&gt;
&lt;li&gt;去数据共享模式：不要共享缓存和数据库等资源，也不要使用总线模式，服务之间的通信和交互只能依赖定义良好的接口，通常使用RESTful样式的API或者透明的RPC调用框架。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;共享数据集成的缺点&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微服务之间的交互除了接口契约，还存在数据存储契约。&lt;/li&gt;
&lt;li&gt;上游数据格式变化，可能导致下游的处理逻辑出问题。&lt;/li&gt;
&lt;li&gt;多个服务共享一个资源服务，资源服务的运维难以划清职责和界限。&lt;/li&gt;
&lt;li&gt;多机房部署，需要考虑到服务和资源的路由情况，跨机房调用，难以实现服务自治。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3.4 微服务的分解和组合模式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用微服务架构划分服务和团队是微服务架构实施的重要一步，良好的&lt;strong&gt;划分和拆分&lt;/strong&gt;使系统达到&lt;strong&gt;松耦合和高内聚&lt;/strong&gt;的效果，然后通过微服务的&lt;strong&gt;灵活组装&lt;/strong&gt;可以满足上层的各种各样的业务处理需求。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;组合微服务方式&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;**服务代理模式：**最简单的服务组合模式，它根据业务的需求选择调用后端的某个服务。在返回给使用端之前，代理可以对后端服务的输出进行加工，也可以直接把后端服务的返回结果返回给使用端。一般会对读请求切换设计一个开关，开关打开时查询新系统，开关关闭时查询老系统。典型的案例：平滑的系统迁移。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/65a0d9da608.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;**服务聚合模式：**最常用的服务组合模式，它根据业务流程处理的需要，以一定的顺序调用依赖的多个微服务，对依赖的微服务返回的数据进行组合、加工和转换，最后以一定的形式返回给使用方。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/df3fe9f7ab8.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;聚合服务可以是前端应用&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/89e1aaf84e2.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;也可以是纯后台服务&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;9&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/e246122bee7.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;服务串联模式：&lt;strong&gt;类似于一个工作流，服务直接的调用通常使用&lt;/strong&gt;同步&lt;/strong&gt;的RESTful风格的远程调用实现。优点是在非串联服务的正后面增加节点，串联服务无感知；缺点是不建议服务的层级太多。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;10&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/c6cf20dce1d.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;**服务分支模式：**是服务代理模式、服务聚合模式和服务串联模式相结合的产物。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;11&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/f11b24f2056.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;以电商平台的支付服务架构为例&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;12&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/7f5cee5e425.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;服务异步消息模式：&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;13&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/673b6086717.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;以电商平台交易完成后向物流系统发起消息通知为例&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;14&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/11ca8e43da7.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;**服务共享数据模式：**其实是反模式，用于单元化架构和遗留的整体服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;15&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/e0d4840629f.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;3.5 微服务的容错模式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;网络通信是不稳定、不可靠的，一个服务依赖的服务可能出错、超时或者宕机。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;**舱壁隔离模式：**微服务容器分组和线程池隔离&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;熔断模式&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;16&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/db297b3a205.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;**限流模式：**计数器，令牌桶，信号量&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;17&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/f877330ad12.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;**失效转移模式：**当发生了熔断和限流时，采用快速失败的策略，直接返回使用方错误；若有备份服务，迅速切换；有可能是某台机器出问题，采用重试方式。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3.6 微服务的粒度&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;微服务初衷是按照业务的功能进行拆分，直到服务功能和职责单一，甚至拆到不可再拆。原则是拆分到可以合理排版底层的自服务来获得相应的组合服务，同时考虑团队人员分配。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4、Java平台微服务架构的项目组织形式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.1 微服务项目的依赖关系&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一方库：本服务在JVM进程内依赖的Jar包。&lt;/li&gt;
&lt;li&gt;二方库：在服务外通过网络通信或者RPC调用的服务的Jar包。&lt;/li&gt;
&lt;li&gt;三方库：所依赖的其他公司或者组织提供的服务或者模块。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;18&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/64859d365b8.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;4.2 微服务项目的层级结构&lt;/strong&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;19&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/bf372170759.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;4.3 微服务项目的持续发布&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;微服务项目需要实现自动化的持续部署和持续集成的功能，包括：代码管理、自动编译、发布QA、自动化测试、性能测试、准生产部署和测试、生产环境发布等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5、服务化管理和治理框架的技术选型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.1 RPC&lt;/strong&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;20&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/ea2ea1c2c03.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;21&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/7bc2d0de1a8.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;5.2 服务化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;SOA服务化时代的服务化框架和平台&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;22&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/733b7f279fd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;23&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/d4d5abd210f.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;24&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/252a36d635f.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;25&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/c6f77fdf537.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;5.3 微服务&lt;/strong&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;26&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/6c9b0a78438.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;27&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/518d7a5273b.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;28&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/07ea01edc67.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;29&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/27e05e02e6e.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;30&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/97d1a90654e.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;31&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/b63c329eebd.jpeg&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
">分布式微服务架构设计原理</a>
      </div>
      
      <div class="item">
        <a class="result-title" style="opacity: 0;" href="https://jboone1989.github.io/post/zookeeper/"" data-c="
          &lt;p&gt;Zookeeper是一个&lt;strong&gt;分布式协调服务&lt;/strong&gt;，可用于服务发现，分布式锁，分布式领导选举，配置管理等。Zookeeper提供了一个类似于Linux文件系统的树形结构（可认为是轻量级的内存文件系统，但只适合存少量信息，完全不适合存储大量文件或者大文件），同时提供了对于每个节点的监控与通知机制。&lt;/p&gt;
&lt;h2 id=&#34;zookeeper中的一些概念&#34;&gt;zookeeper中的一些概念&lt;/h2&gt;
&lt;h3 id=&#34;1-顺序一致性&#34;&gt;&lt;strong&gt;1、顺序一致性&lt;/strong&gt;&lt;/h3&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;1&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/20180608091516108.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;zookeeper采用了&lt;strong&gt;递增的事务Id&lt;/strong&gt;来标识，所有的proposal（提议）都在被提出的时候加上了&lt;code&gt;zxid&lt;/code&gt;，&lt;code&gt;zxid&lt;/code&gt;实际上是一个64位的数字，高32位是&lt;strong&gt;epoch&lt;/strong&gt;用来标识leader是否发生改变，如果有新的leader产生出来，epoch会自增，&lt;strong&gt;低 32 位是counter消息计数器&lt;/strong&gt;，用来递增计数。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;epoch&lt;/strong&gt;：可以理解为当前集群所处的年代或者周期，每个leader 就像皇帝，都有自己的年号，所以每次改朝换代，leader 变更之后，都会在前一个年代的基础上加 1。这样就算旧的 leader 崩溃恢复之后，也没有人听他的了，因为follower 只听从当前年代的 leader 的命令。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;**counter消息计数器:**每接收到一条事务消息这个值就+1&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当处理事务请求时，会先成一个事务ID（ZXID）如图，同一个Leader的统治下epoch是相同的，counter消息计数器随着事务的增加而递增，会按照请求顺序转发给Leader，并保存在一个FIFO队列中，这样就可以保证事务的顺序一致性。同时当这个Leader挂了，新选举出的Leader的epoch会+1，这样当这个节点在链接上来的时候，未处理的事务由于epoch过期了全部清除过期的事务&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;2&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/bv8xel.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;2-数据模型&#34;&gt;2、数据模型&lt;/h3&gt;
&lt;p&gt;zookeeper的数据模型和文件系统类似，每一个节点称为：znode.  是zookeeper中的最小数据单元。每一个znode上都可以保存数据和挂载子节点。 从而构成一个层次化的属性结构节点特性；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;持久化节点&lt;/strong&gt;：节点创建后会一直存在zookeeper服务器上，直到主动删除；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;持久化有序节点&lt;/strong&gt;：每个节点都会为它的一级子节点维护一个顺序；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;临时节点&lt;/strong&gt;： 临时节点的生命周期和客户端的会话保持一致。当客户端会话失效，该节点自动清理；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;临时有序节点&lt;/strong&gt;：在临时节点上多加一个顺序性特性；&lt;/p&gt;
&lt;h3 id=&#34;3-会话&#34;&gt;3、会话&lt;/h3&gt;
&lt;p&gt;会话中的请求按FIFO顺序执行。一旦客户端连接到服务器，将建立会话并向客户端分配会话ID 。客户端以特定的时间间 隔发送心跳以保持会话有效。如果&lt;code&gt;ZooKeeper&lt;/code&gt;集合在超过服务器开启时指定的期间（会话超时）都没有从客户端接收到心跳，则它会 判定客户端死机。&lt;/p&gt;
&lt;p&gt;会话超时通常以毫秒为单位。当会话由于任何原因结束时，在该会话期间创建的临时节点也会被删除。&lt;/p&gt;
&lt;h3 id=&#34;4-watcher&#34;&gt;4、Watcher&lt;/h3&gt;
&lt;p&gt;zookeeper提供了分布式数据发布/订阅,zookeeper允许客户端向服务器注册一个watcher监听。当服务器端的节点触发指定事件的 时候会触发watcher。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;一次性触发数据发生改变时，一个watcher event会被发送到client，但是client&lt;strong&gt;只会收到一次这样的信息&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;watcher event异步发送&lt;/p&gt;
&lt;p&gt;watcher的通知事件从server发送到client是&lt;strong&gt;异步&lt;/strong&gt;的，这就存在一个问题，不同的客户端和服务器之间通过socket进行通信，由于&lt;strong&gt;网络延迟或其他因素导致客户端在不同的时刻监听到事件&lt;/strong&gt;，由于Zookeeper本身提供了&lt;strong&gt;ordering guarantee，即客户端监听事件后，才会感知它所监视znode发生了变化&lt;/strong&gt;。所以我们使用Zookeeper不能期望能够监控到节点每次的变化。Zookeeper&lt;strong&gt;只能保证最终的一致性，而无法保证强一致性&lt;/strong&gt;。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;注册watcher &lt;strong&gt;&lt;code&gt;getData&lt;/code&gt;、exists、&lt;code&gt;getChildren&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;凡是事务类型的操作，都会触发watcher &lt;strong&gt;create、delete、&lt;code&gt;setData&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;事件的实现原理&#34;&gt;事件的实现原理&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/20180613085557311.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/20180613085628613.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;br&gt;
&lt;img src=&#34;zookeeper.assets/20180613085645577.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;5-acl&#34;&gt;5、ACL&lt;/h3&gt;
&lt;p&gt;zookeeper提供控制节点访问权限的功能，用于有效的保证zookeeper中数据的安全性。&lt;/p&gt;
&lt;p&gt;CREATE /READ/WRITE/DELETE/ADMIN&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;zookeeper的命令操作&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. create [-s] [-e] path data acl
-s 表示节点是否有序
-e 表示是否为临时节点
默认情况下，是持久化节点

2. get path [watch]:获得指定 path的信息

3.set path data [version]:修改节点 path对应的data

4.delete path [version]:删除节点
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;6-stat信息&#34;&gt;&lt;strong&gt;6、stat信息&lt;/strong&gt;&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;cversion = 0       子节点的版本号
aclVersion = 0     表示acl的版本号，修改节点权限
dataVersion = 1    表示的是当前节点数据的版本号

czxid    节点被创建时的事务ID
mzxid   节点最后一次被更新的事务ID
pzxid    当前节点下的子节点最后一次被修改时的事务ID

ctime = Sat Aug 05 20:48:26 CST 2017:创建时间
mtime = Sat Aug 05 20:48:50 CST 2017：修改时间

ephemeralOwner = 0x0   创建临时节点的时候，会有一个sessionId 。 该值存储的就是这个sessionid
dataLength = 3    数据值长度
numChildren = 0  子节点数
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;7-zookeeper-下-server工作状态&#34;&gt;7、Zookeeper 下 Server工作状态&lt;/h3&gt;
&lt;p&gt;LEADING：说明此节点已经是leader节点，处于领导者地位的状态，差不多就是一般集群中的master。但在zookeeper中，只有leader才有写权限，其他节点（FOLLOWING）是没有写权限的，可以读&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;LOOKING&lt;/strong&gt;：选举中，正在寻找leader，即将进入leader选举流程中&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;FOLLOWING&lt;/strong&gt;：跟随者，表示当前集群中的leader已经选举出来了，主要具备以下几个功能点&lt;/p&gt;
&lt;p&gt;​            向leader发送请求（PING消息、REQUEST消息、ACK消息、REVALIDATE消息）&lt;/p&gt;
&lt;p&gt;​            接收leader消息并进行处理；&lt;/p&gt;
&lt;p&gt;​            接收client发送过来的请求，如果为写请求，会发送给Leader进行投票处理，然后返回client结果。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;OBSERVING&lt;/strong&gt;：OBSERVING和FOLLOWING差不多，但不参加投票和选举，接受leader选举后的结果&lt;/p&gt;
&lt;p&gt;##Zookeeper的应用&lt;/p&gt;
&lt;h3 id=&#34;1-zk的命名服务&#34;&gt;1、&lt;code&gt;zk&lt;/code&gt;的命名服务&lt;/h3&gt;
&lt;p&gt;命名服务是指通过指定的名字来获取资源或者服务的地址，利用&lt;code&gt;zk&lt;/code&gt;创建一个全局的路径，即是唯一的路径，这个路径就可以作为一个 名字，指向集群中的集群，提供的服务的地址，或者一个远程的对象等等。&lt;/p&gt;
&lt;h3 id=&#34;2-zk的配置管理&#34;&gt;2、&lt;code&gt;zk&lt;/code&gt;的配置管理&lt;/h3&gt;
&lt;p&gt;程序分布式的部署在不同的机器上，将程序的配置信息放在&lt;code&gt;zk&lt;/code&gt;的znode下，当有配置发生改变时，也就是znode发生变化时，可以通 过改变&lt;code&gt;zk&lt;/code&gt;中某个目录节点的内容，利用watcher通知给各个客户端，从而更改配置。&lt;/p&gt;
&lt;h3 id=&#34;3-zookeeper集群管理&#34;&gt;3、Zookeeper集群管理&lt;/h3&gt;
&lt;p&gt;所谓集群管理无在乎两点：是否有机器退出和加入、选举master。&lt;/p&gt;
&lt;p&gt;对于第一点，所有机器约定在父目录下创建临时目录节点，然后监听父目录节点的子节点变化消息。一旦有机器挂掉，该机器与  zookeeper的连接断开，其所创建的临时目录节点被删除，所有其他机器都收到通知：某个兄弟目录被删除。 新机器加入也是类似，所有机器收到通知：&lt;/p&gt;
&lt;p&gt;对于第二点，我们稍微改变一下，所有机器创建 临时顺序编号目录节点，每次选取编号最小的机器作为master就好。&lt;/p&gt;
&lt;h3 id=&#34;4-队列管理&#34;&gt;4、队列管理&lt;/h3&gt;
&lt;p&gt;两种类型的队列：&lt;/p&gt;
&lt;p&gt;1、同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。&lt;/p&gt;
&lt;p&gt;在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。&lt;/p&gt;
&lt;p&gt;2、队列按照 FIFO 方式进行入队和出队操作。&lt;/p&gt;
&lt;p&gt;和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。在特定的目录下创建PERSISTENT_SEQUENTIA L节点，创建成功时Watcher通知等待的队列，队列删除序列号最小的节点用以消费。此场景下Zookeeper的znode用于消息存储， znode存储的数据就是消息队列中的消息内容，SEQUENTIAL序列号就是消息的编号，按序取出即可。由于创建的节点是持久化的， 所以不必担心队列消息的丢失问题。&lt;/p&gt;
&lt;h3 id=&#34;5-zookeeper分布式锁&#34;&gt;5、Zookeeper分布式锁&lt;/h3&gt;
&lt;p&gt;有了zookeeper的一致性文件系统，锁的问题变得容易。锁服务可以分为两类，一个是保持独占，另一个是控制时序。  对于第一类，我们将zookeeper上的一个znode看作是一把锁，通过&lt;code&gt;createznode&lt;/code&gt;的方式来实现。所有客户端都去创建  /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。用完删除掉自己创建的distribute_lock 节点就释放 出锁。&lt;/p&gt;
&lt;p&gt;对于第二类， /distribute_lock 已经预先存在，所有客户端在它下面创建临时顺序编号目录节点，和选master一样，编号最小 的获得锁，用完删除，依次方便。&lt;/p&gt;
&lt;h2 id=&#34;zookeeper集群&#34;&gt;Zookeeper集群&lt;/h2&gt;
&lt;h3 id=&#34;41处理读请求&#34;&gt;4.1处理读请求：&lt;/h3&gt;
&lt;p&gt;​    任意节点都可以去处理读请求不需要转发：&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;3&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/20180607214225328.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h3 id=&#34;42-写请求事务请求&#34;&gt;4.2、写请求（事务请求）&lt;/h3&gt;
&lt;p&gt;​    会转发给Leader(改进版2pc，过半同意即可)&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;4&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/20180607214358436.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;​    1.事务请求发送到follower服务器节点（若发送给Leader节点少了转发这一步）&lt;/p&gt;
&lt;p&gt;​    2.首先会把事务请求转发给leader， Leader 接收到消息请求后，将消息赋予一个&lt;code&gt;zxid&lt;/code&gt;，并保存在一个FIFO队列中，这样就可以保证事务的顺序一致性；&lt;/p&gt;
&lt;p&gt;​    3.leader 服务器把客户端的请求转化成一个事务 Proposal（提议），并把这个 Proposal 分发给集群中的所有 Follower 服务器，&lt;/p&gt;
&lt;p&gt;​    4.当 follower 接收到 proposal，先把 proposal 写到磁盘，写入成功以后再向 leader 回复一个 ack&lt;/p&gt;
&lt;p&gt;​    5.Leader 就会再次向所有的Follower 服务器发送 Commit 消息，要求各个 follower 节点对前面的一个 Proposal 进行提交，同时会在本地执行该消息;&lt;/p&gt;
&lt;p&gt;​    6.把最后的结果同步给Observer节点,&lt;/p&gt;
&lt;p&gt;​    7.把结果返回给客户端。&lt;/p&gt;
&lt;h3 id=&#34;43-集群角色&#34;&gt;4.3、集群角色&lt;/h3&gt;
&lt;h4 id=&#34;leader-角色&#34;&gt;Leader 角色&lt;/h4&gt;
&lt;p&gt;Leader 服务器是整个 zookeeper 集群的核心，主要的工作 任务有两项&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. 事物请求的唯一调度和处理者，保证集群事物处理的顺序性 

2. 集群内部各服务器的调度者
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;follower-角色&#34;&gt;Follower 角色&lt;/h4&gt;
&lt;p&gt;Follower 角色的主要职责是&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. 处理客户端非事务请求、转发事物请求给leader 服务器

2. 参与事物请求 Proposal 的投票（需要半数以上服务器 通过才能通知 leadercommit 数据; Leader 发起的提案，要求 Follower 投票）

3. 参与 Leader 选举的投票
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;observer-角色&#34;&gt;Observer 角色&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;Observer 是zookeeper3.3 开始引入的一个全新的服务器角色，从字面来理解，该角色充当了观察者的角色。观察 zookeeper 集群中的最新状态变化并将这些状态变化同步到 observer 服务器上。

Observer 的工作原理与 follower 角色基本一致，而它和 follower 角色唯一的不同在于 observer 不参与任何形式的投票，包括事物请求 Proposal的投票和leader选举的投票。

注意：observer 服务器只提供非事物请求服务，通常在于不影响集群事物处理能力的前提下提升集群非事物处理的能力
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;44-集群组成&#34;&gt;4.4、集群组成&lt;/h3&gt;
&lt;p&gt;通常 zookeeper 是由 2n+1 台 server 组成，每个 server 都知道彼此的存在。&lt;/p&gt;
&lt;p&gt;对于 2n+1 台 server，只要有 n+1 台（大多数）server 可用，整个系统保持可用。&lt;/p&gt;
&lt;p&gt;我们已经了解到，一个 zookeeper 集群如果要对外提供可用的服务，那么集群中必须要有过半的机器正常工作并且彼此之间能够正常通信，基于这个特性，如果向搭建一个能够允许 F 台机器 down 掉的集群，那么就要部署 2*F+1 台服务器构成的 zookeeper 集群。因此 3 台机器构成的 zookeeper 集群，能够在挂掉一台机器后依然正常工作。&lt;/p&gt;
&lt;p&gt;​    一个 5 台机器集群的服务，能够对 2 台机器怪调的情况下进行容灾。如果一台由 6 台服务构成的集群，同样只能挂掉 2 台机器。因此， 5 台和 6 台在容灾能力上并没有明显优势，反而增加了网络通信负担。系统启动时，集群中的 server 会选举出一台 server 为 Leader，其它的就作为 follower（这里先不考虑 observer 角色）。之所以要满足这样一个等式，是因为一个节点要成为集群中的 leader，需要有超过及群众过半数的节点支持，这个涉及到 leader 选举算法。同时也涉及到事务请求的提交投票&lt;/p&gt;
&lt;h2 id=&#34;zab协议原子消息广播协议&#34;&gt;ZAB协议（原子消息广播协议）&lt;/h2&gt;
&lt;p&gt;ZAB协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，&lt;/p&gt;
&lt;h3 id=&#34;zab-协议的核心定义&#34;&gt;ZAB 协议的核心定义&lt;/h3&gt;
&lt;p&gt;当整个集群在启动时，或者当 leader 节点出现网络中断、崩溃等情况时，ZAB 协议就会进入恢复模式并选举产生新的 Leader，当 leader 服务器选举出来后，并且集群中有过半的机器和该 leader 节点完成数据同步后（同步指的是数据同步，用来保证集群中过半的机器能够和 leader 服务器的数据状态保持一致），ZAB 协议就会退出恢复模式。当集群中已经有过半的 Follower 节点完成了和 Leader 状态同步以后，那么整个集群就进入了消息广播模式。这个时候，在 Leader 节点正常工作时，启动一台新的服务器加入到集群，那这个服务器会直接进入数据恢复模式，和 leader 节点进行数据同步。同步完成后即可正常对外提供非事务请求的处理。&lt;/p&gt;
&lt;h3 id=&#34;zab协议4阶段&#34;&gt;ZAB协议4阶段&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Leader election（选举阶段）：节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。只有到达 广播阶段（broadcast） 准 leader 才会成为真正的 leader。这一阶段的目的是就是为了选出一个准 leader，然后进入下一个阶段。&lt;/li&gt;
&lt;li&gt;Discovery（发现阶段）：在这个阶段，followers 跟准 leader 进行通信，同步 followers 最近接收的事务提议。这个一阶段的主要目的是发现当前大多数节点接收的最新提议，并且准 leader 生成新的 epoch，让 followers 接受，更新它们的 accepted Epoch&lt;br&gt;
一个 follower 只会连接一个 leader，如果有一个节点 f 认为另一个 follower p 是 leader，f 在尝试连接 p 时会被拒绝，f 被拒绝之后，就会进入重新选举阶段。&lt;/li&gt;
&lt;li&gt;Synchronization（同步阶段）：同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。只有当 大多数节点都同步完成，准 leader 才会成为真正的 leader。follower 只会接收 &lt;code&gt;zxid&lt;/code&gt; 比自己的 &lt;code&gt;lastZxid&lt;/code&gt; 大的提议。&lt;/li&gt;
&lt;li&gt;Broadcast（广播阶段）：到了这个阶段，Zookeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。&lt;br&gt;
ZAB 提交事务并不像 2PC 一样需要全部 follower 都 ACK，只需要得到超过半数的节点的 ACK 就可以了。&lt;br&gt;
ZAB协议JAVA实现（FLE-发现阶段和同步合并为 Recovery Phase（恢复阶段））&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;zab协议两种模式&#34;&gt;ZAB协议两种模式&lt;/h3&gt;
&lt;p&gt;由定义可知ZAB协议主要有两种模式&lt;/p&gt;
&lt;p&gt;​        1.消息广播模式&lt;/p&gt;
&lt;p&gt;​        2.数据恢复模式&lt;/p&gt;
&lt;h4 id=&#34;消息广播的实现原理&#34;&gt;消息广播的实现原理&lt;/h4&gt;
&lt;p&gt;消息广播存在事务处理过程中（改良版本的2pc）：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1. Leader 接收到消息请求后，将消息赋予一个全局唯一的64 位自增 id，叫：zxid，通过 zxid 的大小比较既可以实现因果有序这个特征；
2. Leader 为每个 follower 准备了一个 FIFO 队列（通过 TCP协议来实现，以实现了全局有序这一个特点）将带有 zxid的消息作为一个提案（proposal）分发给所有的 follower；
3. 当 follower 接收到 proposal，先把 proposal 写到磁盘，写入成功以后再向 leader 回复一个 ack
4. 当 leader 接收到合法数量（超过半数节点）的 ACK 后，leader 就会向这些 follower 发送 commit 命令，同时会在本地执行该消息
5. 当 follower 收到消息的 commit 命令以后，会提交该消息
&lt;/code&gt;&lt;/pre&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;5&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/20180607220648571.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;h4 id=&#34;崩溃恢复数据恢复&#34;&gt;崩溃恢复(数据恢复)&lt;/h4&gt;
&lt;p&gt;ZAB 协议的这个基于原子广播协议的消息广播过程，在正 常情况下是没有任何问题的，但是一旦 Leader 节点崩溃，或者新机器加入，或者由于网络问题导致 Leader 服务器失去了过半的 Follower 节点的联系（leader 失去与过半 follower 节点联系，可能是 leader 节点和 follower 节点之间产生了网络分区，那么此时的 leader 不再是合法的 leader 了），那么就 会进入到崩溃恢复模式。&lt;/p&gt;
&lt;h5 id=&#34;已经被处理的消息不能丢失&#34;&gt;已经被处理的消息不能丢失&lt;/h5&gt;
&lt;p&gt;当 leader 收到合法数量 follower 的 ACKs 后，就向各个 follower 广播 COMMIT 命令，同时也会在本地执行 COMMIT 并向连接的客户端返回「成功」。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果在各个 follower 在收到 COMMIT 命令前Leader 就挂了，导致剩下的服务器并没有执行都这条消息。&lt;/strong&gt;&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;6&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/20180607220958652.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;Leader 对事务消息发起 commit 操作，该消息在follower1 上执行了，但是 follower2 还没有收到 commit，Leader就已经挂了，而实际上客户端已经收到该事务消息处理成功的回执了。所以在 zab 协议下需要保证所有机器都要执行这个事务消息&lt;/p&gt;
&lt;h5 id=&#34;被丢弃的消息不能再次出现&#34;&gt;被丢弃的消息不能再次出现&lt;/h5&gt;
&lt;p&gt;当 leader 接收到消息请求生成 proposal 后就挂了，其他 follower 并没有收到此 proposal，因此经过恢复模式重新选了 leader 后，这条消息是被跳过的。此时，之前 挂了的 leader 重新启动并注册成了follower，他保留了被跳过消息的 proposal 状态，与整个系统的状态是不一致的，需要将其删除。&lt;/p&gt;
&lt;p&gt;如图：在集群正常运行过程中的某一个时刻,Leader节点先后广播P1,P2,C1,C2；其中当Leader服务器将消息P2提交后，就立即崩溃推出。这种情况下当崩溃的服务器再起链接的时候C1和C2事务将会被抛弃删除。&lt;/p&gt;
&lt;h2 id=&#34;zookeeper节点宕机如何处理&#34;&gt;Zookeeper节点宕机如何处理？&lt;/h2&gt;
&lt;p&gt;Zookeeper本身也是集群，推荐配置不少于3个服务器。Zookeeper自身也要保证当一个节点宕机时，其他节点会继续提供服务。&lt;/p&gt;
&lt;p&gt;如果是一个Follower宕机，还有2台服务器提供访问，因为Zookeeper上的数据是有多个副本的，数据并不会丢失；&lt;/p&gt;
&lt;p&gt;如果是一个Leader宕机，Zookeeper会选举出新的Leader。&lt;/p&gt;
&lt;p&gt;ZK集群的机制是只要超过半数的节点正常，集群就能正常提供服务。只有在ZK节点挂得太多，只剩一半或不到一半节点能工作，集群才失效。&lt;/p&gt;
&lt;p&gt;所以&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;3个节点的cluster可以挂掉1个节点(leader可以得到2票&amp;gt;1.5)&lt;/li&gt;
&lt;li&gt;2个节点的cluster就不能挂掉任何1个节点了(leader可以得到1票&amp;lt;=1)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;zookeeper选取主leader&#34;&gt;&lt;strong&gt;Zookeeper选取主leader&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Zab&lt;/code&gt;就进入了恢复模式，恢复模式需要重新选举出一个新的leader，让所有的Server都恢复到一个正确的状态。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;7&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/20190419232751273.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;假如有以下5台机器server1、server2、server3、server4、server5，每个server 自身都有一票，在初始化或者server崩溃数过半的时候，每个server都有一个自身的&lt;code&gt;myid&lt;/code&gt;(zookeeper配置文件)，这里按1、2、3、4、5算，在选举过程中主要是依据&lt;code&gt;zxid&lt;/code&gt;和&lt;code&gt;myid&lt;/code&gt;来进行轮训server然后比较统计投票。&lt;code&gt;zxid&lt;/code&gt;(ZooKeeper Transaction Id，每次请求对应一个唯一的&lt;code&gt;zxid&lt;/code&gt;，如果&lt;code&gt;zxid&lt;/code&gt;a &amp;lt; &lt;code&gt;zxid&lt;/code&gt;b ，则可以保证a一定发生在b之前)。&lt;/p&gt;
&lt;p&gt;选举分为两种情况，初始化和leader挂掉的时候，要进行leader选举，至少需要2台机器，集群机器台数基本是奇数。&lt;/p&gt;
&lt;h5 id=&#34;初始化&#34;&gt;初始化&lt;/h5&gt;
&lt;p&gt;当启动初始化集群的时候，server1的&lt;code&gt;myid&lt;/code&gt;为1，&lt;code&gt;zxid&lt;/code&gt;为0   server2的&lt;code&gt;myid&lt;/code&gt;为2，&lt;code&gt;zxid&lt;/code&gt;同样是0，以此类推。此种情况下&lt;code&gt;zxid&lt;/code&gt;都是为0。&lt;strong&gt;先比较&lt;code&gt;zxid&lt;/code&gt;，再比较&lt;code&gt;myid&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务器1启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器1的状态一直属于Looking(选举状态)。&lt;/li&gt;
&lt;li&gt;服务器2启动，给自己投票，同时与之前启动的服务器1交换结果，由于服务器2的&lt;code&gt;myid&lt;/code&gt;大所以服务器2胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。&lt;/li&gt;
&lt;li&gt;服务器3启动，给自己投票，同时与之前启动的服务器1,2交换信息，由于服务器3的&lt;code&gt;myid&lt;/code&gt;最大所以服务器3胜出，此时投票数正好大于半数，所以服务器3成为领导者，服务器1,2成为小弟。&lt;/li&gt;
&lt;li&gt;服务器4启动，给自己投票，同时与之前启动的服务器1,2,3交换信息，尽管服务器4的&lt;code&gt;myid&lt;/code&gt;大，但之前服务器3已经胜出，所以服务器4只能成为小弟。&lt;/li&gt;
&lt;li&gt;服务器5启动，后面的逻辑同服务器4成为小弟&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当选举机器过半的时候，已经选举出leader后，后面的就跟随已经选出的leader，所以4和5跟随成为leader的server3。所以，在初始化的时候，一般到过半的机器数的时候谁的&lt;code&gt;myid&lt;/code&gt;最大一般就是leader&lt;/p&gt;
&lt;h5 id=&#34;运行期间&#34;&gt;运行期间&lt;/h5&gt;
&lt;p&gt;按照上述初始化的情况，server3成为了leader，在运行期间处于leader的server3挂了，那么非Observer服务器server1、server2、server4、server5会将自己的节点状态变为LOOKING状态&lt;/p&gt;
&lt;p&gt;1、开始进行leader选举。现在选举同样是根据&lt;code&gt;myid&lt;/code&gt;和&lt;code&gt;zxid&lt;/code&gt;来进行&lt;/p&gt;
&lt;p&gt;2、首先每个server都会给自己投一票竞选leader。假设server1的&lt;code&gt;zxid&lt;/code&gt;为123，server2的&lt;code&gt;zxid&lt;/code&gt;为124，server4的&lt;code&gt;zxid&lt;/code&gt;为169，server5的&lt;code&gt;zxid&lt;/code&gt;为188&lt;/p&gt;
&lt;p&gt;3、同样先是比较&lt;code&gt;zxid&lt;/code&gt;再比较，server1、server2、server4依次比较，server4根据优先条件选举为leader。然后server5还是跟随server4，即使server5的&lt;code&gt;zxid&lt;/code&gt;最大，但是当选举到server4的时候，机器数已经过半。不再进行选举，跟随已经选举的leader&lt;/p&gt;
&lt;p&gt;在leader选举的时候会有30s-120s的过程，在这期间也是无法提供服务的。如果用zookeeper要作为服务发现是个弊端，基本无法忍受，zookeeper本身是一个CP系统，保证数据的一致性，在恢复的时候再提供服务，并没有多好高可用的方案。如果leader发生故障选举时无法提供服务发现对一个大型应用来说可能是致命的。&lt;/p&gt;
&lt;h3 id=&#34;zookeeper同步流程&#34;&gt;Zookeeper同步流程&lt;/h3&gt;
&lt;p&gt;当领导者被选举出来，&lt;code&gt;zk&lt;/code&gt;就进入状态同步过程。&lt;/p&gt;
&lt;p&gt;1、Leader等待Follower连接；&lt;/p&gt;
&lt;p&gt;2、Follower连接leader，将最大的&lt;code&gt;zxid&lt;/code&gt;发送给leader；&lt;/p&gt;
&lt;p&gt;3、Leader根据follower的&lt;code&gt;zxid&lt;/code&gt;确定同步点；&lt;/p&gt;
&lt;p&gt;4、完成同步后通知follower 已经成为&lt;code&gt;uptodate&lt;/code&gt;状态；&lt;/p&gt;
&lt;p&gt;5、Follower收到&lt;code&gt;uptodate&lt;/code&gt;消息后，又可以重新接受client的请求进行服务了。&lt;/p&gt;
&lt;figure data-type=&#34;image&#34; tabindex=&#34;8&#34;&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/jboone1989/pictures@master/img/bv8xag.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34;&gt;&lt;/figure&gt;
&lt;p&gt;leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态。&lt;/p&gt;
&lt;h2 id=&#34;zoocfg配置文件分析&#34;&gt;&lt;strong&gt;&lt;code&gt;zoo.cfg&lt;/code&gt;配置文件分析&lt;/strong&gt;&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;tickTime=2000  zookeeper中最小的时间单位长度 （ms）
initLimit=10  follower节点启动后与leader节点完成数据同步的时间
syncLimit=5 leader节点和follower节点进行心跳检测的最大延时时间
dataDir=/tmp/zookeeper  表示zookeeper服务器存储快照文件的目录
dataLogDir 表示配置 zookeeper事务日志的存储路径，默认指定在dataDir目录下
clientPort =2181：clientPort这个端口就是客户端（应用程序）连接Zookeeper服务器的端口,Zookeeper会监听这个端口接受客户端的访问请求。
    server.A=B：C：D
    server.1=zk_node1:2881:3881
    server.2=zk_node2:2881:3881
    server.3=zk_node3:2881:3881
    A是一个数字,表示这个是第几号服务器；
    B是这个服务器的IP地址（或者是与IP地址做了映射的主机名）；
    C第一个端口用来集群成员的信息交换,表示这个服务器与集群中的Leader服务器交换信息的端口；
    D是在leader挂掉时专门用来进行选举leader所用的端口。
    注意：如果是伪集群的配置方式，不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号。
&lt;/code&gt;&lt;/pre&gt;
">Zookeeper笔记</a>
      </div>
      
    </div>
    <div class="page">
      <div id="page_ul"></div>
    </div>
  </div>
</div>
<script>
  !function () {
    let searchMask = document.querySelector('#search_mask');
    let result = document.querySelector('#result');
    let items = document.querySelectorAll('.item');
    let searchBox = document.querySelector('#search');
    let statCount = document.querySelector('#stat_count');
    let statTimes = document.querySelector('#stat_times');
    let pageUl = document.querySelector('#page_ul');
    let close = document.querySelector('#close');
    
    close.addEventListener('click', function() {
      searchMask.style = 'display: none;'
    })

    let finds = [];
    let contents = [];
    let pageSize = 10;
    items.forEach(item => {
      let a = item.querySelector('a');
      contents.push({
        title: a.innerText,
        details: a.dataset.c,
        link: a.href
      })
      item.remove();
    })

    function insertStr(soure, start, count) {
      let newStr = soure.substr(start, count);
      return soure.slice(0, start) + '<em>' + newStr + '</em>' + soure.slice(start + count);
    }

    pageUl.addEventListener('click', function(event) {
      let target = event.target;
      if (target.__proto__ === HTMLSpanElement.prototype) {
        appendResults(parseInt(target.dataset.i));
      }
    })

    function appendResults(index) {
      let htmlResult = '';
      let start = index || 0;
      let end = Math.min(start + pageSize, finds.length);
      for (let i = start; i < end; i++) {
        const current = finds[i];
        let html = current.title;
        let sum = 0;
        let positions = current.positions;
        positions.forEach(position => {
          html = insertStr(html, position.start + sum, position.count);
          sum += 9;
        })
        htmlResult += `<div class="item"><a class="result-title" href="${current.link}">${html}</a></div>`;
      }
      result.innerHTML = htmlResult;
      pageUl.innerHTML = '';
      let count = finds.length / pageSize;
      let lis = '';
      if (start !== 0) {
        lis += `<span class="fa fa-angle-left" data-i='${start - 1}'></span>`;
      }
      for (let i = 0; i < count; i++) {
        lis += `<span class='${i === start?'current':''}' data-i='${i}'>${i+1}</span>`;     
      }
      if (start+1 < count) {
        lis += `<span class="fa fa-angle-right" data-i='${start+1}'></span>`;  
      }
      pageUl.innerHTML = lis;
    }

    function search(delay) {
      let timer = null
      return function () {
        clearTimeout(timer)
        timer = setTimeout(() => {
          let start = Date.now();
          let segments = searchBox.value.split(' ').filter(c => c != '');
          if (segments.length <= 0) {
            return;
          }
          finds = [];
          let htmlResult = '';
          contents.forEach(content => {
            let title = content.title;
            let positions = [];
            let find = false;
            segments.forEach((segment) => {
              if (content.title.includes(segment)) {
                find = true;
                positions.push({
                  start: content.title.indexOf(segment),
                  count: segment.length
                })
              } else if (content.details.includes(segment)) {
                find = true;
              }
            });
            if (find) {
              finds.push({
                title: content.title,
                link: content.link,
                positions
              });
            }
          })
          appendResults(0);
          statCount.textContent = finds.length;
          statTimes.textContent = Date.now() - start;
        }, delay)
      }
    }
    searchBox.addEventListener('input', search(200));
  }()
</script>

<input hidden id="copy" />
<script>
  !function () {
    let times = document.querySelectorAll('.publish-time');
    for (let i = 0; i < times.length; i++) {
      let date = times[i].dataset.t;
      let time = Math.floor((new Date().getTime() - new Date(date).getTime()) / 1000);
      if (time < 60) {
        str = time + '秒之前';
      } else if (time < 3600) {
        str = Math.floor(time / 60) + '分钟之前';
      } else if (time >= 3600 && time < 86400) {
        str = Math.floor(time / 3600) + '小时之前';
      } else if (time >= 86400 && time < 259200) {
        str = Math.floor(time / 86400) + '天之前';
      } else {
        str = times[i].textContent;
      }
      times[i].textContent = str;
    }
  }();
</script>

<script>
  let language = '';
  if (language !== '') {
    let map = new Map();
    if (language === 'en') {
      map.set('search', 'Search');
      map.set('category', 'Categories');
      map.set('article', 'Articles');
      map.set('tag', 'Tags');
      map.set('top', 'Top');
      map.set('publish', 'published');
      map.set('minute', ' minutes');
      map.set('read-more', 'Read More');
      map.set('view', 'View');
      map.set('words', ' words');
      map.set('category-in', 'category in');
      map.set('preview', 'Meta');
      map.set('index', 'Toc');
      map.set('no-archives', "You haven't created yet");
      map.set('archives', " articles in total");
      map.set('cloud-tags', " tags in total");
      map.set('copyright', "Copyright: ");
      map.set('author', "Author: ");
      map.set('link', "Link: ");
      map.set('leave-message', "Leave a message");
      map.set('format', "Links Format");
      map.set('site-name', "Name: ");
      map.set('site-link', "Link: ");
      map.set('site-desc', "Desc: ");
      map.set('stat', " related results, taking ");
      map.set('stat-time', " ms");
      map.set('site-img', "Image: ");
    }

    if (map.size > 0) {
      let lanElems = document.querySelectorAll('.language');
      lanElems.forEach(elem => {
        let lan = elem.dataset.lan, text = map.get(lan);
        if (elem.__proto__ === HTMLInputElement.prototype) {
          elem.placeholder = text
        } else {
          if (elem.dataset.count) {
            text = elem.dataset.count + text;
          }
          elem.textContent = text;
        }
      })
    }
  }
  //拿来主义(真香)^_^，Clipboard 实现摘自掘金 https://juejin.im/post/5aefeb6e6fb9a07aa43c20af
  window.Clipboard = (function (window, document, navigator) {
    var textArea,
      copy;

    // 判断是不是ios端
    function isOS() {
      return navigator.userAgent.match(/ipad|iphone/i);
    }
    //创建文本元素
    function createTextArea(text) {
      textArea = document.createElement('textArea');
      textArea.value = text;
      textArea.style.width = 0;
      textArea.style.height = 0;
      textArea.clientHeight = 0;
      textArea.clientWidth = 0;
      document.body.appendChild(textArea);
    }
    //选择内容
    function selectText() {
      var range,
        selection;

      if (isOS()) {
        range = document.createRange();
        range.selectNodeContents(textArea);
        selection = window.getSelection();
        selection.removeAllRanges();
        selection.addRange(range);
        textArea.setSelectionRange(0, 999999);
      } else {
        textArea.select();
      }
    }

    //复制到剪贴板
    function copyToClipboard() {
      try {
        document.execCommand("Copy")
      } catch (err) {
        alert("复制错误！请手动复制！")
      }
      document.body.removeChild(textArea);
    }

    copy = function (text) {
      createTextArea(text);
      selectText();
      copyToClipboard();
    };

    return {
      copy: copy
    };
  })(window, document, navigator);

  function copyCode(e) {
    if (e.srcElement.tagName === 'SPAN' && e.srcElement.classList.contains('copy-code')) {
      let code = e.currentTarget.querySelector('code');
      var text = code.innerText;
      if (e.srcElement.textContent === '复制成功') {
        return;
      }
      e.srcElement.textContent = '复制成功';
      (function (elem) {
        setTimeout(() => {
          if (elem.textContent === '复制成功') {
            elem.textContent = '复制代码'
          }
        }, 1000);
      })(e.srcElement)
      Clipboard.copy(text);
    }
  }

  let pres = document.querySelectorAll('pre');
  pres.forEach(pre => {
    let code = pre.querySelector('code');
    let copyElem = document.createElement('span');
    copyElem.classList.add('copy-code');
    copyElem.textContent = '复制代码';
    pre.appendChild(copyElem);
    pre.onclick = copyCode
  })

</script>
<script src="/media/js/motion.js"></script>

<script src="https://cdn.jsdelivr.net/gh/cferdinandi/smooth-scroll/dist/smooth-scroll.polyfills.min.js"></script>
<script>
  var scroll = new SmoothScroll('a[href*="#"]', {
    speed: 200
  });
</script>





</html>